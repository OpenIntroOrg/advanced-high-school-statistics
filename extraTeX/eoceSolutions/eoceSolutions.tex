\chapter{Exercise solutions}
\label{eoceSolutions}





%_______________
\eocesolch{Data collection}



%_______________
\begin{multicols}{2}

% 1 - migraine_and_acupuncture_intro

\eocesol{(a)~Treatment: $10/43 = 0.23 \rightarrow 23\%$. 
(b)~Control: $2/46 = 0.04 \rightarrow 4\%$. 
(c)~A higher percentage of patients in the treatment group were pain 
free 24 hours after receiving acupuncture. 
(c)~It is possible that the observed difference between the two group 
percentages is due to chance.}

% 3 - study_components_airpoll

\eocesol{(a)~``Is there an association between air pollution exposure and preterm births?"
(b)~143,196 births in Southern California between 1989 and 1993.
(c)~Measurements of carbon monoxide, nitrogen dioxide, ozone, and particulate 
matter less than 10$\mu g/m^3$ (PM$_{10}$) collected at air-quality-monitoring 
stations as well as length of gestation. Continous numerical variables. }

% 5 - study_components_cheaters

\eocesol{(a)~``Does explicitly telling children not to cheat affect their likelihood to 
cheat?".
(b)~160 children between the ages of 5 and 15.
(c)~Four variables: (1) age (numerical, continuous), (2) sex (categorical), 
(3) whether they were an only child or not (categorical), (4) whether they 
cheated or not (categorical).}

% 7 - migraine_and_acupuncture_exp_resp

\eocesol{Explanatory: acupuncture or not.
Response: if the patient was pain free or not.}

% 9 - fisher_irises

\eocesol{(a)~$50 \times 3 = 150$. 
(b)~Four continuous numerical variables: sepal length, sepal width, petal length, and petal width. 
(c)~One categorical variable, species, with three levels: \emph{setosa}, \emph{versicolor}, and \emph{virginica}.}

% 11 - airports

\eocesol{(a)~Airport ownership status (public/private),
    airport usage status (public/private),
    latitude,
    and longitude.
(b)~Airport ownership status: categorical, not ordinal.
    Airport usage status: categorical, not ordinal.
    Latitude: numerical, continuous.
    Longitude: numerical, continuous.}

% 13 - scope_airpoll

\eocesol{(a)~Population: all births, sample: 143,196 births between 1989 and 1993 in 
Southern California. 
(b)~If births in this time span at the geography can be considered to be 
representative of all births, then the results are generalizable to the 
population of Southern California. However, since the study is observational 
the findings cannot be used to establish causal relationships.}

% 15 - scope_buteyko

\eocesol{(a)~Population: all asthma patients aged 18-69 who rely on medication for 
asthma treatment. Sample: 600 such patients.
(b)~If the patients in this sample, who are likely not randomly sampled, can 
be considered to be representative of all asthma patients aged 18-69 who rely 
on medication for asthma treatment, then the results are generalizable to the 
population defined above. Additionally, since the study is experimental, the 
findings can be used to establish causal relationships.}

% 17 - relax_after_work_definitions

\eocesol{(a)~Observation.
(b)~Variable.
(c)~Sample statistic (mean).
(d)~Population parameter (mean).}

% 19 - course_satisfaction_sections

\eocesol{(a)~Observational.
(b)~Use stratified sampling to randomly sample a fixed number of students, 
say 10, from each section for a total sample size of 40 students.}

% 21 - internet_life_expectancy

\eocesol{(a)~Positive, non-linear, somewhat strong. Countries in which a higher 
percentage of the population have access to the internet also tend to have 
higher average life expectancies, however rise in life expectancy trails 
off before around 80 years old.
(b)~Observational.
(c)~Wealth: countries with individuals who can widely afford the internet 
can probably also afford basic medical care. (Note: Answers may vary.)}

% 23 - evaluate_sampling_methods

\eocesol{(a)~Simple random sampling is okay. In~fact, it's rare for simple random 
sampling to not be a reasonable sampling method! 
(b)~The student opinions may vary by field of study, so the stratifying 
by this variable makes sense and would be reasonable. 
(c)~Students of similar ages are probably going to have more similar 
opinions, and we want clusters to be diverse with respect to the outcome 
of interest, so this would \textbf{not} be a good approach. (Additional 
thought: the clusters in this case may also have very different numbers 
of people, which can also create unexpected sample sizes.)}

% 25 - scope_haters

\eocesol{(a)~The cases are 200 randomly sampled men and women.
(b)~The response variable is attitude towards a fictional microwave oven.
(c)~The explanatory variable is dispositional attitude.
(d)~Yes, the cases are sampled randomly.
(e)~This is an observational study since there is no random assignment to 
treatments.
(f)~No, we cannot establish a causal link between the explanatory and response 
variables since the study is observational.
(g)~Yes, the results of the study can be generalized to the population at 
large since the sample is random.}

% 27 - sampling_strategies

\eocesol{(a)~Simple random sample. Non-response bias, if only those people who have 
strong opinions about the survey responds his sample may not be representative 
of the population.
(b)~Convenience sample. Under coverage bias, his sample may not be 
representative of the population since it consists only of his friends. It is 
also possible that the study will have non-response bias if some choose to not 
bring back the survey.
(c)~Convenience sample. This will have a similar issues to handing out surveys 
to friends.
(d)~Multi-stage sampling. If the classes are similar to each other with 
respect to student composition this approach should not introduce bias, 
other than potential non-response bias.}

% 29 - light_exam_performance

\eocesol{(a)~Exam performance.
(b)~Light level: fluorescent overhead lighting, yellow overhead lighting, no overhead 
lighting (only desk lamps).
(c)~Sex: man, woman.}

% 31 - light_noise_exam_performance

\eocesol{(a)~Exam performance.
(b)~Light level (overhead lighting, yellow overhead lighting, no overhead lighting) and 
noise level (no noise, construction noise, and human chatter noise).
(c)~Since the researchers want to ensure equal representation of graduate and undergraduate students, program type will be a blocking variable.}

% 33 - soda_preference

\eocesol{Need randomization and blinding. One possible outline: \\
(1)~Prepare two cups for each 
participant, one containing regular Coke and the other containing Diet Coke. Make sure 
the cups are identical and contain equal amounts of soda. Label the cups A (regular) and 
B (diet). (Be sure to randomize A and B for each trial!) \\
(2)~Give each participant the 
two cups, one cup at a time, in random order, and ask the participant to record a value 
that indicates how much she liked the beverage.  Be sure that neither the participant nor 
the person handing out the cups knows the identity of the beverage to make this a double-blind experiment. \\
(Answers may vary.)}

% 35 - seattle_pet_names

\eocesol{(a)~Observational study.
(b)~Dog: Lucy. Cat: Luna.
(c)~Oliver and Lily.
(d)~Positive, as the popularity of a name for dogs increases, so does the 
popularity of that name for cats. }

% 37 - chia_weight_loss

\eocesol{(a)~Experiment.
(b)~Treatment: 25 grams of chia seeds twice a day, control: placebo. 
(c)~Yes, gender.
(d)~Yes, single blind since the patients were blinded to the treatment 
they received.
(e)~Since this is an experiment, we can make a causal statement. However, since the 
sample is not random, the causal statement cannot be generalized to the population at 
large.}

% 39 - flawed_reasoning

\eocesol{(a)~Non-responders may have a different response to this question,
    e.g. parents who returned the surveys likely don't have difficulty
    spending time with their children.
(b)~It is unlikely that the women who were reached at the same
    address 3 years later are a random sample. These missing responders
    are probably renters (as opposed to homeowners) which means that
    they might have a lower socio-economic status than the respondents.
(c)~There is no control group in this study, this is an observational
    study, and there may be confounding variables, e.g. these people
    may go running because they are generally healthier and/or do
    other exercises.}

% 41 - eat_better_feel_better

\eocesol{(a)~Randomized controlled experiment.
(b)~Explanatory: treatment group (categorical, with 3 levels).
    Response variable: Psychological well-being.
(c)~No, because the participants were volunteers.
(d)~Yes, because it was an experiment.
(e)~The statement should say ``evidence'' instead of ``proof''.}

% 43 - stanford_open_policing

\eocesol{(a)~County, state, driver's race, whether the car was searched or not,
    and whether the driver was arrested or not.
(b)~All categorical, non-ordinal.
(c)~Response: whether the car was searched or not.
    Explanatory: race of the driver.}



%_______________
\end{multicols}



%_______________
\eocesolch{Summarizing data}



%_______________
\begin{multicols}{2}

% 1 - acs

\eocesol{(a) There is a weak and positive relationship between age and income. With so few points it is difficult to tell the form of the relationship (linear or not) however the relationship does look somewhat curved.
\includegraphics[width = 0.75\textwidth]{ch_summarizing_data/figures/eoce/acs/income_age}\\
(b) \\
\includegraphics[width = 0.75\textwidth]{ch_summarizing_data/figures/eoce/acs/income_age_male}\\
\includegraphics[width = 0.75\textwidth]{ch_summarizing_data/figures/eoce/acs/income_age_female}\\
(c) For males as age increases so does income, however this pattern is not apparent for females.}

% 3 - fiber_cereal

\eocesol{(a) \\
\texttt{~~0 $|$ 000003333333 \\
~~0 $|$ 7779 \\
~~1 $|$ 0011 \\
Legend: 1 | 0 = 10\%} \\
(b) \\
\includegraphics[width = 70mm]{ch_summarizing_data/figures/eoce/fiber_cereal/cereal_fiber_dot} \\
(c) \\
\includegraphics[width = 60mm]{ch_summarizing_data/figures/eoce/fiber_cereal/cereal_fiber_hist} \\
\includegraphics[width = 60mm]{ch_summarizing_data/figures/eoce/fiber_cereal/cereal_fiber_relhist} \\
(d) 40\% (Note: if using only rel. freq. histogram, you can only get an estimate because 7 is in the middle of the bin.  Use the dot plot to get a more accurate answer.)}

% 5 - mammal_life_spans

\eocesol{(a)~Positive association: mammals with longer gestation periods tend to live longer as 
well.
(b)~Association would still be positive.
(c)~No, they are not independent. See part~(a).}

% 7 - smoking

\eocesol{Both distributions are right skewed and bimodal with modes at 10 and 20 cigarettes; note that people may be rounding their answers to half a pack or a whole pack. The median of each distribution is between 10 and 15 cigarettes. The middle 50\% of the data (the IQR) appears to be spread equally in each group and have a width of about 10 to 15. There are potential outliers above 40 cigarettes per day. It appears that respondents who smoke only a few cigarettes (0 to 5) smoke more on the weekdays than on weekends.}

% 9 - UKSmoking_amounts_data

\eocesol{(a)~$\bar{x}_{amtWeekends} = 20$, $\bar{x}_{amtWeekdays} = 16$.
(b)~$s_{amtWeekends} = 0$, $s_{amtWeekdays} = 4.18$. In this very small sample, higher on weekdays.}

% 11 - days_off_mining

\eocesol{Any 10 employees whose average number of days off is between the minimum and the mean 
number of days off for the entire workforce at this plant.}

% 13 - means_sds

\eocesol{(a)~Dist~2 has a higher mean since $20 > 13$, and a higher standard deviation 
since 20 is further from the rest of the data than 13.
(b)~Dist~1 has a higher mean since $-20 > -40$, and Dist~2 has a 
higher standard deviation since -40 is farther away from the rest of the data than -20.
(c)~Dist~2 has a higher mean since all values in this distribution are higher 
than those in Dist~1, but both distribution have the same standard deviation 
since they are equally variable around their respective means.
(d)~Both distributions have the same mean since they're both centered at 300, but 
Dist~2 has a higher standard deviation since the observations are farther from 
the mean than in Dist~1.}

% 15 - air_quality_durham

\eocesol{(a)~About 30.
(b)~Since the distribution is right skewed the mean is higher than the median.
(c)~Q1: between 15 and 20, Q3: between 35 and 40, IQR: about 20.
(d)~Values that are considered to be unusually low or high lie more than 1.5$\times$IQR 
away from the quartiles. Upper fence: Q3 + 1.5 $\times$ IQR =  $37.5 + 1.5 \times 20 = 67.5$; 
Lower fence: Q1 - 1.5 $\times$ IQR =  $17.5 + 1.5 \times 20 =  -12.5$; The lowest AQI 
recorded is not lower than 5 and the highest AQI recorded is not higher than 65, which 
are both within the fences. Therefore none of the days in this sample would be considered 
to have an unusually low or high AQI.}

% 17 - hist_vs_box

\eocesol{The histogram shows that the distribution is bimodal, which is not apparent in the box 
plot. The box plot makes it easy to identify more precise values of observations outside 
of the whiskers.}

% 19 - dist_shape_pets_dist_height

\eocesol{(a)~The distribution of number of pets per household is likely right skewed as there is a natural boundary at 0 and only a few people have many pets. Therefore the center would be best described by the median, and variability would be best described by the IQR.
(b)~The distribution of number of distance to work is likely right skewed as there is a natural boundary at 0 and only a few people live a very long distance from work. Therefore the center would be best described by the median, and variability would be best described by the IQR.
(c)~The distribution of heights of males is likely symmetric. Therefore the center would be best described by the mean, and variability would be best described by the standard deviation.}

% 21 - income_coffee_shop

\eocesol{(a)~The median is a much better measure of the typical amount earned by these 42 
people. The mean is much higher than the income of 40 of the 42 people. This is 
because the mean is an arithmetic average and gets affected by the two extreme observations. The median does not get effected as much since it is robust to 
outliers.
(b)~The IQR  is a much better measure of variability in the amounts earned by nearly 
all of the 42 people. The standard deviation gets affected greatly by the two high 
salaries, but the IQR is robust to these extreme observations.}

% 23 - county_commute_times

\eocesol{(a)~The distribution is unimodal and symmetric with a mean of about 25 minutes 
and a standard deviation of about 5 minutes. There does not appear to be any 
counties with unusually high or low mean travel times. Since the distribution 
is already unimodal and symmetric, a log transformation is not necessary.
(b)~Answers will vary. There are pockets of longer travel time around DC, 
Southeastern NY, Chicago, Minneapolis, Los Angeles, and many other big cities. 
There is also a large section of shorter average commute times that overlap 
with farmland in the Midwest. Many farmers' homes are adjacent to their 
farmland, so their commute would be brief, which may explain why the 
average commute time for these counties is relatively low.}

% 25 - area_under_curve_1

\eocesol{(a)~8.85\%.
(b)~6.94\%.
(c)~58.86\%.
(d)~4.56\%. \\
\includegraphics[width=0.23\textwidth]{ch_summarizing_data/figures/eoce/area_under_curve_1/zltNeg}
\includegraphics[width=0.23\textwidth]{ch_summarizing_data/figures/eoce/area_under_curve_1/zgtPos}
\includegraphics[width=0.23\textwidth]{ch_summarizing_data/figures/eoce/area_under_curve_1/zBet}
\includegraphics[width=0.23\textwidth]{ch_summarizing_data/figures/eoce/area_under_curve_1/zgtAbs}}

% 27 - GRE_intro_ap

\eocesol{(a)~$Z_{VR} = 1.29$, $Z_{QR} = 0.52$. \\
\includegraphics[width=0.3\textwidth]{ch_summarizing_data/figures/eoce/GRE_intro_ap/GRE_intro.pdf} \\
(b)~She scored 1.29 standard deviations above the mean on the Verbal 
Reasoning section and 0.52 standard deviations above the mean on the 
Quantitative Reasoning section.
(c)~She did better on the Verbal Reasoning section since her Z-score on that 
section was higher.
(d)~$Perc_{VR} = 0.9007 \approx 90\%$, $Perc_{QR} = 0.6990 \approx 70\%$.
(e)~$100\% - 90\% = 10\%$ did better than her on VR, and $100\% - 70\% = 30\%$
 did better than her on QR.
(f)~We cannot compare the raw scores since they are on different scales. 
Comparing her percentile scores is more appropriate when comparing her 
performance to others.
(g)~Answer to part (b) would not change as Z-scores can be calculated for 
distributions that are not normal. However, we could not answer parts~(c)-(e) 
since we cannot use the normal probability table to calculate probabilities 
and percentiles without a normal model.}

% 29 - GRE_cutoffs

\eocesol{(a)~$Z = 0.84$, which corresponds to approximately 159 on QR.
(b)~$Z = -0.52$, which corresponds to approximately 147 on VR.}

% 31 - la_weather_intro

\eocesol{(a)~$Z = 1.2$, $P(Z > 1.2) = 0.1151$. \\
(b)~$Z= -1.28 \to 70.6\degree$F or colder.}

% 33 - la_weather_unit_change_ap

\eocesol{(a)~$Z = 1.08$, $P(Z > 1.08) = 0.1401$.
(b)~The answers are very close because only the units were changed. (The only 
reason why they differ at all because 28\degree C is 
82.4\degree F, not precisely 83\degree F.)
(c)~Since $IQR = Q3 - Q1$, we first need to find $Q3$ and $Q1$ and take the 
difference between the two. Remember that $Q3$ is the $75^{th}$ and $Q1$ is 
the $25^{th}$ percentile of a distribution. Q1 = 23.13, Q3 = 26.86, IQR = 26.
86 - 23.13 = 3.73.}

% 35 - stats_scores_empirical_rule

\eocesol{$14/20=70\%$ are within 1 SD. Within 2 SD: $19/20=95\%$. Within 3 SD: $20/20 = 100\%$. They follow this rule closely.}

% 37 - antibiotic_use_children

\eocesol{(a)~We see the order of the categories and the relative frequencies in the bar plot.
(b)~There are no features that are apparent in the pie chart but not in the bar plot.
(c)~We usually prefer to use a bar plot as we can also see the relative frequencies of the categories in this graph.}

% 39 - dream_act_mosaic

\eocesol{The vertical locations at which the ideological groups break into the Yes, No, 
and Not Sure categories differ, which indicates that likelihood of supporting 
the DREAM act varies by political ideology. This suggests that the two variables 
may be dependent.}

% 41 - randomization_avandia

\eocesol{(a)~(i) False. Instead of comparing counts, we should compare percentages of people in each group who suffered cardiovascular problems.
(ii)~True.
(iii)~False. Association does not imply causation. We cannot infer a causal 
relationship based on an observational study. The difference from part~(ii) 
is subtle.
(iv)~True. \\
(b)~Proportion of all patients who had cardiovascular problems: $\frac{7,979}{227,571} \approx 0.035$ \\
(c)~The expected number of heart attacks in the rosiglitazone group, if having 
cardiovascular problems and treatment were independent, can be calculated as the 
number of patients in that group multiplied by the overall cardiovascular problem 
rate in the study: $67,593 * \frac{7,979}{227,571} \approx 2370$. \\
(d)~(i)~$H_0$: The treatment and cardiovascular problems are independent. They have 
no relationship, and the difference in incidence rates between the rosiglitazone and 
pioglitazone groups is due to chance.
$H_A$: The treatment and cardiovascular problems are not independent. The difference 
in the incidence rates between the rosiglitazone and pioglitazone groups is not due 
to chance and rosiglitazone is associated with an increased risk of serious 
cardiovascular problems.
(ii)~A higher number of patients with cardiovascular problems than expected under 
the assumption of independence would provide support for the alternative hypothesis 
as this would suggest that rosiglitazone increases the risk of such problems.
(iii)~In the actual study, we observed 2,593 cardiovascular events in the 
rosiglitazone group. In the 1,000 simulations under the independence model, we 
observed somewhat less than 2,593 in every single simulation, which suggests that 
the actual results did not come from the independence model. That is, the variables 
do not appear to be independent, and we reject the independence model in favor of 
the alternative. The study's results provide convincing evidence that rosiglitazone 
is associated with an increased risk of cardiovascular problems.}

% 43 - makeup_exam

\eocesol{(a)~Decrease: the new score is smaller than the mean of the 24 previous scores.
(b)~Calculate a weighted mean. Use a weight of 24 for the old mean and 1 for the new 
mean: $(24\times 74 + 1\times64)/(24+1) = 73.6$.
%There are other ways to solve this 
%exercise that do not use a weighted mean.
(c)~The new score is more than 1 standard deviation away from the previous mean, so 
increase.}

% 45 - dist_shape_tv_watchers

\eocesol{No, we would expect this distribution to be right skewed. There are two reasons 
for this: (1)~there is a natural boundary at 0 (it is not possible to watch less 
than 0 hours of TV), (2)~the standard deviation of the distribution is very large 
compared to the mean.}

% 47 - oscar_winners

\eocesol{The distribution of ages of best actress winners are right skewed with a 
median around 30 years. The distribution of ages of best actress winners 
is also right skewed, though less so, with a median around 40 years. The 
difference between the peaks of these distributions suggest that best actress 
winners are typically younger than best actor winners. The ages of best actress 
winners are more variable than the ages of best actor winners. There are 
potential outliers on the higher end of both of the distributions. }

% 49 - stats_scores_box

\eocesol{\includegraphics[width = 40mm]{ch_summarizing_data/figures/eoce/stats_scores_box/stats_scores_boxplot.pdf}}

% 51 - birth_weight

\eocesol{(a)~ $Z=\frac{5.5-7.44}{1.33}=-1.49; P(Z < -1.49) = 0.068.$
Approximately 6.8\% of the newborns were of low birth weight.  
(b)~$Z=\frac{10-7.44}{1.33}=1.925$. Using a lower bound of 2 and an upper bound of 5, we get $P(Z > 1.925) = 0.027$. Approximately 2.7\% of the newborns weighed over 10 pounds.
(c)~Approximately 2.7\% of the newborns weighed over 10 pounds. Because there were 23,419 of them, about $0.027 \times 23419 \approx 632$ weighed greater than 10 pounds.
(d)~Because we have the percentile, this is the inverse problem. To get the Z-score, use the inverse normal option with 0.90 to get $Z = 1.28$. Then solve for $x$ in $1.28 = \frac{x - 7.44}{1.33}$ to get $x = 9.15$. To be at the 90th percentile among this group, a newborn would have to weigh 9.15 pounds.
}

% 53 - speeding_i5_intro

\eocesol{(a)~93.94\%.
(b)~93.53\%.
(c)~80.49~miles/hour.
(d)~70.54\%.}



%_______________
\end{multicols}



%_______________
\eocesolch{Probability}



%_______________
\begin{multicols}{2}

% 1 - tf_prob_definitions

\eocesol{(a)~False. These are independent trials.
(b)~False. There are red face cards.
(c)~True. A card cannot be both a face card and an ace.}

% 3 - four_games_one_winner

\eocesol{(a)~10 tosses. Fewer tosses mean more variability in the sample fraction of heads, 
meaning there's a better chance of getting at least 60\% heads.
(b)~100 tosses. More flips means the observed proportion of heads would often be 
closer to the average, 0.50, and therefore also above 0.40.
(c)~100 tosses. With more flips, the observed proportion of heads would often be 
closer to the average, 0.50.
(d)~10 tosses. Fewer flips would increase variability in the fraction of tosses 
that are heads.}

% 5 - coin_flips

\eocesol{(a)~$0.5^{10}$ = 0.00098.
(b)~$0.5^{10}$ = 0.00098.
(c)~$P$(at least one tails) = $1 - P$(no tails) = $1 - (0.5^{10}) \approx 1 - 0.001 = 0.999$.}

% 7 - swing_voters

\eocesol{(a)~No, there are voters who are both independent and swing voters. \\
(b)\\
\includegraphics[width=40mm]{ch_probability/figures/eoce/swing_voters/swing_voters.pdf} \\
(c)~Each Independent voter is either a swing voter or not. Since 35\% of voters 
are Independents and 11\% are both Independent and swing voters, the other 24\% 
must not be swing voters.
(d)~0.47.
(e)~0.53.
(f)~P(Independent) $\times$ P(swing) = $0.35\times0.23 = 0.08$, which 
does not equal P(Independent and swing) = 0.11, so the events are dependent.}

% 9 - disjoint_indep

\eocesol{(a)~If the class is not graded on a curve, they are independent. If graded on a 
curve, then neither independent nor disjoint -- unless the instructor will only give 
one A, which is a situation we will ignore in parts~(b) and~(c).
(b)~They are probably not independent: if you study together, your study habits 
would be related, which suggests your course performances are also related.
(c)~No. See the answer to part~(a) when the course is not graded on a curve. More 
generally: if two things are unrelated (independent), then one occurring does not 
preclude the other from occurring.}

% 11 - edu_attain_couples

\eocesol{(a)~$0.16 + 0.09 = 0.25$.
(b)~$0.17 + 0.09 = 0.26$.
(c)~Assuming that the education level of the husband and wife are independent: 
$0.25 \times 0.26 = 0.065$. You might also notice we actually made a second 
assumption: that the decision to get married is unrelated to education level.
(d)~The husband/wife independence assumption is probably not reasonable, because 
people often marry another person with a comparable level of education. We will 
leave it to you to think about whether the second assumption noted in part~(c) is 
reasonable.}

% 13 - joint_cond

\eocesol{(a)~No, but we could if A and B are independent.
(b-i)~0.21.
(b-ii)~0.79.
(b-iii)~0.3. 
(c)~No, because 0.1 $\ne$ 0.21, where 0.21 was the value computed under 
independence from part~(a).
(d)~0.143.}

% 15 - global_warming

\eocesol{(a)~No, 0.18 of respondents fall into this combination.
(b)~$0.60 + 0.20 - 0.18 = 0.62$.
(c)~$0.18 / 0.20 = 0.9$.
(d)~$0.11 / 0.33 \approx 0.33$.
(e)~No, otherwise the answers to (c) and (d) would be the same.
(f)~$0.06 / 0.34 \approx 0.18$.}

% 17 - marbles_in_urn

\eocesol{(a)~0.3.
(b)~0.3.
(c)~0.3.
(d)~$0.3\times0.3=0.09$.
(e)~Yes, the population that is being sampled from is identical in each draw.}

% 19 - chips_in_bag

\eocesol{(a)~$2 / 9 \approx 0.22$.
(b)~$3 / 9 \approx 0.33$.
(c)~$\frac{3}{10} \times \frac{2}{9} \approx 0.067$.
(d)~No, e.g. in this exercise, removing one chip meaningfully 
changes the probability of what might be drawn next.}

% 21 - student_outfits

\eocesol{$P(^1$leggings, $^2$jeans, $^3$jeans$) = \frac{5}{24} \times \frac{7}{23} \times \frac{6}{22} = 0.0173$. 
However, the person with leggings could have come 2nd or 3rd, and these each 
have this same probability, so $3 \times 0.0173 = 0.0519$.}

% 23 - tree_drawing_box_plots

\eocesol{(a) \\
\includegraphics[width=60mm]{ch_probability/figures/eoce/tree_drawing_box_plots/tree_drawing_box_plots}
(b)~0.84}

% 25 - tree_lupus

\eocesol{0.0714. Even when a patient tests positive for lupus, there is only a 7.14\% 
chance that he actually has lupus. House may be right. \\

\includegraphics[width=60mm]{ch_probability/figures/eoce/tree_lupus/tree_lupus.pdf}}

% 27 - smog_check_1

\eocesol{(a)~P(pass) = 0.5, but it should be 0.16.
(b)~P(pass) = 0.2, instead of 0.16.
(c)~P(pass) = 0.17, instead of 0.16.}

% 29 - smog_check_2

\eocesol{(a)~Starting at row 3 of the random number table, we will read across the table two digits at a time. If the random number is between 00-15, the car will fail the pollution test. If the number is between 16-99, the car will pass the test. (Answers may vary.)
(b)~Fleet 1: 18-52-97-32-85-95-29 $\rightarrow$ P-P-P-P-P-P-P $\rightarrow$ fleet passes \\
Fleet 2: 14-96-06-67-17-49-59 $\rightarrow$ F-P-F-P-P-P-P $\rightarrow$ fleet fails \\
Fleet 3: 05-33-67-97-58-11-81 $\rightarrow$ F-P-P-P-P-F-P $\rightarrow$ fleet fails \\
Fleet 4: 23-81-83-21-71-08-50 $\rightarrow$ P-P-P-P-P-F-P $\rightarrow$ fleet fails \\
Fleet 5: 82-84-39-31-83-14-34 $\rightarrow$ P-P-P-P-P-F-P $\rightarrow$ fleet fails 
(c)~4 / 5 = 0.80}

% 31 - college_smokers

\eocesol{(a)~13.
(b)~No, these 27 students are not a random sample from the university's student 
population. For example, it might be argued that the proportion of smokers among 
students who go to the gym at 9 am on a Saturday morning would be lower than the 
proportion of smokers in the university as a whole.}

% 33 - hearts

\eocesol{(a)~E(X) = 3.59. SD(X) = 9.64.
(b)~E(X) = -1.41. SD(X) = 9.64.
(c)~No, the expected net profit is negative, so on average you expect to lose money.}

% 35 - portfolio_return

\eocesol{5\% increase in value.}

% 37 - roulette_american

\eocesol{E = -0.0526. SD = 0.9986.}

% 39 - lemonade

\eocesol{(a)~Let X represent the amount of lemonade in the pitcher, Y represent the amount of lemonade in a glass, and W represent the amount left over after. Then, $\mu_{W} = E(X - Y) = 64 - 12 = 52$
(b)~$\sigma_{W} = \sqrt{SD(X)^2 + SD(Y)^2} = \sqrt{1.732^2 + 1^2} \approx \sqrt{4} = 2$
(c)~$P(W > 50) = P\left(Z > \frac{50 - 52}{2}\right) = P(Z > -1) = 1 - 0.1587 = 0.8413$}

% 41 - GRE_scores_3

\eocesol{(a)~The combined scores follow a normal distribution with $\mu_{combined} = 304$ and $\sigma_{combined} = 10.38$. Then, P(combined score $>$ 320) is approximately 0.06.
(b)~Z=1.28 (using calculator or table).  Then we set $1.28=\frac{x-304}{10.38}$ and find $x\approx 317$.}

% 43 - is_it_bernouilli

\eocesol{(a)~No. The cards are not independent. For example, if the first card is an 
ace of clubs, that implies the second card cannot be an ace of clubs. 
Additionally, there are many possible categories, which would need to be 
simplified.
(b)~No. There are six events under consideration. The Bernoulli distribution 
allows for only two events or categories. Note that rolling a die could be a 
Bernoulli trial if we simply to two events, e.g. rolling a 6 and not rolling 
a 6, though specifying such details would be necessary.}

% 45 - eye_color_geometric

\eocesol{(a)~$0.875^2\times 0.125 = 0.096$.
(b)~$\mu=8$, $\sigma=7.48$.}

% 47 - bernoulli_mean_derivation

\eocesol{If ${p}$ is the probability of a success, then the mean of a Bernoulli random variable $X$ is given by \\
$\mu = E[X] = P(X = 0) \times 0 + P(X = 1) \times 1$ \\
$= (1 - p) \times 0 + p\times 1 = 0 + p = p$}

% 49 - exploring_combinations_ap

\eocesol{(a)~$5\choose 1$ = 5.
(b)~$5\choose 4$ = 5.
(c)~$5\choose 3$ = 10.\\
(d)~$5\choose 3$ + $5\choose 4$ + $5\choose 5$ = 10 + 5 + 1 = 16.  }

% 51 - underage_drinking_intro

\eocesol{(a)~Binomial conditions are met: 
(1)~Independent trials: In a random sample, whether or not one 18-20 year 
old has consumed alcohol does not depend on whether or not another one has.
(2)~Fixed number of trials: $n = 10$.
(3)~Only two outcomes at each trial: Consumed or did not consume alcohol.
(4)~Probability of a success is the same for each trial: $p = 0.697$.
(b)~0.203.
(c)~0.203.
(d)~0.167.
(e)~0.997.}

% 53 - dreidel

\eocesol{(a)~$1-0.75^3 = 0.5781$.
(b)~0.1406.
(c)~0.4219.
(d)~$1-0.25^3=0.9844$.}

% 55 - underage_drinking_normal_approx

\eocesol{(a)~$\mu 34.85$, $\sigma = 3.25$
(b)~$Z = \frac{45 - 34.85}{3.25} = 3.12$. 45 is more than 3 standard 
deviations away from the mean, we can assume that it is an unusual 
observation. Therefore yes, we would be surprised.
(c)~Using the normal approximation, 0.0009. With 0.5 correction, 0.0015.}

% 57 - grade_dists

\eocesol{(a)~Invalid. Sum is greater than~1.
(b)~Valid. Probabilities are between 0 and 1, and they sum to 1. In this class, 
every student gets a~C.
(c)~Invalid. Sum is less than~1.
(d)~Invalid. There is a negative probability.
(e)~Valid. Probabilities are between 0 and 1, and they sum to~1.
(f)~Invalid. There is a negative probability.}

% 59 - tree_hiv_swaziland

\eocesol{0.8247. \\
\includegraphics[width=60mm]{ch_probability/figures/eoce/tree_hiv_swaziland/tree_hiv_swaziland.pdf}}

% 61 - cost_of_breakfast

\eocesol{(a)~E = \$3.90. SD = \$0.34. \\
(b)~E = \$27.30. SD = \$0.89.}

% 63 - university_admissions

\eocesol{Want to find the probability that there will be 1,787 or more enrollees. 
Using the normal approximation, with $\mu = np = 2,500 \times 0.7 = 1750$ and 
$\sigma = \sqrt{np(1-p)} = \sqrt{2,500 \times 0.7 \times 0.3} \approx 23$, 
$Z = 1.61$, and $P(Z > 1.61) = 0.0537$. With a 0.5 correction: 0.0559.}

% 65 - roulette_winnings

\eocesol{0 wins (-\$3): 0.1458. 1 win (-\$1): 0.3936. 2 wins (+\$1): 0.3543. 
3 wins (+\$3): 0.1063.}

\end{multicols}



%_______________
\eocesolch{Distributions of random variables}


%_______________
\begin{multicols}{2}


% 1 - distribution_p_hat_1

\eocesol{(a)~Each observation in each of the distributions represents the sample proportion ($\hat{p}$) from samples of size  $n = 20$, $n = 100$, and $n = 500$, respectively. (b)~The centers for all three distributions are at 0.95, the true population parameter. When $n$ is small, the distribution is skewed to the left and not smooth. As $n$ increases, the variability of the distribution (standard deviation) decreases, and the shape of the distribution becomes more unimodal and symmetric.}

% 3 - distribution_p_hat_3

\eocesol{(a)~$SD_{\hat{p}} = \sqrt{p(1-p) / n} = 0.0707$. This describes the typical distance that the sample proportion will deviate from the true proportion, $p = 0.5$.
(b)~$\hat{p}$ approximately follows $N(0.5, 0.0707)$. $Z = (0.55 - 0.50) / 0.0707 \approx 0.71$. This corresponds to an upper tail of about 0.2389. That is, $P(\hat{p} > 0.55) \approx 0.24$.}

% 5 - nearsighted_children

\eocesol{(a)~First we need to check that the necessary conditions are met. There are $200 \times 0.08 = 16$ expected successes and $200 \times (1 - 0.08) = 184$ expected failures, therefore the success-failure condition is met. Then the binomial distribution can be approximated by $N(\mu = 16, \sigma = 3.84)$. $P(X < 12) = P(Z < -1.04) = 0.1492$.
(b)~Since the success-failure condition is met the sampling distribution of $\hat{p} \sim N(\mu = 0.08, \sigma = 0.0192)$. $P(\hat{p} < 0.06) = P(Z < -1.04) = 0.1492$.
(c)~As expected, the two answers are the same.}

% 7 - ages_pennies_1

\eocesol{(a)~The distribution is unimodal and strongly right skewed with a median between 5 and 10 years old. Ages range from 0 to slightly over 50 years old, and the middle 50\% of the distribution is roughly between 5 and 15 years old. There are potential outliers on the higher end.
(b)~When the sample size is small, the sampling distribution is right skewed, just like the population distribution. As the sample size increases, the sampling distribution gets more unimodal, symmetric, and approaches normality. The variability also decreases. This is consistent with the Central Limit Theorem.}

% 9 - housing_prices

\eocesol{(a)~Right skewed. There is a long tail on the higher end of the distribution but 
a much shorter tail on the lower end.
(b)~Less than, as the median would be less than the mean in a right skewed 
distribution.
(c)~We should not.
(d)~Even though the population distribution is not normal, the conditions for 
inference are reasonably satisfied, with the possible exception of skew. If the 
skew isn't very strong (we should ask to see the data), then we can use the 
Central Limit Theorem to estimate this probability. For now, we'll assume the 
skew isn't very strong, though the description suggests it is at least moderate 
to strong. Use $N(1.3, SD_{\bar{x}} = 0.3/\sqrt{60})$: $Z=2.58$ $\to$ 0.0049.
(e)~It would decrease it by a factor of $1/\sqrt{2}$.}

% 11 - identify_dist_symm_pop

\eocesol{The centers are the same in each plot, and each data set is from a nearly normal 
distribution, though the histograms may not look very normal since each 
represents only 100 data points. The only way to tell which plot corresponds to 
which scenario is to examine the variability of each distribution. Plot B is the 
most variable, followed by Plot A, then Plot C. This means Plot B will 
correspond to the original data, Plot A to the sample means with size 5, and 
Plot C to the sample means with size 25.}

% 13 - penny_weights

\eocesol{(a)~$Z=-3.33$ $\to$ 0.0004.
(b)~The population SD is known and the data are nearly normal, so the sample 
mean will be nearly normal with distribution $N(\mu, \sigma/\sqrt{n})$, i.e. 
$N(2.5, 0.0095)$.
(c)~$Z=-10.54$ $\to$ $\approx0$.
(d)~See below:
\begin{center}
\includegraphics[width=0.48\textwidth]{ch_distributions/figures/eoce/penny_weights/penny_weights_sketch.pdf}
\end{center}
(e)~We could not estimate (a) without a nearly normal population distribution. 
We also could not estimate (c) since the sample size is not sufficient to yield 
a nearly normal sampling distribution if the population distribution is not 
nearly normal.}

% 15 - songs_on_ipod

\eocesol{(a)~We cannot use the normal model for this calculation, but we can use the 
histogram. About 500 songs are shown to be longer than 5 minutes, so the 
probability is about $500/3000 = 0.167$.
(b)~Two different answers are reasonable. $^{Option~1}$Since the population 
distribution is only slightly skewed to the right, even a small sample size will 
yield a nearly normal sampling distribution. We also know that the songs are 
sampled randomly and the sample size is less than 10\% of the population, so the 
length of one song in the sample is independent of another.  We are looking for 
the probability that the total length of 15 songs is more than 60 minutes, which 
means that the average song should last at least $60/15 = 4$ minutes. Using 
$SD_{\bar{x}}=1.63/\sqrt{15}$, $Z=1.31$ $\to$ 0.0951. $^{Option~2}$Since the 
population distribution is not normal, a small sample size may not be sufficient 
to yield a nearly normal sampling distribution. Therefore, we cannot estimate 
the probability using the tools we have learned so far.
(c)~We can now be confident that the conditions are satisfied. 
$Z = 0.92$ $\to$ 0.1788.}

% 17 - wireless_routers

\eocesol{(a)~$SD_{\bar{x}}=\frac{25}{\sqrt{75}}=2.89$.
(b)~$Z=1.73$, which indicates that the two values are not unusually distant from each other when accounting for the uncertainty in John's point estimate.}

% 19 - university_admissions

\eocesol{Want to find the probability that there will be 1,787 or more enrollees. 
Using the normal approximation, with $\mu = np = 2,500 \times 0.7 = 1750$ and 
$\sigma = \sqrt{np(1-p)} = \sqrt{2,500 \times 0.7 \times 0.3} \approx 23$, 
$Z = 1.61$, and $P(Z > 1.61) = 0.0537$. With a 0.5 correction: 0.0559.}

% 21 - overweight_baggage

\eocesol{$Z = 1.56$, $P(Z > 1.56) = 0.0594$, i.e. 6\%.}

% 23 - overweight_baggage_2

\eocesol{This is the same as checking that the average bag weight of the 10 bags is greater than 46 lbs. $SD_{\bar{x}}=\frac{3.2}{\sqrt{10}}=1.012$; $z= \frac{46-45}{1.012}=0.988$; $P(z > 0.988)=0.162=16.2\%$.}

% 25 - young_hispanics_2019

\eocesol{First we need to check that the necessary conditions are met. There are $100 \times 0.360 = 36.0$ expected successes and $100 \times (1 - 0.360) = 64.0$ expected failures, therefore the success-failure condition is met. Calculate using either (1) the normal approximation to the binomial distribution or (2) the sampling distribution of $\hat{p}$. (1) The binomial distribution can be approximated by $N(\mu = 0.360, \sigma = 4.8)$. $P(X \ge 35) = P(Z > -0.208) = 0.5823$. (2) The sampling distribution of $\hat{p} \sim N(\mu = 0.360, \sigma = 0.048)$. $P(\hat{p} > 0.35) = P(Z > -0.208) = 0.5823$.}



%_______________
\end{multicols}



%_______________
\eocesolch{Foundations for inference}



%_______________
\begin{multicols}{2}

% 1 - identify_parameter_1

\eocesol{(a)~Mean. Each student reports a numerical value: a number of hours.
(b)~Mean. Each student reports a number, which is a percentage, and we can 
average over these percentages.
(c)~Proportion. Each student reports Yes or No, so this is a categorical 
variable and we use a proportion.
(d)~Mean. Each student reports a number, which is a percentage like in part~(b).
(e)~Proportion. Each student reports whether or not s/he expects to get a job, 
so this is a categorical variable and we use a proportion.}

% 3 - comp_chips_quality_ctrl_prop

\eocesol{(a)~The sample is from all computer chips manufactured
    at the factory during the week of production.
    We might be tempted to generalize the population
    to represent all weeks, but we should exercise
    caution here since the rate of defects may change
    over time.
(b)~The fraction of computer chips manufactured
    at the factory during the week of production
    that had defects.
(c)~Estimate the parameter using the data:
    $\hat{p} = \frac{27}{212} = 0.127$.
(d)~\emph{Standard error} (or $SE$).
(e)~Compute the $SE$ using
    $\hat{p} = 0.127$ in place of $p$:
    $SE
      \approx \sqrt{\frac{\hat{p}(1 - \hat{p})}{n}}
      = \sqrt{\frac{0.127(1 - 0.127)}{212}}
      = 0.023$.
(f)~The standard error is the
    standard deviation of $\hat{p}$.
    A value of 0.10 would be about one standard
    error away from the observed value, which would
    not represent a very uncommon deviation.
    (Usually beyond about 2 standard errors
    is a good rule of thumb.)
    The engineer should not be surprised.
(g)~Recomputed standard error using $p = 0.1$:
    $SE = \sqrt{\frac{0.1(1 - 0.1)}{212}}
      = 0.021$.
    This value isn't very different,
    which is typical when the standard error
    is computed using relatively similar
    proportions (and even sometimes when
    those proportions are quite different!).}

% 5 - repeated_water_samples_prop

\eocesol{(a)~Sampling distribution.
(b)~If the population proportion is in the 5-30\% range,
    the success-failure condition would be satisfied and
    the sampling distribution would be symmetric.
(c)~We use the standard error to describe the variability:
    $SE
      = \sqrt{\frac{p (1 - p)}{n}}
      = \sqrt{\frac{0.08 (1 - 0.08)}{800}}
      = 0.0096$.
(d)~Standard error.
(e)~The distribution will tend to be more variable
    when we have fewer observations per sample.}

% 7 - chronic_illness_intro

\eocesol{Recall that the general formula is $point~estimate \pm z^{\star} \times SE$.
First, identify the three different values. The point estimate is 45\%, 
$z^{\star} = 1.96$ for a 95\% confidence level, and $SE = 1.2\%$. Then, plug the 
values into the formula:
$ 45\% \pm 1.96 \times 1.2\% \quad\to\quad (42.6\%, 47.4\%) $
We are 95\% confident that the proportion of US adults who live with one or more 
chronic conditions is between 42.6\% and 47.4\%.}

% 9 - chronic_illness_tf

\eocesol{(a)~False. Confidence intervals provide a range of plausible values, and 
sometimes the truth is missed. A 95\% confidence interval ``misses'' about 5\% 
of the time.
(b)~True. Notice that the description focuses on the true population value.
(c)~True. If we examine the 95\% confidence interval computed in Exercise~\ref{chronic_illness_tf}, we can see that 50\% is not included in this interval. This 
means that in a hypothesis test, we would reject the null hypothesis that the 
proportion is~0.5.
(d)~False. The standard error describes the uncertainty in the overall estimate 
from natural fluctuations due to randomness, not the uncertainty corresponding 
to individuals' responses.}

% 11 - er_wait_intro_prop_ok

\eocesol{(a)~False. Inference is made on the population parameter, not the point 
estimate. The point estimate is always in the confidence interval.
(b)~True.
(c)~False. The confidence interval is not about a sample mean.
(d)~False. To be more confident that we capture the parameter, we need a wider 
interval. Think about needing a bigger net to be more sure of catching a fish in 
a murky lake.
(e)~True. Optional explanation: This is true since the normal model was used to 
model the sample mean. The margin of error is half the width of the interval, 
and the sample mean is the midpoint of the interval.
(f)~False. In the calculation of the standard error, we divide the standard 
deviation by the square root of the sample size. To cut the SE (or margin of 
error) in half, we would need to sample $2^2 = 4$ times the number of people in 
the initial sample.}

% 13 - identify_hypotheses_prop_and_mean_1

\eocesol{(a)~$H_0: p = 0.5$
    (Neither a majority nor minority of students' grades improved)
  $H_A: p \neq 0.5$
    (Either a majority or a minority of students' grades improved) \\
(b)~$H_0: \mu = 15$
    (The average amount of company time each employee spends not 
    working is 15 minutes for March Madness.)
  $H_A: \mu \neq 15$
    (The average amount of company time each employee spends not 
    working is different than 15 minutes for March Madness.)}

% 15 - online_communication_prop_ht_errors

\eocesol{(1)~The hypotheses should be about the
    population proportion ($p$), not the sample proportion.
(2)~The null hypothesis should have an equal sign.
(3)~The alternative hypothesis should have a not-equals
    sign, and
(4)~it should reference the null value, $p_0 = 0.6$,
    not the observed sample proportion.
The correct way to set up these hypotheses is:
$H_0: p = 0.6$ and
$H_A: p \neq 0.6$.}

% 17 - cyberbullying_prop_ci_ht

\eocesol{(a)~This claim is reasonable, since the entire interval
    lies above 50\%.
(b)~The value of 70\% lies outside of the interval,
    so we have convincing evidence that the researcher's
    conjecture is wrong.
(c)~A~90\% confidence interval will be narrower than a
    95\%~confidence interval.
    Even without calculating the interval,
    we can tell that 70\% would not fall in the interval,
    and we would reject the researcher's conjecture based
    on a 90\% confidence level as well.}

% 19 - minimum_wage_prop_1

\eocesol{(i)~Set up hypotheses. $H_0$: $p = 0.5$, $H_A$: $p \neq 0.5$.
  We will use a significance level of $\alpha = 0.05$.
(ii)~Check conditions: simple random sample gets us independence,
  and the success-failure conditions is satisfied since
  $0.42 \times 1000 = 420$ and $(1 - 0.42) \times 1000 = 580$
  are both at least~10.
(iii)~Next, we calculate:
  $SE = \sqrt{0.5 (1 - 0.5) / 1000} = 0.016$.
  $Z = \frac{0.42 - 0.5}{0.016} = -5$,
  which has a one-tail area of about 0.0000003,
  so the p-value is twice this one-tail area at
  0.0000006.
(iv)~Make a conclusion:
  Because the p-value is less than $\alpha = 0.05$,
  we reject the null hypothesis and conclude that the
  fraction of US adults who believe raising the minimum
  wage will help the economy is not 50\%.
  Because the observed value is less than 50\% and we
  have rejected the null hypothesis, we can conclude
  that this belief is held by fewer than 50\% of US adults.
(For reference, the survey also explores support for
changing the minimum wage, which is a different
question than if it will help the economy.)}

% 21 - backwards_prop_1

\eocesol{If the p-value is 0.05, this means the test statistic would be
either $Z = -1.96$ or $Z = 1.96$.
We'll show the calculations for $Z = 1.96$.
Standard error:
$SE = \sqrt{0.3 (1 - 0.3) / 90} = 0.048$.
Finally, set up the test statistic formula and solve
for $\hat{p}$:
$1.96 = \frac{\hat{p} - 0.3}{0.048}
  \to \hat{p} = 0.394$
Alternatively, if $Z = -1.96$ was used: $\hat{p} = 0.206$.}

% 23 - errors_fibromyalgia

\eocesol{(a)~$H_0$: Anti-depressants do not affect the symptoms
    of Fibromyalgia.
    $H_A$: Anti-depressants do affect the symptoms of
    Fibromyalgia (either helping or harming).
(b)~Concluding that anti-depressants either help or worsen
    Fibromyalgia symptoms when they actually do neither.
(c)~Concluding that anti-depressants do not affect
    Fibromyalgia symptoms when they actually do.}

% 25 - relax_after_work

\eocesol{(a)~We are 95\% confident that Americans spend an average
    of 1.38 to 1.92 hours per day relaxing or pursuing
    activities they enjoy.
(b)~Their confidence level must be higher as the width
    of the confidence interval increases as the confidence
    level increases.
(c)~The new margin of error will be smaller,
    since as the sample size increases,
    the standard error decreases,
    which will decrease the margin of error.}

% 27 - errors_food_safety

\eocesol{(a)~$H_0$: The restaurant meets food safety and sanitation regulations.
$H_A$: The restaurant does not meet food safety and sanitation regulations.
(b)~The food safety inspector concludes that the restaurant does not meet food 
safety and sanitation regulations and shuts down the restaurant when the 
restaurant is actually safe.
(c)~The food safety inspector concludes that the restaurant meets food safety 
and sanitation regulations and the restaurant stays open when the restaurant is 
actually not safe.
(d)~A Type~1 Error may be more problematic for the restaurant owner since his 
restaurant gets shut down even though it meets the food safety and sanitation 
regulations.
(e)~A Type~2 Error may be more problematic for diners since the restaurant 
deemed safe by the inspector is actually not.
(f)~Strong evidence. Diners would rather a restaurant that meet the regulations get
shut down than a restaurant that doesn't meet the regulations not get shut down.}

% 29 - unemployment_relationship

\eocesol{(a)~$H_0: p_{unemp} = p_{underemp}$: The proportions of unemployed and 
underemployed people who are having relationship problems are equal.
$H_A: p_{unemp} \ne p{underemp}$: The proportions of unemployed and 
underemployed people who are having relationship problems are different.
(b)~If in fact the two population proportions are equal, the probability of 
observing at least a 2\% difference between the sample proportions is 
approximately 0.35. Since this is a high probability we fail to reject the null 
hypothesis. The data do not provide convincing evidence that the proportion of 
of unemployed and underemployed people who are having relationship problems are 
different.}

% 31 - nutrition_labels_for_ffi

\eocesol{Because 130 is inside the confidence interval,
we do not have convincing evidence that the true
average is any different than what the nutrition
label suggests.}

% 33 - prac_stat_sig

\eocesol{True. If the sample size gets ever larger, then the
standard error will become ever smaller.
Eventually, when the sample size is large enough and
the standard error is tiny, we can find statistically
significant yet very small differences between the
null value and point estimate (assuming they are not
exactly equal).}

% 35 - gender_pay_gap_medicine

\eocesol{(a)~In effect, we're checking whether
    men are paid more than women (or vice-versa),
    and we'd expect these outcomes with either
    chance under the null hypothesis:
    \begin{align*}
    &H_0: p = 0.5
    &&H_A: p \neq 0.5
    \end{align*}
    We'll use $p$ to represent the fraction of cases
    where men are paid more than women. \\
(b)~Below is the completion of the hypothesis test.
  \begin{itemize}
  \item
    There isn't a good way to check independence here
    since the jobs are not a simple random sample.
    However, independence doesn't seem unreasonable,
    since the individuals in each job are different from
    each other.
    The success-failure condition is met since we check
    it using the null proportion:
    $p_0 n = (1 - p_0) n = 10.5$ is greater than 10.
  \item
    We can compute the sample proportion, $SE$, and
    test statistic:
    \begin{align*}
    \hat{p} &= 19 / 21 = 0.905 \\
    SE &= \sqrt{\frac{0.5 \times (1 - 0.5)}{21}} = 0.109 \\
    Z &= \frac{0.905 - 0.5}{0.109} = 3.72
    \end{align*}
    The test statistic $Z$ corresponds to an upper tail
    area of about 0.0001, so the p-value is 2 times this
    value: 0.0002.
  \item
    Because the p-value is smaller than 0.05, we reject
    the notion that all these gender pay disparities are
    due to chance.
    Because we observe that men are paid more in a higher proportion
    of cases and we have rejected $H_0$, we can conclude that
    men are being paid higher amounts in ways not explainable
    by chance alone.
  \end{itemize}
  If you're curious for more info around this topic,
  including a discussion about adjusting for additional
  factors that affect pay,
  please see the following video by Healthcare Triage:
  \oiRedirect{textbook-yt_healthcare_triage_gender_pay_gap}
      {youtu.be/aVhgKSULNQA}.}



%_______________
\end{multicols}



%_______________
\eocesolch{Inference for categorical data}



%_______________
\begin{multicols}{2}

% 1 - veg_coll_students_CLT

\eocesol{(a)~False. Doesn't satisfy success-failure condition.
(b)~True. The success-failure condition is not satisfied. In most samples we 
would expect $\hat{p}$ to be close to 0.08, the true population proportion. 
While $\hat{p}$ can be much above 0.08, it is bound below by 0, suggesting it 
would take on a right skewed shape. Plotting the sampling distribution would 
confirm this suspicion.
(c)~False. $SE_{\hat{p}} = 0.0243$, and $\hat{p} = 0.12$ is only 
$\frac{0.12 - 0.08}{0.0243} = 1.65$ SEs away from the mean, which would not 
be considered unusual.
(d)~True. $\hat{p}=0.12$ is 2.32 standard errors away from the mean, which is 
often considered unusual.
(e)~False. Decreases the SE by a factor of $1/\sqrt{2}$.}

% 3 - orange_tabbies_CLT

\eocesol{(a)~True. See the reasoning of 6.1(b).
(b)~True. We take the square root of the sample size in the SE formula.
(c)~True. The independence and success-failure conditions are satisfied.
(d)~True. The independence and success-failure conditions are satisfied.}

% 5 - gender_equality

\eocesol{(a)~False. A confidence interval is constructed to estimate the population 
proportion, not the sample proportion.
(b)~True. 95\% CI: $82\%\ \pm\ 2\%$.
(c)~True. By the definition of the confidence level.
(d)~True. Quadrupling the sample size decreases the SE and ME by a factor 
of $1/\sqrt{4}$.
(e)~True. The 95\% CI is entirely above 50\%.}

% 7 - fireworks_CI_concept

\eocesol{With a random sample, independence is 
satisfied. The success-failure condition is also satisfied. 
$ME = z^{\star} \sqrt{ \frac{\hat{p} (1-\hat{p})} {n} } 
= 1.96 \sqrt{ \frac{0.56 \times  0.44}{600} }= 0.0397 \approx 4\%$}

% 9 - study_abroad_CI_decision

\eocesol{(a)~No. The sample only represents students who took the SAT, and this was 
also an online survey.
(b)~(0.5289, 0.5711). We are 90\% confident that 53\% to 57\% of high school 
seniors who took the SAT are fairly certain that they will participate in a 
study abroad program in college.
(c)~90\% of such random samples would produce a 90\% confidence interval 
that includes the true proportion.
(d)~Yes. The interval lies entirely above 50\%.}

% 11 - national_health_plan_HT

\eocesol{(a)~We want to check for a majority (or minority),
    so we use the following hypotheses:
    \begin{align*}
    &H_0: p = 0.5
    &&H_A: p \neq 0.5
    \end{align*}
    We have a sample proportion of $\hat{p} = 0.55$
    and a sample size of $n = 617$ independents. \\
    Since this is a random sample, independence
    is satisfied.
    The success-failure condition is also satisfied:
    $617 \times 0.5$ and $617 \times (1 - 0.5)$
    are both at least 10 (we use the null proportion
    $p_0 = 0.5$ for this check in a one-proportion
    hypothesis test). \\
    Therefore, we can model $\hat{p}$ using a
    normal distribution with a standard error of
    \begin{align*}
    SE = \sqrt{\frac{p(1 - p)}{n}}
      = 0.02
    \end{align*}
    (We use the null proportion $p_0 = 0.5$
    to compute the standard error for a
    one-proportion hypothesis test.)
    Next, we compute the test statistic:
    \begin{align*}
    Z = \frac{0.55 - 0.5}{0.02} = 2.5
    \end{align*}
    This yields a one-tail area of 0.0062,
    and a p-value of $2 \times 0.0062 = 0.0124$. \\
    Because the p-value is smaller than 0.05,
    we reject the null hypothesis.
    We have strong evidence that the support
    is different from 0.5, and since the data
    provide a point estimate above 0.5,
    we have strong evidence to support this
    claim by the TV pundit. \\
(b)~No.
    Generally we expect a hypothesis test
    and a confidence interval to align,
    so we would expect the confidence interval
    to show a range of plausible values
    entirely above 0.5.
    However, if the confidence level is
    misaligned (e.g. a 99\% confidence level
    and a $\alpha = 0.05$ significance level),
    then this is no longer generally true.}

% 13 - taste_test_HT

\eocesol{(a)~$H_0: p = 0.5$. $H_A: p > 0.5$. Independence (random sample, $<10\%$ of 
population) is satisfied, as is the success-failure conditions (using 
$p_0 = 0.5$, we expect 40 successes and 40 failures). $Z = 2.91$ $\to$ p-
value $= 0.0018$. Since the p-value $< 0.05$, we reject the null hypothesis. 
The data provide strong evidence that the rate of correctly identifying a 
soda for these people is significantly better than just by random guessing.
(b)~If in fact people cannot tell the difference between diet and regular 
soda and they randomly guess, the probability of getting a random sample of 
80 people where 53 or more identify a soda correctly would be 0.0018.}

% 15 - national_health_plan_CI_sample_size_replaced

\eocesol{Since a sample proportion ($\hat{p} = 0.55$) is available,
we use this for the sample size calculations.
The margin of error for a 90\% confidence interval is
$1.65 \times SE = 1.65 \times \sqrt{\frac{p(1 - p)}{n}}$.
We want this to be less than 0.01, where we use
$\hat{p}$ in place of $p$:
\begin{align*}
1.65 \times \sqrt{\frac{0.55(1 - 0.55)}{n}} \leq 0.01 \\
1.65^2 \frac{0.55(1 - 0.55)}{0.01^2} \leq n
\end{align*}
From this, we get that $n$ must be at least 6739.}

% 17 - difference_of_props_prob_1

\eocesol{(a)~$\mu_{\hat{p}_{NE}} = 0.01$.
  $\sigma_{\hat{p}_{NE}} = 0.0031$.
(b)~$\mu_{\hat{p}_{NY}} = 0.06$.
  $\sigma_{\hat{p}_{NY}} = 0.0075$.
(c)~$\mu_{\hat{p}_{NY} - \hat{p}_{NB}} = 0.06 - 0.01 = 0.05$.
  $\sigma_{\hat{p}_{NY} - \hat{p}_{NB}} = 0.0081$.
(d)~We can think of $\hat{p}_{NE}$ and $\hat{p}_{NY}$ as being random variables,
  and we are considering the standard deviation of the difference of these two
  random variables, so we square each standard deviation, add them together,
  and then take the square root of the sum:
  \begin{align*}
  SD_{\hat{p}_{NY} - \hat{p}_{NE}}
    = \sqrt{SD_{\hat{p}_{NY}}^2 + SD_{\hat{p}_{NE}}^2}
  \end{align*}}

% 19 - social_experiment_conditions

\eocesol{This is not a randomized experiment, and it is unclear whether people would 
be affected by the behavior of their peers. That is, independence may not 
hold. Additionally, there are only 5 interventions under the provocative 
scenario, so the success-failure condition does not hold. Even if we consider 
a hypothesis test where we pool the proportions, the success-failure 
condition will not be satisfied. Since one condition is questionable and the 
other is not satisfied, the difference in sample proportions will not follow 
a nearly normal distribution.}

% 21 - gender_color_preference_CI_concept

\eocesol{(a)~False. The entire confidence interval is above 0.
(b)~True.
(c)~True.
(d)~True.
(e)~False. It is simply the negated and reordered values: (-0.06,-0.02).}

% 23 - national_health_plan_CI_replaced

\eocesol{(a)~Standard error:
    \begin{align*}
    SE
      = \sqrt{\frac{0.79(1 - 0.79)}{347} +
          \frac{0.55(1 - 0.55)}{617}}
      = 0.03
    \end{align*}
    Using $z^{\star} = 1.96$, we get:
    \begin{align*}
    0.79 - 0.55 \pm 1.96 \times 0.03
      \to (0.181, 0.299)
    \end{align*}
    We are 95\% confident that the proportion
    of Democrats who support the plan is 18.1\%
    to 29.9\% higher than the proportion of
    Independents who support the plan.
(b)~True.}

% 25 - offshore_drill_edu_dontknow_HT

\eocesol{(a)~College grads: 23.7\%. Non-college grads: 33.7\%.
(b)~Let $p_{CG}$ and $p_{NCG}$ represent the proportion of college graduates 
and non-college graduates who responded ``do not know". 
$H_0: p_{CG} = p_{NCG}$. $H_A: p_{CG} \ne p_{NCG}$. Independence is satisfied 
(random sample), and the success-failure 
condition, which we would check using the pooled proportion 
($\hat{p}_{\textit{pool}} = 235/827 = 0.284$), is also satisfied. $Z = -3.18$ $\to$ 
p-value = 0.0014. Since the p-value is very small, we reject $H_0$. The data 
provide strong evidence that the proportion of college graduates who do not 
have an opinion on this issue is different than that of non-college 
graduates. The data also indicate that fewer college grads say they ``do not 
know'' than non-college grads (i.e. the data indicate the direction after we 
reject $H_0$).}

% 27 - sleep_deprived_driver_HT

\eocesol{Subscript $_C$ means control group. Subscript $_T$ means truck drivers. 
$H_0: p_C = p_T$. $H_A: p _C \ne p_T$. Independence is satisfied (random 
samples), as is the success-failure condition, which 
we would check using the pooled proportion ($\hat{p}_{\textit{pool}} = 70/495 = 0.141$). 
$Z = -1.65$ $\to$ p-value $ = 0.0989$. Since the p-value is high (default to alpha = 0.05), we fail to 
reject $H_0$. The data do not provide strong evidence that the rates of sleep 
deprivation are different for non-transportation workers and truck drivers.}

% 29 - hiv_africa_HT

\eocesol{(a)~Summary of the study:
\begin{center}\scriptsize
\begin{tabular}{l l c c c}
        &           & \multicolumn{2}{c}{\textit{Virol. failure}}   &       \\
\cline{3-4}
        &           & Yes       & No        & Total \\
\cline{2-5}
\multirow{2}{*}{\textit{Treatment}}     & Nevaripine    & 26   & 94 & 120   \\
        & Lopinavir & 10            & 110   & 120   \\
\cline{2-5}
        & Total     & 36            & 204   & 240
\end{tabular}
\end{center}
(b)~$H_0: p_N = p_L$. There is no difference in virologic failure rates between 
the Nevaripine and Lopinavir groups. $H_A: p_N \ne p_L$. There is some 
difference in virologic failure rates between the Nevaripine and Lopinavir 
groups.
(c)~Random assignment was used, so the observations in each group are 
independent. If the patients in the study are representative of those in the 
general population (something impossible to check with the given information), 
then we can also confidently generalize the findings to the population. The 
success-failure condition, which we would check using the pooled proportion 
($\hat{p}_{pool} = 36/240 = 0.15$), is satisfied. $Z = 2.89$ $\to$ p-value 
$=0.0039$.
Since the p-value is low, we reject $H_0$.
There is strong evidence of a difference in virologic failure rates between
the Nevaripine and Lopinavir groups.
Treatment and virologic failure do not appear to be independent.}

% 31 - tf_chisq_1

\eocesol{(a)~False. The chi-square distribution has one parameter called degrees of 
freedom.
(b)~True.
(c)~True.
(d)~False. As the degrees of freedom increases, the shape of the chi-square 
distribution becomes more symmetric.}

% 33 - opensource_text_chisq_GOF

\eocesol{(a)~$H_0$: The distribution of the format of the book used by the students 
follows the professor's predictions. $H_A$: The distribution of the format of 
the book used by the students does not follow the professor's predictions.
(b)~$E_{hard~copy} = 126 \times  0.60 = 75.6$. 
$E_{print} = 126 \times  0.25 = 31.5$.
$E_{online} = 126 \times  0.15 = 18.9$.
(c)~Independence:  The sample is not random. However, if the professor has 
reason to believe that the proportions are stable from one term to the next 
and students are not affecting each other's study habits, independence could be reasonable. Sample size: All expected counts are at least 5.
(d)~$\chi^2 = 2.32$, $df=2$, p-value = 0.313.
(e)~Since the p-value is large, we fail to reject $H_0$. The data do not 
provide strong evidence indicating the professor's predictions were 
statistically inaccurate.}

% 35 - quitters_chisq_independence

\eocesol{(a)~Two-way table:
\begin{center}\scriptsize
\begin{tabular}{l l c c c}
& \multicolumn{2}{c}{\textit{Quit}} &       \\
\cline{2-3}
\textit{Treatment}      & Yes       & No        & Total \\
\hline
Patch + support group   & 40            & 110   & 150   \\
Only patch          & 30            & 120   & 150   \\
\cline{1-4}
Total               & 70            & 230   & 300 \\
\cline{1-4}
\end{tabular}
\end{center}
(b-i)~$E_{row_1, col_1} = \frac{(row~1~total)\times(col~1~total)}{table~total} = 35$. 
This is lower than the observed value. \\
(b-ii)~$E_{row_2, col_2} = \frac{(row~2~total)\times(col~2~total)}{table~total} = 115$. 
This is lower than the observed value.}

% 37 - offshore_drilling_chisq_indep_ahss

\eocesol{$H_0$: Opinions regarding offshore drilling for oil and earning a college degree are independent.
 $H_A$: Opinions regarding offshore drilling for oil and earning a college degree are dependent.
\begin{align*}
&E_{row~1, col~1} = 151.5 && E_{row~1, col~2} = 134.5 \\
&E_{row~2, col~1} = 162.1 && E_{row~2, col~2} = 143.9 \\
&E_{row~3, col~1} = 124.5 && E_{row~3, col~2} = 110.5
\end{align*}
Independence: The samples are both random, unrelated, and from less 
than 10\% of the population, so independence between observations is 
reasonable. Sample size: All expected counts are at least 5.
$\chi^2 = 11.47$, $df = 2$ $\to$ p-value = 0.003.
Since the p-value $< \alpha$, we reject $H_0$.  There is strong 
evidence that there is an association between support for off-shore 
drilling and having a college degree.}

% 39 - active_learning_HT_concept

\eocesol{No. The samples at the beginning and at the end of the semester are not 
independent since the survey is conducted on the same students.}

% 41 - ship_gifts_chisq_indep_conditions

\eocesol{(a)~$H_0$:~The age of Los Angeles residents is independent of shipping carrier 
preference variable. $H_A$:~The age of Los Angeles residents is associated with 
the shipping carrier preference variable. 
(b)~The conditions are not satisfied since some expected counts are below~5.}

% 43 - college_smokers_CI_sample_size

\eocesol{(a)~Independence is satisfied (random sample),
    as is the success-failure condition (40 smokers, 160 
    non-smokers).
    The 95\% CI: (0.145, 0.255).
    We are 95\% confident that 14.5\% 
    to 25.5\% of all students at this university smoke.
(b)~We want $z^{\star}SE$ to be no larger than 0.02 for
    a 95\% confidence level.
    We use $z^{\star}=1.96$ and plug in the point estimate
    $\hat{p}=0.2$ within the SE formula:
    $1.96\sqrt{0.2(1-0.2)/n} \leq 0.02$.
    The sample size $n$ should be at least 1,537.}

% 45 - life_after_college_CI

\eocesol{(a)~Proportion of graduates from this university who found a job within one 
year of graduating. $\hat{p} = 348/400 = 0.87$.
(b)~This is a random sample, so the 
observations are independent.
Success-failure condition is satisfied: 348 
successes, 52 failures, both well above~10.
(c)~(0.8371, 0.9029). We are 95\% confident that approximately 84\% to 90\% 
of graduates from this university found a job within one year of completing 
their undergraduate degree.
(d)~95\% of such random samples would produce a 95\% confidence interval 
that includes the true proportion of students at this university who found a 
job within one year of graduating from college.
(e)~(0.8267, 0.9133). Similar interpretation as before.
(f)~99\% CI is wider, as we are more confident that the true proportion is 
within the interval and so need to cover a wider range.}

% 47 - rps_chisq_GOF

\eocesol{Use a chi-squared goodness of fit test.
$H_0$: Each option is equally likely.
$H_A$: Some options are preferred over others.
Total sample size: 99.
Expected counts: (1/3) * 99 = 33 for each option. These are all above 5, so 
conditions are satisfied.
$df = 3 - 1 = 2$ and 
$\chi^2 = \frac{(43 - 33)^2}{33} + \frac{(21 - 33)^2}{33} + \frac{(35 - 33)^2}{33} = 7.52 
\rightarrow$ p-value $= 0.023$. Since 
the p-value is less than 5\%, we reject $H_0$. The data provide convincing 
evidence that some options are preferred over others.}

% 49 - mobile_browsing_HT_CI

\eocesol{(a)~$H_0: p = 0.38$. $H_A: p \ne 0.38$. Independence (random sample)
and the success-failure condition are satisfied. $Z=-20.5$ 
$\to$ p-value $\approx 0$. Since the p-value is very small, we reject $H_0$. 
The data provide strong evidence that the proportion of Americans who only 
use their cell phones to access the internet is different than the Chinese 
proportion of 38\%, and the data indicate that the proportion is lower in 
the US.
(b)~If in fact 38\% of Americans used their cell phones as a primary access 
point to the internet, the probability of obtaining a random sample of 2,254 
Americans where 17\% or less or 59\% or more use their only their cell 
phones to access the internet would be approximately 0.
(c)~(0.1545, 0.1855). We are 95\% confident that approximately 15.5\% to 
18.6\% of all Americans primarily use their cell phones to browse the 
internet.}

% 51 - chisq_choose_test_from_description

\eocesol{(a)~Since there are 3 independent random samples here,
  we do a test of homogeneity. $df = 2$.
(b)~Goodness of fit test, $df = 2$.
(c)~Goodness of fit test, $df = 4$.}



%_______________
\end{multicols}



%_______________
\eocesolch{Inference for numerical data}



%_______________
\begin{multicols}{2}

% 1 - identify_critical_t

\eocesol{(a)~$df=6-1=5$, $t_{5}^{\star} = 2.02$ (column with two tails of 0.10, 
row with $df=5$).
(b)~$df=21-1=20$, $t_{20}^{\star} = 2.53$ (column with two tails of 0.02, 
row with $df=20$).
(c)~$df=28$, $t_{28}^{\star} = 2.05$.
(d)~$df=11$, $t_{11}^{\star} = 3.11$.}

% 3 - find_T_pval_1_2_sided

\eocesol{(a)~0.085, do not reject $H_0$.
(b)~0.003, reject $H_0$.
(c)~0.438, do not reject $H_0$.
(d)~0.042, reject $H_0$.}

% 5 - work_backwards_1

\eocesol{The mean is the midpoint: $\bar{x} = 20$. Identify the margin of error: 
$ME = 1.015$, then use $t^{\star}_{35} = 2.03$ and $SE=s/\sqrt{n}$ in the 
formula for margin of error to identify $s = 3$.}

% 7 - ny_sleep_habits_2_sided

\eocesol{(a)~$H_0$: $\mu = 8$ (New Yorkers sleep 8 hrs per night on average.) 
$H_A$: $\mu \neq 8$ (New Yorkers sleep less or more than 8 hrs per
night on average.)
(b)~Independence: The sample is random.
The min/max suggest there are no concerning outliers.
$T = -1.75$. $df=25-1=24$.
(c)~ p-value $= 0.093$.
If in fact the true population mean of the 
amount New Yorkers sleep per night was 8 hours,
the probability of getting a 
random sample of 25 New Yorkers where the average
amount of sleep is 7.73 hours
per night or less (or 8.27 hours or more) is 0.093.
(d)~Since p-value $>$ 0.05, do not reject $H_0$.
The data do not provide strong evidence that
New Yorkers sleep more or less than 8 hours per night
on average.
(e)~Yes, since we did not rejected $H_0$.}

% 9 - find_mean_2_sided

\eocesol{$T$ is either -2.09 or 2.09.
Then $\bar{x}$ is one of the following:
\begin{align*}
-2.09 &= \frac{\bar{x} - 60}{\frac{8}{\sqrt{20}}} \ \rightarrow \ \bar{x} = 56.26 \\
2.09 &= \frac{\bar{x} - 60}{\frac{8}{\sqrt{20}}} \ \rightarrow \ \bar{x} = 63.74
\end{align*}}

% 11 - play_piano

\eocesol{(a)~We will conduct a 1-sample $t$-test. $H_0$: $\mu = 5$. $H_A$: $\mu < 5$. 
We'll use $\alpha = 0.05$. This is a random sample, so the observations are 
independent. To proceed, we assume the distribution of years of piano lessons 
is approximately normal. $SE = 2.2 / \sqrt{20} = 0.4919$. The test statistic is 
$T = (4.6 - 5) / SE = -0.81$. $df = 20 - 1 = 19$. The one-tail p-value is about 
0.21, which is bigger than $\alpha = 0.05$, so we do not reject $H_0$. That is, 
we do not have sufficiently strong evidence to reject Georgianna's claim. \\
(b)~Using $SE = 0.4919$ and $t_{df = 19}^{\star} = 2.093$, the confidence 
interval is (3.57, 5.63). We are 95\% confident that the average number of 
years a child takes piano lessons in this city is 3.57 to 5.63 years. \\
(c)~They agree, since we did not reject the null hypothesis and the null value 
of 5 was in the $t$-interval.}

% 13 - car_insurance_savings

\eocesol{If the sample is large, then the margin of error will be about 
$1.96 \times 100 / \sqrt{n}$. We want this value to be less than 10, which 
leads to $n \geq 384.16$, meaning we need a sample size of at least 385 (round 
up for sample size calculations!).}

% 15 - air_quality_shortened

\eocesol{Paired, data are recorded in the same cities at two
different time points. 
The temperature in a city at one point is not independent
of the temperature in the same city at another time point.}

% 17 - paired_or_not_1

\eocesol{(a)~Since it's the same students at the beginning and the end of the semester, 
there is a pairing between the datasets, for a given student their beginning 
and end of semester grades are dependent.
(b)~Since the subjects were sampled randomly, each observation in the men's 
group does not have a special correspondence with exactly one observation in 
the other (women's) group.
(c)~Since it's the same subjects at the beginning and the end of the study, 
there is a pairing between the datasets, for a subject student their beginning 
and end of semester artery thickness are dependent.
(d)~Since it's the same subjects at the beginning and the end of the study, 
there is a pairing between the datasets, for a subject student their beginning 
and end of semester weights are dependent.}

% 19 - global_warming_v2_1

\eocesol{(a)~For each observation in one data set,
    there is exactly one specially corresponding
    observation in the other data set for the
    same geographic location.
    The data are paired.
(b)~$H_0: \mu_{\text{diff}} = 0$
    (There is no difference in average number
    of days exceeding 90\textdegree{}F in 1948
    and 2018 for NOAA stations.)
    $H_A: \mu_{\text{diff}} \neq 0$
    (There is a difference.)
(c)~Locations were randomly sampled, so independence
    is reasonable.
    The sample size is at least 30, so we're just looking
    for particularly extreme outliers:
    none are present (the observation off left in the
    histogram would be considered a clear outlier,
    but not a particularly extreme one).
    Therefore, the conditions are satisfied.
(d)~$SE = 17.2 / \sqrt{197} = 1.23$.
    $T = \frac{2.9 - 0}{1.23} = 2.36$
    with degrees of freedom $df = 197 - 1 = 196$.
    This leads to a one-tail area of 0.0096
    and a p-value of about 0.019.
(e)~Since the p-value is less than 0.05,
    we reject $H_0$.
    The data provide strong evidence that
    NOAA stations observed more 90\textdegree{}F
    days in 2018 than in 1948.
(f)~Type~1 Error, since we may have incorrectly
    rejected $H_0$.
    This error would mean that NOAA stations
    did not actually observe a decrease, but the
    sample we took just so happened to make it
    appear that this was the case.
(g)~No, since we rejected $H_0$,
    which had a null value of 0.}

% 21 - global_warming_v2_2

\eocesol{(a)~$SE = 1.23$ and $z^{\star} = 1.65$.
    $2.9 \pm 1.65 \times 1.23 \to (0.87, 4.93)$. \\
(b)~We are 90\% confident that there was an
    increase of 0.87 to 4.93 in the average number
    of days that hit 90\textdegree{}F in 2018
    relative to 1948 for NOAA stations. \\
(c)~Yes, since the interval lies entirely above~0.}

% 23 - difference_of_means_prob_1

\eocesol{(a)~$\mu_{\bar{x}_1} = 15$, $\sigma_{\bar{x}_1} = 20 / \sqrt{50} = 2.8284$.
(b)~$\mu_{\bar{x}_2} = 20$, $\sigma_{\bar{x}_1} = 10 / \sqrt{30} = 1.8257$.
(c)~$\mu_{\bar{x}_2 - \bar{x}_1} = 20 - 15 = 5$,
  $\sigma_{\bar{x}_2 - \bar{x}_1}
    = \sqrt{\left(20 / \sqrt{50}\right)^2 + \left(10 / \sqrt{30}\right)^2} = 3.3665$.
(d)~Think of $\bar{x}_1$ and $\bar{x}_2$ as being random variables,
  and we are considering the standard deviation of the difference of these two
  random variables, so we square each standard deviation, add them together,
  and then take the square root of the sum:
  \begin{align*}
  SD_{\bar{x}_2 - \bar{x}_1}
    = \sqrt{SD_{\bar{x}_2}^2 + SD_{\bar{x}_1}^2}
  \end{align*}}

% 25 - diamonds_1

\eocesol{$H_0: \mu_{0.99} = \mu_{1}$ and $H_A: \mu_{0.99} \ne \mu_{1}$. Independence: 
Both samples are random and represent less than 10\% of their respective 
populations. Also, we have no reason to think that the 0.99 carats are not 
independent of the 1 carat diamonds since they are both sampled randomly. 
Normality: The distributions are not extremely skewed, hence we can assume 
that the distribution of the average differences will be nearly normal as 
well. $T_{22} = 2.82$, p-value $>$ 0.01. Since p-value $<$ 0.05, 
reject $H_0$. The data provide convincing evidence that the average 
standardized price of 0.99 carats and 1 carat diamonds are different.}

% 27 - chick_wts_linseed_horsebean

\eocesol{(a)~Chicken fed linseed weighed an average of 218.75 grams
while those fed horsebean weighed an average of 160.20 grams.
Both distributions are relatively symmetric with no apparent
outliers.
There is more variability in the weights of chicken fed linseed. \\
(b)~$H_0: \mu_{ls} = \mu_{hb}$. $H_A: \mu_{ls} \ne \mu_{hb}$. \\
We leave the conditions to you to consider. \\
$T=3.02$, $df = min(11, 9) = 9$ $\to$ p-value $= 0.014$.
Since p-value $<$ 0.05, reject $H_0$.
The data provide strong evidence that there is a
significant difference between the average weights of 
chickens that were fed linseed and horsebean. \\
(c)~Type~1 Error, since we rejected $H_0$. \\
(d)~Yes, since p-value $>$ 0.01, we would not have rejected~$H_0$.}

% 29 - chick_wts_casein_soybean

\eocesol{$H_0: \mu_C = \mu_S$. $H_A: \mu_C \ne \mu_S$.
$T = 3.27$, $df=11$ $\to$ p-value $= 0.007$.
Since p-value $< 0.05$, reject $H_0$.
The data provide strong evidence that the average weight
of chickens that were fed casein is different than the
average weight of chickens that were fed soybean
(with weights from casein being higher).
Since this is a randomized experiment, the observed 
difference can be attributed to the diet.}

% 31 - prison_isolation_T

\eocesol{Let $\mu_{diff} = \mu_{pre} - \mu_{post}$.
$H_0: \mu_{diff} = 0$:
Treatment has no effect.
$H_A: \mu_{diff} \neq 0$:
Treatment has an effect on P.D.T. scores, either positive or negative.
Conditions:
The subjects are randomly assigned to treatments, so independence within
and between groups is satisfied. 
All three sample sizes are smaller than 30, so we look for clear outliers.
There is a borderline outlier in the first treatment group.
Since it is borderline, we will proceed,
but we should report this caveat with any results.
For all three groups: $df=13$.
$T_1 = 1.89 \to$ p-value = 0.081,
$T_2 = 1.35 \to$ p-value = 0.200),
$T_3 = -1.40 \to$ (p-value = 0.185).
We do not reject the null hypothesis for any of these groups.
As earlier noted, there is some uncertainty about if
the method applied is reasonable for the first group.}

% 33 - gaming_distracted_eating_intake

\eocesol{$H_0: \mu_{T} = \mu_{C}$. $H_A: \mu_{T} \ne \mu_{C}$. $T=2.24$, $df=21$ $\to$ 
p-value $= 0.036$. Since p-value $<$ 0.05, reject $H_0$.
The data provide 
strong evidence that the average food consumption by the patients in the 
treatment and control groups are different. Furthermore, the data indicate 
patients in the distracted eating (treatment) group consume more food than 
patients in the control group.}

% 35 - sample_size_pairing

\eocesol{False. While it is true that paired analysis requires equal sample sizes, 
only having the equal sample sizes isn't, on its own, sufficient for doing 
a paired test. Paired tests require that there be a special correspondence 
between each pair of observations in the two groups.}

% 37 - hen_eggs

\eocesol{(a)~We are building a distribution of sample statistics, in this case the sample 
mean. Such a distribution is called a sampling distribution.
(b)~Because we are dealing with the distribution of sample means, we need to 
check to see if the Central Limit Theorem applies. Our sample size is greater 
than 30, and we are told that random sampling is employed. With these conditions 
met, we expect that the distribution of the sample mean will be nearly normal 
and therefore symmetric.
(c)~Because we are dealing with a sampling distribution, we measure its 
variability with the standard error. $SE = 18.2 / \sqrt{45} = 2.713$.
(d)~The sample means will be more variable with the smaller sample size.}

% 39 - exclusive_relationships

\eocesol{Independence: it is a random sample,
so we can assume that the students in this
sample are independent of each other with 
respect to number of exclusive relationships
they have been in.
Notice that there are no students who have
had no exclusive relationships in the 
sample, which suggests some student responses
are likely missing
(perhaps only positive values were reported).
The sample size is at least 30, and there are
no particularly extreme outliers, so the normality
condition is reasonable.
90\% CI: (2.97, 3.43).
We are 90\% confident that undergraduate students
have been in 2.97 to 3.43 
exclusive relationships, on average.}

% 41 - online_communication

\eocesol{First, the hypotheses should be about the population mean ($\mu$), not the 
sample mean. Second, the null hypothesis should have an equal sign and the 
alternative hypothesis should be about the null hypothesized value, not the 
observed sample mean.
The correct way to set up these hypotheses is shown below:
\begin{align*}
H_0&: \mu = 10~hours \\
H_A&: \mu \neq 10~hours
\end{align*}
A two-sided test allows us to consider the possibility
that the data show us something that we would find surprising.}

% 43 - friday_13th_traffic

\eocesol{(a)~These data are paired. For example, the Friday the 13th in say, September 
1991, would probably be more similar to the Friday the 6th in September 1991 
than to Friday the 6th in another month or year. \\
(b)~Let $\mu_{\textit{diff}} = \mu_{sixth} - \mu_{thirteenth}$. $H_0: \mu_{\textit{diff}} = 0$. 
$H_A: \mu_{\textit{diff}} \ne 0$. \\
(c)~Independence: The months selected are not random. However, if we think 
these dates are roughly equivalent to a simple random sample of all such Friday 
6th/13th date pairs, then independence is reasonable.
To proceed, we must make this strong assumption,
though we should note this assumption in any reported results.
Normality: With fewer than 10 observations,
we would need to see clear outliers to be concerned.
There is a borderline outlier on the right of the histogram of the differences,
so we would want to report this in formal analysis results. \\
(d)~$T = 4.93$ for $df = 10 - 1 = 9$ $\to$ p-value = 0.001. \\
(e)~Since p-value $<$ 0.05, reject $H_0$. The data provide strong evidence that 
the average number of cars at the intersection is higher on Friday the 
6$^{\text{th}}$ than on Friday the 13$^{\text{th}}$. (We should exercise caution
about generalizing the interpetation to all intersections or roads.) \\
(f)~If the average number of cars passing the intersection actually was the 
same on Friday the 6$^{\text{th}}$ and $13^{th}$, then the probability that we 
would observe a test statistic so far from zero is less than 0.01. \\
(g)~We might have made a Type~1 Error, i.e. incorrectly rejected the null 
hypothesis.}



%_______________
\end{multicols}



%_______________
\eocesolch{Introduction to linear regression}



%_______________
\begin{multicols}{2}

% 1 - visualize_residuals

\eocesol{(a)~The residual plot will show randomly distributed residuals around 0. 
The variance is also approximately constant.
(b)~The residuals will show a fan shape, with higher variability for 
smaller $x$. There will also be many points on the right above the line. 
There is trouble with the model being fit here.}

% 3 - identify_relationships_1

\eocesol{(a)~Strong relationship, but a straight line would not fit the data.
(b)~Strong relationship, and a linear fit would be reasonable.
(c)~Weak relationship, and trying a linear fit would be reasonable.
(d)~Moderate relationship, but a straight line would not fit the data.
(e)~Strong relationship, and a linear fit would be reasonable.
(f)~Weak relationship, and trying a linear fit would be reasonable.}

% 5 - exams_grades_correlation

\eocesol{(a)~Exam 2 since there is less of a scatter in the plot of final 
exam grade versus exam 2. Notice that the relationship between 
Exam 1 and the Final Exam appears to be slightly nonlinear.
(b)~Exam 2 and the final are relatively close to each other 
chronologically, or Exam 2 may be cumulative so has greater 
similarities in material to the final exam. Answers may vary.}

% 7 - match_corr_1

\eocesol{(a)~$r = -0.7$ $\rightarrow$ (4).
(b)~$r = 0.45$ $\rightarrow$ (3).
(c)~$r = 0.06$ $\rightarrow$ (1).
(d)~$r = 0.92$ $\rightarrow$ (2).}

% 9 - speed_height_gender

\eocesol{(a)~The relationship is positive, weak, and possibly linear. However, 
there do appear to be some anomalous observations along the left where 
several students have the same height that is notably far from the 
cloud of the other points. Additionally, there are many students who 
appear not to have driven a car, and they are represented by a set of 
points along the bottom of the scatterplot.
(b)~There is no obvious explanation why simply being tall should lead 
a person to drive faster. However, one confounding factor is gender. 
Males tend to be taller than females on average, and personal 
experiences (anecdotal) may suggest they drive faster. If we were to 
follow-up on this suspicion, we would find that sociological studies 
confirm this suspicion.
(c)~Males are taller on average and they drive faster. The gender 
variable is indeed an important confounding variable.}

% 11 - coast_starlight_corr_units

\eocesol{(a)~There is a somewhat weak, positive, possibly linear relationship 
between the distance traveled and travel time. There is clustering 
near the lower left corner that we should take special note of.
(b)~Changing the units will not change the form, direction or strength 
of the relationship between the two variables. If longer distances 
measured in miles are associated with longer travel time measured in 
minutes, longer distances measured in kilometers will be associated 
with longer travel time measured in hours.
(c)~Changing units doesn't affect correlation: $r = 0.636$.}

% 13 - body_measurements_shoulder_height_corr_units

\eocesol{(a)~There is a moderate, positive, and linear relationship between 
shoulder girth and height.
(b)~Changing the units, even if just for one of the variables, will 
not change the form, direction or strength of the relationship between 
the two variables.}

% 15 - corr_woman_spouse_age_ap

\eocesol{In each part, we can write the woman's age as a linear function of 
the spouse's age. \\
(a)~$age_{W} = age_{S} + 3$. \\
(b)~$age_{W} = age_{S} - 2$. \\
(c)~$age_{W} = 2 \times age_{S}$. \\
Since the slopes are positive and these are perfect linear 
relationships, the correlation will be exactly 1 in all three parts. 
An alternative way to gain insight into this solution is to create a 
mock data set, e.g. 5 women aged 26, 27, 28, 29, and 30, then find the 
spouses ages for each women in each part and create a scatterplot.}

% 17 - regression_units

\eocesol{Correlation: no units. Intercept: kg. Slope: kg/cm.}

% 19 - residual_apple_weight

\eocesol{Over-estimate. Since the residual is calculated as 
$observed\ -\ predicted$, a negative residual means that the 
predicted value is higher than the observed value.}

% 21 - tourism_spending_reg_conds

\eocesol{(a)~There is a positive, very strong, linear association between the 
number of tourists and spending.
(b)~Explanatory: number of tourists (in thousands). Response: 
spending (in millions of US dollars).
(c)~We can predict spending for a given number of tourists using a 
regression line. This may be useful information for determining how 
much the country may want to spend in advertising abroad, or to 
forecast expected revenues from tourism.
(d)~Even though the relationship appears linear in the scatterplot, 
the residual plot actually shows a nonlinear relationship. This is 
not a contradiction: residual plots can show divergences from 
linearity that can be difficult to see in a scatterplot. A simple 
linear model is inadequate for modeling these data. It is also 
important to consider that these data are observed sequentially, 
which means there may be a hidden structure not evident in the 
current plots but that is important to consider.}

% 23 - coast_starlight_reg

\eocesol{(a)~First calculate the slope: 
$b_1 = R\times s_y/s_x = 0.636 \times 113 / 99 = 0.726$. 
Next, make use of the fact that the regression line passes through 
the point $(\bar{x},\bar{y})$: $\bar{y} = b_0 + b_1 \times \bar{x}$. 
Plug in $\bar{x}$, $\bar{y}$, and $b_1$, and solve for $b_0$: 51. 
Solution: $\widehat{travel~time} = 51 + 0.726 \times distance$.
(b)~$b_1$: For each additional mile in distance, the model predicts 
an additional 0.726 minutes in travel time. $b_0$: When the distance 
traveled is 0 miles, the travel time is expected to be 51 minutes. It 
does not make sense to have a travel distance of 0 miles in this 
context. Here, the $y$-intercept serves only to adjust the height of 
the line and is meaningless by itself.
(c)~$R^2 = 0.636^2 = 0.40$. About 40\% of the variability in travel 
time is accounted for by the model, i.e. explained by the distance 
traveled.
(d)~$\widehat{travel~time} = 51 + 0.726 \times distance 
= 51 + 0.726 \times 103 \approx 126$ minutes. (Note: we should be 
cautious in our predictions with this model since we have not yet 
evaluated whether it is a well-fit model.)
(e)~$e_i = y_i - \hat{y}_i = 168 - 126 = 42$ minutes. A positive 
residual means that the model underestimates the travel time.
(f)~No, this calculation would require extrapolation.}

% 25 - murders_poverty_reg

\eocesol{(a)~$\widehat{murder} = -29.901 + 2.559 \times poverty\%$.
(b)~Expected murder rate in metropolitan areas with no poverty is -29.
901 per million. This is obviously not a meaningful value, it just 
serves to adjust the height of the regression line.
(c)~For each additional percentage increase in poverty, we expect 
murders per million to be higher on average by 2.559.
(d)~Poverty level explains 70.52\% of the variability in murder rates 
in metropolitan areas.
(e)~$\sqrt{0.7052} = 0.8398$.}

% 27 - outliers_1

\eocesol{(a)~There is an outlier in the bottom right. Since it is far from the 
center of the data, it is a point with high leverage. It is also an 
influential point since, without that observation, the regression 
line would have a very different slope. \\
(b)~There is an outlier in the bottom right. Since it is far from the 
center of the data, it is a point with high leverage. However, it 
does not appear to be affecting the line much, so it is not an 
influential point. \\
(c)~The observation is in the center of the data (in the x-axis 
direction), so this point does \emph{not} have high leverage. This 
means the point won't have much effect on the slope of the line and 
so is not an influential point.}

% 29 - urban_homeowners_outlier

\eocesol{(a)~There is a negative, moderate-to-strong, somewhat linear 
relationship between percent of families who own their home and the 
percent of the population living in urban areas in 2010. There is one 
outlier: a state where 100\% of the population is urban. The 
variability in the percent of homeownership also increases as we move 
from left to right in the plot.
(b)~The outlier is located in the bottom right corner, horizontally 
far from the center of the other points, so it is a point with high 
leverage. It is an influential point since excluding this point from 
the analysis would greatly affect the slope of the regression line.}

% 31 - body_measurements_weight_height_inf

\eocesol{(a)~The relationship is positive, moderate-to-strong, and linear. 
There are a few outliers but no points that appear to be influential. \\
(b)~$\widehat{weight} = -105.0113 + 1.0176 \times height$. \\
Slope: For each additional centimeter in height, the model
predicts the average weight to be 1.0176 additional kilograms
(about 2.2 pounds).   \\
Intercept: People who are 0 centimeters tall are expected to weigh -
105.0113 kilograms. This is obviously not possible. Here, the $y$-
intercept serves only to adjust the height of the line and is 
meaningless by itself. \\
(c)~$H_0$: The true slope coefficient of height is zero 
($\beta_1 = 0$). \\
$H_A$: The true slope coefficient of height is 
different than zero ($\beta_1 \neq 0$). \\
The p-value for the two-sided alternative hypothesis
($\beta_1 \ne 0$) is incredibly small, so we reject $H_0$.
The data provide convincing evidence that height and 
weight are positively correlated.
The true slope parameter is indeed greater than~0. \\
(d)~$R^2 = 0.72^2 = 0.52$. Approximately 52\% of the variability in 
weight can be explained by the height of individuals.}

% 33 - spouses_2_ap

\eocesol{(a)~$H_0$: $\beta = 0$. $H_A$: $\beta \neq 0$.
The p-value, as reported in the table, is incredibly small
and is smaller than 0.05, so we reject $H_0$.
The data provide convincing evidence that women's and spouses' 
heights are positively correlated. \\
(b)~$\widehat{height}_{S} = 43.5755 + 0.2863 \times height_{W}$. \\
(c)~Slope: For each additional inch in woman's height, the spouse's height is expected to be an additional 0.2863 inches, on 
average. Intercept: Women who are 0 inches tall are predicted to have 
spouses who are 43.5755 inches tall. The intercept here is 
meaningless, and it serves only to adjust the height of the line. \\
(d)~The slope is positive, so $r$ must also be positive. 
$r = \sqrt{0.09} = 0.30$. \\
(e)~63.2612. Since $R^2$ is low, the prediction based on this 
regression model is not very reliable. \\
(f)~No, we should avoid extrapolating.}

% 35 - murders_poverty_inf

\eocesol{(a)~$H_0: \beta_1 = 0; H_A: \beta_1 \ne 0$
(b)~The p-value for this test is approximately 0, therefore we reject 
$H_0$. The data provide convincing evidence that poverty percentage 
is a significant predictor of murder rate.
(c)~$n = 20, df = 18, T^*_{18} =  2.10$; $2.559 \pm 2.10 \times 0.390 
= (1.74, 3.378)$; For each percentage point poverty is higher, murder 
rate is expected to be higher on average by 1.74 to 3.378 per million.
(d)~Yes, we rejected $H_0$ and the confidence interval does not 
include 0.}

% 37 - pickup

\eocesol{(a)~The relationship is positive, linear, and moderate.  Due to the clear non-constant variance in the residuals, a linear model is not appropriate for modeling the relationship between hours worked and income.
(b)~Neither are a particularly: For the logged model, the scatter plot and residual plot show more constant variance in the residuals. However, the scatterplot with the logged model looks to have a bit of curvature.
(c)~For each hour increase hours works we would expect the income to increase on average by a factor of $e^{0.058} \approx 1.06 $, i.e. by 6\%.}

% 39 - tf_correlation

\eocesol{(a)~True.
(b)~False, correlation is a measure of the linear association 
between any two numerical variables.}

% 41 - starbucks_cals_protein

\eocesol{There is an upwards trend. However, the variability is higher for 
higher calorie counts, and it looks like there might be two clusters 
of observations above and below the line on the right, so we should 
be cautious about fitting a linear model to these data.}

% 43 - match_corr_3

\eocesol{(a)~$r = -0.72 \to (2)$
(b)~$r = 0.07 \to (4)$
(c)~$r = 0.86 \to (1)$
(d)~$r = 0.99 \to (3)$}

% 45 - trees_volume_height_diameter

\eocesol{(a)~There is a weak-to-moderate, positive, linear association between height 
and volume. There also appears to be some non-constant variance since the volume 
of trees is more variable for taller trees.
(b)~There is a very strong, positive association between diameter and volume. The 
relationship may include slight curvature.
(c)~Since the relationship is stronger between volume and diameter, using diameter 
would be preferred. However, as mentioned in part (b), the relationship between 
volume and diameter may not be, and so we may benefit from a model that properly 
accounts for nonlinearity.}



%_______________
\end{multicols}
