\begin{chapterpage}{Probability, random variables, and probability distributions}
  \chaptertitle{Probability, random \titlebreak{} variables, and probability \titlebreak{} distributions}
  \label{probability}
  \label{ch_probability}
\chaptersection{assocationCategoricalData}
  \chaptersection{basicsOfProbability}
  \chaptersection{conditionalProbabilitySection}
  \chaptersection{randomVariablesSection}
  \chaptersection{binomDist}
\chaptersection{normalDist}
\chaptersection{CLTintro}
\end{chapterpage}
\renewcommand{\chapterfolder}{ch_probability}
\index{probability|(}

\chapterintro{Probability forms a foundation of statistics,
  and you're probably \mbox{already}
  aware of many of the ideas.  However, formalization of the concepts is new for most. We begin by introducing probability concepts
  through examples that will be familiar to most people.  Then we analyze and apply discrete probability distributions, including the binomial distribution, and the most important continuous distribution in statistics - the normal distribution.  Finally, we introduce the concept of a sampling distribution which will lay the groundwork for the next two chapters. }



%__________________


\section[Relationships between two categorical variables]{\D{\hspace{-1.5mm}}Relationships between two categorical variables}

\label{assocationCategoricalData}
\index{data!email|(}

\sectionintro{

\noindent%
How do we visualize and summarize categorical data?  How can we see the relationship between two categorical variables?  For example, is there an association between the categorical variables of homeownership type and application type?  Does email type provide any useful value in classifying email as spam or not spam?  
In this section, we will introduce tables and other basic tools for categorical data that are used throughout this book.  


% library(openintro); data(email); dim(email)

%%
\subsection*{Learning objectives}
\begin{enumerate}
\setlength{\itemsep}{0mm}
\item Compare tabular and graphical representations for the relationship between two categorical variables.  

\item Justify a claim using tabular and graphical representations for the distributions of two categorical variables.

\item Calculate summary statistics from two-way tables.

\item Compare summary statistics for two categorical variables.

\item Justify a claim using summary statistics for two categorical variables.


\end{enumerate}
}
%%
\subsection{Introduction to two-way tables}
% library(openintro); dim(loans_full_schema)

\renewcommand{\loanapphomeAA}{3496}
\renewcommand{\loanapphomeAB}{3839}
\renewcommand{\loanapphomeAC}{1170}
\renewcommand{\loanapphomeAD}{8505}
\renewcommand{\loanapphomeBA}{362}
\renewcommand{\loanapphomeBB}{950}
\renewcommand{\loanapphomeBC}{183}
\renewcommand{\loanapphomeBD}{1495}

\newcommand{\loanapphomeAAp}{0.3496}
\newcommand{\loanapphomeABp}{0.3839}
\newcommand{\loanapphomeACp}{0.1170}
\newcommand{\loanapphomeADp}{0.8505}
\newcommand{\loanapphomeBAp}{0.0362}
\newcommand{\loanapphomeBBp}{0.0950}
\newcommand{\loanapphomeBCp}{0.0183}
\newcommand{\loanapphomeBDp}{0.1495}

\renewcommand{\loanapphomeDA}{3858}
\renewcommand{\loanapphomeDAPt}{0.3858} % Overall frequency
\renewcommand{\loanapphomeDB}{4789}
\renewcommand{\loanapphomeDC}{1353}
\renewcommand{\loanapphomeDD}{10000}
\renewcommand{\loanapphomeDAp}{0.3858}
\renewcommand{\loanapphomeDBp}{0.4789}
\renewcommand{\loanapphomeDCp}{0.1353}
\renewcommand{\loanapphomeN}{\loanapphomeDD{}}
\index{data!loans\_full\_schema|(}

In Section~\ref{categoricalData} we summarized \var{homeownership}, a categorical variable from the \data{loan} data set that has three levels, using a one-way frequency table and a one-way relative frequency table.  Those tables are reproduced here.\\

\begin{center}
\begin{tabular}{cc}
\centering
\begin{tabular}{lc}
  \var{homeownership} & Count \\
  \hline
  rent & \loanapphomeDA{} \\
  mortgage & \loanapphomeDB{} \\
  own & \loanapphomeDC{} \\
  \hline
  Total & \loanapphomeDD{} \\ 
  \hline
\end{tabular}
\quad \quad \quad \quad
\centering
\begin{tabular}{lc}
  \var{homeownership} & Relative Frequency \\
  \hline
  rent & \loanapphomeDAp{} \\
  mortgage & \loanapphomeDBp{} \\
  own & \loanapphomeDCp{} \\
  \hline
  Total & 1.000 \\ 
\hline
\end{tabular}
\end{tabular}
\end{center}


Sometimes we to represent the frequencies split among \emph{two} categorical variables.  Figure~\ref{loan_home_app_type_totals} summarizes two variables:
\var{app\us{}type}
%\footnote{For those readers already familiar
%  with \emph{joint probabilities}, \resp{joint} in the table
%  refers to a level of the \var{app\us{}type} variable
%  for a joint application.
%  The does not refer to a joint probability!}
and \var{homeownership}.
A table that summarizes data for two categorical variables in
this way is called a \term{two-way table} or a \term{contingency table}.
In a two-way frequency table, each value in the table represents the count or number of times
a particular combination of outcomes occurred.
For example, the value \loanapphomeAA{} corresponds to the number of
loans in the data set where the borrower rents
and the application type was individual.

Row and column totals are also included.
The \term{row totals} \index{contingency table!row totals}
provide the total counts across each row
(e.g. $\loanapphomeAA{} + \loanapphomeAB{} +
  \loanapphomeAC{} = \loanapphomeAD{}$),
and \term{column totals} \index{contingency table!column totals}
are total counts down each column.

\begin{figure}[ht]
\centering
\begin{tabular}{ll  ccc  rr}
  & & \multicolumn{3}{c}{\bf \var{homeownership}} & \\
  \cline{3-5}
  & & rent & mortgage & own & Total & \hspace{2mm}\  \\ 
  \cline{2-6}
  & individual &
      \loanapphomeAA{} &
      \loanapphomeAB{} &
      \loanapphomeAC{} &
      \loanapphomeAD{} \\
  \raisebox{1.5ex}[0pt]{\var{app\us{}type}} &
  joint &
      \loanapphomeBA{} &
      \loanapphomeBB{} &
	  \loanapphomeBC{} &
	  \loanapphomeBD{} \\
  \cline{2-6}
  & Total &
      \loanapphomeDA{} &
      \loanapphomeDB{} &
      \loanapphomeDC{} &
      \loanapphomeDD{} \\
  \cline{2-6}
\end{tabular}
\caption{A two-way frequency table for
    \var{app\us{}type} and \var{homeownership}.}
\label{loan_home_app_type_totals}
%library(openintro); library(xtable); tab <- table(loans_full_schema[,c("application_type", "homeownership")])[, c("RENT", "MORTGAGE", "OWN")]; xtable(tab); rowSums(tab); colSums(tab); sum(tab)
\end{figure}

\newpage
We can also create a two-way relative frequency table that shows the proportion for each combination of categories.  These proportions are called \term{joint relative frequencies}.  To calculate these, we divide every count in the frequency table by the entire table total of 10,000.  For example, we calculate the proportion of the loans that are classified as \resp{own} \emph{and} \resp{individual} as  \loanapphomeAC{}/10,000 =  \loanapphomeACp{}.

The row and column totals are called the \term{marginal relative frequencies}.  The marginal relative frequency for the first row is \loanapphomeADp{}, which found by taking the \var{individual} row total divided by the total for the entire table.  The marginal relative frequency for the second column is \loanapphomeDBp{}, which is found by taking the \var{mortgage} column total divided by the total for the entire table.

\begin{figure}[ht]
\centering
\begin{tabular}{ll  ccc  rr}
  & & \multicolumn{3}{c}{\bf \var{homeownership}} & \\
  \cline{3-5}
  & & rent & mortgage & own & Total & \hspace{2mm}\  \\ 
  \cline{2-6}
  & individual &
      \loanapphomeAAp{} &
      \loanapphomeABp{} &
      \loanapphomeACp{} &
      \loanapphomeADp{} \\
  \raisebox{1.5ex}[0pt]{\var{app\us{}type}} &
  joint &
      \loanapphomeBAp{} &
      \loanapphomeBBp{} &
	  \loanapphomeBCp{} &
	  \loanapphomeBDp{} \\
  \cline{2-6}
  & Total &
      \loanapphomeDAp{} &
      \loanapphomeDBp{} &
      \loanapphomeDCp{} &
      1.000 \\
  
  \cline{2-6}
\end{tabular}
\caption{A two-way relative frequency table for
    \var{app\us{}type} and \var{homeownership}.}
\label{loan_home_app_type_props}
%library(openintro); library(xtable); tab <- table(loans_full_schema[,c("application_type", "homeownership")])[, c("RENT", "MORTGAGE", "OWN")]; xtable(tab); rowSums(tab); colSums(tab); sum(tab)
\end{figure}



\subsection{Graphical representations for two categorical variables}
\label{bar_plots_subsection}
\label{mosaic_plots_subsection}

%Contingency tables using row or column proportions
%are especially useful for examining how two categorical
%variables are related.

Bar~charts and mosaic~plots  provide a way to visualize and compare the distributions of categorical variables.  A \termsub{segmented bar~chart}{bar chart!segmented}, or stacked bar~chart,
is a graphical display of two-way table information.
For example, a~segmented bar~chart is shown in Figure~\ref{loan_app_type_home_seg_bar},
where we have first created a bar~chart using the
\var{homeownership} variable and then divided each group
by the levels of \mbox{\var{app\us{}type}}.

One related visualization to the segmented bar~chart is the
\termsub{side-by-side bar~chart}{bar chart!side-by-side}.  An example is shown in
Figure~\ref{loan_app_type_home_sbs_bar}.

Figures~\ref{loan_app_type_home_seg_bar_standardized} and \ref{loan_app_type_home_sbs_bar_standardized} show a standardize segmented bar~chart and a standardized side-by-side bar chart.  These visualizations are helpful for understanding
the proportion of individual or joint loan applications
for borrowers in each level of \var{homeownership}.
Additionally, because the proportions of \resp{joint}
and \resp{individual} vary across the groups,
we can conclude that the two variables are associated.

\newcommand{\loanapptypehomesegbarplotwidth}{0.46\textwidth}
\begin{figure}[h]
  \centering

  \subfigure[]{
    \Figuress[A stacked bar plot with Homeownership on the horizontal axis and Frequency (count) on the Vertical axis, where "app\_type" is used to break each bar into two categories: "joint" application type and "individual" application type. The first bar is for "Rent" and extends up to about 3900 total for the two application types together. This "Rent" bar is also broken into two categories, blue for "individual" and yellow for "joint". The bottom portion of the bar, running up to about 3500, is blue to represent the "joint" applications where the application had a "rent" value for homeownership, and the rest (about vertical height representing about 400) of the bar is yellow to represent the "individual" applications. The second bar is for "Mortgage" at about 4700 total, the bottom 3900 of which are shown as blue for individual applications and the top of which is yellow for "joint" applications and appears to have a height of about 800. The third bar is for "Own" at about 1300, of which about 1100 is for the individual (blue) application type and about 200 of which is joint (yellow) application type. Again, each homeownership bar is broken into a lower (blue) and upper portion (yellow) portion to express the breakdown of a homeownership level into the application types, allowing us to express a breakdown along two categorical variables in a single plot.]
{\loanapptypehomesegbarplotwidth}
        {loan_app_type_home_seg_bar}
        {loan_app_type_home_seg_bar}
    \label{loan_app_type_home_seg_bar}
  }
  \subfigure[]{
    \Figuress[A side-by-side bar plot is shown. In this side-by-side plot, instead of having the blue and yellow portions of a single bar for a homeownership level, such as rent, the bar has been slimmed down and the blue and yellow portions are now side-by-side, each resting on the horizontal axis. Reading across, we see a blue and yellow bar side-by-side and touching. These are shown over a homeownership category of "rent". The first of these two bars is blue for "individual" application type (having a height of about 3500) and the second is yellow for the "joint" application type (having a height of about 400). After this first group of two bars, there is a small horizontal gap before the next pair of bars that represent the mortgage homeownership category. Here again, there is first a blue bar for individual application type, where this blue bar stretches up to a value of about 3900, and next to it is a yellow bar for the joint application type, which stretches up to about 800. After this second pair of bars, there is a little more space as we move right along the plot before we reach the "own" homeownership category, which shows another pair of bars: blue (with a bar reaching a frequency or count of about 1100) and yellow (with a bar reaching a value of about 200).]
{\loanapptypehomesegbarplotwidth}
        {loan_app_type_home_seg_bar}
        {loan_app_type_home_sbs_bar}
    \label{loan_app_type_home_sbs_bar}
  }
  \subfigure[]{
    \Figuress[The third plot is a standardized version of the stacked bar plot, where each bar has been standardized to add up to 1. This bar plot shows the homeownership variable and its three levels -- from left to right: rent, mortgage, and own -- as their own bars, where each bar runs from the horizontal axis at 0 up to a value of 1. This standardization where all total bars span the same vertical distance allows for an easier comparison of the proportional breakdown of the coloring in each stacked bar. The coloring breakdown of each bar represents the application type: individual (blue) and joint (yellow). For the first bar, rent, the blue runs up to about 0.9 on the vertical, and the yellow portion of the bar runs from 0.9 to 1.0. In the second bar, mortgage, the blue runs from horizontal axis up to about 0.8, and the yellow portion of the bar runs from 0.8 to 1.0. The third bar, own, has its blue portion run from the horizontal axis up to about 0.87, and the yellow portion runs from 0.87 to 1.0.]
{\loanapptypehomesegbarplotwidth}
        {loan_app_type_home_seg_bar}
        {loan_app_type_home_seg_bar_standardized}
    \label{loan_app_type_home_seg_bar_standardized}
  }
  \subfigure[]{
    \Figuress[The last plot is a standardized version of the side-by-side bar plot, where each pair of bars has been standardized to add up to 1. This allows us to compare the proportion of individual (blue bar) to proportion of joint (yellow bar) within each of the three types of homeownership levels (rent, mortgage, own).]
{\loanapptypehomesegbarplotwidth}
        {loan_app_type_home_seg_bar}
        {loan_app_type_home_sbs_bar_standardized}
    \label{loan_app_type_home_sbs_bar_standardized}
  }
%  \subtable{
%    \footnotesize
%    \begin{tabular}{l  ccc  r}
%      \multicolumn{5}{l}{Contingency table summarizing}\\
%      \multicolumn{5}{l}{application type and homeownership:} \\
%      \\
%      & \multicolumn{3}{c}{\bf \var{homeownership}} & \\
%      \cline{2-4}
%      \var{app\us{}type} &
%          rent & mortgage & own & Total \\ 
%      \hline
%      individual &
%          \loanapphomeAA{} &
%          \loanapphomeAB{} &
%          \loanapphomeAC{} &
%          \loanapphomeAD{} \\
%      joint &
%          \loanapphomeBA{} &
%          \loanapphomeBB{} &
%    	  \loanapphomeBC{} &
%    	  \loanapphomeBD{} \\
%      \hline
%      Total &
%          \loanapphomeDA{} &
%          \loanapphomeDB{} &
%          \loanapphomeDC{} &
%          \loanapphomeDD{} \\
%      \hline
%      \ \\
%      \ \\
%      \multicolumn{5}{l}{Version of the table}\\
%      \multicolumn{5}{l}{with column proportions:} \\
%      \\
%      & \multicolumn{3}{c}{\bf \var{homeownership}} & \\
%      \cline{2-4}
%      \var{app\us{}type} &
%          rent & mortgage & own & Total \\ 
%      \hline
%      individual &
%          0.906 &
%          0.802 &
%          0.865 &
%          0.851 \\
%      joint &
%          0.094 &
%          0.198 &
%          0.135 &
%          0.150 \\
%      \hline
%      Total & 1.000 & 1.000 & 1.000 & 1.000 \\
%      \hline
%      \ \\
%    \end{tabular}
%    \label{loan_app_type_home_copied_table}
%  }
  \caption{\subref{loan_app_type_home_seg_bar} segmented
      bar~chart for \var{homeownership},
      where the counts have been further broken down
      by \var{app\us{}type}.
      \subref{loan_app_type_home_sbs_bar}~Side-by-side
      bar~chart for \var{homeownership}
      and \var{app\us{}type}.
      \subref{loan_app_type_home_seg_bar_standardized}~Standardized
      version of the segmented bar~chart.
      \subref{loan_app_type_home_sbs_bar_standardized}~Standardized
      side-by-side bar~chart.
     }
  \label{loan_app_type_home_seg_bar_plot}
\end{figure}

\begin{examplewrap}
\begin{nexample}{Examine the four bar~charts in
    Figure~\ref{loan_app_type_home_seg_bar_plot}.
    When is the segmented, side-by-side, standardized
    segmented bar~chart, or standardized side-by-side the most useful?}
  The segmented bar~chart is most useful when it's reasonable
  to assign one variable as the explanatory variable and
  the other variable as the response, since we are effectively
  grouping by one variable first and then breaking it down by
  the others.

  Side-by-side bar~charts are more agnostic in their display
  about which variable, if any, represents the explanatory
  and which the response variable.
  It is also easy to discern the number of cases
  in of the six different group combinations.
  However, one downside
  is that it tends to require more horizontal space;
  the narrowness of Figure~\ref{loan_app_type_home_sbs_bar}
  makes the plot feel a bit cramped.
  Additionally, when two groups are of very different sizes,
  as we see in the \resp{own} group relative to either of the
  other two groups,
  it is difficult to discern if there is an association
  between the variables.

  The standardized segmented bar~chart is helpful if the primary
  variable in the segmented bar~chart is relatively imbalanced,
  e.g. the \resp{own} category has only a third of the
  observations in the \resp{mortgage} category,
  making the simple segmented bar~chart less useful for
  checking for an association.
  The major downside of the standardized version
  is that we lose all sense of how many cases each of the
  bars represents.

The last plot is a standardized side-by-side bar chart. It shows the joint and individual groups as proportions within each level of homeownership, and it offers similar benefits and tradeoffs to the standardized version of the stacked bar plot.
\end{nexample}
\end{examplewrap}



\newpage 
A \term{mosaic plot} is a visualization technique
suitable for two-way tables that resembles
a standardized segmented bar~chart with the added benefit
that we still see the relative group sizes of the
primary variable as well.

To get started in creating our first mosaic plot,
we'll break a square into columns for each category
of the \var{homeownership} variable,
with the result shown in Figure~\ref{loan_home_mosaic}.
Each column represents a level of \var{homeownership},
and the column widths correspond to the proportion of
loans in each of those categories.
For~instance, there are fewer loans where the borrower
is an owner than where the borrower has a mortgage.
In general, mosaic plots use box \emph{areas}
to represent the number of cases in each category.

\begin{figure}[h]
  \centering
  \subfigure[]{
    \Figures[A one-variable mosaic plot is shown for the homeownership variable, which has levels rent, mortgage, and own. A one-variable mosaic plot can first be pictured as a square that has partitions running vertically, breaking that square up into three pieces, one piece per level. The portion of the square assigned to each piece is proportional to the number of cases for each level. In this particular mosaic plot, we see a "rent" piece on the left portion of the square that has been colored green -- this tall rectangle represents about 40\% of the square. Now considering the middle tall rectangle, which is blue and has been labeled as "mortgage", its width is close to half of the total width of the square. The rightmost tall rectangle is red and is labeled "own", and it appears to represent a little more than 10\% of the total width of the rectangle.]
{0.36}
        {loan_app_type_home_mosaic_plot}
        {loan_home_mosaic}
    \label{loan_home_mosaic}
  }
  \subfigure[]{
    \Figures[A two-variable mosaic plot is shown, partitioned with vertical slices first for the homeownership variable in the same way as a one-variable mosaic plot, and then each of the tall rectangle from that one-variable mosaic plot has been sliced horizontally to represent the application types individual (shown as the upper portion of each tall rectangle) and joint (shown as the lower portion of each tall rectangle). Taking the first tall rectangle on the left of the mosaic plot, which is green and labeled as "rent", it is divided into a small "joint" rectangle at the bottom of the "rent" rectangle and a much larger upper portion that represents the "individual" application types of the rent homeownership cases. This same partitioning is repeated for the tall middle rectangle representing the blue mortgage homeownership cases, where a small portion of those applications are broken off into a smaller rectangle on the bottom for "joint" and a larger rectangle for the cases that are "individual". Similarly, the rightmost tall rectangle that is red and represents "own" has been divided into a lower rectangle for "joint" and an upper portion for "individual" application types. The benefit of this plot is that we can now get a sense of the proportional makeup of each homeownership category by looking at the relative widths of the three different colored tall rectangles, and we can also look at where each of these tall rectangles is broken into joint and individual applications. In this case, the tall rectangle for rent is broken lower than the mortgage and own levels, indicating it has fewer of the "joint" application types (which if you recall, was the lower sub-divided rectangles). The "own" category also has its horizontal break a bit lower than the "mortgage" rectangle's break, implying the mortgage category has the highest proportion of joint applications of the rent, mortgage, and own homeownership categories.]
{0.44}
        {loan_app_type_home_mosaic_plot}
        {loan_app_type_home_mosaic}
    \label{loan_app_type_home_mosaic}
  }
  \caption{\subref{loan_home_mosaic}~The one-variable mosaic
      plot for \var{homeownership}.
      \subref{loan_app_type_home_mosaic}~Two-variable mosaic
      plot for both \var{homeownership}
      and \var{app\us{}type}.}
  \label{loan_app_type_home_mosaic_plot}
\end{figure}

To finish the completed mosaic plot, the single-variable
mosaic plot is further divided into pieces in
Figure~\ref{loan_app_type_home_mosaic} using the
\var{app\us{}type} variable.
As with the standardized segmented bar~chart in Figure~\ref{loan_app_type_home_seg_bar_standardized}, each column is split proportional to the
number of loans from individual and joint
borrowers.
For example, the second column represents loans
where the borrower has a mortgage,
and it was divided into individual loans (upper)
and joint loans (lower).
As another example, the bottom segment of the third column
represents loans where the borrower owns their home
and applied jointly, while the upper segment
of this column represents
borrowers who are homeowners and filed individually.
We can again use this plot to see that
the \var{homeownership} and \var{app\us{}type}
variables are associated, since some columns are divided
in different vertical locations than others,
which was the same technique used for checking an
association in the standardized segmented bar~chart.

\D{\newpage}

In Figure~\ref{loan_app_type_home_mosaic},
we chose to first split by the homeowner status
of the borrower.
However, we could have instead first split by
the application type, as in
Figure~\ref{loan_app_type_home_mosaic_rev}.
Like with the bar~charts, it's common to use
the explanatory variable to represent the
first split in a mosaic plot,
and then for the response to break
up each level of the explanatory variable.%
%if these labels are reasonable to attach to
%the variables under consideration.

\begin{figure}[h]
  \centering
  \Figures[A two-variable mosaic plot that has been first divided vertically using the mortgage application type (individual on the left and joint on the right), and then each of those rectangles subdivided horizontally ("own" in red on the bottom, "mortgage" in blue in the middle, and "rent" in green on the top). The "individual" category as the left main rectangle spans about 85\% of the square, while the right main rectangle for "joint" spans about 15\% of the square. The homeownership breakdown within each of the main rectangles shows "own" represents roughly the same proportion in each, running up about 10\% of the way up from the bottom. The next subdivided portion of each rectangle is "mortgage", and here we see that the left "individual" rectangle has only about 45\% of its rectangle as "mortgage" while it represents about 60\%  in the right "joint" rectangle. The "rent" subdivided portions at the top of each rectangle represents about 40\% of the left "individual" rectangle and about 25\% of the "joint" rectangle.]
{0.5}
      {loan_app_type_home_mosaic_plot}
      {loan_app_type_home_mosaic_rev}
  \caption{Mosaic plot where loans are grouped by
      the \var{homeownership} variable after they've
      been divided into the \resp{individual} and
      \resp{joint} application types.}
  \label{loan_app_type_home_mosaic_rev}
\end{figure}

%In a similar way, a mosaic plot representing row proportions of Figure~\ref{loan_home_app_type_totals} could be constructed, as shown in Figure~\ref{loan_app_type_home_mosaic_rev}. However, because it is more insightful for this application to consider the fraction of spam in each category of the \var{number} variable, we prefer Figure~\ref{loan_app_type_home_mosaic}.



\subsection{Conditional relative frequencies}

The bar charts and mosaic plots encountered in the previous section provide visual representations of counts or proportions in two-way tables.  We will find these summaries useful when looking for evidence of an association between two categorical variables, such as \resp{app\us{}type} and \var{homeownership}.  For instance, suppose we are interested in the following:  for applicants who \resp{rent}, what proportion apply as an individual and what proportion apply jointly?  Also, how does this compare to applicants whose \var{homeownership} type is \resp{mortgage}?   

We can calculate the proportion of individual or joint application types \emph{within each} \var{homeownership} type and compare them.  These proportions are called \term{conditional relative freqencies}.  Looking at Figure~\ref{colPropAppTypeHomeownership}, we will condition on \var{homeownership} type and compute \emph{column} proportions: we take each cell frequency and divide it by the column total to see what proportion of the column variable it represents.  Notice that these proportions can be seen in the standardized stacked and segmented bar graphs shown in Figure~\ref{loan_app_type_home_seg_bar_plot} and in the mosaic plot in Figure~\ref{loan_app_type_home_mosaic}.

\newpage

In Figure~\ref{colPropAppTypeHomeownership}, the value 0.906 indicates that 90.6\% of renters applied as individuals.  This is equivalent to saying that the rate of individual applications among renters is 90.6\%.   This rate is higher than among those with mortgages (80.2\%) or who own their own home (85.1\%). Because these rates vary between the three levels of \var{homeownership} (\resp{rent}, \resp{mortgage}, \resp{own}), this provides evidence that the \var{app\us{}type} and \var{homeownership} variables are associated.

\begin{figure}[h]
\centering%\small
\begin{tabular}{l rrr r}
  \hline
  & rent & mortgage & own & Total \\
  \hline
  individual &
%      $\loanapphomeAA{}/\loanapphomeDA{} = 0.906$ &
%      $\loanapphomeAB{}/\loanapphomeDB{} = 0.802$ &
%      $\loanapphomeAC{}/\loanapphomeDC{} = 0.865$ &
%      $\loanapphomeAD{}/\loanapphomeDD{} = 0.851$ \\
      0.906 &
      0.802 &
      0.865 &
      0.851 \\
  joint &
%      $\loanapphomeBA{}/\loanapphomeDA{} = 0.094$ &
%      $\loanapphomeBB{}/\loanapphomeDB{} = 0.198$ &
%      $\loanapphomeBC{}/\loanapphomeDC{} = 0.135$ &
%      $\loanapphomeBD{}/\loanapphomeDD{} = 0.150$ \\
      0.094 &
      0.198 &
      0.135 &
      0.150 \\
  \hline
  Total & 1.000 & 1.000 & 1.000 & 1.000 \\
  \hline
\end{tabular}
\caption{A two-way table with column proportions for the
    \var{app\us{}type} and \var{homeownership}
    variables.
    The total for the last column is off by 0.001 due
    to a rounding error.}
\label{colPropAppTypeHomeownership}
\end{figure}


We can also ask a different question.  What proportion of \resp{individual} applicants rent, have a mortgage, or own?  And how does this compare to \resp{joint} applicants?  Here, we condition on \var{app\us{}type} and we calculate row proportions:  we take each cell frequency and divide it by the row total to see what proportion of the row variable it represents, as shown in Figure~\ref{rowPropAppTypeHomeownership}.  To calculate the row proportion at the intersection of
\resp{individual} and \resp{rent}, we divide
\loanapphomeAA{} by the row total of \loanapphomeAD{}, which equals 0.411 and represents the proportion of individual
applicants who rent.

\begin{figure}[h]
\centering
\begin{tabular}{l rrr r}
  \hline
  & rent & mortgage & own & Total \\
  \hline
  individual & 
%      $\loanapphomeAA{}/\loanapphomeAD{} = 0.411$ &
%      $\loanapphomeAB{}/\loanapphomeAD{} = 0.451$ &
%      $\loanapphomeAC{}/\loanapphomeAD{} = 0.138$ &
      0.411 &
      0.451 &
      0.138 &
      1.000 \\
  joint &
%      $\loanapphomeBA{}/\loanapphomeBD{} = 0.242$ &
%      $\loanapphomeBB{}/\loanapphomeBD{} = 0.635$ &
%      $\loanapphomeBC{}/\loanapphomeBD{} = 0.122$ &
      0.242 &
      0.635 &
      0.122 &
      1.000 \\
  \hline
  Total &
%      $\loanapphomeDA{}/\loanapphomeDD{} = 0.386$ &
%      $\loanapphomeDB{}/\loanapphomeDD{} = 0.479$ &
%      $\loanapphomeDC{}/\loanapphomeDD{} = 0.135$ &
      0.386 &
      0.479 &
      0.135 &
      1.000 \\
  \hline
\end{tabular}
\caption{A two-way table with row proportions
    for the \var{app\us{}type} and
    \var{homeownership} variables.
    The row total is off by 0.001 for the
    \resp{joint} row due to a rounding error.}
\label{rowPropAppTypeHomeownership}
\end{figure}

When comparing these row proportions, we would look down columns to see if the proportion of loans where the borrower rents, has a mortgage, or owns varied across the \resp{individual} to \resp{joint} application types.  Here we also see an association: those with a \resp{joint} application are more likely to have a mortgage and less likely to rent than those with an \resp{individual} application.  We can see these row proportions in the mosaic plot in Figure~\ref{loan_app_type_home_mosaic_rev}, while we can see the column proportions in the mosaic plot in Figure~\ref{loan_app_type_home_mosaic}.



\begin{exercisewrap}
\begin{nexercise}
(a)~What does 0.802 represent in
Figure~\ref{colPropAppTypeHomeownership}?
(b)~What does 0.451 represent in
Figure~\ref{rowPropAppTypeHomeownership}?
\footnotemark{}
\end{nexercise}
\end{exercisewrap}
\footnotetext{(a)~0.802 represents the fraction
  of applicants with mortgages who applied as individuals.
  (b)~0.451 represents the proportion of individual
  applicants who have a mortgage.}

\begin{exercisewrap}
\begin{nexercise}
(a)~What does 0.135 represent in the
Figure~\ref{colPropAppTypeHomeownership}?
(b)~What does 0.122 at the intersection of \resp{joint} and
\resp{own} represent in
Figure~\ref{rowPropAppTypeHomeownership}?\footnotemark{}
\end{nexercise}
\end{exercisewrap}
\footnotetext{(a)~0.135 represents the proportion of home-owning borrowers
  who had a joint application for the loan.
  (b)~0.122 represents the proportion of joint borrowers
  who own their home.}

\D{\newpage}

\index{data!email|(}

\begin{examplewrap}
\begin{nexample}{
    Data scientists use statistics to filter spam from incoming
    email messages.
    By noting specific characteristics of an email,
    a data scientist may be able to classify some emails as spam
    or not spam with high accuracy.
    One such characteristic is whether the email
    contains no numbers, small numbers, or big numbers.
    Another characteristic is the email format, which
    indicates whether or not an email has any HTML content,
    such as bolded text.
    We'll focus on email format and spam status using the
    \data{email} data set, and these variables are summarized
    in a two-way table in
    Figure~\ref{emailSpamHTMLTableTotals}.
    Which would be more helpful to someone hoping to classify
    email as spam or regular email for this table:
    row or column proportions?}
  \label{weighingRowColumnProportions}
  A data scientist would be interested in how the proportion
  of spam changes within each email format.
  This corresponds to column proportions:
  the proportion of spam in plain text emails
  and the proportion of spam in HTML emails.

  If we generate the column proportions, we can see
  that a higher proportion of plain text emails are
  spam ($209/1195 = 17.5\%$)
  than compared to HTML emails ($158/2726 = 5.8\%$).
  This information on its own is insufficient to classify
  an email as spam or not spam, as over 80\% of plain text
  emails are not spam.
  Yet, when we carefully combine this information with many
  other characteristics,
  we stand a reasonable chance of being able to classify
  some emails as spam or not spam with confidence.
\end{nexample}
\end{examplewrap}

\begin{figure}[ht]
\centering
\begin{tabular}{l cc r}
  \hline
  & text & HTML & Total \\ 
  \hline
  spam & 209 & 158 & 367 \\ 
  not spam & 986 & 2568 & 3554 \\ 
  \hline
  Total & 1195 & 2726 & 3921 \\
  \hline
\end{tabular}
\caption{A two-way table for \var{spam} and \var{format}.}
\label{emailSpamHTMLTableTotals}
%library(openintro); library(xtable); data(email); tab <- table(email[,c("spam", "format")])[2:1,]; tab; colSums(tab); rowSums(tab)
\end{figure}

Example~\ref{weighingRowColumnProportions} points out
that row and column proportions are not equivalent.
Before settling on one form for a table,
it is important to consider each to ensure that the
most useful table is constructed.  

We will revisit this idea of ``conditioning" on a row or column variable to look for association between two variables in Section~\ref{conditionalProbabilitySection} when we investigate conditional probability.  To determine of the association is ``significant" or not, we will have to wait for Chapter~\ref{ch_inference_for_props}, Inference for categorical data: proportions.

\begin{examplewrap}
\begin{nexample}{Look back to the mosaic plots in Figures~\ref{loan_app_type_home_mosaic} and \ref{loan_app_type_home_mosaic_rev}
    and the tables in Figures~\ref{rowPropAppTypeHomeownership}
    and~\ref{colPropAppTypeHomeownership}.
    Are there any obvious scenarios where one might be more
    useful than the other?}
  None that we thought were obvious!
  What is distinct about \var{app\us{}type}
  and \var{homeownership} vs the email example is that
  these two variables don't have a clear explanatory-response
  variable relationship that we might hypothesize
  (see Section~\ref{explanatoryAndResponse} for these terms).
  Usually it is most useful to ``condition'' on the
  explanatory variable.
  For instance, in the email example, the email format
  was seen as a possible explanatory variable of whether
  the message was spam, so we would find it more interesting
  to compute the relative frequencies (proportions)
  for each email format.
\end{nexample}
\end{examplewrap}

\D{\newpage}

%\Comment{Any risk with the above example that students
%  would think they need not know how to describe (what
%  are effectively) conditional probabilities based
%  on row or column proportions?
%  If so, we could add in an exercise that calls this
%  out and requires them to create such a description.}


\index{data!loans\_full\_schema|)}

\index{data!email|)}

%\D{\newpage}

\subsection*{Section summary}
\begin{itemize}
 
\item A \termni{two-way table}, also called a contingency table, can be used to summarize and
compare data for two categorical variables. The entries in the cells of the table
can be frequencies (i.e., counts) or relative frequencies (i.e., proportions).

\item \termni{Side-by-side bar charts}, \termni{segmented bar charts}, and \termni{mosaic plots} are examples
of graphs used to display the relationship between two categorical variables.
In these graphs, the frequency or relative frequency of each category, or level,
of one of the categorical variables is displayed for each category of the other
categorical variable.

\item Graphical representations of two categorical variables can be used to compare
the relationship of one categorical variable across the levels of the other
categorical variable and determine whether the two variables are associated.

\item Tabular and graphical representations for the distributions of two categorical
variables may reveal information that can be used to justify claims about the
variables in context.

\item A \termni{joint relative frequency} in a two-way table is a cell frequency divided by the
total for the entire table.

\item A \termni{marginal relative frequency} in a two-way table is a row total divided by the
total for the entire table or a column total divided by the total for the entire
table.

\item A \termni{conditional relative frequency} is a relative frequency computed by restricting
to a particular level, or category of interest. A conditional relative frequency can
be a cell frequency in a column divided by the total for that column or it can be a cell
frequency in a row divided by the total for that row.
 
\item Summary statistics for two categorical variables can be used to compare
distributions for evidence of an association between the two variables and may reveal information that
can be used to justify claims about the variable in context.

\end{itemize}




%%%%%%%%%%%Section Exercises
{\input{ch_probability/TeX/relationships_between_two_categorical_variables.tex}}

%______________________________________________
\section[Probability basics]{Probability basics}
\label{basicsOfProbability}


\sectionintro{
\noindent%
What is the probability of rolling an even number on a die?  Of getting 5 heads in row when tossing a coin?  Of drawing a Heart or an Ace from a deck of cards?  The study of probability is fun and interesting in its own right, but it also forms the foundation for statistical models and inferential procedures, many of which we will investigate in upcoming chapters.


\subsection*{Learning objectives}
\begin{enumerate}
\setlength{\itemsep}{0mm}
\item Estimate probabilities using
simulations.


\item Calculate probabilities
for events and their
complements.

\item Justify why two events are
mutually exclusive (or disjoint)
using joint probability.

\item Calculate probabilities for
independent events.

\end{enumerate}
}

\subsection{Introductory examples}

\begin{examplewrap}
\begin{nexample}{A ``die'', the singular of dice, is a cube with six faces numbered \resp{1}, \resp{2}, \resp{3}, \resp{4}, \resp{5}, and \resp{6}. What is the chance of getting \resp{1} when rolling a die?}\label{probOf1}
If the die is fair, then the chance of a \resp{1} is as good as the chance of any other number. Since there are six outcomes, the chance must be 1-in-6 or, equivalently, $1/6$.
\end{nexample}
\end{examplewrap}

\begin{examplewrap}
\begin{nexample}{What is the chance of getting a \resp{1} or \resp{2} in the next roll?}\label{probOf1Or2}
\resp{1} and \resp{2} constitute two of the six equally likely possible outcomes, so the chance of getting one of these two outcomes must be $2/6 = 1/3$.
\end{nexample}
\end{examplewrap}

\begin{examplewrap}
\begin{nexample}{What is the chance of getting either \resp{1}, \resp{2}, \resp{3}, \resp{4}, \resp{5}, or \resp{6} on the next roll?}\label{probOf123456}
100\%. The outcome must be one of these numbers.
\end{nexample}
\end{examplewrap}

\begin{examplewrap}
\begin{nexample}{What is the chance of not rolling a \resp{2}?}\label{probNot2}
Since the chance of rolling a \resp{2} is $1/6$ or $16.\bar{6}\%$, the chance of not rolling a \resp{2} must be $100\% - 16.\bar{6}\%=83.\bar{3}\%$ or $5/6$.

Alternatively, we could have noticed that not rolling a \resp{2} is the same as getting a \resp{1}, \resp{3}, \resp{4}, \resp{5}, or \resp{6}, which makes up five of the six equally likely outcomes and has probability $5/6$.
\end{nexample}
\end{examplewrap}

\D{\newpage}

\begin{examplewrap}
\begin{nexample}{Consider rolling two dice. If $1/6^{th}$ of the time the first die is a \resp{1} and $1/6^{th}$ of those times the second die is a \resp{1}, what is the chance of getting two \resp{1}s?}\label{probOf2Ones}
If $16.\bar{6}$\% of the time the first die is a \resp{1} and $1/6^{th}$ of \emph{those} times the second die is also a \resp{1}, then the chance that both dice are \resp{1} is $(1/6)\times (1/6)$ or $1/36$.
\end{nexample}
\end{examplewrap}

%%
\subsection{Estimating probabilities using simulation}

\index{random process|(}

We use probability to build tools to describe and understand apparent randomness. We often frame probability in terms of a \term{random process} giving rise to an \term{outcome}.  A random process generates results that are determined by chance.  An outcome is the result of one trial of a random process.
\begin{center}
\begin{tabular}{lll}
Roll a die &$\rightarrow$ & \resp{1}, \resp{2}, \resp{3}, \resp{4}, \resp{5}, or \resp{6} \\
Flip a coin &$\rightarrow$ & \resp{H} or \resp{T} \\
\end{tabular}
\end{center}
Rolling a die or flipping a coin is a seemingly random process and each gives rise to an outcome.  

\begin{onebox}{Probability}
The \term{probability} of an outcome is the proportion of times the outcome would occur if we observed the random process an infinite number of times.\end{onebox}

Probability is defined as a proportion, and it always takes values between 0~and~1 (inclusively). It may also be displayed as a percentage between 0\% and 100\%.

An \term{event} is a collection of outcomes.  Probability can be illustrated by rolling a die many times. Consider the event ``roll a 1".   We can use a \term{simulation} to model this event and to estimate the likelihood of the event by calculating the relative frequency of the event.  The \term{relative frequency} of an event is the proportion of times the event occurs out of the number of trials. Let $\hat{p}_n$ be the proportion of outcomes that are \resp{1} after the first $n$ rolls. As the number of rolls increases, $\hat{p}_n$ (the relative frequency of rolls) will converge to the probability of rolling a \resp{1}, $p = 1/6$. Figure~\ref{dieProp} shows this convergence for 100,000 die rolls. The tendency of $\hat{p}_n$ to stabilize around $p$, that~is, the tendency of the relative frequency to stabilize around the true probability, is described by the \term{Law of Large Numbers}.

\begin{figure}[ht]
\centering
\Figure[A line plot is shown. The horizontal axis is "n (number of rolls)", which increases exponentially in values from 1 to 10 to 100 to 1,000 to 10,000 and then to 100,000. The vertical axis is for "p-hat sub n" and has a range from 0.0 to about 0.35. A horizontal dashed line is also shown at one-sixth. The line representing the fraction of rolls that take a value of 1 starts at 0 with the first roll and stays there until it reaches about 4, then it jumps up to 0.25 and bounces around and then up around 0.35 at 10 rolls before decreasing close to one-sixth. Here it bounces between 0.13 and 0.22 up to 100 rolls, and it continues becoming more stable around one-sixth with more rolls, not deviating further than about 0.03 from one-sixth through 1,000 rolls. It continues to get even more stable, not deviating more than about 0.015 from the value of one-sixth through about 5,000 rolls, after which it is nearly indistinguishable from one-sixth for more than 5,000 rolls.]
{0.8}{dieProp}
\caption{The fraction of die rolls that are 1 at each stage in a simulation. The relative frequency tends to get closer to the probability $1/6 \approx 0.167$ as the number of rolls increases.}
\label{dieProp}
\end{figure}

\begin{onebox}{Law of Large Numbers}
The law of large numbers states that for independent trials, as the number of
trials increases, the long-run relative frequency of the outcome or event gets
closer and closer to a single value.\end{onebox}

Occasionally the proportion will veer off from the probability and appear to defy the Law of Large Numbers, as $\hat{p}_n$ does many times in Figure~\ref{dieProp}. However, these deviations become smaller as the number of rolls increases.  

Above we write $p$ as the probability of rolling a \resp{1}. We can also write this probability as
\begin{eqnarray*}
P(\text{rolling a \resp{1}})
\end{eqnarray*}

As we become more comfortable with this notation, we will abbreviate it further. For instance, if it is clear that the process is ``rolling a die'', we could abbreviate $P($rolling a \resp{1}$)$ as~$P($\resp{1}$)$.

\begin{exercisewrap}
\begin{nexercise} \label{randomProcessExercise}
Random processes include rolling a die and flipping a coin. (a) Think of another random process. (b) Describe all the possible outcomes of that process. For instance, rolling a die is a random process with potential outcomes \resp{1}, \resp{2}, ...,~\resp{6}.~\footnotemark
\end{nexercise}
\end{exercisewrap}
\footnotetext{Here are four examples. (i) Whether someone gets sick in the next month or not is an apparently random process with outcomes \resp{sick} and \resp{not}. (ii) We can \emph{generate} a random process by randomly picking a person and measuring that person's height. The outcome of this process will be a positive number. (iii) Whether the stock market goes up or down next week is a seemingly random process with possible outcomes \resp{up}, \resp{down}, and \resp{no\us{}change}. Alternatively, we could have used the percent change in the stock market as a numerical outcome. (iv) Whether your roommate cleans her dishes tonight probably seems like a random process with possible outcomes \resp{cleans\us{}dishes} and \resp{leaves\us{}dishes}.}

What we think of as random processes are not necessarily random, but they may just be too difficult to understand exactly. The fourth example in the footnote solution to Guided Practice~\ref{randomProcessExercise} suggests a roommate's behavior is a random process. However, even if a roommate's behavior is not truly random, modeling her behavior as a random process can still be useful.

\begin{onebox}{Modeling a process as random}
It can be helpful to model a process as random even if it is not truly random.\end{onebox}

\index{random process|)}
%%
\subsection{Sample space and complement of an event}

Rolling a die produces a value in the set $\{$\resp{1}, \resp{2}, \resp{3}, \resp{4}, \resp{5}, \resp{6}$\}$. This set of all possible outcomes is called the \term{sample space} ($S$) for rolling a die. The probability of the sample space is 1: if we roll a die, it will come up as one of the numbers among \resp{1}, \resp{2}, \resp{3}, \resp{4}, \resp{5}, or \resp{6}. Additionally, the probability of any event is always between 0 and 1, inclusive.

We can say that the probability of rolling an even number when rolling a die is 3/6 = 1/2, because there are three possible outcomes that are even (\resp{2}, \resp{4}, \resp{6}) among the six possible outcomes and each of the outcomes in the sample space is equally likely.  More generally, if all outcomes in the sample space are equally likely, then the theoretical probability an event $E$ will occur can be found by dividing the number of outcomes in event $E$ by the total number of outcomes in the sample space.  Probability calculations tend to be more straightforward when each possible outcome is equally likely. However, this is often not the case. For example, while someone playing the lottery can either win or not win, the chance of winning is not 50\%!  

\D{\newpage}

We often use the sample space to examine the scenario where an event does not occur. Let $D=\{$\resp{2}, \resp{3}$\}$ represent the event that the outcome of a die roll is \resp{2} or \resp{3}. Then the \term{complement} represents all outcomes in our sample space that are not in $D$, which is denoted by $D^c = \{$\resp{1}, \resp{4}, \resp{5}, \resp{6}$\}$. That is, $D^c$ is the set of all possible outcomes not already included in $D$. Figure~\ref{complementOfD} shows the relationship between $D$, $D^c$, and the sample space $S$.

\begin{figure}[hht]
\centering
  \Figure[The numbers of 1, 2, 3, 4, 5, and 6 are shown in order. The numbers 2 and 3 are encircled and labeled "D". The numbers 1, 4, 5, and 6 are encircled and labeled "D-to-the-C" for the complement of D. Then there is a larger encircling of all of the numbers that his labeled "S" for the sample space.]
{0.5}{complementOfD}
\caption{Event $D=\{$\resp{2}, \resp{3}$\}$ and its complement, $D^c = \{$\resp{1}, \resp{4}, \resp{5}, \resp{6}$\}$. $S$~represents the sample space, which is the set of all possible events.}
\label{complementOfD}
\end{figure}

\begin{exercisewrap}
\begin{nexercise}
(a) Compute $P(D^c) = P($rolling a \resp{1}, \resp{4}, \resp{5}, or \resp{6}$)$. (b) What is $P(D) + P(D^c)$?\footnotemark
\end{nexercise}
\end{exercisewrap}
\footnotetext{(a)~The outcomes are disjoint and each has probability $1/6$, so the total probability is $4/6=2/3$. (b)~We can also see that $P(D)=\frac{1}{6} + \frac{1}{6} = 1/3$. Because $D$ and $D^c$ are disjoint, $P(D) + P(D^c) = 1$.}

\begin{exercisewrap}
\begin{nexercise}
Events $A=\{$\resp{1}, \resp{2}$\}$ and $B=\{$\resp{4}, \resp{6}$\}$ are shown in Figure~\ref{disjointSets} on page~\pageref{disjointSets}. (a) Write out what $A^c$ and $B^c$ represent. (b)~Compute $P(A^c)$ and $P(B^c)$. (c)~Compute $P(A)+P(A^c)$ and $P(B)+P(B^c)$.\footnotemark\end{nexercise}
\end{exercisewrap}
\footnotetext{Brief solutions: (a)~$A^c=\{$\resp{3}, \resp{4}, \resp{5}, \resp{6}$\}$ and $B^c=\{$\resp{1}, \resp{2}, \resp{3}, \resp{5}$\}$. (b)~Noting that each outcome is disjoint, add the individual outcome probabilities to get $P(A^c)=2/3$ and $P(B^c)=2/3$. (c)~$A$~and~$A^c$ are disjoint, and the same is true of $B$~and~$B^c$. Therefore, $P(A) + P(A^c) = 1$ and $P(B) + P(B^c) = 1$.}


An event $A$ together with its complement $A^c$ comprise the entire sample space. Because of this we can say that $P(A) + P(A^c) = 1$.

\begin{onebox}{Complement}
The complement of event $A$ is denoted $A^c$, and $A^c$ represents all outcomes not in~$A$. $A$ and $A^c$ are mathematically related: \vspace{-2mm}
\begin{eqnarray*}\label{complement}
P(A) + P(A^c) = 1, \quad\text{i.e.}\quad P(A) = 1-P(A^c)
\end{eqnarray*}\vspace{-6.5mm}\end{onebox}

In simple examples, computing $A$ or $A^c$ is feasible in a few steps. However, using the complement can save a lot of time as problems grow in complexity.

\begin{exercisewrap}
\begin{nexercise}
A die is rolled 10 times. (a)~What is the complement of getting at least one 6 in 10 rolls of the die? (b)~What is the complement of getting at most three 6's in 10 rolls of the die?\footnotemark
\end{nexercise}
\end{exercisewrap}
\footnotetext{(a)~The complement of getting at least one 6 in ten rolls of a die is getting zero 6's in the 10 rolls. (b)~The complement of getting at most three 6's in 10 rolls is getting four, five, ..., nine, or ten 6's in 10~rolls.}


\D{\newpage}

%%
\subsection{Disjoint or mutually exclusive outcomes}

\index{disjoint|(}
\index{mutually exclusive|(}

Two outcomes are called \term{disjoint} or \term{mutually exclusive} if they cannot both happen in the same trial. For instance, if we roll a die, the outcomes \resp{1} and \resp{2} are disjoint since they cannot both occur on a single roll. On the other hand, the outcomes \resp{1} and ``rolling an odd number'' are not disjoint since both occur if the outcome of the roll is a \resp{1}. The terms \emph{disjoint} and \emph{mutually exclusive} are equivalent and interchangeable.

Calculating the probability of disjoint outcomes is easy. When rolling a die, the outcomes \resp{1} and \resp{2} are disjoint, and we compute the probability that one of these outcomes will occur by adding their separate probabilities:
\begin{eqnarray*}
P(\text{\resp{1} or \resp{2}}) = P(\text{\resp{1}})+P(\text{\resp{2}}) = 1/6 + 1/6 = 1/3
\end{eqnarray*}
What about  the probability of rolling a \resp{1}, \resp{2}, \resp{3}, \resp{4}, \resp{5}, or \resp{6}? Here again, all of the outcomes are disjoint so we add the probabilities:
\begin{eqnarray*}
&&P(\text{\resp{1} or \resp{2} or \resp{3} or \resp{4} or \resp{5} or \resp{6}}) \\
	&&\quad= P(\text{\resp{1}})+P(\text{\resp{2}})+P(\text{\resp{3}})+P(\text{\resp{4}})+P(\text{\resp{5}})+P(\text{\resp{6}}) \\
	&&\quad= 1/6 + 1/6 + 1/6 + 1/6 + 1/6 + 1/6 = 1.
\end{eqnarray*}
The Addition Rule guarantees the accuracy of this approach when the outcomes are disjoint.

\begin{onebox}{Addition Rule of disjoint outcomes}\index{Addition Rule of disjoint outcomes} If $A_1$ and $A_2$ represent two disjoint outcomes, then the probability that one of them occurs is given by
\begin{eqnarray*}
P(A_1\text{ or } A_2) = P(A_1) + P(A_2)
\end{eqnarray*}
If there are many disjoint outcomes $A_1$, ..., $A_k$, then the probability that one of these outcomes will occur is
\begin{eqnarray*}
P(A_1) + P(A_2) + \cdots + P(A_k)
\end{eqnarray*}
\end{onebox}

\begin{exercisewrap}
\begin{nexercise}
We are interested in the probability of rolling a \resp{1}, \resp{4}, or \resp{5}. (a) Explain why the outcomes \resp{1}, \resp{4}, and \resp{5} are disjoint. (b) Apply the Addition Rule for disjoint outcomes to determine $P($\resp{1} or \resp{4} or \resp{5}$)$.\footnotemark
\end{nexercise}
\end{exercisewrap}
\footnotetext{(a) The random process is a die roll, and at most one of these outcomes can come up. This means they are disjoint outcomes. (b)~$P($\resp{1} or \resp{4} or \resp{5}$) = P($\resp{1}$)+P($\resp{4}$)+P($\resp{5}$) = \frac{1}{6} + \frac{1}{6} + \frac{1}{6} = \frac{3}{6} = \frac{1}{2}$}

\index{data!email|(}
\begin{exercisewrap}
\begin{nexercise}
In the \data{email} data set in Chapter~\ref{ch_one_variable_data}, the \var{number} variable described whether no number (labeled \resp{none}), only one or more small numbers (\resp{small}), or whether at least one big number appeared in an email (\resp{big}). Of the 3,921 emails, 549 had no numbers, 2,827 had only one or more small numbers, and 545 had at least one big number. (a) Are the outcomes \resp{none}, \resp{small}, and \resp{big} disjoint? (b) Determine the proportion of emails with value \resp{small} and \resp{big} separately. (c) Use the Addition Rule for disjoint outcomes to compute the probability a randomly selected email from the data set has a number in it, small or big.\footnotemark
\end{nexercise}
\end{exercisewrap}
\footnotetext{(a) Yes. Each email is categorized in only one level of \var{number}. (b) Small: $\frac{2827}{3921} = 0.721$. Big: $\frac{545}{3921} = 0.139$. (c) $P($\resp{small} or \resp{big}$) = P($\resp{small}$) + P($\resp{big}$) = 0.721 + 0.139 = 0.860$.}
\index{data!email|)}

\D{\newpage}

\index{event|(}

Statisticians rarely work with individual outcomes and instead consider \indexthis{\emph{sets}}{sets} or \indexthis{\emph{collections}}{collections} of outcomes. Let $A$ represent the event where a die roll results in \resp{1} or \resp{2} and $B$~represent the event that the die roll is a \resp{4} or a \resp{6}. We write $A$ as the set of outcomes $\{$\resp{1},~\resp{2}$\}$ and $B=\{$\resp{4}, \resp{6}$\}$. These sets are commonly called \termsub{events}{event}. Because $A$ and $B$ have no elements in common, they are disjoint events. $A$ and $B$ are represented in Figure~\ref{disjointSets}.

\begin{figure}[hhh]
\centering
  \Figure[Six numbers are shown in order: 1, 2, 3, 4, 5, and 6. The numbers 1 and 2 are circled and labeled with the letter "A", the numbers 2 and 3 are circled and labeled with the letter "B", and the numbers 4 and 6 are circled with a label of the letter "C". (This last circle is not an actual circle but is a drawn enclosure that omits the number 5.)]{0.45}{disjointSets}
\caption{Three events, $A$, $B$, and $D$, consist of outcomes from rolling a die. $A$ and $B$ are disjoint since they do not have any outcomes in common.}
\label{disjointSets}
\end{figure}

The Addition Rule applies to both disjoint outcomes and disjoint events. The probability that one of the disjoint events $A$ or $B$ occurs is the sum of the separate probabilities:
\begin{eqnarray*}
P(A\text{ or }B) = P(A) + P(B) = 1/3 + 1/3 = 2/3
\end{eqnarray*}

\begin{exercisewrap}
\begin{nexercise}
(a) Verify the probability of event $A$, $P(A)$, is $1/3$ using the Addition Rule. (b) Do the same for event $B$.\footnotemark
\end{nexercise}
\end{exercisewrap}
\footnotetext{(a) $P(A) = P($\resp{1} or \resp{2}$) = P($\resp{1}$) + P($\resp{2}$) = \frac{1}{6} + \frac{1}{6} = \frac{2}{6} = \frac{1}{3}$. (b) Similarly, $P(B) = 1/3$.}

\begin{exercisewrap}
\begin{nexercise} \label{exerExaminingDisjointSetsABD}
(a) Using Figure~\ref{disjointSets} as a reference, what outcomes are represented by event $D$? (b) Are events $B$ and $D$ disjoint? (c) Are events $A$ and $D$ disjoint?\footnotemark
\end{nexercise}
\end{exercisewrap}
\footnotetext{(a)~Outcomes \resp{2} and \resp{3}. (b)~Yes, events $B$ and $D$ are disjoint because they share no outcomes. (c)~The events $A$ and $D$ share an outcome in common, \resp{2}, and so are not disjoint.}

\begin{exercisewrap}
\begin{nexercise}
In Guided Practice~\ref{exerExaminingDisjointSetsABD}, you confirmed $B$ and $D$ from Figure~\ref{disjointSets} are disjoint. Compute the probability that either event $B$ or event $D$ occurs.\footnotemark
\end{nexercise}
\end{exercisewrap}
\footnotetext{Since $B$ and $D$ are disjoint events, use the Addition Rule: $P(B$ or $D) = P(B) + P(D) = \frac{1}{3} + \frac{1}{3} = \frac{2}{3}$.}

\index{event|)}
\index{disjoint|)}
\index{mutually exclusive|)}



%%
\subsection{Joint probabilies when events are independent}
\label{probabilityIndependence}

Just as variables and observations can be independent, random processes can be independent, too. Two processes are \term{independent} if knowing the outcome of one provides no useful information about the outcome of the other. For instance, flipping a coin and rolling a die are two independent processes -- knowing the coin was heads does not help determine the outcome of a die roll. On the other hand, stock prices usually move up or down together, so they are not independent.  To define independence mathematically, we will have to wait for the discussion of conditional probability in the next section.  

Example~\ref{probOf2Ones} provides a basic example of two independent processes: rolling two dice. We want to determine the probability that both will be \resp{1}. Suppose one of the dice is red and the other white. If the outcome of the red die is a \resp{1}, it provides no information about the outcome of the white die. We first encountered this same question in Example~\ref{probOf2Ones} (page~\pageref{probOf2Ones}), where we calculated the probability using the following reasoning: $1/6^{th}$ of the time the red die is a \resp{1}, and $1/6^{th}$ of \emph{those} times the white die will also be \resp{1}. This is illustrated in Figure~\ref{indepForRollingTwo1s}. Because the rolls are independent, the probabilities of the corresponding outcomes can be multiplied to get the final answer: $(1/6)\times(1/6)=1/36$. This can be generalized to many independent processes.

\D{\newpage}

\begin{figure}[hht]
\centering
\Figure[A black rectangle outlines the graphic and has a label of "All rolls". Inside that rectangle, a vertical strip of the rectangle about one-sixths wide is shaded and labeled with "one-sixth of the first rolls are a 1". A horizontal section representing about one-sixth of that vertical slice is shaded differently and labeled "one-sixth of those times where the first roll is a 1 the second roll is also a 1".]
{0.55}{indepForRollingTwo1s}
\caption{$1/6^{th}$ of the time, the first roll is a \resp{1}. Then $1/6^{th}$ of \emph{those} times, the second roll will also be a \resp{1}.}
\label{indepForRollingTwo1s}
\end{figure}

\begin{examplewrap}
\begin{nexample}{What if there was also a blue die independent of the other two? What is the probability of rolling the three dice and getting all \resp{1}s?}\label{threeDice}
The same logic applies from Example~\ref{probOf2Ones}. If $1/36^{th}$ of the time the white and red dice are both \resp{1}, then $1/6^{th}$ of \emph{those} times the blue die will also be \resp{1}, so multiply:
{\begin{align*}
P(white=\text{\small\resp{1} and } red=\text{\small\resp{1} and } blue=\text{\small\resp{1}})
	&= P(white=\text{\small\resp{1}})\times P(red=\text{\small\resp{1}})\times P(blue=\text{\small\resp{1}}) \\
	&= (1/6)\times (1/6)\times (1/6)
	= 1/216
\end{align*}} \vspace{-4mm}
\end{nexample}
\end{examplewrap}

Examples~\ref{probOf2Ones} and~\ref{threeDice} illustrate what is called the Multiplication Rule for independent processes.

\begin{onebox}{Multiplication Rule for independent processes}\index{Multiplication Rule for independent events}
If $A$ and $B$ represent events from two different and independent processes, then the probability that both $A$ and $B$ occur can be calculated as the product of their separate probabilities: \vspace{-1.5mm}
\begin{eqnarray*}\label{eqForIndependentEvents}
P(A \text{ and }B) = P(A) \times  P(B)
\end{eqnarray*}
Similarly, if there are $k$ events $A_1$, ..., $A_k$ from $k$ independent processes, then the probability they all occur is\vspace{-1.5mm}
\begin{eqnarray*}
P(A_1) \times  P(A_2)\times  \cdots \times  P(A_k)
\end{eqnarray*}\vspace{-6mm}\end{onebox}

\begin{exercisewrap}
\begin{nexercise} \label{ex2Handedness}
About 9\% of people are left-handed. Suppose 2 people are selected at random from the U.S. population. Because the sample size of 2 is very small relative to the population, it is reasonable to assume these two people are independent. (a)~What is the probability that both are left-handed? (b)~What is the probability that both are right-handed?\footnotemark
\end{nexercise}
\end{exercisewrap}
\footnotetext{(a) The probability the first person is left-handed is $0.09$, which is the same for the second person. We apply the Multiplication Rule for independent processes to determine the probability that both will be left-handed: $0.09\times 0.09 = 0.0081$.

(b) It is reasonable to assume the proportion of people who are ambidextrous (both right- and left-handed) is nearly 0, which results in $P($right-handed$)=1-0.09=0.91$. Using the same reasoning as in part~(a), the probability that both will be right-handed is $0.91\times 0.91 = 0.8281$.}

\D{\newpage}

\begin{exercisewrap}
\begin{nexercise} \label{ex5Handedness}
Suppose 5 people are selected at random.\footnotemark{}\D{\vspace{-1.5mm}}
\begin{enumerate}
\setlength{\itemsep}{0mm}
\item[(a)] What is the probability that all are right-handed?
\item[(b)] What is the probability that all are left-handed?
\item[(c)] What is the probability that not all of the people are right-handed?
\end{enumerate}
\end{nexercise}
\end{exercisewrap}
\footnotetext{(a)~The abbreviations \resp{RH} and \resp{LH} are used for right-handed and left-handed, respectively. Since each are independent, we apply the Multiplication Rule for independent processes:
\begin{align*}
P(\text{all five are \resp{RH}})
&= P(\text{first = \resp{RH}, second = \resp{RH}, ..., fifth = \resp{RH}}) \\
&= P(\text{first = \resp{RH}})\times P(\text{second = \resp{RH}})\times  \dots \times P(\text{fifth = \resp{RH}}) \\
&= 0.91\times 0.91\times 0.91\times 0.91\times 0.91 = 0.624
\end{align*}

(b)~Using the same reasoning as in~(a), $0.09\times 0.09\times 0.09\times 0.09\times 0.09 = 0.0000059$

(c)~Use the complement, $P($all five are \resp{RH}$)$, to answer this question:
\begin{align*}
P(\text{not all \resp{RH}})
	= 1 - P(\text{all \resp{RH}})
	= 1 - 0.624 = 0.376
\end{align*}} 

Suppose the variables \var{handedness} and \var{gender} are independent, i.e. knowing someone's \var{gender} provides no useful information about their \var{handedness} and vice-versa. Then we can compute whether a randomly selected person is right-handed and female\footnote{The actual proportion of the U.S. population that is \resp{female} is about 50\%, and so we use 0.5 for the probability of sampling a woman. However, this probability does differ in other countries.} using the Multiplication Rule:
\begin{eqnarray*}
P(\text{right-handed and female}) &=& P(\text{right-handed}) \times  P(\text{female}) \\
&=& 0.91 \times  0.50 = 0.455
\end{eqnarray*}


\begin{exercisewrap}
\begin{nexercise}
Three people are selected at random.\footnotemark \D{\vspace{-1.5mm}}
\begin{enumerate}
\setlength{\itemsep}{0mm}
\item[(a)] What is the probability that the first person is male and right-handed?
\item[(b)] What is the probability that the first two people are male and right-handed?.
\item[(c)] What is the probability that the third person is female and left-handed?
\item[(d)] What is the probability that the first two people are male and right-handed and the third person is female and left-handed?
\end{enumerate}
\end{nexercise}
\end{exercisewrap}
\footnotetext{Brief answers are provided. (a)~This can be written in probability notation as $P($a randomly selected person is male and right-handed$)=0.455$. (b) 0.207. (c) 0.045. (d) 0.0093.}

Sometimes we wonder if one outcome provides useful information about another outcome. The question we are asking is, are the occurrences of the two events independent? We say that two events $A$ and $B$ are independent if they satisfy Equation~\eqref{eqForIndependentEvents}.

\begin{examplewrap}
\begin{nexample}{If we shuffle up a deck of cards and draw one, is the event that the card is a heart independent of the event that the card is an ace?}
The probability the card is a heart is $1/4$ and the probability that it is an ace is $1/13$. The probability the card is the ace of hearts is $1/52$. We check whether Equation~\ref{eqForIndependentEvents} is satisfied:
\begin{align*}
P({\color{redcards}\heartsuit})\times P(\text{ace}) = \frac{1}{4}\times \frac{1}{13} = \frac{1}{52}
					= P({\color{redcards}\heartsuit}\text{ and ace})
\end{align*}
Because the equation holds, the event that the card is a heart and the event that the card is an ace are independent events.
\end{nexample}
\end{examplewrap}


\D{\newpage}

%%
\subsection*{Section summary}

\begin{itemize}

\item A \termni{random process} generates results that are determined by chance.

\item An \termni{outcome} is the result of one trial of a random process.

\item An \termni{event} is a collection of outcomes.

\item \termni{Simulation} is a way to model random events such that the simulated outcomes
closely match real-world outcomes. All possible outcomes are associated with
a value to be determined by chance. Record the counts of simulated outcomes
and the count total.

\item The \termni{probability} of an outcome or event is its long-run relative frequency
that is, its relative frequency over a large number of trials.

\item The \termni{relative frequency} of an outcome or event determined from empirical
data can be used to estimate the actual, or true, probability of that outcome or
event.

\item The \termni{law of large numbers} states that for independent trials, as the number of
trials increases, the long-run relative frequency of the outcome or event gets
closer and closer to a single value.

\item The probability of an event is always between 0 and 1, inclusive.

\item The \termni{sample space} of a random process is the set of all possible
nonoverlapping outcomes. The probability of the sample space is 1.

\item If all outcomes in the sample space are equally likely, then the theoretical
probability an event $E$ will occur can be found by dividing the number of outcomes in event $E$ by the total number of outcomes in the sample space.

\item The probability of the \termni{complement} of an event $E$, which can written as ``not $E$" or $E^c$, is equal to 1$-$ P($E$), i.e. P($E^c$) = 1$-$ P($E$).  This can also be applied as P($E$) = 1$-$ P($E^c$).

\item The probability that events $A$ and $B$ both will occur, that is the \termni{joint probability} of $A$ and $B$, is the probability of the intersection of $A$ and $B$.

\item Two events $A$ and $B$ are \termni{mutually exclusive}, or \termni{disjoint}, if they cannot happen together. In this case, the events do not overlap and $P(A \text { and } B) = 0$.

\item In the \emph{special case} where $A$ and $B$ are \term{disjoint} events:  $P(A \text{ or } B) = P(A) + P(B)$.  

\item When considering only two events, the probability that one \emph{or} the other happens is equal to the probability that \emph{at least one} of the two events happens.  

\item To find the probability that \emph{at least one} of several events occurs, use a special case of the rule of \termsub{complements}{rule of complements}\index{complement}:  $P(\text{at least one}) = 1- P(\text{none})$.  

\item Two events are \term{independent} when the occurrence of one does not change the likelihood of the other.  Outcomes of coin tosses or rolls of a dice are classic examples of independent events.

\item In the \emph{special case} where $A$ and $B$ are \term{independent}:
$P(A \text{ and } B) = P(A)\times P(B)$.

\end{itemize}

%%%%%%%%%Section Exercises
{\input{ch_probability/TeX/probability_basics.tex}}




%_________________
\section[Conditional probability, intersections, and unions]{\D{\hspace{-3.5mm}}Conditional probability, intersections, and unions}
\label{conditionalProbabilitySection}

\sectionintro{
\noindent%
  What is the likelihood that a machine learning
    algorithm will misclassify a photo as being about fashion
    if it is not actually about fashion?     How does the probability of surviving smallpox given being vaccinated compare to the probability of being vaccinated given having survived smallpox? To answer these questions, we investigate conditional probabilities.  We also develop a general formula for ``and" probabilities and a general formula for ``or" probabilities.

%%
\subsection*{Learning objectives}
\begin{enumerate}
\setlength{\itemsep}{0mm}

\item Calculate probabilities using two-way tables and Venn diagrams.

\item Calculate and interpret conditional probabilities.

\item Use a tree diagram along with the conditional probability rule to solve ``inverted" conditional probabilities.

\item Calculate the probability of joint events whether or not the events are independent.

\item Calculate the probability of the union of two events, whether or not the events are mutually exclusive.

\item Determine whether two events are independent and whether they are mutually exclusive.


\end{enumerate} 
}


%%
\subsection{Exploring probabilities with a two-way table}

\index{data!photo\_classify|(}

\newcommand{\fashN}{1822}
% In order of ML, then Human
\newcommand{\fashYY}{197}
\newcommand{\fashYN}{22}
\newcommand{\fashYA}{219}
\newcommand{\fashNY}{112}
\newcommand{\fashNN}{1491}
\newcommand{\fashNA}{1603}
\newcommand{\fashAY}{309}
\newcommand{\fashAN}{1513}
\newcommand{\fashAA}{\fashN{}}
%\newcommand{\fashPYY}{}
%\newcommand{\fashPYN}{}
%\newcommand{\fashPNY}{}
%\newcommand{\fashPNN}{}
%\newcommand{\fashPYA}{0.12}
%\newcommand{\fashPNA}{0.88}
%\newcommand{\fashPAY}{}
%\newcommand{\fashPAN}{}
%\newcommand{\fashPYCY}{}
%\newcommand{\fashPYCN}{}
%\newcommand{\fashPNCY}{}
%\newcommand{\fashPNCN}{}
\newcommand{\fashCYPY}{0.96}
\newcommand{\fashCYPN}{0.04}
\newcommand{\fashCNPY}{0.07}
\newcommand{\fashCNPN}{0.93}

The \data{photo\us{}classify} data set represents
a sample of \fashN{} photos from a photo sharing website.
Data scientists have been working to improve a classifier for
whether the photo is about fashion or not, and these 659 photos
represent a test for their classifier.
Each photo gets two classifications:
the first is called \var{mach\us{}learn} and gives
a classification from a machine
learning~(ML)\index{machine learning (ML)} system of
either \resp{pred\us{}fashion} or \resp{pred\us{}not}.
Each of these \fashN{} photos have also been classified carefully
by a team of people, which we take to be the source of truth;
this variable is called \var{truth} and takes values
\resp{fashion} and \resp{not}.
Figure~\ref{contTableOfFashionPhotos} summarizes the results.

\begin{figure}[ht]
\centering
\begin{tabular}{ll ccc rr}
&& \multicolumn{2}{c}{\var{truth}} & \hspace{1cm} &  \\
\cline{3-4}
&& \resp{fashion} & \resp{not} & Total  \\
\cline{2-5}
& \resp{pred\us{}fashion} &
    \fashYY{} & \fashYN{} & \fashYA{} \\
\raisebox{1.5ex}[0pt]{\var{mach\us{}learn}}
    & \resp{pred\us{}not} \hspace{0.5cm} &
    \fashNY{} & \fashNN{} & \fashNA{}   \\
\cline{2-5}
& Total & \fashAY{} & \fashAN{} & \fashN{} \\
\end{tabular}
\caption{two-way table summarizing the
    \data{photo\us{}classify} data set.}
\label{contTableOfFashionPhotos}
\end{figure}
% library(openintro); table(photo_classify)

\begin{figure}[ht]
  \centering
  \Figure[A Venn diagram is shown, using boxes instead of circles, for the two categories of "ML Predicts Fashion" and "Fashion Photos" that partially overlap. The section of the rectangle for ML Predicts Fashion that is non-overlapping is labeled with 0.01. The section of the rectangle for Fashion Photos that is non-overlapping is labeled with 0.06. The overlapping section is labeled with 0.11. Outside of the rectangles is a label for "Neither" with a value 0.82.]
{0.6}{photoClassifyVenn}
  \caption{A Venn diagram using boxes for the \data{photo\us{}classify} data set.}
  \label{photoClassifyVenn}
\end{figure}

\begin{examplewrap}
\begin{nexample}{If a photo is actually about fashion,
    what is the chance the ML classifier correctly identified
    the photo as being about fashion?}
  We can estimate this probability using the data.
  Of the \fashAY{} fashion photos,
  the ML algorithm correctly classified \fashYY{} of the photos:
\begin{align*}
P(\text{\var{mach\us{}learn} is \resp{pred\us{}fashion}
    given \var{truth} is \resp{fashion}})
  = \frac{\fashYY{}}{\fashAY{}}
  = 0.638
\end{align*}
\end{nexample}
\end{examplewrap}

\begin{examplewrap}
\begin{nexample}{We sample a photo from the data set
    and learn the ML algorithm predicted this photo
    was not about fashion.
    What is the probability that it was incorrect and
    the photo is about fashion?}
  If the ML classifier suggests a photo is not about fashion,
  then it comes from the second row in the data set.
  Of~these \fashNA{} photos, \fashNY{} were actually
  about fashion:
\begin{align*}
P(\text{\var{truth} is \resp{fashion}
    given \var{mach\us{}learn} is \resp{pred\us{}not}})
  = \frac{\fashNY{}}{\fashNA{}}
  = 0.070
\end{align*}
\end{nexample}
\end{examplewrap}


%
\subsection{Marginal and joint probabilities}
\label{marginalAndJointProbabilities}

\index{marginal probability|(}
\index{joint probability|(}

Figure~\ref{contTableOfFashionPhotos} includes row and
column totals for each variable separately in the
\data{photo\us{}classify} data set.
These totals represent
\termsub{marginal probabilities}{marginal probability}
for the sample, which are the probabilities based on a
single variable without regard to any other variables.
For instance, a probability based solely on the
\var{mach\us{}learn} variable is a marginal probability:
\begin{align*}
P(\text{\var{mach\us{}learn} is \resp{pred\us{}fashion}})
    = \frac{\fashYA{}}{\fashN{}}
    = 0.12
\end{align*}
A probability of outcomes for two or more variables
or processes is called a
\termsub{joint \mbox{probability}}{joint probability}:
\begin{align*}
P(\text{\var{mach\us{}learn} is \resp{pred\us{}fashion}
    and \var{truth} is \resp{fashion}})
  = \frac{\fashYY{}}{\fashN{}}
  = 0.11
\end{align*}
It is common to substitute a comma for ``and'' in a joint
probability, although using either the word ``and'' or a
comma is acceptable:
\begin{center}
$P(\text{\var{mach\us{}learn} is \resp{pred\us{}fashion},
    \var{truth} is \resp{fashion}})$ \\[2mm]
means the same thing as \\[2mm]
$P(\text{\var{mach\us{}learn} is \resp{pred\us{}fashion}
    and \var{truth} is \resp{fashion}})$
\end{center}

\begin{onebox}{Marginal and joint probabilities}
  If a probability is based on a single variable,
  it is a \emph{\hiddenterm{marginal probability}}.
  The probability of outcomes for two or more variables
  or processes is called a \emph{\hiddenterm{joint probability}}.
\end{onebox}

\D{\newpage}

We use \term{table proportions} to summarize joint probabilities
for the \data{photo\us{}classify} sample.
These proportions are computed by dividing each count in
Figure~\ref{contTableOfFashionPhotos} by the table's total,
\fashN{}, to obtain the proportions in
Figure~\ref{photoClassifyProbTable}.
The joint probability distribution of the \var{mach\us{}learn}
and \var{truth} variables is shown in
Figure~\ref{photoClassifyDistribution}.

\begin{figure}[h]
\centering
\begin{tabular}{l rr r}
\hline
& \var{truth}: \resp{fashion} &
    \var{truth}: \resp{not} & Total  \\
\hline
\var{mach\us{}learn}: \resp{pred\us{}fashion} \hspace{0.5cm}
    & 0.1081 & 0.0121 & 0.1202 \\
\var{mach\us{}learn}: \resp{pred\us{}not}
    & 0.0615 & 0.8183 & 0.8798  \\
\hline
Total & 0.1696 & 0.8304 & 1.00 \\
\hline
\end{tabular}
\caption{Probability table summarizing the
    \var{photo\us{}classify} data set.}
\label{photoClassifyProbTable}
\end{figure}

\begin{figure}[h]
\centering
\begin{tabular}{l c}
  \hline
Joint outcome & Probability \\
  \hline
\var{mach\us{}learn} is \resp{pred\us{}fashion}
    and \var{truth} is \resp{fashion} & 0.1081 \\
\var{mach\us{}learn} is \resp{pred\us{}fashion}
    and \var{truth} is \resp{not} & 0.0121 \\
\var{mach\us{}learn} is \resp{pred\us{}not}
    and \var{truth} is \resp{fashion} & 0.0615 \\
\var{mach\us{}learn} is \resp{pred\us{}not}
    and \var{truth} is \resp{not} & 0.8183 \\
   \hline
Total & 1.0000 \\
\hline
\end{tabular}
\caption{Joint probability distribution for the \data{photo\us{}classify} data set.}
\label{photoClassifyDistribution}
\end{figure}


\begin{exercisewrap}
\begin{nexercise}
Verify Figure~\ref{photoClassifyDistribution} represents
a probability distribution: events are disjoint,
all probabilities are non-negative, and the probabilities
sum to~1.\footnotemark
\end{nexercise}
\end{exercisewrap}
\footnotetext{Each of the four outcome combination are disjoint,
   all probabilities are indeed non-negative, and the sum of
   the probabilities is $0.1081 + 0.0121 + 0.0615 + 0.8183 = 1.00$.}

We can compute marginal probabilities using joint probabilities
in simple cases.
For example, the probability that a randomly selected photo from the
data set is about fashion is found by summing the outcomes in which \var{truth} takes value \resp{fashion}:%
\index{marginal probability|)}\index{joint probability|)}
\newcommand{\ultruthfashion}[0]
    {\underline{\var{truth} is \resp{fashion}}}%
\begin{align*}
P(\text{\ultruthfashion{}})
  &= P(\text{\var{mach\us{}learn} is \resp{pred\us{}fashion}
        and \ultruthfashion{}}) \\
    & \qquad + P(\text{\var{mach\us{}learn} is \resp{pred\us{}not}
        and \ultruthfashion{}}) \\
  &= 0.1081 + 0.0615 \\
  &= 0.1696
\end{align*}


\subsection{Defining conditional probability}

\index{conditional probability|(}

The ML classifier predicts whether a photo is about fashion,
even if it is not perfect.
We would like to better understand how to use information
from a variable like \var{mach\us{}learn} to improve our
probability estimation of a second variable, which in this
example is \var{truth}.

The probability that a random photo from the data set is about
fashion is about 0.17.
If we knew the machine learning classifier predicted the
photo was about fashion, could we get a better estimate of the
probability the photo is actually about fashion?
Absolutely.
To do so, we limit our view to only those \fashYA{} cases
where the ML classifier predicted that the photo was about
fashion and look at the fraction where the photo was actually
about fashion:
\begin{align*}
P(\text{\var{truth} is \resp{fashion} given
    \var{mach\us{}learn} is \resp{pred\us{}fashion}})
  = \frac{\fashYY{}}{\fashYA{}}
  = 0.900
\end{align*}
We call this a \term{conditional probability} because
we computed the probability under a condition:
the ML classifier prediction said the photo was about fashion.

\D{\newpage}

There are two parts to a conditional probability,
the \term{outcome of interest} and the \term{condition}.
It is useful to think of the condition as information we know
to be true, and this information usually can be described as
a known outcome or~event.
We generally separate the text inside our probability notation
into the outcome of interest and the condition with a
vertical bar:
\begin{align*}
&& P(\text{\var{truth} is \resp{fashion} given
    \var{mach\us{}learn} is \resp{pred\us{}fashion}}) \\
&& \quad = P(\text{\var{truth} is \resp{fashion}\ }|
    \text{\ \var{mach\us{}learn} is \resp{pred\us{}fashion}})
  = \frac{\fashYY{}}{\fashYA{}}
  = 0.900
\end{align*}
The vertical bar ``$|$'' is read as \emph{given}.


In the last equation, we computed the probability a photo
was about fashion based on the condition that the ML algorithm
predicted it was about fashion as a fraction:
\begin{align*}
& P(\text{\var{truth} is \resp{fashion}\ }|
    \text{\ \var{mach\us{}learn} is \resp{pred\us{}fashion}}) \\
  &\quad = \frac{\text{\# cases where \var{truth} is \resp{fashion}
       and \var{mach\us{}learn} is \resp{pred\us{}fashion}}}
     {\text{\# cases where \var{mach\us{}learn} is \resp{pred\us{}fashion}}}\\
  &\quad = \frac{\fashYY{}}{\fashYA{}}
      = 0.900
\end{align*}
We considered only those cases that met the condition,
\var{mach\us{}learn} is \resp{pred\us{}fashion}, and then
we computed the ratio of those cases that satisfied our
outcome of interest, photo was actually about fashion.

Frequently, marginal and joint probabilities are provided
instead of count data.
For example, disease rates are commonly listed in percentages
rather than in a count format.
We would like to be able to compute conditional probabilities
even when no counts are available, and we use the last equation
as a template to understand this technique.

We considered only those cases that satisfied the condition,
where the ML algorithm predicted fashion.
Of these cases, the conditional probability was the
fraction representing the outcome of interest, that the
photo was about fashion.
Suppose we were provided only the information in
Figure~\ref{photoClassifyProbTable}, i.e. only probability data.
Then if we took a sample of 1000 photos, we would anticipate
about 12.0\% or $0.120\times 1000 = 120$ would be predicted to be
about fashion (\var{mach\us{}learn} is \resp{pred\us{}fashion}).
Similarly, we would expect about 10.8\% or
$0.108\times 1000 = 108$ to meet both the information criteria
and represent our outcome of interest.
Then the conditional probability can be computed as
\begin{align*}
&P(\text{\var{truth} is \resp{fashion}}\ |\ 
    \text{\var{mach\us{}learn} is \resp{pred\us{}fashion}}) \\
  &= \frac{\text{\# (\var{truth} is \resp{fashion}
      and \var{mach\us{}learn} is \resp{pred\us{}fashion})}}
    {\text{\# (\var{mach\us{}learn} is \resp{pred\us{}fashion})}} \\
  &= \frac{108}{120}
		= \frac{0.108}{0.120}
		= 0.90
\end{align*}
Here we are examining exactly the fraction of two probabilities,
0.108 and 0.120, which we can write as
\begin{align*}
P(\text{\var{truth} is \resp{fashion} and
    \var{mach\us{}learn} is \resp{pred\us{}fashion}})
\quad\text{and}\quad
P(\text{\var{mach\us{}learn} is \resp{pred\us{}fashion}}).
\end{align*}
The fraction of these probabilities is an example of the
general formula for conditional probability.

\begin{onebox}{Conditional probability}
  The conditional probability of the outcome of interest $A$
  given condition $B$ is computed as the following:
  \begin{align*}
  P(A | B) = \frac{P(A\text{ and }B)}{P(B)}
  \end{align*}
\end{onebox}

\D{\newpage}

\begin{exercisewrap}
\begin{nexercise}
\label{fashionProbOfMLNotGivenTruthNot}%
(a) Write out the following statement in conditional
probability notation:
``\emph{The probability that the ML prediction was correct,
if the photo was about fashion}''.
Here the condition is now based on the photo's
\var{truth} status, not the ML algorithm. \\[1mm]
(b)~Determine the probability from part (a).
Figure~\vref{photoClassifyProbTable} may be helpful.\footnotemark
\end{nexercise}
\end{exercisewrap}
\footnotetext{(a) If the photo is about fashion and the
  ML algorithm prediction was correct, then the ML algorithm
  my have a value of \resp{pred\us{}fashion}:
  $P(\text{\var{mach\us{}learn} is \resp{pred\us{}fashion}}\ |
      \ \text{\var{truth} is \resp{fashion}})$
  (b)~The equation for conditional probability indicates we
  should first find
  $P(\text{\var{mach\us{}learn} is \resp{pred\us{}fashion}
    and \var{truth} is \resp{fashion}}) = 0.1081$
  and $P(\text{\var{truth} is \resp{not}}) = 0.1696$.
  Then the ratio represents the conditional probability:
  $0.1081 / 0.1696 = 0.6374$.}

\begin{exercisewrap}
\begin{nexercise}
\label{whyCondProbSumTo1}%
(a)~Determine the probability that the algorithm is incorrect
if it is known the photo is about fashion. \\[1mm]
(b)~Using the answers from part~(a) and
Guided Practice~\ref{fashionProbOfMLNotGivenTruthNot}(b),
compute
\begin{align*}
&P(\text{\var{mach\us{}learn} is \resp{pred\us{}fashion}}
    \ |\ \text{\var{truth} is \resp{fashion}}) \\
&\qquad  +\ P(\text{\var{mach\us{}learn} is \resp{pred\us{}not}}
    \ |\ \text{\var{truth} is \resp{fashion}})
\end{align*}
(c)~Provide an intuitive argument to explain why the sum
in~(b) is~1.\footnotemark
\end{nexercise}
\end{exercisewrap}
\footnotetext{(a)~This probability is
  $\frac{P(\text{\var{mach\us{}learn} is \resp{pred\us{}not},
      \var{truth} is \resp{fashion}})}
    {P(\text{\var{truth} is \resp{fashion}})}
  = \frac{0.0615}{0.1696} = 0.3626$.
  (b)~The total equals~1.
  (c)~Under the condition the photo is about fashion,
      the ML algorithm must have either predicted it was
      about fashion or predicted it was not about fashion.
      The complement still works for conditional probabilities,
      provided the probabilities are conditioned on the same
      information.}

\index{conditional probability|)}
\index{data!photo\_classify|)}

\index{data!smallpox|(}

The \data{smallpox} data set provides a sample of 6,224 individuals from the year 1721 who were exposed to smallpox in Boston.\footnote{Fenner F. 1988. \emph{Smallpox and Its Eradication (History of International Public Health, No. 6)}. Geneva: World Health Organization. ISBN 92-4-156110-6.} Doctors at the time believed that inoculation, or vaccination that involved exposing a person to the disease in a controlled form, could reduce the likelihood of death.

Each case represents one person with two variables: \var{inoculated} and \var{result}. The variable \var{inoculated} takes two levels: \resp{yes} or \resp{no}, indicating whether the person was inoculated or not. The variable \var{result} has outcomes \resp{lived} or \resp{died}. These data are summarized in Tables~\ref{smallpoxContingencyTable} and~\ref{smallpoxProbabilityTable}.

\begin{figure}[h]
\centering
\begin{tabular}{ll rr r}
& & \multicolumn{2}{c}{inoculated} & \\
\cline{3-4}
& & \resp{yes} & \resp{no} & Total  \\
\cline{2-5}
		& \resp{lived}     & 238 & 5136 & 5374 \\
\raisebox{1.5ex}[0pt]{\var{result}} &  \resp{died} \hspace{0.5cm} & 6 & 844 & 850  \\
\cline{2-5}
	& Total & 244 & 5980 & 6224 \\
\end{tabular}
\caption{Contingency table for the \data{smallpox} data set.}
\label{smallpoxContingencyTable}
\end{figure}

\begin{figure}[h]
\centering
\begin{tabular}{ll rr r}
& & \multicolumn{2}{c}{inoculated} & \\
\cline{3-4}
& & \resp{yes} & \resp{no} & Total  \\
   \cline{2-5}
 & \resp{lived}     & 0.0382 & 0.8252 & 0.8634 \\
\raisebox{1.5ex}[0pt]{\var{result}} & \resp{died} \hspace{0.5cm} & 0.0010 & 0.1356  & 0.1366  \\
   \cline{2-5}
& Total & 0.0392 & 0.9608 & 1.0000 \\
\end{tabular}
\caption{Table proportions for the \data{smallpox} data, computed by dividing each count by the table total, 6224.}
\label{smallpoxProbabilityTable}
\end{figure}

\begin{exercisewrap}
\begin{nexercise} \label{probDiedIfNotInoculated}
Write out, in formal notation, the probability a randomly selected person who was not inoculated died from smallpox, and find this \mbox{probability.}\footnotemark
\end{nexercise}
\end{exercisewrap}
\footnotetext{$P($\var{result} = \resp{died} $|$ \resp{not inoculated}$) = \frac{P(\text{\var{result} = \resp{died} and \resp{not inoculated}})}{P(\text{\resp{not inoculated}})} = \frac{0.1356}{0.9608} = 0.1411$.}

\D{\newpage}

\begin{exercisewrap}
\begin{nexercise}
Determine the probability that an inoculated person died from smallpox. How does this result compare with the result of Guided Practice~\ref{probDiedIfNotInoculated}?\footnotemark
\end{nexercise}
\end{exercisewrap}
\footnotetext{$P($\resp{died} $|$ \resp{inoculated}$) = \frac{P(\text{\resp{died} and \resp{inoculated}})}{P(\text{\resp{inoculated}})} = \frac{0.0010}{0.0392} = 0.0255$. The death rate for individuals who were inoculated is only about 1~in~40 while the death rate is about 1~in~7 for those who were not inoculated.}\D{\vspace{-5mm}}

\begin{exercisewrap}
\begin{nexercise}\label{SmallpoxInoculationObsExpExercise}
The people of Boston self-selected whether or not to be inoculated. (a) Is this study observational or was this an experiment? (b) Can we draw a causal conclusion using these data? (c) What is a potential confounding variable that might influence whether someone lived or died and also affect whether that person was inoculated?\footnotemark
\end{nexercise}
\end{exercisewrap}
\footnotetext{Brief answers: (a)~Observational. (b)~No, we cannot draw a causal conclusion from this observational study.  (However, further research has shown that inoculation is effective at reducing death rates.) (c)~Accessibility to the latest and best medical care, so income could be a confounding variable. There are other valid answers for part~(c).}\D{\vspace{-5mm}}
\index{data!smallpox|)}


%%
\subsection{General multiplication rule for joint probabilities}

When finding joint probabilities, we can use the General Multiplication Rule.

\begin{onebox}{General Multiplication Rule}
If $A$ and $B$ represent two outcomes or events, then to find the joint probability $A$ and $B$ we use: \vspace{-1.5mm}
\begin{eqnarray*}
P(A \cap B) = P(A)\times P(B | A)
\end{eqnarray*} \vspace{-6.5mm} \par
\end{onebox}
This General Multiplication Rule can also be seen as a rearrangement of the conditional probability rule:  $ P(B | A) = \frac{P(A \cap B)}{P(A)}$.

\begin{examplewrap}
\begin{nexample}{Consider the \data{smallpox} data set. Suppose we are given only two pieces of information: 96.08\% of residents were not inoculated, and 85.88\% of the residents who were not inoculated ended up surviving. How could we compute the probability that a resident was not inoculated and lived?}
We will compute our answer using the General Multiplication Rule and then verify it using Figure~\ref{smallpoxProbabilityTable}. We want to determine
\begin{eqnarray*}
P(\text{\resp{not inoculated} and \resp{lived}})
\end{eqnarray*}
and we are given:
\begin{eqnarray*}
P(\text{\resp{not inoculated}})=0.9608\\
P(\text{\resp{lived}}\ |\ \text{\resp{not inoculated}})=0.8588
\end{eqnarray*}
Among the 96.08\% of people who were not inoculated, 85.88\% survived, so:
\begin{eqnarray*}
P(\text{\resp{not inoculated} and \resp{lived}}) =  0.9608 \times 0.8588 = 0.825.
\end{eqnarray*}
This is equivalent to the General Multiplication Rule. We can confirm this probability in Figure~\ref{smallpoxProbabilityTable} at the intersection of \resp{no} and \resp{lived} (with a small rounding error).
\end{nexample}
\end{examplewrap}

\D{\newpage}

\begin{exercisewrap}
\begin{nexercise}
Use $P($\resp{inoculated}$) = 0.0392$ and $P($\resp{lived} $|$ \resp{inoculated}$) = 0.9754$ to determine the probability that a person was both inoculated and lived.\footnotemark
\end{nexercise}
\end{exercisewrap}
\footnotetext{The answer is 0.0382, which can be verified using Figure~\ref{smallpoxProbabilityTable}.}\D{\vspace{-2mm}}

\begin{exercisewrap}
\begin{nexercise}
If 97.54\% of the inoculated people lived, what proportion of inoculated people must have~died?\footnotemark{}
\end{nexercise}
\end{exercisewrap}
\footnotetext{There were only two possible outcomes: \resp{lived} or \resp{died}. This means that 100\% - 97.54\% = 2.46\% of the people who were inoculated died.}\D{\vspace{-2mm}}




%%
\subsection{Tree diagrams and inverted conditional probabilities}
\label{bayesTheoremSubsection}


\index{tree diagram|(}

\termsub{Tree diagrams}{tree diagram} are a tool to organize outcomes and probabilities around the structure of the data. They are most useful when two or more processes occur in a sequence and each process is conditioned on its predecessors.

The \data{smallpox} data fit this description. We see the population as split by \var{inoculation}: \mbox{\resp{inoculated}} and \resp{not\,inoculated}. Following this split, survival rates were observed for each group. This structure is reflected in the tree diagram shown in Figure~\ref{smallpoxTreeDiagram}. The first branch for \var{inoculation} is said to be the \term{primary} branch while the other branches are \term{secondary}.

\begin{figure}[ht]
\centering
\Figures[A tree diagram with a primary branch "Inoculation" and a secondary branch "Result". The Inoculated primary branching leads to two options: "Inoculated" with a probability of 0.0392 and "Not inoculated" with a probability of 0.9608. Each of these branches has secondary branches with conditional probabilities for the "Result" conditional on "Inoculated". The Inoculated branch breaks into branches for "Lived" (0.9754) and "Died" (0.0246). Next, turning our attention to the "Not inoculated" primary branch, it also has secondary branches of Lived and Died with conditional probabilities 0.8589 and 0.1411, respectively.]
{0.85}{smallpoxTreeDiagram}{smallpoxTreeDiagramReduced}
\caption{A tree diagram of the \data{smallpox} data set.}
\label{smallpoxTreeDiagram}
\end{figure}

Tree diagrams are annotated with probabilities for the primary and secondary branches, as shown in Figure~\ref{smallpoxTreeDiagram}. This tree diagram splits the smallpox data by \var{inoculation} into \mbox{\resp{inoculated}} and \resp{not\,inoculated} with respective probabilities 0.0392 and 0.9608. The secondary branches are conditioned on the first, so we assign conditional probabilities to these branches.
For example, the top secondary branch in Figure~\ref{smallpoxTreeDiagram} is the probability of \resp{lived} conditioned on \resp{inoculated}.

To calculate a joint probability, we use the General Multiplication Rule.  For example:
\begin{align*}
P(\text{\var{inoculated} and \resp{lived}}) &= P(\text{\var{inoculated}})\times P(\text{\resp{lived}}\ |\ \text{\var{inoculated}}) \\
	&= 0.0392\times 0.9754 \\
	&=0.0382
\end{align*}

\D{\newpage}

\begin{examplewrap}
\begin{nexample}{What is the probability that a randomly selected person lived?}There are two ways that a person could have lived:  be inoculated \emph{and} lived OR not be inoculated \emph{and} lived. To find this probability, we sum the two disjoint probabilities:
\begin{align*}
P(\text{\resp{lived}}) &= P(\text{\resp{inoculated} \text{ and } \resp{lived}}) + P(\text{\resp{not\,inoculated} \text{ and } \resp{lived}}) \\
&=0.0392 \times 0.9754 + 0.9608 \times 0.8589 \\
&= 0.0382 + 0.8252 \\
&= 0.8634
\end{align*}
\end{nexample}
\end{examplewrap}

\begin{examplewrap}
\begin{nexample}{What is the probability that a randomly selected person who was inoculated lived?}This is equivalent to asking the proportion that lived among those who were inoculated.  This probability can be written as $P(\text{\resp{lived}}\ |\ \text{\var{inoculated}})$ and can be found in the second branch as 0.9754.
\end{nexample}
\end{examplewrap}

Now, instead of asking the probability that a randomly selected person who was inoculated lived, we might want to know the probability that a randomly selected person who lived was inoculated.  That is, instead of $P(\text{\resp{lived}}\ |\ \text{\var{inoculated}})$, we want to find $P(\text{\var{inoculated}}\ |\ \text{\resp{lived}})$. This is more challenging because it cannot be read directly from the tree diagram. However, we can apply the conditional probability rule to find this ``inverted" conditional probability.  

\begin{align*}
P(\text{\resp{inoculated}}\ |\ \text{\var{lived}})  &= \frac{P(\text{\var{inoculated} and \resp{lived}})}{P(\text{\resp{lived}})} \\[1mm]
  &=\frac{0.0392 \times 0.9754}{0.0392 \times 0.9754 + 0.9608 \times 0.8589}\\[2mm]
  &=\frac{0.0382}{0.8634}\\[2mm]
  &= 0.0442
\end{align*}

You might be surprised to see that $P(\text{\var{inoculated}}\ |\ \text{\resp{lived}})$ is only 0.0442 while the probability $P(\text{\resp{lived}}\ |\ \text{\var{inoculated}})$ is 0.9754.  While most people who were inoculated lived, it is not true that most people who lived were inoculated. These two conditional probabilities are very different because the subset \resp{lived} is much larger than the subset \var{inoculated}.

We can also observe that the events ``inoculated" and ``lived" are dependent.  The conditional probability that someone was inoculated given that they lived (0.0442) is greater than the unconditional probability that someone was inoculated (0.0392).

\begin{exercisewrap}
\begin{nexercise}What is the probability that a random selected person who died was inoculated?\footnotemark
\end{nexercise}
\end{exercisewrap}
\footnotetext{
This is equivalent to $P(\text{\resp{inoculated}}\ |\ \text{\var{died}})$. This conditional probability can be found as $\frac{P(\text{\var{inoculated} and \resp{died}})}{P(\text{\resp{died}})} = \frac{0.0392 \times 0.0246}{0.0392 \times 0.0246 \ +\ 0.9608 \times 0.1411} = \frac{0.00096}{0.13653} = 0.0070$. Among those who died, only 0.70\% were inoculated. }

\D{\newpage}

\begin{examplewrap}
\begin{nexample} 
{Jose visits campus every Thursday evening. However, some days the parking garage is full, often due to college events. There are academic events on 35\% of evenings, sporting events on 20\% of evenings, and no events on 45\% of evenings. When there is an academic event, the garage fills up about 25\% of the time, and it fills up 70\% of evenings with sporting events. On evenings when there are no events, it only fills up about 5\% of the time. If Jose comes to campus and finds the garage full, what is the probability that there is a sporting event? Use a tree diagram to solve this problem.}
The tree diagram, with three primary branches, is shown below. \\
\Figures[A tree diagram with a primary branch "Event" and a secondary branch "Garage full". The primary "Event" branching has three possibilities of "Academic" with probability 0.35, "Sporting" with probability 0.20, and "None" with probability 0.45. Each of these three branches has two secondary branches. The "Academic" primary branch breaks into branches for "Full" that has a conditional probability of 0.25, and a "Spaces Available" secondary branch with a conditional probability of 0.75. The "Sporting" primary branch breaks into branches for "Full" that has a conditional probability of 0.7, and a "Spaces Available" secondary branch with a conditional probability of 0.3. The "None" primary branch breaks into branches for "Full" that has a conditional probability of 0.05, and a "Spaces Available" secondary branch with a conditional probability of 0.95.]
{.9}{treeDiagramGarage}{treeDiagramGarageReduced}

We want to find the probability that there is a sporting event given that the garage is full.
\begin{align*}
P(\text{sporting event} \ |\ \text{garage full}) &= \frac{P(\text{sporting event and garage full})}{P(\text{garage full})} \\[1mm]
&=\frac{0.20\times 0.7}{0.35\times 0.25 + 0.20\times 0.7 + 0.45\times 0.05}\\[2mm]
&=\frac{0.14}{0.0875 + 0.14 + 0.0225}\\[2mm]
&= 0.56.
\end{align*}
If the garage is full, there is a 56\% probability that there is a sporting event. \vspace{0.1mm} \\\

\end{nexample}
\end{examplewrap}

This example offers a way to update our belief about whether there is a sporting event, academic event, or no event going on at the school based on the information that the parking lot is full. This strategy of \emph{updating beliefs} is the foundation of an entire theory of statistics called \term{Bayesian statistics}. While Bayesian statistics has many applications, we will not have time to cover it in this book.

\index{tree diagram|)}
\index{conditional probability|)}


\D{\newpage}

%%
\subsection{Sampling without replacement}
\label{smallPop}
\index{without replacement}

\begin{examplewrap}
\begin{nexample}{Professors sometimes select a student at random to answer a question. If each student has an equal chance of being selected and there are 15 people in your class, what is the chance that you will get selected for the next question?}
If there are 15 people to ask and none are skipping class, then the probability is $1/15$, or about $0.067$.
\end{nexample}
\end{examplewrap}

\begin{examplewrap}
\begin{nexample}{If the professor asks 3 questions, what is the probability that you will not be selected? Assume that she will not pick the same person twice in a given lecture.}\label{3woRep}
For the first question, she will pick someone else with probability $14/15$. When she asks the second question, she only has 14 people who have not yet been asked. Thus, if you were not picked on the first question, the probability you are again not picked is $13/14$. Similarly, the probability you are again not picked on the third question is $12/13$, and the probability of not being picked for any of the three questions is
\begin{eqnarray*}
&&P(\text{not picked in 3 questions}) \\
&&\quad = P(\text{\var{Q1}} = \text{\resp{not\us{}picked}\text{ and }}\text{\var{Q2}} = \text{\resp{not\us{}picked}\text{ and }}\text{\var{Q3}} = \text{\resp{not\us{}picked}.}) \\
&&\quad = \frac{14}{15}\times\frac{13}{14}\times\frac{12}{13} = 0.80
\end{eqnarray*}
\end{nexample}
\end{examplewrap}

\begin{exercisewrap}
\begin{nexercise}
What rule permitted us to multiply the probabilities in Example~\ref{3woRep}?\footnotemark
\end{nexercise}
\end{exercisewrap}
\footnotetext{We used the General Multiplication Rule to find the product of three probabilities, where the second and third are conditional probabilities:  \begin{align*}P(\var{Q1} = \resp{not\us{}picked})\times P(\text{\var{Q2}} =  \text{\resp{not\us{}picked}}\ |\ \text{\var{Q1}} = \text{\resp{not\us{}picked}})\times P(\text{\var{Q3}} =  \text{\resp{not\us{}picked}}\ |\ \text{\var{Q1}} = \text{\resp{not\us{}picked} \text{and }}\text{\var{Q2}} = \text{\resp{not\us{}picked}})
\end{align*}
}


\begin{examplewrap}
\begin{nexample}{Suppose the professor randomly picks without regard to who she already selected, i.e. students can be picked more than once. What is the probability that you will not be picked for any of the three questions?}\label{3wRep}
Each pick is independent, and the probability of not being picked for any individual question is $14/15$. Thus, we can use the Multiplication Rule for independent processes.
\begin{eqnarray*}
&&P(\text{not picked in 3 questions}) \\
&&\quad = P(\text{\var{Q1}} = \text{\resp{not\us{}picked}\text{ and }}\text{\var{Q2}} = \text{\resp{not\us{}picked}\text{ and }}\text{\var{Q3}} = \text{\resp{not\us{}picked}.}) \\
&&\quad = \frac{14}{15}\times\frac{14}{15}\times\frac{14}{15} = 0.813
\end{eqnarray*}
You have a slightly higher chance of not being picked compared to when she picked a new person for each question. However, you now may be picked more than once.
\end{nexample}
\end{examplewrap}

%\begin{exercisewrap}
%\begin{nexercise}
%Under the setup of Example~\ref{3wRep}, what is the probability of being picked to answer all three questions?\footnotemark
%\end{nexercise}
%\end{exercisewrap}
%\footnotetext{$P($being picked to answer all three questions$) = \left(\frac{1}{15}\right)^3 = 0.00030$.}

\D{\newpage}

If we sample from a small population \termni{without replacement}, we no longer have independence between our observations. In Example~\ref{3woRep}, the probability of not being picked for the second question was conditioned on the event that you were not picked for the first question. In Example~\ref{3wRep}, the professor sampled her students \termni{with replacement}: she repeatedly sampled the entire class without regard to who she already picked.


\begin{exercisewrap}
\begin{nexercise} \label{compare15}
Continuing Examples~\ref{3woRep} and \ref{3wRep}, if the professor asks three questions, what is the probability that you will be chosen at least once if she chooses students randomly without replacement (repeats not allowed)?  What if she chooses randomly with replacement (repeats allowed)?  There are 15 students in the class.\footnotemark
\end{nexercise}
\end{exercisewrap}
\footnotetext{(a) If you don't get chosen at least once, that means you never get chosen.  Therefore, using complements, the probability of being chosen at least once is equal to 1 $-$ the probability of never being chosen. \\ Without replacement: P(chosen at least once) = $1-(14/15)(13/14)(12/13) = 1-0.80 = 0.20$.  \\(b)~With replacement: P(chosen at least once) = $1-(14/15)^3 = 1-0.813 = 0.187$.}

\begin{exercisewrap}
\begin{nexercise} \label{compare150}
Now, let's say that you are in a large lecture hall with 150 students.  If the professor asks three questions, what is the probability that you will be chosen at least once if she chooses students randomly without replacement?  What if she chooses randomly with replacement?\footnotemark
\end{nexercise}
\end{exercisewrap}
\footnotetext{(a) Without replacement: P(chosen at least once) = $1-(149/150)(148/149)(147/148) = 1-0.9800 = 0.0200$.  \\(b)~With replacement:  P(chosen at least once) = $1-(149/150)^3 = 1-0.9801 = 0.0199$.}

\begin{examplewrap}
\begin{nexample}{Compare your answers to Guided Practice~\ref{compare15} and to Guided Practice~\ref{compare150}.  What do you notice?}
The probability of being chosen at least once when the professor randomly samples 3 students out of 15 without replacement versus with replacement differs by 0.003 (0.20$-$0.187).  The probability of being chosen at least once when the professor randomly samples 3 students out of 150 without replacement versus with replacement differs by 0.0001 (0.0200$-$0.0199).   When the population size is larger relative to the sample size, the difference between the conditional and the unconditional probabilities used in the probability calculations is smaller.  Therefore, when the population size is large relative to the sample size, the difference between sampling without replacement and sampling with replacement becomes negligible.
\label{comparewithvswithoutrepl}
\end{nexample}
\end{examplewrap}

When taking a small sample from a much larger population and sampling without replacement, the observations are technically not independent but can be treated \emph{as if} they were independent for calculation purposes.  A rule of thumb says that if the sample size is less than 10\% of the population size, or equivalently if the population size is at least 10 times greater than the sample size, then the observations can be treated as if they were independent.

%\begin{exercisewrap}
%\begin{nexercise} \label{followUpToRaffleOf30TicketsWWOReplacement}
%Compare your answers in Guided Practice~\ref{raffleOf30TicketsWWOReplacement}. How much influence does the sampling method have on your chances of winning a prize?\footnotemark
%\end{nexercise}
%\end{exercisewrap}
%\footnotetext{There is about a 10\% larger chance of winning a prize when using sampling without replacement.}


%
%\begin{exercisewrap}
%\begin{nexercise} \label{raffleOf30TicketsWWOReplacement}
%Your department is holding a raffle. They sell 30 tickets and offer seven prizes. (a) They place the tickets in a hat and draw one for each prize. The tickets are sampled without replacement, i.e. the selected tickets are not placed back in the hat. What is the probability of winning a prize if you buy one ticket? (b)~What if the tickets are sampled with replacement?\footnotemark
%\end{nexercise}
%\end{exercisewrap}
%\footnotetext{(a) First determine the probability of not winning. The tickets are sampled without replacement, which means the probability you do not win on the first draw is $29/30$, $28/29$ for the second, ..., and $23/24$ for the seventh. The probability you win no prize is the product of these separate probabilities: $23/30$. Therefore, the probability of winning (at least) one prize is $1 - 23/30 = 7/30 = 0.233$. (b)~When the tickets are sampled with replacement, there are seven independent draws. Again we first find the probability of not winning a prize: $(29/30)^7 = 0.789$. Thus, the probability of winning (at least) one prize when drawing with replacement is 0.211.}
%
%\begin{exercisewrap}
%\begin{nexercise} \label{followUpToRaffleOf30TicketsWWOReplacement}
%Compare your answers in Guided Practice~\ref{raffleOf30TicketsWWOReplacement}. How much influence does the sampling method have on your chances of winning a prize?\footnotemark
%\end{nexercise}
%\end{exercisewrap}
%\footnotetext{There is about a 10\% larger chance of winning a prize when using sampling without replacement.}
%
%Had we repeated Guided Practice~\ref{raffleOf30TicketsWWOReplacement} with 300 tickets instead of 30, we would have found something interesting: the results would be nearly identical. The probability would be 0.0233 without replacement and 0.0231 with replacement. 

\begin{onebox}{Sampling without replacement}
When the sample size is only a small fraction of the population (under 10\%), observations can be considered independent even when sampling without replacement.
\end{onebox}
\label{samplingworeplacement}


\D{\newpage}

\subsection{Independence considerations in conditional probability}

If two processes are independent, then knowing the outcome of one should provide no information about the other. We can show this is mathematically true using conditional probabilities.

\begin{exercisewrap}
\begin{nexercise} \label{condProbOfRollingA1AfterOne1}
Let $X$ and $Y$ represent the outcomes of rolling two dice. (a)~What is the probability that the first die, $X$, is \resp{1}? (b)~What is the probability that both $X$ and $Y$ are \resp{1}? (c)~Use the formula for conditional probability to compute $P(Y =$ \resp{1} $\ |\ X = $ \resp{1}$)$, then compare this to $P(Y=1)$.\footnotemark
\end{nexercise}
\end{exercisewrap}
\footnotetext{Brief solutions: (a) $1/6$. (b) $1/36$. (c)~$P(Y =$ \resp{1} $\ |\ X = $ \resp{1}$)$=$\frac{P(Y = \text{ \resp{1} and }X=\text{ \resp{1}})}{P(X=\text{ \resp{1}})} = \frac{1/36}{1/6} = 1/6$. This probability is the same as $P(Y=1)=1/6$. The probability that $Y=1$ was unchanged by knowledge about $X$, which makes sense as $X$ and $Y$ are independent.}

We can also show that in Guided Practice~\ref{condProbOfRollingA1AfterOne1}(c) the conditioning information has no influence by using the Multiplication Rule for independence processes:
\begin{eqnarray*}
P(Y=\text{\resp{1}}\ |\ X=\text{\resp{1}})
	&=& \frac{P(Y=\text{\resp{1} and }X=\text{\resp{1}})}{P(X=\text{\resp{1}})} \\
	&=& \frac{P(Y=\text{\resp{1}})\times \color{oiGB}P(X=\text{\resp{1}})}{\color{oiGB}P(X=\text{\resp{1}})} \\
	&=& P(Y=\text{\resp{1}})
\end{eqnarray*}

\begin{exercisewrap}
\begin{nexercise}
Ron is watching a roulette table in a casino and notices that the last five outcomes were \resp{black}. He figures that the chances of getting \resp{black} six times in a row is very small (about $1/64$) and puts his paycheck on red. What is wrong with his reasoning?\footnotemark
\end{nexercise}
\end{exercisewrap}
\footnotetext{He has forgotten that the next roulette spin is independent of the previous spins. Casinos do employ this practice; they post the last several outcomes of many betting games to trick unsuspecting gamblers into believing the odds are in their favor. This is called the \term{gambler's fallacy}.}

%%
\subsection{Probabilities when events are not disjoint}

Let's consider calculations for two events that are not disjoint in the context of a \indexthis{regular deck of 52 cards}{deck of cards}, represented in Figure~\ref{deckOfCards}. If you are unfamiliar with the cards in a regular deck, please see the footnote.\footnote{The 52 cards are split into four \term{suits}: $\clubsuit$ (club), {\color{redcards}$\diamondsuit$} (diamond), {\color{redcards}$\heartsuit$} (heart), $\spadesuit$ (spade). Each suit has its 13 cards labeled: \resp{2}, \resp{3}, ..., \resp{10}, \resp{J} (jack), \resp{Q} (queen), \resp{K} (king), and \resp{A} (ace). Thus, each card is a unique combination of a suit and a label, e.g. {\color{redcards}\resp{4$\heartsuit$}} and \resp{J$\clubsuit$}. The 12 cards represented by the jacks, queens, and kings are called \termsub{\resp{face cards}}{face card}. The cards that are {\color{redcards}$\diamondsuit$} or {\color{redcards}$\heartsuit$} are typically colored {\color{redcards}red} while the other two suits are typically colored black.}

\begin{figure}[h]
\centering
\begin{tabular}{lll lll lll lll l}
\resp{2$\clubsuit$} & \resp{3$\clubsuit$} & \resp{4$\clubsuit$} & \resp{5$\clubsuit$} & \resp{6$\clubsuit$} & \resp{7$\clubsuit$} & \resp{8$\clubsuit$} & \resp{9$\clubsuit$} & \resp{10$\clubsuit$} & \resp{J$\clubsuit$} & \resp{Q$\clubsuit$} & \resp{K$\clubsuit$} & \resp{A$\clubsuit$}  \\
\color{redcards} \resp{2$\diamondsuit$} & \color{redcards}\resp{3$\diamondsuit$} & \color{redcards}\resp{4$\diamondsuit$} & \color{redcards}\resp{5$\diamondsuit$} & \color{redcards}\resp{6$\diamondsuit$} & \color{redcards}\resp{7$\diamondsuit$} & \color{redcards}\resp{8$\diamondsuit$} & \color{redcards}\resp{9$\diamondsuit$} & \color{redcards}\resp{10$\diamondsuit$} & \color{redcards}\resp{J$\diamondsuit$} & \color{redcards}\resp{Q$\diamondsuit$} & \color{redcards}\resp{K$\diamondsuit$} & \color{redcards}\resp{A$\diamondsuit$} \\
\color{redcards}\resp{2$\heartsuit$} & \color{redcards}\resp{3$\heartsuit$} & \color{redcards}\resp{4$\heartsuit$} & \color{redcards}\resp{5$\heartsuit$} & \color{redcards}\resp{6$\heartsuit$} & \color{redcards}\resp{7$\heartsuit$} & \color{redcards}\resp{8$\heartsuit$} & \color{redcards}\resp{9$\heartsuit$} & \color{redcards}\resp{10$\heartsuit$} & \color{redcards}\resp{J$\heartsuit$} & \color{redcards}\resp{Q$\heartsuit$} & \color{redcards}\resp{K$\heartsuit$} & \color{redcards}\resp{A$\heartsuit$} \\
\resp{2$\spadesuit$} & \resp{3$\spadesuit$} & \resp{4$\spadesuit$} & \resp{5$\spadesuit$} & \resp{6$\spadesuit$} & \resp{7$\spadesuit$} & \resp{8$\spadesuit$} & \resp{9$\spadesuit$} & \resp{10$\spadesuit$} & \resp{J$\spadesuit$} & \resp{Q$\spadesuit$} & \resp{K$\spadesuit$} & \resp{A$\spadesuit$}
\end{tabular}
\caption{Representations of the 52 unique cards in a deck.}
\label{deckOfCards}
\end{figure}

\begin{exercisewrap}
\begin{nexercise}
(a) What is the probability that a randomly selected card is a diamond? (b)~What is the probability that a randomly selected card is a face~card?\footnotemark
\end{nexercise}
\end{exercisewrap}
\footnotetext{(a) There are 52 cards and 13 diamonds. If the cards are thoroughly shuffled, each card has an equal chance of being drawn, so the probability that a randomly selected card is a diamond is $P({\color{redcards}\diamondsuit}) = \frac{13}{52} = 0.250$. (b)~Likewise, there are 12 face cards, so $P($face card$) = \frac{12}{52} = \frac{3}{13} = 0.231$.}

\D{\newpage}

\termsub{Venn diagrams}{venn diagram} are useful when outcomes can be categorized as ``in'' or ``out'' for two or three variables, attributes, or random processes. The Venn diagram in Figure~\ref{venn} uses a oval to represent diamonds and another to represent face cards. If a card is both a diamond and a face card, it falls into the intersection of the ovals. If it is a diamond but not a face card, it will be in part of the left oval that is not in the right oval (and so on). The total number of cards that are diamonds is given by the total number of cards in the diamonds oval: $10+3=13$. The probabilities are also shown (e.g. $10/52 = 0.1923$).

\begin{figure}
\centering
\Figure[A Venn diagram is shown. One oval is labeled "Diamonds" with a total proportion of 0.25 and a second oval is labeled "Face cards" with a total proportion 0.2308. The two ovals overlap and share 3 cards, which have a proportion of 0.0577 of a deck of cards. The portion of the diamond cards oval that is not overlapping with the other oval is labeled with a "10" for 10 cards and a proportion of 0.1923. The portion of the face cards oval that is not overlapping the other oval is labeled with a "9" for 9 cards and a proportion of 0.2308. It is also noted in the figure that "There are also 30 cards that are neither diamonds nor face cards".]
{0.65}{venn}
\caption{A Venn diagram for diamonds and face cards.}
\label{venn}
\end{figure}

\begin{exercisewrap}
\begin{nexercise}
Using the Venn diagram, verify $P($face card$) = 12/52=3/13$.\footnotemark\end{nexercise}
\end{exercisewrap}
\footnotetext{The Venn diagram shows face cards split up into ``face card but not {\color{redcards}$\diamondsuit$}'' and ``face card and {\color{redcards}$\diamondsuit$}''. Since these correspond to disjoint events, $P($face card$)$ is found by adding the two corresponding probabilities: $\frac{3}{52} + \frac{9}{52} = \frac{12}{52} = \frac{3}{13}$.}


Let $A$ represent the event that a randomly selected card is a diamond and $B$ represent the event that it is a face card. How do we compute $P(A$ or $B)$? Events $A$ and $B$ are not disjoint -- the cards {\color{redcards}$J\diamondsuit$}, {\color{redcards}$Q\diamondsuit$}, and {\color{redcards}$K\diamondsuit$} fall into both categories -- so we cannot use the Addition Rule for disjoint events. Instead we use the Venn diagram. We start by adding the probabilities of the two events:
\begin{eqnarray*}
P(A) + P(B) = P({\color{redcards}\diamondsuit}) + P(\text{face card}) = 13/52 + 12/52
\label{overCountFaceDiamond}
\end{eqnarray*}
However, the three cards that are in both events were counted twice, once in each probability. We must correct this double counting:
\begin{eqnarray*}
P(A\text{ or } B) &=&P({\color{redcards}\diamondsuit}) + P(\text{face card})  \notag \\
 &=& P({\color{redcards}\diamondsuit}) + P(\text{face card}) - P({\color{redcards}\diamondsuit}  \text{ and face card}) \label{diamondFace} \\
 &=& 13/52 + 12/52 - 3/52 \notag \\
 &=& 22/52 = 11/26 \notag
\end{eqnarray*}
Equation~(\ref{diamondFace}) is an example of the \term{General Addition Rule}.

\begin{onebox}{General Addition Rule}
If $A$ and $B$ are any two events, disjoint or not, then the probability that A or B will occur is
\begin{eqnarray*}
P(A\text{ or }B) = P(A) + P(B) - P(A\text{ and }B)
\label{generalAdditionRule}
\end{eqnarray*}
where $P(A$ and $B)$ is the probability that both events occur.\end{onebox}

\D{\newpage}

\begin{onebox}{Symbolic notation for ``and" and ``or"}
The symbol $\cap$ means intersection and is equivalent to ``and".

The symbol  $\cup$ means union and is equivalent to ``or".

It is common to see the General Addition Rule written as
\begin{eqnarray*}
P(A \cup B) = P(A) + P(B) - P(A \cap B)
\end{eqnarray*}
\end{onebox}

\begin{onebox}{``or'' is inclusive}
When we write, ``or"  in statistics, we mean ``and/or'' unless we explicitly state otherwise. Thus, $A$ or $B$ occurs means $A$, $B$, or both $A$ and $B$ occur. This is equivalent to at least one of $A$ or $B$ occurring.\end{onebox}

\begin{exercisewrap}
\begin{nexercise}
(a) If $A$ and $B$ are disjoint, describe why this implies $P(A$ and $B) = 0$. (b) Using part (a), verify that the General Addition Rule simplifies to the simpler Addition Rule for disjoint events if $A$ and $B$ are disjoint.\footnotemark
\end{nexercise}
\end{exercisewrap}
\footnotetext{(a) If $A$ and $B$ are disjoint, $A$ and $B$ can never occur simultaneously. (b) If $A$ and $B$ are disjoint, then the last term of Equation~(\ref{generalAdditionRule}) is 0 (see part (a)) and we are left with the Addition Rule for disjoint events.}

\index{data!email|(}

\begin{exercisewrap}
\begin{nexercise}\label{emailSpamNumberVennExer}
% library(openintro); data(email); table(email[,c("spam", "number")]); table(email[,c("number")]); table(email[,c("spam")])
In the \data{email} data set with 3,921 emails, 367 were spam, 2,827 contained some small numbers but no big numbers, and 168 had both characteristics. Create a Venn diagram for this setup.\footnotemark
\end{nexercise}
\end{exercisewrap}
\footnotetext{%
\begin{minipage}[t]{0.65\textwidth}
Both the counts and corresponding {\color{oiB}probabilities} (e.g. $2659/3921 = 0.678$) are shown. Notice that the number of emails represented in the left oval corresponds to $2659 + 168 = 2827$, and the number represented in the right oval is $168 + 199 = 367$.
\end{minipage}\ %
\begin{minipage}[c]{0.3\textwidth}
\hfill\includegraphics[height=13mm]{ch_probability/figures/emailSpamNumberVenn/emailSpamNumberVenn} \vspace{-9mm}
\end{minipage}\\[1mm]
\ 
}

\begin{exercisewrap}
\begin{nexercise}
(a) Use your Venn diagram from Guided Practice~\ref{emailSpamNumberVennExer} to determine the probability a randomly drawn email from the \data{email} data set is spam and had small numbers (but not big numbers). (b)~What is the probability that the email had either of these attributes?\footnotemark
\index{data!email|)}
\end{nexercise}
\end{exercisewrap}
\footnotetext{(a)~The solution is represented by the intersection of the two ovals: 0.043. (b)~This is the sum of the three disjoint probabilities shown in the ovals: $0.678 + 0.043 + 0.051 = 0.772$.}



%%
\subsection{Checking for independent and mutually exclusive events}

If $A$ and $B$ are independent events, then the probability of $B$ being true is unchanged if $A$ is true. Mathematically, this is written as
\begin{align*}
P(B | A) &= P(B)
\end{align*}
The General Multiplication Rule states that $P(A \cap B)$ equals $P(A)\times P(B | A)$. If $A$ and $B$ are independent events, we can replace $P(B|A)$ with $P(B)$ and the following multiplication rule applies:
\begin{align*}
P(A \cap B) &= P(A)\times P(B)
\end{align*}

\D{\newpage}

\begin{onebox}{Checking whether two events are independent}
To determine if two events $A$ and $B$ are independent, check whether one of the following equations holds (there is no need to check both equations):
\begin{align*}
P(B | A) &= P(B)&
P(A\cap B) &= P(A)\times P(B)
\end{align*}
If the equation that is checked holds true (the left and right sides are equal), then $A$ and $B$ are independent. If the equation does not hold, then $A$ and $B$ are dependent.\end{onebox}

\begin{examplewrap}
\begin{nexample}{Are teenager college attendance and parent college degrees independent or dependent? Use information from Figure~\ref{contTableOfParStCollegeCopy}, which shows data from a simulated sample.}\label{teenParentCollegeIndependentExample}
We'll check for independence by seeing if the relationship $P(B | A) = P(B)$ holds. If the \var{teen} and \var{parents} variables are independent, it must be true that
\begin{align*}
P(\text{\var{teen} \resp{college}}\ |\ \text{\var{parent} \resp{degree}})
	&= P(\text{\var{teen} \resp{college}})
\end{align*}
Using Figure~\ref{contTableOfParStCollegeCopy}, we check whether equality holds in this equation.
\begin{align*}
P(\text{\var{teen} \resp{college}}\ |\ \text{\var{parent} \resp{degree}})
	&\overset{?}{=} P(\text{\var{teen} \resp{college}}) \\
\frac{231}{280} &\overset{?}{=}\frac{445}{792}\\	
0.83 &\neq 0.56
\end{align*}
Because the sides are not equal, teenager college attendance and parent degree are dependent. We estimate the probability a teenager attended college to be higher if we know that one of the teen's parents has a college degree.
\end{nexample}
\end{examplewrap}

\begin{figure}[ht]
\centering
\begin{tabular}{ll rr r rr}
  && \multicolumn{2}{c}{\var{parents}} & \hspace{1cm} &  \\
  \cline{3-4}
	&& \resp{degree} & \resp{not} & Total  \\
  \cline{2-5}
	& \resp{college}     & 231 & 214 & 445 \\
\raisebox{1.5ex}[0pt]{\var{teen}}	& \resp{not} \hspace{0.5cm} & 49 & 298 & 347   \\
  \cline{2-5}
	& Total & 280 & 512 & 792 \\
\end{tabular}
\caption{Contingency table summarizing the \data{family\us{}college} data set.}
\label{contTableOfParStCollegeCopy}
\end{figure}

\begin{exercisewrap}
\begin{nexercise}
Also show that teenager college attendance and parent college degree are dependent by showing that  $P(A\cap B) \ne P(A)\times P(B)$.\footnotemark\end{nexercise}
\end{exercisewrap}
\footnotetext{We check for equality in the following equation:
\begin{align*}
P(\text{\var{teen} \resp{college}} \cap \text{\var{parent} \resp{degree}})&\overset{?}{=} P(\text{\var{teen} \resp{college}})\times P(\text{\var{parent} \resp{degree}})\\
\frac{231}{792}&\overset{?}{=}\frac{445}{792}\times \frac{280}{792}\\
0.292 &\neq 0.199
\end{align*}
These terms are not equal, which confirms what we learned in Example~\ref{teenParentCollegeIndependentExample}: teenager college attendance and parent college degrees are dependent.}

\D{\newpage}

If $A$ and $B$ are mutually exclusive events, then $A$ and $B$ cannot occur at the same time. Mathematically, this is written as
\begin{align*}
P(A \cap  B) &= 0
\end{align*}
The General Addition Rule states that $P(A \cup B) \text{ equals }P(A) + P(B) - P(A \cap B)$. If $A$ and $B$ are mutually exclusive events, we can replace $P(A \text{ and }B)$ with 0 and the following special addition rule applies:
\begin{align*}
P(A \cup B) &= P(A) + P(B)
\end{align*}

\begin{onebox}{Checking whether two events are mutually exclusive (disjoint)}
To determine if events $A$ and $B$ are mutually exclusive, check whether one of the following equations holds (there is no need to check both equations):
\begin{align*}
P(A \cap B) &= 0&
P(A\cup B) &= P(A) + P(B)
\end{align*}
If the equation that is checked holds true (the left and right sides are equal), $A$ and $B$ are mutually exclusive. If the equation does not hold, then $A$ and $B$ are not mutually exclusive.\end{onebox}

%\begin{onebox}{Checking whether two events are mutually exclusive}
%If $A$ and $B$ are mutually exclusive (disjoint) events, then the probability of $A$ and $B$ occurring at the same time is zero. Mathematically, this is written as
%\begin{align*}
%P(A \text{ and}B) &= 0
%\end{align*}
%The General Addition Rule states $P(A\text{ or}B) \text{ equals}P(A) + P(B) - P(A \text{ and}B)$. If $A$ and $B$ are mutually exclusive events, we can replace $P(A \text{ and}B)$ with 0 and the following addition rule applies:
%\begin{align*}
%P(A\text{ or}B) &= P(A) + P(B)
%\end{align*}
%If asked to determine if events $A$ and $B$ are mutually exclusive, check one of the two equations above. If the equation holds, the events $A$ and $B$ are mutually exclusive. If the equation does not hold (the left and right sides are not equal), then $A$ and $B$ are not mutually exclusive.}
%\end{tipBox}

\begin{examplewrap}
\begin{nexample}{Are teen college attendance and parent college degree mutually exclusive?}
Looking in the table, we see that there are 231 instances where both the teenager attended college and parent has a degree, indicating the probability of both events occurring is greater than 0. Since we have found an example where both of these events happen together, these two events are not mutually exclusive. We can write this more formally as: 
\begin{align*}
P(\text{\var{teen} \resp{college}} \cap \text{\var{parent} \resp{degree}}) = \frac{231}{792}\neq 0
\end{align*}
Since this probability is not zero, teenager college attendance and parent college degree are not mutually exclusive.
\end{nexample}
\end{examplewrap}

\begin{onebox}{Mutually exclusive and independent are different}
If two events are mutually exclusive, then if one is true, the other cannot be true. This implies the two events are in some way connected, meaning they must be dependent.\\

If two events are independent, then if one occurs, it is still possible for the other to occur, meaning the events are not mutually exclusive.\end{onebox}

\begin{onebox}{Dependent events need not be mutually exclusive.}
{If two events are dependent, this does not imply that they are mutually exclusive. For example, teenager college attendance and parent college degree are dependent, but these events are not mutually exclusive.}
\end{onebox}

\index{probability|)}


\D{\newpage}

%%
\subsection*{Section summary}

\begin{itemize}

\item A \term{conditional probability} can be written as $P(A | B)$ and is read, \mbox{``Probability of $A$ given $B$".}

\item In a conditional probability of the form $P(A | B)$, we are given information about $B$.  In an \term{unconditional probability} of the form $P(A)$, we are not given any information.

\item To find the probability of $A$ given $B$, use the \termni{conditional probability rule} \mbox{$P(A | B) = \frac{P(A \cap B)}{P(B)}$.}

\item To find the probability of $A$ \emph{and} $B$, that is $A$ intersect $B$, use the \term{General Multiplication Rule}: 
$P(A \cap B) = P(A) \times P(B | A)$.  Equivalently, $P(A \cap B)$ can be found using the conditional probability rule by multiplying $P(A | B)$ times $P(B)$. 

\item Sometimes, the conditional probability $P(B | A)$ may be known, but we want to find the ``inverted" probability $P(A | B)$.  In this case, draw a tree diagram and apply the conditional probability rule $P(A | B)=\frac{P(A \cap B)}{P(B)}$, where $P(B)$ is computed using multiple pieces of information from the tree diagram.

\item Two events are \term{independent} when the outcome of one has no effect on the outcome of the other.  When $A$ and $B$ are independent, $P(B | A) = P(B)$ and $P(A | B) = P(A)$.

\item In the \emph{special case} where $A$ and $B$ are \term{independent}, $P(A \cap B) = P(A)\times P(B)$.

\item When sampling \textbf{with} replacement, events are independent.  When sampling without replacement from a very large population, events may be considered as if they were independent, and the use of conditional or unconditional probabilities will make little difference in the answer when calculating joint probabilities.

\item When sampling \term{without replacement} from a small population, events are dependent and one cannot simply multiply unconditional probabilities to find a joint probability.   

\item To find the probability of $A$ \emph{or} $B$, that is $A$ union $B$, use the \termni{General Addition Rule}: $P(A \text{ or  B}) = P(A) + P(B) - P(A \text{ and } B)$, also written as: $P(A \cup B) = P(A) + P(B) - P(A \cap B)$.

\item When $A$ and $B$ are \termni{mutually exclusive} (disjoint), $P(A \cap B) = 0$.

\item In the special case where $A$ and $B$ are \termni{mutually exclusive} (disjoint), $P(A \cup B) = P(A) + P(B)$.

\item If $A$ and $B$ are \term{mutually exclusive}, they must be \term{dependent}, because the occurrence of one of them changes the probability that the other occurs to 0.






\end{itemize} 

%%%%%%%%%Section Exercises
{\input{ch_probability/TeX/conditional_probability_intersections_and_unions.tex}}





%________________________________________
\section[Discrete random variables]{Discrete random variables }
\label{randomVariablesSection}
\index{random variable|(}

\sectionintro{
\noindent%
We can consider the number of textbooks that a student a particular university will purchase to be a random variable.  What does the distribution look like?  How can we calculate the expected number of textbooks purchased and the typical variation in that number?  If we know the average cost per textbook, how can we calculate the expected \emph{amount} of money a student at this university will spend on textbooks and the typical variation in that amount?  In this section, we define and summarize random variables such as these, and we look at some of their properties.


%%
\subsection*{Learning objectives}

\begin{enumerate}
\setlength{\itemsep}{0mm}

\item Construct a probability distribution for a discrete random variable.

\item Calculate mean and standard deviation for a discrete random variable

\item Interpret the mean and standard deviation for a discrete random variable.

\end{enumerate}
}

%%
\subsection{Probability distributions}

The sum of the roll of two dice can vary from roll to roll.  We call a variable or process such as this a \term{random variable}, and we usually represent a random variable with a capital letter such as $X$, $Y$, or $Z$. 

\begin{onebox}{Random variable}
A random process or variable with a numerical outcome.\end{onebox}

A \term{probability distribution} for a discrete random variable shows the probability
associated with every possible value of the random variable. Figure~\ref{diceProb} shows the probability distribution for the sum of two dice.

\begin{figure}[hhh]
\centering
\begin{tabular}{l ccc ccc ccc cc}
  \ \vspace{1mm} \\
  \hline
  \ \vspace{-3mm} \\
Dice sum\vspace{0.3mm} & 2 & 3 & 4 & 5 & 6 & 7 & 8 & 9 & 10 & 11 & 12  \\
Probability & $\frac{1}{36}$ & $\frac{2}{36}$ & $\frac{3}{36}$ & $\frac{4}{36}$ & $\frac{5}{36}$ & $\frac{6}{36}$ & $\frac{5}{36}$ & $\frac{4}{36}$ & $\frac{3}{36}$ & $\frac{2}{36}$ & $\frac{1}{36}$\vspace{1mm} \\
   \hline
\end{tabular}
\caption{Probability distribution for the sum of two dice.}
\label{diceProb}
\end{figure}

In order for a distribution to represent a valid probability distribution, it must satisfy certain rules.

\begin{onebox}{Rules for probability distributions}
A probability distribution is a list of the possible outcomes with corresponding probabilities that satisfies three rules: \vspace{-2mm}
\begin{enumerate}
\setlength{\itemsep}{0mm}
\item The outcomes listed must be disjoint.
\item Each probability must be between 0 and 1.
\item The probabilities must total 1. \vspace{1mm}
\end{enumerate}\end{onebox}


\begin{examplewrap}
\begin{nexample}{Based on the probability distribution table shown in Figure~\ref{diceProb}, what is the probability of getting a dice sum of greater than 10? }
To be greater than 10 means to be 11 or 12.  So the probability of the dice sum being greater than 10 is $\frac{2}{36} +  \frac{1}{36} = \frac{3}{36}$.
\end{nexample}
\end{examplewrap}

It is common to want to know the probability of getting less than or equal to a certain value.  In this case, a \term{cumulative probability distribution} can be used.  Instead of identifying the probability of each value, we record the probability of being less than or equal to each value as shown in the figure below.

\begin{figure}[hhh]
\centering
\begin{tabular}{l ccc ccc ccc cc}
  \ \vspace{1mm} \\
  \hline
  \ \vspace{-3mm} \\
Dice sum\vspace{0.3mm} & 2 & 3 & 4 & 5 & 6 & 7 & 8 & 9 & 10 & 11 & 12  \\
Cumulative probability ($\le$ dice sum) & $\frac{1}{36}$ & $\frac{3}{36}$ & $\frac{6}{36}$ & $\frac{10}{36}$ & $\frac{15}{36}$ & $\frac{21}{36}$ & $\frac{26}{36}$ & $\frac{30}{36}$ & $\frac{33}{36}$ & $\frac{35}{36}$ & $\frac{36}{36}$\vspace{1mm} \\
   \hline
\end{tabular}
\caption{Cumulative probability distribution for the sum of two dice.}
\label{diceProbCumulative}

\end{figure}


\begin{examplewrap}
\begin{nexample}{Based on the cumulative probability distribution table shown in Figure~\ref{diceProbCumulative}, what is the probability of getting a dice sum less than or equal to 4?  Greater than 4? }
Because this distribution is a cumulative distribution, we do not need to add up terms.  The probability of being less than or equal to 4 is given in the cumulative distribution as $\frac{6}{36}$.  To be greater than 4 is the complement of being less than or equal to 4, so the probability of a dice sum greater than 4 can be found as $1 - \frac{6}{36} = \frac{30}{36}$.  
\end{nexample}
\end{examplewrap}

%
%\begin{exercisewrap}
%\begin{nexercise}\label{usHouseholdIncomeDistsExercise}
%Table~\ref{usHouseholdIncomeDists} suggests three distributions for household income in the United States. Only one is correct. Which one must it be? What is wrong with the other two?\footnotemark
%  \ \vspace{2mm} \\
%
%\begin{tabular}{r | rr rr}
%
%  \hline
%Income range (\$1000s) & 0-25    & 25-50    & 50-100     & 100+    \\
%  \hline
%(a)\hspace{0.2mm}	 & 0.18 & 0.39 & 0.33 & 0.16 \\
%(b)				 & 0.38 & -0.27 & 0.52 & 0.37 \\
%(c)\hspace{0.2mm}	 & 0.28 & 0.27 & 0.29 & 0.16 \\
%  \hline
%\end{tabular}
%\label{usHouseholdIncomeDists}
%
%\end{nexercise}
%\end{exercisewrap}
%\footnotetext{The probabilities of (a) do not sum to 1. The second probability in (b) is negative. This leaves (c), which sure enough satisfies the requirements of a distribution. One of the three was said to be the actual distribution of US household incomes, so it must be (c).}

Chapter~\ref{ch_one_variable_data} emphasized the importance of plotting data to provide quick summaries. Probability distributions can also be summarized in a histogram or bar plot. The probability distribution for the sum of two dice is shown in Figure~\ref{diceProb} and its histogram is plotted in Figure~\ref{diceSumDist}. 



\begin{figure}[h]
\centering
  \Figure[A bar plot is shown for the sum of two dice, which can take values of 2, 3, 4, 5, and so on up to 12. The vertical axis is labeled as "Probability". The bar for 2 has a height of about 0.025, 3 a height of 0.055, 4 a height of 0.09, 5 a height of 0.115, 6 a height of 0.14, 7 a height of 0.165, 8 a height of 0.14, 9 a height of 0.115, 10 a height of 0.09, 11 a height of 0.055, and 12 a height of 0.025.]
{0.65}{diceSumDist}
\caption{A histogram for the probability distribution of the sum of two~dice.}
\label{diceSumDist}
\end{figure}

%\begin{figure}[h]
%\centering
%  \Figure[A bar plot is shown for ``US Household Incomes" with four income buckets. The vertical axis is labeled as ``Probability". The first income bucket is \$0 to \$25,000 and the bar has a height corresponding to a proportion of about 0.28. The second income bucket is \$25,000 to \$50,000 and has a bar height corresponding to a proportion of about 0.27. The second income bucket is \$50,000 to \$100,000 and has a bar height corresponding to a proportion of about 0.28. The second income bucket is over \$100,000 and has a bar height corresponding to a proportion of about 0.15.]
%{0.63}{usHouseholdIncomeDistBar}
%\caption{A bar graph for the probability distribution of US household income. Because it is artificially separated into four unequal bins, this graph fails to show the shape or skew of the distribution.}
%\label{usHouseholdIncomeDistBar}
%\end{figure}

In these bar plots, the bar heights represent the probabilities of outcomes. If the outcomes are numerical and discrete, it is usually (visually) convenient to make a histogram, as in the case of the sum of two dice. Another example of plotting the bars at their respective locations is shown in Figure~\ref{bookCostDist}.


\D{\newpage}

%%%%%
\subsection{Introduction to expectation}

\begin{examplewrap}
\begin{nexample}{Two books are assigned for a statistics class: a textbook and its corresponding study guide. The university bookstore determined 20\% of enrolled students do not buy either book, 55\% buy the textbook only, and 25\% buy both books, and these percentages are relatively constant from one term to another. If~there are 100 students enrolled, how many books should the bookstore expect to sell to this class?}\label{bookStoreSales}
Around 20 students will not buy either book (0 books total), about 55 will buy one book (55 books total), and approximately 25 will buy two books (totaling 50 books for these 25 students). The bookstore should expect to sell about 105 books for this class.
\end{nexample}
\end{examplewrap}

\begin{exercisewrap}
\begin{nexercise}
Would you be surprised if the bookstore sold slightly more or less than 105 books?\footnotemark
\end{nexercise}
\end{exercisewrap}
\footnotetext{If they sell a little more or a little less, this should not be a surprise. Hopefully it is now clear that there is natural variability in observed data. For example, if we would flip a coin 100 times, it will not usually come up heads exactly half the time, but it will probably be close.}

\begin{examplewrap}
\begin{nexample}{The textbook costs \$137 and the study guide \$33. How much revenue should the bookstore expect from this class of 100 students?}\label{bookStoreRev}
About 55 students will just buy a textbook, providing revenue of
\begin{eqnarray*}
\$137 \times  55 = \$7,535
\end{eqnarray*}
The roughly 25 students who buy both the textbook and the study guide would pay a total of
\begin{eqnarray*}
(\$137 + \$33) \times  25 = \$170 \times  25 = \$4,250
\end{eqnarray*}
Thus, the bookstore should expect to generate about $\$7,535 + \$4,250 = \$11,785$ from these 100 students for this one class. However, there might be some \emph{sampling variability} so the actual amount may differ by a little bit.
\end{nexample}
\end{examplewrap}

\begin{figure}[hhh]
\centering
  \Figure[A probability distribution, which appears similar to a histogram. The horizontal axis is "Cost" and runs from \$0 to \$170. The vertical axis is Probability. There are three bars: a bar with height 0.2 at \$0, a bar with height 0.55 with height \$137, and a bar with height 0.25 at \$170. A red triangle is shown at the mean, located at \$117.85.]
{0.72}{bookCostDist}\caption{Probability distribution for the bookstore's revenue from one student.   The triangle represents the average revenue per student.}
\label{bookCostDist}
\end{figure}

\begin{examplewrap}
\begin{nexample}{What is the average revenue per student for this course?}\label{revFromStudent}
The expected total revenue is \$11,785, and there are 100 students. Therefore the expected revenue per student is $\$11,785/100 =  \$117.85$.
\end{nexample}
\end{examplewrap}


\D{\newpage}

%%
\subsection{Expected value}

\index{expectation|(}

The amount of money a single student will spend on her statistics books is a random variable, and we represent it by $X$.  The possible outcomes of $X$ are labeled with a corresponding lower case letter $x$ and subscripts. For example, we write $x_1=\$0$, $x_2=\$137$, and $x_3=\$170$, which occur with probabilities $0.20$, $0.55$, and $0.25$. The distribution of $X$ is summarized in Figure~\ref{bookCostDist} and Figure~\ref{statSpendDist}.

\begin{figure}[hhh]
\centering
\begin{tabular}{l ccc r}
\hline
$i$	  & 1 & 2 & 3  & Total\\
\hline
$x_i$ & \$0 & \$137 & \$170 & --\\
$P(x_i)$ & 0.20 & 0.55 & 0.25 & 1.00 \\
\hline
\end{tabular}
\caption{The probability distribution for the random variable $X$, representing the bookstore's revenue from a single student. We use $P(x_i)$ to represent the probability of $x_i$.}
\label{statSpendDist}
\end{figure}

We computed the average outcome of $X$ as \$117.85 in Example~\ref{revFromStudent}. We call this average the \term{expected value} of $X$, denoted by $E(X)$\index{EX@$E(X)$}. The expected value of a random variable is computed by adding each outcome weighted by its probability:
\begin{align*}
E(X) &= 0 \cdot  P(0) + 137 \cdot  P(137) + 170 \cdot  P(170) \\
	&= 0 \cdot  0.20 + 137 \cdot  0.55 + 170 \cdot  0.25 = 117.85
\end{align*}

\begin{onebox}{Expected value of a discrete random variable}
If $X$ takes outcomes $x_1$, $x_2$, ..., $x_n$ with probabilities $P(x_1)$, $P(x_2)$, ..., $P(x_n)$, the mean, or expected value, of $X$ is the sum of each outcome multiplied by its corresponding probability:
\begin{align*}
\mu_{\scriptscriptstyle{X}} = E(X) &= \sum_{i=1}^{n}x_i\cdot P(x_i)\\
&= x_1\cdot P(x_1) + x_2\cdot P(x_2) + \cdots + x_n\cdot P(x_n) \notag
\end{align*}
\end{onebox}

The expected value for a random variable represents the average outcome. For example, $E(X)=117.85$ represents the average amount the bookstore expects to make across all students, which we could also write as $\mu=117.85$. While the bookstore will make more than this on some students and less than this on other students, in the long run, the average will be \$117.85.

\begin{onebox}{Interpreting the mean or expected value of a random variable}
The mean or expected value of a random variable can be interpreted as the long-run average outcome of the random variable. 
\end{onebox}


%It is also possible to compute the expected value of a continuous random variable. However, it requires a little calculus and we save it for a later class.\footnote{$\mu_{\scriptscriptstyle{X}} = \int xf(x)dx$ where $f(x)$ represents a function for the density curve.}

In physics, the expectation holds the same meaning as the center of gravity. The distribution can be represented by a series of weights at each outcome, and the mean represents the balancing point. This is represented in Figures~\ref{bookCostDist} and~\ref{bookWts}. The idea of a center of gravity also expands to continuous probability distributions. Figure~\ref{contBalance} shows a continuous probability distribution balanced atop a wedge placed at the mean.

\begin{figure}[h]
\centering
\Figure[A bar is hung by a string, and three weights are hanging on the bar at three different locations. The weights are located at the locations 0, 137, and 170 and have weights proportional to the probabilities 0.2, 0.55, and 0.25, respectively. The weights are balanced, because the string that is suspending the bar is located at the mean of the distribution, 117.85.]
{0.72}{bookWts}
\caption{A weight system representing the probability distribution for $X$. The string holds the distribution at the mean to keep the system balanced.}
\label{bookWts}
\end{figure}

\begin{figure}[h]
\centering
\Figure[A distribution that is skewed to the right is displayed, similar to how a histogram would appear if the bins were so small as to blend together and look continuous. This distribution is balancing atop a triangle located at the mean of the distribution.]
{0.7}{contBalance}
\caption{A continuous distribution can also be balanced at its mean.}
\label{contBalance}
\end{figure}

\index{expectation|)}


\D{\newpage}

%%
\subsection{Variability in random variables}

Suppose you ran the university bookstore. Besides how much revenue you expect to generate, you might also want to know the volatility (variability) in your revenue.

The \indexthis{variance}{variance} and \indexthis{standard deviation}{standard deviation} can be used to describe the variability of a random variable. Section~\ref{variability}
introduced a method for finding the variance and standard deviation for a data set. We first computed deviations from the mean ($x_i - \mu$), squared those deviations, and took an average to get the variance. In the case of a random variable, we again compute squared deviations. However, we take their sum weighted by their corresponding probabilities, just like we did for the expectation. This weighted sum of squared deviations equals the variance, and we calculate the standard deviation by taking the square root of the variance, just as we did in Section~\ref{variability}.

\begin{onebox}{Variance and standard deviation of a discrete random variable}
If $X$ takes outcomes $x_1$, $x_2$, ..., $x_n$ with probabilities $P(x_1)$,  $P(x_2)$, ..., $P(x_n)$ and expected value $\mu_{\scriptscriptstyle{X}}=E(X)$, then to find the standard deviation of $X$, we first find the variance and then take its square root.
\begin{align*}
Var(X) = \sigma^2_X &= \sum_{i=1}^{n} (x_i - \mu_{\scriptscriptstyle{X}})^2 \cdot P(x_i) \notag \\
	&= (x_1-\mu_{\scriptscriptstyle{X}})^2\cdot P(x_1) + (x_2-\mu_{\scriptscriptstyle{X}})^2\cdot P(x_2) + \cdots +  (x_n-\mu_{\scriptscriptstyle{X}})^2\cdot P(x_n) \notag \\
SD(X) = \sigma_{\scriptscriptstyle{X}} &= \sqrt{ \sum_{i=1}^{n} (x_i - \mu_{\scriptscriptstyle{X}})^2 \cdot P(x_i)}\\
&=\sqrt{(x_1-\mu_{\scriptscriptstyle{X}})^2\cdot P(x_1) + (x_2-\mu_{\scriptscriptstyle{X}})^2\cdot P(x_2) + \cdots +  (x_n-\mu_{\scriptscriptstyle{X}})^2\cdot P(x_n)} \notag \\
\end{align*}
\end{onebox}

%Just as it is possible to compute the mean of a continuous random variable using calculus, we can also use calculus to compute the variance.\footnote{$\sigma^2_X = \int (x - \mu_{\scriptscriptstyle{X}})^2f(x)dx$ where $f(x)$ represents a function for the density curve.} However, this topic is beyond the scope of the AP exam.

\begin{examplewrap}
\begin{nexample}{Compute the expected value, variance, and standard deviation of $X$, the revenue of a single statistics student for the bookstore.}
It is useful to construct a table that holds computations for each outcome separately, then add up the results.
\begin{center}
\begin{tabular}{l rrr r}
\hline
$i$ & 1 & 2&  3& Total \\
\hline
$x_i$ & \$0 & \$137 & \$170 &  \\
$P(x_i)$ & 0.20 & 0.55 & 0.25 &  \\
\hline
$x_i \cdot  P(x_i)$ & 0 & 75.35 & 42.50 & 117.85 \\
\hline
\end{tabular}
\end{center}

Thus, the expected value is $\mu_{\scriptscriptstyle{X}}=\$117.85$, which we computed earlier. The variance can be constructed using a similar table:
\begin{center}
\begin{tabular}{l rrr r}
\hline
$i$ & 1 & 2 & 3 & Total \\
\hline
$x_i$ & \$0 & \$137 & \$170 &  \\
$P(x_i)$ & 0.20 & 0.55 & 0.25 &  \\
\hline
$x_i - \mu_{\mbox{\tiny\itshape X}}$ & -117.85 & 19.15 & 52.15 &  \\
$(x_i-\mu_{\mbox{\tiny\itshape X}})^2$ & 13888.62 &  366.72 & 2719.62 &  \\
$(x_i-\mu_{\mbox{\tiny\itshape X}})^2\cdot P(x_i)$ & 2777.7 & 201.7 & 679.9 & 3659.3 \\
\hline
\end{tabular}
\end{center}
The variance of $X$ is $\sigma_{\scriptscriptstyle{X}}^2 = 3659.3$, which means the standard deviation is $\sigma_{\scriptscriptstyle{X}} = \sqrt{3659.3} = \$60.49$.
\end{nexample}
\end{examplewrap}

The standard deviation of $X$, the revenue of a statistics student for the bookstore, is \$60.49.  We interpret this by saying that the typical deviation of revenue of a statistics student from the mean revenue of \$117.85 over the long run is \$60.49.


\begin{onebox}{Interpreting the standard deviation of a random variable}
The standard deviation of a random variable can be interpreted as the typical deviation of the values of a random variable from the mean value of the random variable over the long-run.  
\end{onebox}

\begin{exercisewrap}
\begin{nexercise}
The bookstore also offers a chemistry textbook for \$159 and a book supplement for \$41. From past experience, they know about 25\% of chemistry students just buy the textbook while 60\% buy both the textbook and supplement.\footnotemark
\begin{enumerate}
\item[(a)] What proportion of students don't buy either book? Assume no students buy the supplement without the textbook.
\item[(b)] Let $Y$ represent the revenue from a single student. Write out the probability distribution of $Y$, i.e. a table for each outcome and its associated probability.
\item[(c)] Compute the expected revenue from a single chemistry student.
\item[(d)] Find the standard deviation to describe the variability associated with the revenue from a single student.
\item[(e)] Interpret the mean and the standard deviation in the context of the problem. 
\end{enumerate}
\end{nexercise}
\end{exercisewrap}
\footnotetext{(a) 100\% - 25\% - 60\% = 15\% of students do not buy any books for the class.\\
(b) is represented by the first three lines in the table below. \\
(c) is given as the total on the line $y_i\cdot P(y_i)$, which is \$159.75.\\
(d) is the square-root of the variance listed on in the total on the last line: $\sigma_{\mbox{\tiny\itshape Y}} = \sqrt{Var(Y)} =\sqrt{4800} =69.28$.
\begin{center}
\begin{tabular}{rrrrr}
$i$ (scenario) & 1 (\resp{noBook}) & 2 (\resp{textbook}) & 3 (\resp{both}) & Total \\
  \hline
$y_i$ & 0.00 & 159.00 & 200.00 &  \\
$P(y_i)$ & 0.15 & 0.25 & 0.60 & \\
\hline
$y_i\cdot P(y_i)$ & 0.00 & 39.75 & 120.00 & $E(Y) = 159.75$\\
$y_i-\mu_{\mbox{\tiny\itshape Y}}$ & -159.75 & -0.75 & 40.25 & \\
$(y_i-\mu_{\mbox{\tiny\itshape Y}})^2$ & 25520.06 & 0.56 & 1620.06 & \\
$(y_i-\mu_{\mbox{\tiny\itshape Y}})^2\cdot P(y_i)$ & 3828.0 & 0.1 & 972.0 & $Var(Y) \approx 4800$ \\
\hline
\end{tabular}
\end{center}
(e) In the long run, the average revenue from a chemistry student is \$159.75 and the typical deviation in that revenue from the mean of \$159.75 is \$69.28.
}

\index{random variable|)}


\D{\newpage}

%%
\subsection*{Section summary}

\begin{itemize}

\item A \termni{random variable} is a variable whose values have numerical outcomes that
result from a random phenomenon.  

\item A \termni{probability distribution} for a discrete random variable shows the probability
associated with every possible value of the random variable. The sum of the
probabilities over all possible values of a discrete random variable is 1.

\item A discrete probability distribution can be determined using the rules of
probability or estimated with a simulation.

\item A discrete probability distribution can be represented as a graph, table, or
function showing the probabilities associated with values of a random variable.

\item A cumulative probability distribution can be represented as a table or function
and shows the probability of being less than or equal to each value of the
discrete random variable.

\item A numerical value measuring a characteristic of a probability distribution of a
random variable, or a population, is a \termni{parameter}. The value of a parameter is a
single, fixed value.  The mean and standard deviation are parameters of a probability distribution.

\item The \termni{mean} (expected value) and \termni{standard deviation} of a discrete random variable $X$ can be found using the following formulas, where $x_i$ is a value of the random variable and $P(x_i)$ is the probability of that value: \vspace{-1mm}
\begin{flalign*}
E(X) = \mu_{\scriptscriptstyle{X}} &= \sum{x_i\cdot P(x_i)} &\\
&= x_1\cdot P(x_1) + x_2\cdot P(x_2) + \cdots + x_n\cdot P(x_n) \notag \\
Var(X) = \sigma^2_X &= \sum(x_i - \mu_{\scriptscriptstyle{X}})^2 \cdot P(x_i) \\
&=(x_1-\mu_{\scriptscriptstyle{X}})^2\cdot P(x_1) + (x_2-\mu_{\scriptscriptstyle{X}})^2\cdot P(x_2) + \cdots +  (x_n-\mu_{\scriptscriptstyle{X}})^2\cdot P(x_n) \\
	SD(X) = \sigma_{\scriptscriptstyle{X}} 
	&=\sqrt{\sum(x_i - \mu_{\scriptscriptstyle{X}})^2 \cdot P(x_i)} \notag \\
	 &=\sqrt{(x_1-\mu_{\scriptscriptstyle{X}})^2\cdot P(x_1) + (x_2-\mu_{\scriptscriptstyle{X}})^2\cdot P(x_2) + \cdots +  (x_n-\mu_{\scriptscriptstyle{X}})^2\cdot P(x_n) }
\end{flalign*}
We can think of $P(x_i)$ as the \emph{weight}, and each term is weighted its appropriate amount.

\item The square of the standard deviation of a random variable is called the variance of the random variable and is denoted as $\sigma^2_X$.

\item The mean or expected value can be interpreted as the long-run average
outcome of the random variable, that is the average after many, many repetitions of the random process. The mean of a probability distribution does not need to be a value in the distribution. 

\item The standard deviation can be interpreted as the typical deviation of the values of the random variable from the mean value over the long run, that is after many, many repetitions of the random process.

\item The parameters mean and standard deviation for the probability distribution of a discrete random variable should be interpreted in the context of a specific population.



\end{itemize}




%%%%%%%%%%Section Exercises
{\input{ch_probability/TeX/discrete_random_variables.tex}}




%______________________________________________
\section[Binomial distributions]{Binomial distributions }
\label{binomDist}

\sectionintro{
\noindent%
What is the probability of exactly 50 heads in
100 coin tosses?
If 12 people are randomly selected for a jury, what is the probability that more than 9 of them identify as male?  
 Given that the probability of a defective part is 1\%, how many defective items would we expect in a random shipment of 200 of those parts?  We can model these scenarios and answer these questions using a binomial distribution.


%%
\subsection*{Learning objectives}
\begin{enumerate}
\setlength{\itemsep}{0mm}

\item Justify why a random variable is or is not a binomial random variable.

\item Calculate the mean and
standard deviation for a
binomial distribution.

\item Interpret the mean, standard
deviation, and probabilities for
a binomial distribution.

\item Estimate probabilities of binomial random variables using data from a simulation.

\item Calculate probabilities for a
binomial distribution.

\end{enumerate}
}

%%%%%%
\subsection{Binary variables}
\label{bernoulli}

\newcommand{\insureSprob}{0.7}
\newcommand{\insureSperc}{70\%}
\newcommand{\insureFprob}{0.3}
\newcommand{\insureFperc}{30\%}
\newcommand{\insureDistA}{0.7}
\newcommand{\insureDistB}{0.21}
\newcommand{\insureDistC}{0.063}
\newcommand{\insureDistD}{0.019}
\newcommand{\insureDistE}{0.006}
\newcommand{\insureCDistA}{0.7}
\newcommand{\insureCDistB}{0.91}
\newcommand{\insureCDistC}{0.973}
\newcommand{\insureCDistCComplement}{0.027}
\newcommand{\insureCDistD}{0.992}
\newcommand{\insureCDistE}{0.998}
\newcommand{\insureGeomMean}{1.43}
\newcommand{\insureS}{\resp{not}}
\newcommand{\insureF}{\resp{exceed}}
% Doesn't consider binomial coefficient in next calculated value.
\newcommand{\insureBinomCinDSingleScenario}{0.103}
\newcommand{\insureBinomCinD}{0.412}
\newcommand{\insureBinomEinHSingleScenario}{0.00454}
\newcommand{\insureBinomEinH}{0.254}
\newcommand{\insureBinomFourtyExpValue}{28}
\newcommand{\insureBinomFourtySD}{2.9}
\newcommand{\insureBinomFourtyLower}{22}
\newcommand{\insureBinomFourtyUpper}{34}


\index{distribution!Bernoulli|(}

Many health insurance plans in the United States have
a deductible, where the insured individual is responsible
for costs up to the deductible, and then the costs above
the deductible are shared between the individual and
insurance company for the remainder of the year.

Suppose a health insurance company found that \insureSperc{} of the
people they insure stay below their deductible in any given year.
Each of these people can be thought of as a \term{trial}.
We label a person a \term{success} if her healthcare costs
do not exceed the deductible.
We label a person a \term{failure} if she does exceed her
deductible in the year.
Because \insureSperc{} of the individuals will not exceed their deductible,
we denote the \term{probability of a success} as
$p = \insureSprob{}$.
The probability of a failure is $1 - p$, which would be \insureFprob{} for the insurance
example.

When an individual trial only has two possible outcomes, often
labeled as \resp{success} or \resp{failure}, it is called a
\termsub{Bernoulli random variable}{distribution!Bernoulli}, or more simply, a \term{binary variable} or yes/no variable.
We chose to label a person who does not exceed her deductible
as a ``success'' and all others as ``failures''.
However, we could just as easily have reversed these labels.
The mathematical framework we will build does not depend
on which outcome is labeled a success and which a failure,
as long as we are consistent.


Binary variables are often denoted as \resp{1}
for a success and \resp{0} for a failure.
In addition to being convenient in entering data,
it is also mathematically handy.
Suppose we observe ten trials:
\begin{center}
\resp{1} \resp{1} \resp{1} \resp{0} \resp{1} \resp{0} \resp{0} \resp{1} \resp{1} \resp{0}
\end{center}
Then the \term{sample proportion}, $\hat{p}$, is the
sample mean of these observations:
\begin{align*}
\hat{p} = \frac{\text{\# of successes}}{\text{\# of trials}}
    = \frac{1+1+1+0+1+0+0+1+1+0}{10} = 0.6
\end{align*}%

In general, it is useful to think about a binary random variable as a random process with only two outcomes: a success or failure. Then we build our mathematical framework using the numerical labels \resp{1} and \resp{0} for successes and failures, respectively.

\index{distribution!Bernoulli|)}


\D{\newpage}

%%%%%%%%
\subsection{Introducing the binomial formula}


\index{distribution!binomial|(}


Let's imagine ourselves at the insurance agency
where \insureSperc{} of individuals do not exceed their
deductible. The probability of success (not exceeding the deductible) is $p= \insureSprob{}$.


\begin{examplewrap}
\begin{nexample}{Suppose the insurance agency is considering
    a random sample of four individuals they insure.
    What is the chance exactly one of them will exceed
    the deductible and the other three will not?
    Let's call the four people
    Ariana ($A$),
    Brittany ($B$),
    Carlton ($C$),
    and Damian ($D$)
    for convenience.}
  \label{insureOneOfFourExceedsDeductible}%
  Let's consider a scenario where one person exceeds
  the deductible:
  \begin{align*}
  &P(A=\text{\insureF{}},
      \text{ }B=\text{\insureS{}},
      \text{ }C=\text{\insureS{}},
      \text{ }D=\text{\insureS{}}) \\
    &\quad = P(A=\text{\insureF{}})\ 
        P(B=\text{\insureS{}})\ 
        P(C=\text{\insureS{}})\ 
        P(D=\text{\insureS{}}) \\
    &\quad =  (\insureFprob{})
        (\insureSprob{})
        (\insureSprob{})
        (\insureSprob{}) \\
    &\quad = (\insureSprob{})^3 (\insureFprob{})^1 \\
    &\quad = \insureBinomCinDSingleScenario{}
  \end{align*}
  But there are three other scenarios: Brittany, Carlton,
  or Damian could have been the one to exceed the deductible.
  In each of these cases, the probability is again
  $(\insureSprob{})^3 (\insureFprob{})^1$.
  These four scenarios exhaust all the possible ways that
  exactly one of these four people could have exceeded
  the deductible, so the total probability is
  $4 \times (\insureSprob{})^3 (\insureFprob{})^1
      = \insureBinomCinD{}$.
\end{nexample}
\end{examplewrap}

\begin{exercisewrap}
\begin{nexercise}
Verify that the scenario where Brittany is the only one to exceed the deductible has probability
$(\insureSprob{})^3 (\insureFprob{})^1$.~\footnotemark{}
\end{nexercise}
\end{exercisewrap}
\footnotetext{
  $P(A=\text{\insureS{}},
      \text{ }B=\text{\insureF{}},
      \text{ }C=\text{\insureS{}},
      \text{ }D=\text{\insureS{}})
    = (\insureSprob{})(\insureFprob{})
        (\insureSprob{})(\insureSprob{})
    = (\insureSprob{})^3 (\insureFprob{})^1$.}


In Example~\ref{insureOneOfFourExceedsDeductible}, there were four individuals who could have been the one
to exceed the deductible, and each of these four scenarios
had the same probability $p$ of $\insureSprob{}$.  We use $n$ to represent the number of trials, in this case 4 and we use $x$ to represent the desired number of successes, in this case 1.  This leads us to a more general approach to find probabilities involving exactly $x$ successes in $n$ trials, where the probability in each trial of a success is $p$.

We can write the probability as
\begin{align*}
[\text{\# of scenarios}] \times P(\text{single scenario})
\end{align*}
The first component of this equation is the number of ways
to arrange the $x=3$ successes among the $n=4$ trials.
The second component is the probability of any of the four
(equally probable) scenarios.

Consider $P($single scenario$)$ under the general case of
$x$ successes and $n-x$ failures in the $n$ trials.
In any such scenario, we apply the Multiplication Rule
for independent events:
\begin{align*}
p^x (1 - p)^{n - x}
\end{align*}
This is our general formula for $P($single scenario$)$.

\D{\newpage}

Secondly, we introduce the \term{binomial coefficient}, which gives the number
of ways to choose $x$ successes in $n$ trials,
i.e. arrange $x$ successes and $n - x$ failures:
\begin{align*}
{n\choose x} = \frac{n!}{x! (n - x)!}
\end{align*}

The quantity ${n\choose x}$ is read
\term{n choose x}.\footnote{Other notations for
  $n$ choose $x$ includes $_nC_x$, $C_n^x$, and $C(n,x)$.}
The exclamation point notation (e.g. $n!$) denotes
a \term{factorial} expression.
\begin{align*}
& 0! = 1 \\
& 1! = 1 \\
& 2! = 2\times1 = 2 \\
& 3! = 3\times2\times1 = 6 \\
& 4! = 4\times3\times2\times1 = 24 \\
& \vdots \\
& n! = n\times(n-1)\times...\times3\times2\times1
\end{align*}
Using the formula, we can compute the number of ways
to choose $x = 3$ successes in $n = 4$ trials:
\begin{align*}
{4 \choose 3} = \frac{4!}{3!(4-3)!}
  = \frac{4!}{3!1!} 
  = \frac{4\times3\times2\times1}{(3\times2\times1) (1)}
  = 4
\end{align*}
This result is exactly what we found by carefully thinking
of each possible scenario in
Example~\ref{insureOneOfFourExceedsDeductible}.

Substituting $n$ choose $x$ for the number of scenarios
and $p^x(1-p)^{n-x}$ for the single scenario probability
yields the \term{binomial formula}.

\begin{onebox}{Binomial formula}
Suppose the probability of a single trial being a success is $p$. Then the probability of observing exactly $x$ successes in $n$ independent trials is given by:\vspace{-1mm}
\begin{eqnarray*}
P(X=x)={n\choose x}p^x(1-p)^{n-x} = \frac{n!}{x!(n-x)!}p^x(1-p)^{n-x}
\end{eqnarray*}
where $x=0,1,2,3\dots,n$.
\label{binomialFormula}
\end{onebox}


%%
\subsection{When and how to apply the binomial formula}

\begin{onebox}{Is it binomial? Four conditions to check.}
  \label{isItBinomialTipBox}%
Informally, we can say that the binomial formula is used in questions concerned with\\ ``how many successes out of $n$".  To be binomial the following four conditions must be met.\\

  (1) Each trial outcome is \emph{binary} (can be classified as a success
      or failure). \\
  (2) The trials are \emph{independent}. \\
  (3) The number of trials, $n$, is fixed. \\
  (4) There is the \emph{same} probability of success, $p$, for
      each trial.
\end{onebox}

\noindent A useful acronym to remember these conditions is BINS:  \emph{b}inary, \emph{i}ndependent, $n$ fixed, and \emph{s}ame p.

\D{\newpage}

\begin{examplewrap}
\begin{nexample}{Say we would like to find the probability that 5 of 8 randomly selected individuals from the insurance agency will not exceed the deductible.  Can we use the binomial formula?  }
We are interested in 5 out of 8, which sounds like a ``how many successes out of n" scenario.  To verify we can use the binomial formula we check the following conditions.
\begin{enumerate}
\setlength{\itemsep}{0mm}
\item Each trial outcome is binary (not exceed the insurance deductible or exceed the insurance deductible).
\item The sample is random, but it is not with replacement, so the observations are not entirely independent.  However, as we saw in the Section~\ref{smallPop} (Sampling without replacement), when the sample size is very small compared to the population size, we can treat the observations \emph{as if they were with replacement}, since the composition of the population changes very little with each additional person sampled.  Since we have a random sample of a very small percent of all individuals from the insurance company, we will consider the independence condition met.  
\item The number of trials is fixed ($n = 8$).
\item There is the same probability of a success for each trial. ($p=0.70$)
\end{enumerate}
\label{binex}
\end{nexample}
\end{examplewrap}


\begin{onebox}{Sampling without replacement}
When randomly sampling without replacement, if the sample size is small relative to the population size (rule of thumb: sample size less than 1/10 of the population size), we will consider the observations to be independent. 
\end{onebox}


\begin{examplewrap}
\begin{nexample}{Find the probability that 5 of 8 randomly selected individuals from the insurance agency will not exceed the deductible, i.e. that 3 of them will.
    Recall that 70\% of individuals will not exceed the
    deductible.}
  Here a success is not exceeding the deductible and the
  probability of a success is $p = \insureSprob{}$.  We want to find the probability of $x = 5$ successes in $n = 8$ trials.  
  We previous verified that this scenario is binomial, so we will use the binomial formula. The probability that 5 of 8 will not exceed the
  deductible and 3 will exceed the deductible is given by
  \begin{align*}
  { 8 \choose 5}(\insureSprob{})^5
  (1-\insureSprob{})^{8-5}
    &= \frac{8!}{5!(8-5)!}
        (\insureSprob{})^5(1-\insureSprob{})^{8-5} \\
    &= \frac{8!}{5!3!}
        (\insureSprob{})^5(\insureFprob{})^3
  \end{align*}
  Dealing with the factorial part:
  \begin{align*}
  \frac{8!}{5!3!}
    = \frac{8\times7\times6\times5\times4\times3\times2\times1}
        {(5\times4\times3\times2\times1)(3\times2\times1)}
    = \frac{8\times7\times6}{3\times2\times1}
    = 56
  \end{align*}
  Using $(\insureSprob{})^5(\insureFprob{})^3
    \approx \insureBinomEinHSingleScenario{}$,
  the final probability is about
  $56\times \insureBinomEinHSingleScenario{}
    \approx \insureBinomEinH{}$.
\end{nexample}
\end{examplewrap}


Evaluating the binomial formula by hand can be tedious.  See Section~\ref{techBinomial} for ways to evaluate the binomial formula using technology.


\begin{onebox}{Computing binomial probabilities}
  The first step in using the binomial model is to check
  that the model is appropriate.
  The second step is to identify $n$, $p$, and $x$.
  Finally, apply the binomial formula to determine the probability and interpret the results.%
  \vspace{3mm}

\end{onebox}

\begin{examplewrap}
\begin{nexample}{Approximately 35\% of a population has blood type O+.  Suppose four people show up at a hospital and we want to find the probability that exactly one of them has blood type O+.  Can we use the binomial formula?  }
\label{verifybinomial}
To check if the binomial model is appropriate,
  we must verify the conditions.
\begin{enumerate}
\setlength{\itemsep}{0mm}
\item Each outcome is binary (blood type O+ or not blood type O+).
\item We will suppose that these 4 people comprise a random sample.  This seems reasonable, since one person with a particular blood type showing up at a hospital seems unlikely to affect the chance that other people with that blood type would show up at the hospital.  Though this scenario is without replacement, 4 should be less than 1/10th of all people that show up at the hospital.  Therefore, we can treat the random sample \emph{as if it were} with replacement and consider the independence condition met.
\item We have a fixed number of trials ($n=4$).
\item The probability of a success is the same for each
  trial ($p=0.35$ if we say a ``success'' is someone having blood type O+).
\end{enumerate}
\end{nexample}
\end{examplewrap}


\begin{examplewrap}
\begin{nexample}
{Given that 35\% of a population has blood type O+, what is the probabilty that in a random sample of 4 people:  
\begin{enumerate}[(a)]
\setlength{\itemsep}{0mm}
\item
    none of them have blood type O+?
\item
    exactly one will have blood type O+?
\item
    no more than one will have blood type O+?
\end{enumerate}
}
\begin{enumerate}[(a)]
\item
  $P(X=0)
    = {4 \choose 0} (0.35)^0 (0.65)^4
    = 1\times1\times 0.65^4 = 0.65^4
    = 0.179$\\
Note that we could have answered this question without the binomial formula, using methods from the previous section.
\item 
  $P(X=1)
    = {4 \choose 1} (0.35)^1(0.65)^{3}
    = 0.384$.
  \item We want to find $P(X \le 1)$.  This can be computed as the sum of parts~(a) and~(b):\\
  $P(X \le 1) = P(X=0) + P(X=1) = 0.179 + 0.384 = 0.563$.\\
  There is about a 56.3\% chance that no more than
  one of them will have blood type O+.
\end{enumerate}
\label{bloodTypeOPos}
\end{nexample}
\end{examplewrap}


\begin{exercisewrap}
\begin{nexercise}
What is the probability that at least 3 of 4 people in a random sample will have blood type O+ if 35\% of the population has blood type O+?\footnotemark
\end{nexercise}
\end{exercisewrap}
\footnotetext{$P(\text{at least 3 of 4 have blood type O+})
      = P(X=3) + P(X=4) = {4 \choose 3} (0.35)^3 (0.65)^1+(0.35)^4= 0.111 + 0.015 = 0.126$}


 \begin{exercisewrap}
\begin{nexercise}
The probability that a random smoker will develop a severe
lung condition in her lifetime is about $0.3$.
If you have 4 friends who smoke and you want to find the probability that 1 of them will develop a severe lung condition in her lifetime, can you apply the binomial formula?\footnotemark
\end{nexercise}
\end{exercisewrap}
\footnotetext{While the binary and fixed $n$ conditions are met, most likely the friends know each other, so the independence
  assumption is probably not satisfied.
  For example, acquaintances may have similar smoking habits,
  or those friends might make a pact to quit together.  The same $p$ condition is also not satisfied since this is not a random sample of people.}



%
%Lastly, we consider the binomial coefficient,,
%$n$ choose $x$, under some special scenarios.
%
%\begin{exercisewrap}
%\begin{nexercise}
%Why is it true that ${n \choose 0}=1$ and ${n \choose n}=1$
%for any number $n$?\footnotemark
%\end{nexercise}
%\end{exercisewrap}
%\footnotetext{Frame these expressions into words.
%  How many different ways are there to arrange 0 successes
%  and $n$ failures in $n$ trials?
%  (1 way.)
%  How many different ways are there to arrange $n$ successes
%  and 0 failures in $n$ trials?
%  (1 way.)}
%
%\begin{exercisewrap}
%\begin{nexercise}
%How many ways can you arrange one success and $n-1$ failures
%in $n$ trials?
%How many ways can you arrange $n-1$ successes and one failure
%in $n$ trials?\footnotemark
%\end{nexercise}
%\end{exercisewrap}
%\footnotetext{One success and $n-1$ failures:
%  there are exactly $n$ unique places we can put
%  the success, so there are $n$ ways to arrange one
%  success and $n-1$ failures.
%  A~similar argument is used for the second question.
%  Mathematically, we show these results by verifying
%  the following two equations:
%  \begin{align*}
%  {n \choose 1} = n,
%    \qquad {n \choose n-1} = n
%  \end{align*}}


%%
\subsection{An example of a binomial distribution}

\newcommand{\oposprob}[0]{0.35}
\newcommand{\oposprobcomp}[0]{0.65}

In Guided Practice~\ref{bloodTypeOPos}, we asked various probability questions regarding the number of people out of 4 with blood type O+.  We verified that the scenario was binomial and that each problem could be solved using the binomial formula. Instead of looking at it piecewise, we could describe the entire \emph{distribution} of possible values and their corresponding probabilities. Since there are 4 people, the possible outcomes for the number who will have blood type O+ are: 0, 1, 2, 3, 4.
In Figure~\ref{oPositive4}, we make a distribution table and a histogram showing the probability of each of these outcomes.  
Recall that the probability of a randomly sampled person being blood type O+ is about~\oposprob{}.

\begin{figure}[h]
\begin{minipage}[c]{0.37\textwidth}\centering%
\begin{tabular}{l l}
$x_i$ & $P(x_i)$ \\
\hline
0 &  ${4\choose 0}(\oposprob{})^0(\oposprobcomp{})^{4} = 0.179$ \vspace{1mm}\\
1 &  ${4\choose 1}(\oposprob{})^1(\oposprobcomp{})^{3} = 0.384$  \vspace{1mm}\\
2 & ${4\choose 2}(\oposprob{})^2(\oposprobcomp{})^{2} = 0.311$  \vspace{1mm}\\
3 & ${4\choose 3}(\oposprob{})^3(\oposprobcomp{})^{1} = 0.111$  \vspace{1mm}\\
4 & ${4\choose 4}(\oposprob{})^4(\oposprobcomp{})^{0} = 0.015$  \vspace{1mm}\\
\hline
\end{tabular}
\end{minipage}
\begin{minipage}[c]{0.6\textwidth}\centering%
\Figure[A histogram is shown.  The horizontal axis is labeled ``Number with blood type O+ in a Random Sample of size 4" and ranges from 0 to 4.  The vertical axis is labeled ``Probability" and ranges from 0 to about 0.40.  The histogram appears right skewed.]
{0.95}{oPositive4}
\end{minipage}
\caption{Probability distribution for the number with blood type O+ in a random sample of 4 people. This is a binomial distribution. Correcting for rounding error, the probabilities add up to~1, as they must for any probability distribution.}
\label{oPositive4}
\label{binomDistrOPositive}
\end{figure}

A \termsub{binomial distribution}{distribution!binomial}
is used to describe
the number of successes in a fixed number of independent trials.  A binomial distribution has two parameters: $n$ and $p$, where $n$ is the number of trials and $p$ is the probability of a success.  The example in Figure~\ref{oPositive4} shows a binomial distribution with $n=4$ and $p=0.35$.

To find the probability that a binomial random variable $X$ has exactly $x$ successes, apply the binomial formula as follows:
\begin{align*}
P(X=x) = {n\choose x}p^x(1-p)^{n-x}, \text{ where } x=0,1,2,3\dots,n. 
\end{align*}



%%
\subsection{The mean and standard deviation of a binomial distribution}

We can find the mean and
standard deviation of the probability distribution in Figure~\ref{oPositive4} using the formulas for the mean and standard deviation of a discrete random variable from Section~\ref{randomVariablesSection}.
Those formulas require a lot of calculations, so it is fortunate that there is
an easier way to compute the mean and standard deviation for a binomial
random variable.

\begin{onebox}{Mean and standard deviation of the binomial distribution}
For a binomial distribution with parameters $n$ and $p$, where $n$ is the number of trials and $p$ is the probability of a success, the mean and standard deviation of the number of observed successes are\vspace{-2mm}
\begin{align*}
\mu_{\scriptscriptstyle{X}} &= np
	&\sigma_{\scriptscriptstyle{X}} &= \sqrt{np(1-p)}
\end{align*}
\end{onebox}

\begin{examplewrap}
\begin{nexample}{The probability that a person has blood type O+ is \oposprob{}.  Let X be the number of  people with blood type O+ in a random sample of 40 people.  Calculate and interpret the mean and standard deviation of X.}
In Example~\ref{verifybinomial} we confirmed that the binary, independence, $n$ fixed, and same $p$ conditions were met.  Therefore we can say that X is Binomial with $n=40$ and $p= \oposprob{}$.
\begin{align*}
\mu_{\scriptscriptstyle{X}}=np = 40(\oposprob{}) = 14
\end{align*}
If we were to take many, many random samples of size 40, we would expect to get about 14 people with blood type O+, on average.
\begin{align*}
\sigma_{\scriptscriptstyle{X}} = \sqrt{np(1-p)} = \sqrt{40(\oposprob{})(\oposprobcomp{})} = 3.0
\end{align*}
If we were to take many, many random samples of size 40, the number of people in our sample with blood type O+ would typically vary from the mean of 14 people by about 3 people.
\label{binomialmeansd}
\end{nexample}
\end{examplewrap}

The distribution of the number of people with blood type O+ in a random sample of size 40 is shown in Figure~\ref{oPositive40}.  It is binomial distribution with $n=40$ and $p=0.35$, and it has a mean of 14 and a standard deviation of 3.0.  

\begin{figure}[ht]
\centering
\Figure[A histogram is shown.  The horizontal axis is labeled ``Number with blood type O+ in a Random Sample of size 40" and ranges from 5 to 24.  The vertical axis is labeled ``Probability" and ranges from 0 to about 0.15.  The histogram appears approximately normal.]
{0.63}{oPositive40}
\caption{Distribution for the number of people with blood type O+ in a random sample of size 40, where $p=\oposprob{}$.  The distribution is binomial and is centered on~14 with a standard deviation of 3.  }
\label{oPositive40}
\end{figure}


%%
\subsection{Binomial probabilities for intervals of values}

\begin{examplewrap}
\begin{nexample}{Find the probability of getting between 15 and 17 people, inclusive, with blood type O+ in a random sample of 40 people.  The probability of a randomly sampled person being blood type O+ is 0.35. }
X is the number of people with blood type O+.  X has a binomial distribution with $n=40$ and $p=0.35$.  We want to find $P(15 \le X \le 17)$.  Because the binomial distribution is discrete, we can find this by calculating $P(X = 15) + P(X = 16) + P(X = 17)$ as follows: 
\begin{align*}
P(15 \le X \le 17) &=P(X = 15) + P(X = 16) + P(X = 17)\\
&={40 \choose 15} (0.35)^{15} (0.65)^{25} +  {40 \choose 16} (0.35)^{16} (0.65)^{24} + {40 \choose 17} (0.35)^{17} (0.65)^{23}\\
&= 0.123 + 0.103  + 0.078\\
&= 0.304
\end{align*}
The probability of getting between 15 and 17 people, inclusive, with blood type O+ in a random sample of 40 people is 0.304, or 30.4\%.
\end{nexample}
\end{examplewrap}


\begin{examplewrap}
\begin{nexample}{Find the probability that at least 18 people have blood type O+ in a random sample of 40 people.  The probability of a randomly sampled person being blood type O+ is 0.35. }
X is the number of people with blood type O+.  Here, we want to find the probability that X $\ge$18.

$P(X \ge 18) = P(X = 18) + P(X = 19) + P(X = 20) + \dots P(X = 40)$.

Evaluating this with the binomial formula would involve applying the binomial formula 23 times!  Fortunately, we can use technology to help us.  We first identify the distribution and its parameters.  Here X is Binomial with $n=50$ and $p=0.35$.  We sometimes write this as X is Binomial($n=40$, $p=0.35$). Then we can use a technology option from Section~\ref{techBinomial} to find that \mbox{$P(X \ge 18) = 0.124$.}  There is about a 12.4\% probability of at least 18 people with blood type O+ in a random sample of size 40.  
\end{nexample}
\end{examplewrap}

When using technology to find binomial probabilities, make sure to identify the distribution being used and its parameters, then write a clear probability statement communicating what is being evaluated.  A graph, such as the one shown below in Figure~\ref{oPositive40Desmos}, helps to visualize the distribution and the individual probabilities used in the calculation.     

\begin{figure}[ht]
\centering
\fbox{\Figures[A binomial distribution.]
{1}{oPositive40}{atLeast18}}\vspace{5mm}
\caption{A Desmos graph illustrating a Binomial distribution with $n=40$ and $p=0.35$.  Values greater than or equal to 18 are highlighted.  }
\label{oPositive40Desmos}
\end{figure}

\begin{exercisewrap}
\begin{nexercise}
What is the probability that at most 12 people in a random sample of 40 will have blood type O+ if 35\% of the population has blood type O+?
\footnotemark
\end{nexercise}
\end{exercisewrap}
\footnotetext{X is the number of people with blood type O+.  X is Binomial($n=40$, $p=0.35$).  $P(X \le 12) = 0.314$.  There is a 31.4\% probability that at most 12 people in a random sample of size 40 will have blood type O+.}


%%

\D{\newpage}

%%
\subsection{Technology: binomial probabilities}
\label{techBinomial}

\noindent A spinner has four equally likely options:  red, green, blue, yellow.  If you spin the spinner 6 times, what is the probability you get:
\begin{itemize}
\setlength{\itemsep}{0mm}
\item[a)] Exactly 2 red?  
\item[b)] Less than 2 red?   
\item[c)] At least 3 red?
\end{itemize}

\noindent This scenario describes a \textbf{binomial distribution} with $n = 6$ and $p = 0.25$.\\ 

\noindent \\
\textbf{Desmos}:  Use \texttt{binomialdist(n, p)}, replacing \texttt{n} and \texttt{p} with appropriate values.
\begin{enumerate}
\setlength{\itemsep}{0mm}
\item Type \calctext{binomialdist(6, 0.25)}.
\item Click the triangle next to \calctext{Cumulative Probability}.
\item Select \calctext{Inner}, \calctext{Outer}, \calctext{Left}, or \calctext{Right} as illustrated below.
\item Enter the appropriate boundary value(s) for \calctext{$x$} as illustrated below.
\item Click the magnifying glass to Zoom Fit the graphing window.
\end{enumerate}

\begin{itemize}
\item[a)]  P(Exactly 2 red):  $P(x =  2)$.
\begin{center}
\fbox{\Figures[A Desmos calculator screen is shown.  On the left is the function binomialdist(6, 0.25), with Inner chosen and x between 2 and 2, inclusive.  The probability is given as 0.297.  On the right is a graph of the binomial distribution with parameters n = 6 and p = 0.25.  x, on the horizontal axis, ranges from 0 to 6.  The bar corresponding to x = 2 is highlighted. ]
{0.65}{techonologyProbability}{desmosBinomialEqual}}
\end{center}

\item[ b)] P(Less than 2 red):  $P(x <  2) = P(x \le 1)$.
\begin{center}
\fbox{\Figures[A Desmos calculator screen is shown.  On the left is the function binomialdist(6, 0.25), with Left chosen and x less than or equal to 1.   On the right is a graph of the binomial distribution with parameters n = 6 and p = 0.25.  x, on the horizontal axis, ranges from 0 to 6.  The bars corresponding to x = 0 and x = 1 are highlighted.]
{0.65}{techonologyProbability}{desmosBinomialLess}}
\end{center}

\item[c)] P(At least 3 red):  $P(x \ge  3)$.
\begin{center}
\fbox{\Figures[A Desmos calculator screen is shown.  On the left is the function binomialdist(6, 0.25), with Right chosen and x greater than or equal to 3.   On the right is a graph of the binomial distribution with parameters n = 6 and p = 0.25.  x, on the horizontal axis, ranges from 0 to 6.  The bars corresponding to x = 3, x = 4, x = 5, and x = 6 are highlighted. ]
{0.65}{techonologyProbability}{desmosBinomialGreater}}
\end{center}

\end{itemize}

%%

\D{\newpage}

\noindent \R{}:  Given a binomial distribution with $n=6$ and $p=0.25$, calculate the following probabilities.

\begin{itemize}
\item[a)] P(X = 2).  Use \texttt{dbinom(x, size, prob)} for the probability of exactly \texttt{x}.\\
\noindent\hspace{5mm}Note that ``\texttt{size =}" and ``\texttt{prob =}" can be omitted, but the labels are often included for clarity.  \\
\texttt{> \calctext{dbinom(2, size = 6, prob = 0.25)}} \quad or \quad \texttt{> \calctext{dbinom(2, 6,  0.25)}}\\
\texttt{[1] 0.2966309}\\


\item[b)] P(X $\le$ 1).  Use \texttt{pbinom(q, size, prob)} for the probability of $\le$ \texttt{q} as shown.  \\
\texttt{> \calctext{pbinom(1, size = 6, prob = 0.25})}\\
\texttt{[1] 0.5339355}\\

\item[c)]  P(X $\ge$ 3).\\
\texttt{> \calctext{1 $-$ pbinom(2, size = 6, prob = 0.25)}}\\
\texttt{[1] 0.1694336}\\
\noindent or\\
\texttt{> \calctext{pbinom(2, size = 6, prob = 0.25, lower.tail = FALSE)}}\\ 
\texttt{[1] 0.1694336}\\ \\

\end{itemize}


\noindent \textbf{Calculator}:  NumWorks calculator instructions and example output are included.  For the TI-83/84 and Casio calculators, general instructions are provided, and worked example videos can be accessed via the \includegraphics[height=3mm]{extraTeX/icons/video_camera.png} icon or at \oiRedirect{ti84_playlist}{\textbf{openintro.org/ti}} and \oiRedirect{casio-9750-playlist}{\textbf{openintro.org/casio}}.
\\
\\


\begin{onebox}{NumWorks: Binomial calculations}
\label{binomialnumworks}
Use \calctext{OK} or \calctext{EXE} to make a selection.
\begin{enumerate}
\setlength{\itemsep}{0mm}
\item From the home screen, select \calcbutton{Distributions} then select \calcbutton{Binomial}.  If a list of distributions does not appear, hit the \calcbutton{$\lhookleftarrow$} button (next to \calctext{OK}) as many times as needed.
\item Enter the values of \calctext{n} and \calctext{p} then choose \calcbutton{Next}.  If the screen shows a graph rather than asking for \calctext{n} and \calctext{p}, hit the \calcbutton{$\lhookleftarrow$} button.
\item Hit the left arrow to highlight the graph.  Hit the down arrow to choose whether you want left, inner, right, or exactly, then hit \calcbutton{OK}.  Hit the right arrow and enter the boundary value(s) followed by \calcbutton{EXE}.
\begin{center}
\Figures[ ]
{0.35}{techonologyProbability}{numworksBinomialEqual} \hspace{10mm}
\Figures[ ]
{0.35}{techonologyProbability}{numworksBinomialGreater}
\end{center}
\vspace{-1.5mm}
\end{enumerate}
\end{onebox}

\begin{onebox}{\videohref{ti84_binomial_formula} TI-84: Computing the binomial formula, \pmb{$P(X = \MakeLowercase{x)={n\choose x}p^x(1-p)^{n-x}}$}}
\label{binomialformula}
Use \calcbutton{2ND} \calcbutton{VARS}, \calctext{binompdf} to evaluate the probability of \emph{exactly} $x$ occurrences out of $n$ independent trials of an event with probability $p$. 
\begin{enumerate}
\setlength{\itemsep}{0mm}
\item Select \calcbutton{2ND} \calcbutton{VARS} (i.e. \calctext{DISTR})
\item Choose \calctext{A:binompdf} (use the down arrow to scroll down).
\item Let \calctext{trials} be $n$.
\item Let \calctext{p} be $p$
\item Let \calctext{x value} be $x$.
\item Select \calctext{Paste} and hit \calcbutton{ENTER}.\vspace{-1.5mm}
\end{enumerate}
TI-83: Do step 1, choose \calctext{0:binompdf}, then enter $n$, $p$, and $x$ separated by commas:\\
	\calctext{binompdf(n,~p,~x)}. Then hit \calcbutton{ENTER}. 
\end{onebox}

\begin{onebox}{\videohref{ti84_binomial_cdf} TI-84: Computing \pmb{$P(X \le \MakeLowercase{x)= {n\choose 0}p^0(1-p)^{n-0} + ... + {n\choose x}p^x(1-p)^{n-x}}$} }
\label{binomialcumulative}
Use \calcbutton{2ND} \calcbutton{VARS}, \calctext{binomcdf} to evaluate the cumulative probability of \emph{at most} $x$ occurrences out of $n$ independent trials of an event with probability $p$. 
\begin{enumerate}
\setlength{\itemsep}{0mm}
\item Select \calcbutton{2ND} \calcbutton{VARS} (i.e. \calctext{DISTR})
\item Choose \calctext{B:binomcdf} (use the down arrow).
\item Let \calctext{trials} be $n$.
\item Let \calctext{p} be $p$
\item Let \calctext{x value} be $x$.
\item Select \calctext{Paste} and hit \calcbutton{ENTER}.\vspace{-1.5mm}
\end{enumerate}
TI-83: Do steps 1-2, then enter the values for $n$, $p$, and $x$ separated by commas as follows: \calctext{binomcdf(n,~p,~x)}. Then hit \calctext{ENTER}.\end{onebox}




\begin{onebox}{\videohref{casio_binomial_calculations} Casio fx-9750GII: Binomial calculations}
\ \vspace{-5mm} \
\begin{enumerate}
\setlength{\itemsep}{0mm}
\item Navigate to \calctext{STAT} (\calcbutton{MENU}, then hit \calcbutton{2}).
\item Select \calctext{DIST} (\calcbutton{F5}), and then \calctext{BINM} (\calcbutton{F5}).
\item Choose whether to calculate the binomial distribution for a specific number of successes, $P(X = k)$, or for a range $P(X \leq k)$ of values (0~successes, 1~success, ..., $x$~successes).\vspace{-1.5mm}
  \begin{itemize}
  \setlength{\itemsep}{0mm}
  \item For a specific number of successes, choose \calctext{Bpd} (\calcbutton{F1}). %, which stands for \emph{binomial probability distribution}.
  \item To consider the range 0, 1, ..., $x$ successes, choose \calctext{Bcd}(\calcbutton{F1}). %, which stands for \emph{binomial cumulative distribution}.
  \end{itemize}
\item If needed, set \calctext{Data} to \calctext{Variable} (\calctext{Var} option, which is \calcbutton{F2}).
\item Enter the value for \calctext{x} ($x$), \calctext{Numtrial} ($n$), and \calctext{p} (probability of a success).
\item Hit \calctext{EXE}.
\end{enumerate}
\end{onebox}



\D{\newpage}

\subsection*{Section summary}

\begin{itemize}

\item A \termni{binomial random variable}, $X$, is a discrete random variable that counts the number of successes in $n$ repeated \emph{independent} trials that have only two possible outcomes (success or failure), with a fixed probability of success $p$ and probability of failure $1 -  p$ for each trial.

\item If \textit{X} follows a \termni{binomial distribution} with parameters $n$ and $p$, then:
\begin{itemize}\vspace{-1mm}
\setlength{\itemsep}{0mm}
\item[-] The mean is given by $\mu_{\scriptscriptstyle{X}} = np$. \quad (\emph{center})
\item[-] The standard deviation is given by $\sigma_{\scriptscriptstyle{X}} = \sqrt{np(1-p)}$. \quad (\emph{spread})
\end{itemize}

\item The mean of a binomial distribution tells us about how many successes we expect, on average, across many, many samples of size $n$ from the same population.  

\item The standard deviation of a binomial distribution tells us the typical variation of values from the mean across many, many samples of size $n$ from the same population.  

\item The mean and standard deviation should always be interpreted in context.

\item A probability distribution can be constructed using the rules of probability or estimated with a simulation.

\item The probability that a binomial random variable, $X$, has exactly $x$ successes among $n$ independent trials, when the probability of success is $p$, is calculated as: 
\begin{align*}
P(X=x) = {n\choose x}p^x(1-p)^{n-x}, \text{ where } x=0,1,2,3\dots,n.
\end{align*}

\end{itemize}
\index{distribution!binomial|)}

%%%%%%%%%%Section exercises
{\input{ch_probability/TeX/binomial_distributions.tex}}




%__________________________________________________
\section[Normal distributions]{Normal distributions}
\label{normalDist}

\sectionintro{
\noindent%
What proportion of adults have systolic blood pressure above 140? If the average weight of a piece of carry-on luggage is 11 pounds, what is the probability that 100 random carry on pieces will weigh more than 1200 pounds?
If 55\% of a population supports a certain candidate, what is the probability that she will have less than 50\% support in a random sample of size 200? \vspace{3mm}

\noindent%
There is one distribution that can help us answer all of these questions.
Can you guess what it is?
That's right -- it's the normal distribution.

\subsection*{Learning objectives}
\begin{enumerate}
\setlength{\itemsep}{0mm}

\item Describe the standard normal distribution.

\item Use Z-scores and the standard normal model to approximate a distribution where appropriate.

\item Calculate the proportion of values in a specified interval for a normal distribution.

\item Find boundary values of an interval associated with a given proportion under a normal distribution.  

\item Calculate the mean or standard deviation of a normal distribution given the value of a percentile.

\item Compare measures of relative position for distributions.

\item Estimate the proportion of values in a specified interval of a normal distribution using the empirical rule.

\end{enumerate}
}


%%
\subsection{Normal distribution model}

Among all the distributions we see in practice, one is overwhelmingly the most common. The symmetric, unimodal, bell curve is ubiquitous throughout statistics. Indeed it is so common, that people often know it as the \term{normal curve} or \termsub{normal distribution}{distribution!normal}.\footnote{It is also introduced as the Gaussian distribution after Frederic Gauss, the first person to formalize its mathematical expression.} A normal curve is shown in Figure~\ref{simpleNormal}. 

\begin{figure}[h]
\centering
  \Figure[A bell-shaped curve that is symmetric about its center is shown. This is the normal distribution. From the left, the curve starts low, grad lifting off the horizontal axis before more steeply rising, before it starts to rise more slowly and flattens at its peak. From the peak, it starts to decrease slowly and then more steeply, before gradually flattening out as it approaches the horizontal axis. This is the bell-shaped normal distribution, an it is the shape of many distributions we will encounter throughout this book. In general, going forward, this bell-shaped distribution shape should be remembered whenever the normal distribution is discussed.]
{0.6}{simpleNormal}
\caption{A normal curve.}
\label{simpleNormal}
\end{figure}

\D{\newpage}

The \term{normal distribution} always describes a symmetric, unimodal, bell-shaped curve. However, these curves can look different depending on the details of the model. Specifically, the normal distribution model can be adjusted using two parameters: mean and standard deviation. As you can probably guess, changing the mean shifts the bell curve to the left or right, while changing the standard deviation stretches or constricts the curve. 

Figure~\ref{twoSampleNormals} shows the normal distribution with mean $0$ and standard deviation $1$ in the left panel and the normal distributions with mean $19$ and standard deviation $4$ in the right panel. Figure~\ref{twoSampleNormalsStacked} shows these distributions on the same axis.


\begin{figure}[hht]
\centering
  \Figure[Two normal distributions are shown. The first has a center of 0 and a standard deviation of 1, where the two tails of the normal distribution curve are essentially indistinguishable from a height of 0 for values less than -3 or larger than positive 3. The second normal distribution is centered at 19 and has a standard deviation of 4, where the height of the distribution is indistinguishable from 0 when it is more than 3 standard deviations from the mean.]
{0.95}{twoSampleNormals}
\caption{Both curves represent a normal distribution.  However, they differ in their center and spread. }
\label{twoSampleNormals}
\end{figure}

\begin{figure}[hht]
\centering
  \Figure[Two normal distributions are shown on the same plot. The first has a mean of 0 and a standard deviation of 1. The second has a mean of 19 and a standard deviation of 4. One important property visible in the plot is, because distributions are required to have an area of 1, the normal distribution with a standard deviation of 1 appears much narrower and but also much taller than the second distribution that has a standard deviation of 4.]
{0.67}{twoSampleNormalsStacked}
\caption{The normal distributions shown in Figure~\ref{twoSampleNormals} but plotted together and on the same scale.}
\label{twoSampleNormalsStacked}
\end{figure}

Because the mean and standard deviation describe a normal distribution exactly, they are called the distribution's \termsub{parameters}{parameter}.  The normal distribution with mean $\mu=0$ and standard deviation $\sigma = 1$ is called the \term{standard normal distribution}.%
\index{normal distribution!standard|textbf}.


\begin{onebox}{Normal distribution facts}
Many variables are nearly normal, but none are exactly normal. The normal distribution, while never perfect, provides very close approximations for a variety of scenarios. We will use it to model data as well as probability distributions.\vspace{0.7mm}\end{onebox}


\D{\newpage}

%%
\subsection{Using the normal distribution to approximate empirical distributions}
\noindent%
We often want to put data onto a standardized scale,
which can make comparisons more reasonable.

\newcommand{\satmean}{1100}
\newcommand{\satsd}{200}
\newcommand{\actmean}{21}
\newcommand{\actsd}{6}
\newcommand{\annsatscore}{1300}
\newcommand{\annsatzscore}{1}
\newcommand{\tomsatscore}{24}
\newcommand{\tomsatzscore}{0.5}



 \begin{examplewrap}
\begin{nexample}{ Figure~\vref{satACTstats} shows the mean
    and standard deviation for total scores on the SAT and ACT.
    The distribution of SAT and ACT scores are both nearly normal.  Suppose Ann scored \annsatscore{} on her SAT and Tom scored
    \tomsatscore{} on his ACT.
    Who performed better?}
As we saw in section~\ref{zscores}, we can use Z-scores to compare observations from different distributions.  Using Ann's SAT score, \annsatscore{} , along with the SAT mean and SD, we can find Ann's Z-score.
$$Z_{_{\text{Ann}}}
  = \frac{x_{_{\text{Ann}}} - \mu_{_{\text{SAT}}}}
      {\sigma_{_{\text{SAT}}}}
  = \frac{\annsatscore{} - \satmean{}}{\satsd{}}
  = \annsatzscore{}$$
Similarly, using Tom's ACT score, \tomsatscore{}, along with the ACT mean and
SD we can find his Z-score.
$$Z_{Tom}
  = \frac{x_{\text{Tom}} - \mu_{\text{ACT}}}
      {\sigma_{\text{ACT}}}
  = \frac{\tomsatscore{} - \actmean{}}{\actsd{}}
  = \tomsatzscore{}$$
Because Ann's score was 1 standard deviation above the mean, while Tom's score was 0.5 standard deviations above the mean, we can say that Ann did better than Tom.
 \end{nexample}
\end{examplewrap}

  \begin{figure}[h]
\centering
\begin{tabular}{l r r}
  \hline
  & SAT & ACT \\
  \hline
  Mean \hspace{0.3cm} & \satmean{} & \actmean{} \\
  SD & \satsd{} & \actsd{} \\
  \hline
\end{tabular}
\caption{Mean and standard deviation for the SAT and ACT.}
\label{satACTstats}
\end{figure}

Assuming that both the SAT and ACT distributions are nearly normally distributed, what percent of test takers scored lower than Ann?  What percent scored lower than Tom?  To answer these question exactly, we would need all of the data.  However, if we use the information that SAT and ACT distributions are nearly normal, we can estimate these percents.  Figure~\ref{satActNormals} shows these distributions modeled with a normal curve.  If we can find the percent of the normal curve that is to the left of Ann's score, we could use that percent as our estimate of the percent of the data points that are smaller than Ann's score.  We call this process \emph{normal approximation}.  The steps are:
\begin{enumerate}
\item First verify that the distribution can be reasonably modeled with a normal distribution.
\item Convert value or values of interest to Z-scores.  
\item Find the relevant area/percent under the standard normal curve.
\end{enumerate}
We use the area/percent that we find from the normal curve as our \emph{estimate} of the desired percent. 



\begin{figure}[h]
  \centering
  \Figure[Ann's and Tom's scores shown against the SAT and ACT distributions, which are each shown as normal distributions. The SAT distribution has a mean of 1100 and a standard deviation of 200, while the ACT distribution has a mean of 21 and standard deviation of 6. Ann's score is 1300 for the SAT, and Tom's score is 24 for the ACT. Based on their positioning in their respective plots, it is evident that Ann has a higher relative value for her SAT distribution than Tom has for his ACT score.]
{0.52}{satActNormals}
  \caption{Ann's and Tom's scores shown with the distributions
      of SAT and ACT scores.}
  \label{satActNormals}
\end{figure}


There are many techniques for finding areas under a normal distribution.  The most common approach is to use technology.  In practice, statisticians use statistical software, such as R, Python, or SAS.  In classrooms, it is common to use Desmos or a handheld graphing calculator such as NumWorks, TI, or Casio. Instructions for finding areas of a normal distribution using these R, Desmos, and these handheld graphing calculators are provided in Section~\ref{technormal}. 

Another option for finding tail areas is to use what's called a \term{probability table}; these are occasionally used in classrooms but rarely in practice.  Appendix~\ref{normalProbabilityTable} contains such a table and a guide for how to use it.

%%
\subsection{Normal probability examples}

Combined SAT scores are approximated well by a normal model with mean \satmean{} and standard deviation \satsd{}.

\begin{examplewrap}
\begin{nexample}{How many standard units above average is a score of 1190 on the SAT?  What is the probability that a randomly selected SAT taker scores at least 1190 on the SAT?}\label{satAbove1190Exam}
The probability that a randomly selected SAT taker scores at least 1190 on the SAT is equivalent to the proportion of all SAT takers that score at least 1190 on the SAT. First, always draw and label a picture of the normal distribution. (Drawings need not be exact to be useful.) We are interested in the probability that a randomly selected score will be above 1190, so we shade this upper tail:
\begin{center}
  \Figure[A normal distribution with a mean of 1100 and standard deviation of 200 has the area below the distribution shaded for horizontal values larger than 1190.]
{0.4}{satAbove1190}\hspace{5mm}
  \Figures[A normal distribution with a mean of 0 and standard deviation of 1 has the area below the distribution shaded for horizontal values larger than 0.45.]
{0.4}{satAbove1190}{satAbove1190Z}
\end{center}
The labels on the distributions correspond to the mean and to values 2 standard deviations above and below the mean. 

The number of standard units 1190 is above average on the SAT corresponds to the Z-score of 1190.  With $\mu=\satmean{}$, $\sigma=\satsd{}$, the Z-score that corresponds to $x=1190$ is computed as
\begin{eqnarray*}
Z = \frac{x - \mu}{\sigma} = \frac{1190 - \satmean{}}{\satsd{}} = \frac{90}{200} = 0.45
\end{eqnarray*}
To estimate the probability that a randomly selected SAT taker scores at least 1190 on the SAT, we can find the area under the standard normal curve to right of  $Z=0.45$.  Using technology, we find $P(Z \ge 0.45) = 0.326$.   The probability that a randomly selected score is at least 1190 on the SAT is 0.326.
\end{nexample}
\end{examplewrap}


\begin{onebox}{Always draw a picture first, and do the calculations second}
For any normal probability situation, \emph{always} draw and label the normal curve and shade the area of interest first. The picture will provide an estimate of the probability. \end{onebox}



\begin{examplewrap}
\begin{nexample}{Mika earned a 1030 on her SAT. What is her percentile?} \label{edwardSatBelow1030}
First, a picture is needed. Mika's percentile is the proportion of people who got less than or equal to 1030. 
\begin{center}
\Figure[A normal distribution with mean 1100 and standard deviation 200 is shaded from the left up to a vertical line at 1030.]
{0.4}{satBelow1030}\hspace{5mm}
\Figures[A normal distribution with mean 0 and standard deviation 1 is shaded from the left up to a vertical line at -0.35.]
{0.4}{satBelow1030}{satBelow1030Z}
\end{center}
Identifying the mean $\mu=1100$, the standard deviation $\sigma=200$, and the cutoff for the tail area $x=1030$ makes it easy to compute the Z-score:
\begin{eqnarray*}
Z = \frac{x - \mu}{\sigma} = \frac{1030 - 1100}{200} = -0.35
\end{eqnarray*}
Using technology, we determine that $P(Z \le -0.35) = 0.363$. Mika is at the $36^{th}$ percentile.
\label{edwardpercentile}
\end{nexample}
\end{examplewrap}

In Example~\ref{edwardpercentile}, we standardized the value $x = 1030$ and used technology to find the area to the left of $Z=-0.35$ under the standard normal distribution ($\mu$ = 0, $\sigma$ = 1).  Instead of this traditional method, we can also use technology to find the area to the left of 1030 under the normal distribution with $\mu$ = 1100 and $\sigma$ = 200.  When using this approach, full communication should include the following:
\begin{itemize}
\item Draw a graph and shade the desired boundary region as we did in the upper left graph.
\item Identify the distribution and its parameters.   X is SAT score.  X is Normal with $\mu=1100$ and $\sigma=200$.   We sometimes write this as X is Normal($\mu=1100$, $\sigma=200$). 
\item Write a probability statement that corresponds to the shaded area:  $P(X \le 1030) = 0.363$.
\item Answer the question in context:  Mika is at the $36^{th}$ percentile.
\end{itemize}

\begin{exercisewrap}
\begin{nexercise}
Use the results of Example~\ref{edwardSatBelow1030} to compute the proportion of SAT takers who did better than Mika. Also draw a new picture.\footnotemark
\end{nexercise}
\end{exercisewrap}
\footnotetext{If about 36\% of SAT takers got less than or equal to Mika, then about 64\% must have done better than her. \\
\Figures{.35}{satBelow1030}{satAbove1030}}

The last several problems have focused on finding the probability or percentile for a particular observation. It is also possible to identify the value corresponding to a particular percentile.



\begin{examplewrap}
\begin{nexample}{Carlos believes he can get into his preferred college if he scores in the 80th percentile or better on the SAT.  How many standard deviations above the average SAT score will Carlos have to be and what score does this correspond to?  }
Here, we are given a percentile rather than an SAT score, so we work backwards. As always, first draw the picture.  We shade the lower 80\% of the area under the curve.
\begin{center}
\Figure[A normal distribution with mean 1100 and standard deviation 200 is shaded from the left up to a vertical line which makes the shaded area equal to 80\%.]
{.3}{sat80thPercentile}\hspace{5mm}
\Figures[A normal distribution with mean 1100 and standard deviation 200 is shaded from the left up to a vertical line which makes the shaded area equal to 80\%.]
{.3}{sat80thPercentile}{sat80thPercentileZ}
\end{center}
First, we find the Z-score associated with the 80th percentile. Using technology, we find that $P(Z \le 0.8416) = 0.80$. In any normal distribution, a value with a Z-score of 0.8416 will be at the 80th percentile. Once we have the Z-score, we work backwards to find the x value that corresponds to the 80th percentile using the Z-score formula.
\begin{align*}
Z &= \frac{x-\mu}{\sigma} \\
0.8416 &= \frac{x-1100}{200} \\
0.8416 \times 200+1100 &= x \\
x& = 1268.32
\end{align*}
Carlos will have to be 0.8416 standard deviations above the mean SAT score to be at the 80th percentile, and he will need a score of about 1268.
\label{carlos80thpercentile}
\end{nexample}
\end{examplewrap}


To find the score needed to be at the 80th percentile, we can also work with the non-standardized normal distribution with $\mu = 1100$ and $\sigma = 200$. As we did in Example~\ref{edwardpercentile}, we communicate our work as follows.  
\begin{itemize}
\item First draw the distribution, shading the desired region as we did in the upper left graph.
\item Identify the distribution and its parameters.  X is SAT score.  X is Normal($\mu=1100$, $\sigma=200$).
\item Write a probability statement that corresponds to the shaded area.  $P(X \le 1268) = 0.80$.
\item Answer the question in context.  Carlos should aim for a score of 1268 to be at the 80th percentile.
\end{itemize}

\begin{exercisewrap}
\begin{nexercise}Erica scored at the 20th percentile on the SAT. What was her SAT score?\footnotemark\end{nexercise}
\end{exercisewrap}
\footnotetext{First, draw a picture, shading the lower 20\% of the normal distribution.
\begin{center}
\Figures[A normal distribution with mean 1100 and standard deviation 200 is shaded from the left up to a vertical line which makes the shaded area equal to 20\%.]
{.2}{sat80thPercentile}{sat20thPercentile}
\end{center}
Using Normal($\mu=0$, $\sigma = 1$), we find that the Z-score with 20\% of the area to the left of it is $-0.8416$: $P(Z \le -0.8416) = 0.20$. Next, set up the Z-score formula and solve for $x$: $-0.8416 = \frac{x-1100}{200} \rightarrow x = 931.7$. Or, using X is Normal($\mu=1100$, $\sigma=200$), we find $P(x \le 931.7) = 0.20$.  Erica scored approximately 932.  Notice that the 20th percentile and 80th percentile values are the same distance away from the mean of 1100.}

While it is convenient to be able to directly find areas under a normal distribution with arbitrary parameters, understanding Z-scores and the concept of standardization is fundamental to statistics.  Consider the following example, where working with a standard normal distribution and Z-scores is necessary to solve the problem.

\begin{examplewrap}
\begin{nexample}{Assume that systolic blood pressure for adults is approximately normally distributed with a mean of 125 mmHg.  If 10 percent of adults have systolic blood pressure above 138, what is the standard deviation of the distribution?}
Here we are looking for the standard deviation, not a particular \textit{x}-value.  We know that the distribution is approximately normal and that the \textit{x}-value of 138 corresponds to the 90th percentile, so we can find the Z-score for that \textit{x}-value.  Then we can use the Z-score formula to solve for the standard deviation.

\begin{center}
\Figures[A normal distribution with mean 0 and standard deviation 1.  The lower 90\% is shaded.]
{0.4}{sat90thPercentileSD}{sat90thPercentileSDZ}\hspace{5mm}
\Figure[A normal distribution with mean 1100 and standard deviation 200.  The lower 90\% is shaded.]
{0.4}{sat90thPercentileSD}
\end{center}

Using technology and the Normal($\mu=0$, $\sigma=1$) distribution, we find that $P(Z \ge 1.282) = 0.10$.  We then plug $Z = 1.282$ into the Z-score formula and solve for $\sigma$.
\begin{align*}
Z &= \frac{x-\mu}{\sigma} \\
1.282 &= \frac{138-125}{\sigma} \\
\sigma &= \frac{138-125}{1.282}  \\
\sigma & = 10.1
\end{align*}
The standard deviation of systolic blood pressure is estimated as 10.1 mmHg.
\label{normalfindmean}
\end{nexample}
\end{examplewrap}



\begin{onebox}{If the data are not nearly normal, don't use the normal approximation}
{Before using the normal approximation method, verify that the data or distribution is approximately normal. If it is not, the normal approximation will give incorrect results. Also remember that all answers based on normal approximations are in fact approximations and are not exact.}
\end{onebox}

Finally, we should observe that it is possible for a normal random variable to fall 4,~5, or~even more standard deviations from the mean. The probability of being further than 4 standard deviations from the mean is about 1-in-15,000. For 5 and 6 standard deviations, it is about 1-in-2 million and 1-in-500 million, respectively. However, while the tails of the normal distribution extend infinitely in either direction, our data sets are finite and normal approximation in the extreme tails is unlikely to be very accurate, even for bell-shaped data sets.


\D{\newpage}

%%%%
\subsection{Technology: normal probabilities and boundary values}
\label{normal}
\label{technormal}

\noindent Given a standard normal distribution ($\mu = 0$, $\sigma = 1$),\\

\noindent (i) find the following probabilities:
\begin{itemize}
\setlength{\itemsep}{0mm}
\item[(a)]  Probability of a value between $-2$ and $2$.
\item[(b)]  Probability of a value less than $-1.5$.
\end{itemize}

\noindent (ii) find the following boundary values:
\label{normalvalue}

\begin{itemize}
\setlength{\itemsep}{0mm}
\item[(a)] The value that corresponds to the 40th percentile.
\item[(b)] The value $z^{\star}$ such that 95\% of the distribution lies between $-z^{\star}$ and $z^{\star}$. 
\end{itemize} 

\noindent *With the standard normal distribution ($\mu = 0$, $\sigma = 1$), the values of the distribution correspond to Z-scores.   If a problem involves a normal distribution with a different mean and standard deviation (e.g. battery life), we can use the mean and standard deviation of that distribution in place of 0 and 1.  \\

\noindent \textbf{Desmos}:  Use \texttt{normaldist(mean, stdev)}, replacing \texttt{mean} and \texttt{stdev} with appropriate values. 
 
\begin{enumerate}
\setlength{\itemsep}{0mm}
\item Type \calctext{normaldist(0,1)}.  
\item Click the triangle next to \calctext{Cumulative Probability}. 
\item Select \calctext{Inner}, \calctext{Outer}, \calctext{Left}, or \calctext{Right} as illustrated below.
\item 
\begin{itemize}
\item[(i)] To find a probability, choose \calctext{Area} and enter the boundary value(s) for $x$.  
\item[(ii)] To find a boundary value, choose \calctext{Bounds} and enter the area as a decimal to the right of the $=$ sign.  
\end{itemize}
\item Click the magnifying glass to Zoom Fit the graphing window.
\end{enumerate}

\noindent (i) Finding probabilities/areas.
\begin{itemize}
\setlength{\itemsep}{0mm}
\item[(a)] $P(-2 \le x \le 2)$.  
\begin{center}
\fbox{\Figures[A Desmos calculator screen is shown.  On the left is the function normaldist(0, 1), with Inner selected, Area selected, and x between $-2$ and 2.  The probability is given as 0.954.  On the right is a graph of the normal distribution with parameters $\mu = 0$ and $\sigma = 1$.  x, on the horizontal axis, ranges from $-4$ to $4$.  The area between $-2$ and $2$ is shaded. ]
{0.65}{techonologyProbability}{desmosNormalCenter}}
\end{center}

\item[(b)] $P(x < -1.5)$.   Note: for a continuous distribution $P(x < -1.5) = P(x \le -1.5)$.  
\begin{center}
\fbox{\Figures[A Desmos calculator screen is shown.  On the left is the function normaldist(0, 1), with Left selected, Area selected, and x less than or equal to $-1.5$.  The probability is given as 0.067.  On the right is a graph of the normal distribution with parameters $\mu = 0$ and $\sigma = 1$.  x, on the horizontal axis, ranges from $-4$ to $4$.  The area to the left of $-1.5$ is shaded. ]
{0.65}{techonologyProbability}{desmosNormalLeft}}
\end{center}

%\item[(c)] $P(x > -1)$.  
%\begin{center}
%\fbox{\Figures[A Desmos calculator screen is shown.  On the left is the function normaldist(0, 1), with Right selected, Area selected, and x greater than or equal to $-1$.  The probability is given as 0.841.  On the right is a graph of the normal distribution with parameters $\mu = 0$ and $\sigma = 1$.  x, on the horizontal axis, ranges from $-4$ to $4$.  The area to the right of $-1$ is shaded. ]
%{0.65}{techonologyProbability}{desmosNormalRight}}
%\end{center}

\end{itemize}

\D{\newpage}

\noindent (ii) Finding boundary values.

\begin{itemize}
\setlength{\itemsep}{0mm}

\item[(a)] The value that corresponds to the 40th percentile.  P($x \le \ ? $) = 0.40.
\begin{center}
\fbox{\Figures[A Desmos calculator screen is shown.  On the left is the function normaldist(0, 1), with Left selected, Bounds selected, and probability inputted as 0.40.  The x value is shown as $-0.253$.  On the right is a graph of the normal distribution with parameters $\mu = 0$ and $\sigma = 1$.  x, on the horizontal axis, ranges from $-4$ to $4$.  The area shaded corresponds to the lower 40 percent of the graph. ]
{0.65}{techonologyProbability}{desmosNormalInverseLess}}
\end{center}

\item[(b)] The value $z^{\star}$ such that 95\% of the distribution lies between $-z^{\star}$ and $z^{\star}$.  \mbox{P($ -z^{\star}  \le x \le z^{\star} $) = 0.95.}
\begin{center}
\fbox{\Figures[A Desmos calculator screen is shown.  On the left is the function normaldist(0, 1), with Inner selected, Bounds selected, and probability inputted as 0.95.  The x value is shown as $1.96$.  On the right is a graph of the normal distribution with parameters $\mu = 0$ and $\sigma = 1$.  x, on the horizontal axis, ranges from $-4$ to $4$.  The area shaded corresponds to the middle 95\% percent of the graph. ]
{0.65}{techonologyProbability}{desmosNormalInverseCenter}}
\end{center}
\end{itemize}
\label{zstarcalc}
%%
%%


\noindent \\
\R{}:   Normal probabilities and boundary values for the standard normal distribution.
\\

\noindent (i) Finding probabilities/areas.  Use the \texttt{pnorm(x, mean, stdev)} function, which gives the area to the \emph{left} of the \texttt{x} value entered, unless specified otherwise. Note that ``\texttt{mean =}" and ``\texttt{sd =}" can be omitted, but the labels are often included for clarity.

\begin{itemize}
\item[(a)] P($-2 \le X \le 2$).\\
\texttt{> \calctext{pnorm(2,  0, 1) - pnorm(-2,  0, 1)}}\\
\texttt{[1] 0.9544997}\\

\item[(b)] P($X \le 1.5$).\\
\texttt{> \calctext{pnorm(-1.5, mean = 0, sd = 1)}}\\
\texttt{[1] 0.0668072}\\

\end{itemize}

\noindent (ii) Finding boundary values.  Use the \texttt{qnorm(p, mean, stdev)} function. \texttt{qnorm()} returns the value that has the entered probability \texttt{p} to the \emph{left} of it, unless specified otherwise.  

\begin{itemize}
\item[(a)] Find the value that corresponds to the 40th percentile.  \\
\texttt{> \calctext{qnorm(0.40, 0, 1)}}\\
\texttt{[1] -0.2533471}\\

\item[(b)] Find the value $z^{\star}$ such that 95\% of the distribution lies between $-z^{\star}$ and $z^{\star}$.  This implies that 2.5\% in the upper (and lower) tail.\\
\texttt{> \calctext{qnorm(0.025, mean = 0, sd = 1, lower.tail = FALSE)}}\\
\texttt{[1] 1.959964}\\ \\

\end{itemize}

\D{\newpage}

%%%%%
\noindent \textbf{Calculator}:  NumWorks calculator instructions and example output are included.  For the TI-83/84 and Casio calculators, general instructions are provided, and worked example videos can be accessed via the \includegraphics[height=3mm]{extraTeX/icons/video_camera.png} icon or at \oiRedirect{ti84_playlist}{\textbf{openintro.org/ti}} and \oiRedirect{casio-9750-playlist}{\textbf{openintro.org/casio}}.
\\
\\
\\

\begin{center}
\begin{onebox}{NumWorks: Normal probabilities and boundary values}
\label{normalnumworks}
Use \calctext{OK} or \calctext{EXE} to make a selection.
\begin{enumerate}
\setlength{\itemsep}{0mm}
\item From the home screen, select \calcbutton{Distributions} then select \calcbutton{Normal}.  If a list of distributions does not show up, hit the \calcbutton{$\lhookleftarrow$} button (next to \calctext{OK}) as many times as needed.
\item Enter \calctext{$\mu$} and \calctext{$\sigma$} then choose \calcbutton{Next}.  Note: if the screen shows a graph, hit the \calcbutton{$\lhookleftarrow$} button.
\item Hit the left arrow to highlight the graph.  Hit the down arrow to choose whether you want left, inner, or right, then hit \calcbutton{OK}.  Hit the right arrow to enter the desired value(s).
\begin{itemize}
\item[(i)] For a probability, enter the boundary value(s), then hit \calcbutton{EXE}.  
\end{itemize}
\begin{center}
\Figures[ ]
{0.35}{techonologyProbability}{numworksNormalCenter}\hspace{10mm}
\Figures[ ]
{0.35}{techonologyProbability}{numworksNormalLess}
\end{center}
\begin{itemize}
\item[(ii)] For a boundary value, enter the desired area as a decimal to the right of the $=$ sign, then hit \calcbutton{EXE}.
\end{itemize}
\begin{center}
\Figures[ ]
{0.35}{techonologyProbability}{numworksNormalInverseLess}\hspace{10mm}
\Figures[ ]
{0.35}{techonologyProbability}{numworksNormalInverseCenter}
\end{center}
\end{enumerate}
\end{onebox}
\end{center}

\D{\newpage}

%%%
\begin{onebox}{\videohref{ti84_normal_curve_area} TI-84: Normal probabilities}
\ \vspace{-5mm} \
\begin{enumerate}
\setlength{\itemsep}{0mm}
\item Choose \calcbutton{2ND} \calcbutton{VARS} (i.e. \calctext{DISTR}).
\item Choose \calctext{2:normalcdf}.
\item Enter the \calctext{lower} (left) value and the \calctext{upper} (right) value.
\vspace{-1.5mm}
  \begin{itemize}
  \setlength{\itemsep}{0mm}
  \item If finding just a lower tail area, set \calctext{lower} to \calctext{-$\infty$} ($-$1E99).
  \item If finding just an upper tail area, set \calctext{upper} to \calctext{$\infty$} (1E99).
\end{itemize}
\item Enter $\calctextmath{\mu}$ and $\calctextmath{\sigma}$. 
\item Down arrow, choose \calctext{Paste}, and hit \calcbutton{ENTER}.\vspace{-1.5mm}
\end{enumerate}
TI-83: Do steps 1-2, then enter the lower bound, upper bound, $\mu$, and $\sigma$ separated by commas as follows:  \mbox{\calctext{normalcdf(lower, upper, $\mu$, $\sigma$)}}.  Then hit \calcbutton{ENTER}.
\end{onebox}


%
\begin{onebox}{\videohref{ti84_Z_score_for_a_percentile} TI-84: Boundary values for a normal distribution}
\label{invNorm}
Use \calcbutton{2ND} \calcbutton{VARS}, \calctext{invNorm} to find the X-value that corresponds to a given percentile.
\begin{enumerate}
\setlength{\itemsep}{0mm}
\item Choose \calcbutton{2ND} \calcbutton{VARS} (i.e. \calctext{DISTR}).
\item Choose \calctext{3:invNorm}.
\item Let \calctext{Area} be the desired percent as a decimal.
\item Enter the appropriate values for $\calctextmath{\mu}$ and $\calctextmath{\sigma}$.  If you want a Z-score enter $\calctextmath{\mu}$ as \calctext{0} and $\calctextmath{\sigma}$ as \calctext{1}.
\item Let \calctext{Tail} be LEFT if entering a percentile.  For a value with a certain percent above it, choose RIGHT.  For a value with a certain percent between $\pm$ that value, choose CENTER.
\item Down arrow, choose \calctext{Paste}, and hit \calcbutton{ENTER}.\vspace{-1.5mm}
\end{enumerate}
TI-83: Do steps 1-2, then enter the percentile as a decimal, $\mu$, and $\sigma$ separated by commas as follows: \mbox{\calctext{invNorm(area to left, $\mu$, $\sigma$}).} Then hit \calcbutton{ENTER}.\end{onebox}


%%%%
\begin{onebox}{\videohref{casio_normal_curve_area} Casio fx-9750GII: Normal probabilities}
\ \vspace{-5mm} \
\begin{enumerate}
\setlength{\itemsep}{0mm}
\item Navigate to \calctext{STAT} (\calcbutton{MENU}, then hit \calcbutton{2}).
\item Select \calctext{DIST} (\calcbutton{F5}), then \calctext{NORM} (\calcbutton{F1}), and then \calctext{Ncd} (\calcbutton{F2}).
\item If needed, set \calctext{Data} to \calctext{Variable} (\calctext{Var} option, which is \calcbutton{F2}).
\item Enter the \calctext{Lower} Z-score and the \calctext{Upper} Z-score. Set $\calctextmath{\sigma}$ to \calctext{1} and $\calctextmath{\mu}$ to \calctext{0}.\vspace{-1.5mm}
  \begin{itemize}
  \setlength{\itemsep}{0mm}
  \item If finding just a lower tail area, set \calctext{Lower} to \calctext{-5}.
  \item For an upper tail area, set \calctext{Upper} to \calctext{5}.
  %\item If finding a middle area (e.g. $Z_{lower} = 0.5$ to $Z_{upper} = 1.5$), set the \calctext{lower} and \calctext{upper} values appropriately.
  \end{itemize}
\item Hit \calctext{EXE}, which will return the area probability (\calctext{p}) along with the Z-scores for the lower and upper bounds.
\end{enumerate}
\end{onebox}


\begin{onebox}{\videohref{casio_Z_score_for_a_percentile} Casio fx-9750GII: Boundary values for a normal distribution}
\ \vspace{-5mm} \
\begin{enumerate}
\setlength{\itemsep}{0mm}
\setlength{\itemsep}{0mm}
\item Navigate to \calctext{STAT} (\calcbutton{MENU}, then hit \calcbutton{2}).
\item Select \calctext{DIST} (\calcbutton{F5}), then \calctext{NORM} (\calcbutton{F1}), and then \calctext{InvN} (\calcbutton{F3}).
\item If needed, set \calctext{Data} to \calctext{Variable} (\calctext{Var} option, which is \calcbutton{F2}).
\item Decide which tail area to use (\calctext{Tail}), the tail area (\calctext{Area}), and then enter the $\calctextmath{\sigma}$ and $\calctextmath{\mu}$ values.
\item Hit \calctext{EXE}.
\end{enumerate}
\end{onebox}


\D{\newpage}

%%
\subsection{68-95-99.7 rule}

Here, we present a useful rule of thumb for the probability of falling
within 1, 2, and 3 standard deviations of the mean in the normal distribution.
The 68-95-99.7 rule, also known as the \emph{empirical rule}\index{empirical rule},
will be useful in a wide range of practical settings,
especially when trying to make a quick estimate without technology or a Z-table.

\begin{figure}[h]
\centering
\Figure[A normal distribution is shown. The central region, from one standard deviation below the mean to one standard deviation above the mean, is shaded blue and is labeled with a value of 68\%. The region further out to two standard deviations below the mean to two standard deviations above the mean is shaded green (besides the portion shaded blue) and is labeled with a value of 95\%. The region further out to three standard deviations below the mean to three standard deviations above the mean is shaded yellow (besides the portions shaded green or blue) and is labeled with a value of 99.7\%. Those percentages -- 68\%, 95\%, and 99.7\% -- represent the portions of the area below a normal distribution within 1, 2, and 3 standard deviations of the mean.]
{0.72}{6895997}
\caption{Probabilities for falling within 1, 2, and 3 standard deviations of the mean in a normal distribution.}
\label{6895997}
\end{figure}

This implies that for an approximately normal distribution, the area that falls between $Z=-1$ and $Z=1$ is about 68\% and the area between $Z=-2$ and $Z=2$ is about 95\%.  

It is possible for a normal random variable to fall 4,~5, or~even more standard deviations from the mean. However, these occurrences are very rare if the data are nearly normal. The probability of being further than 4 standard deviations from the mean is about 1-in-15,000. For 5 and 6 standard deviations, it is about 1-in-2 million and 1-in-500 million, respectively.

\begin{exercisewrap}
\begin{nexercise}
SAT scores closely follow the normal model with mean $\mu = 1100$ and standard deviation $\sigma = 200$. (a) About what percent of test takers score 700 to 1500? (b) About what percent score between 1100 and 1500?\footnotemark
\end{nexercise}
\end{exercisewrap}
\footnotetext{(a) 700 and 1500 represent two standard deviations above and below the mean, which means about 95\% of test takers score between 700 and 1500. (b)~Because 1100 is the mean and the normal model is symmetric, half of the test takers from part~(a) score 1100 to 1500.  So about $\frac{95\%}{2} = 47.5\%$ score between 1100 and 1500.}


\D{\newpage}

%%
\subsection*{Section summary}

\begin{itemize}
\item A \termni{Z-score} represents the number of standard deviations a value in a data set is above or below the mean.  To calculate a \mbox{Z-score} use: $Z = \frac{x-\text{mean}}{SD}$.  

\item A \termni{continuous random variable} is a variable that can take on any value within a
specified domain. Every interval within the domain has a probability associated
with it.  The total probability or area under a continuous distribution is 1.

\item A \termni{normal distribution} can be described as a continuous, unimodal, bell-shaped,
and symmetric curve.  Normal distributions are the most commonly used distribution in Statistics.  Many continuous random variables and some large data sets have an approximately normal distribution, but none are exactly normal.  

\item The normal distribution, or the normal curve, is identified by two parameters,
the mean $\mu$ and the standard deviation $\sigma$. The smaller the standard deviation,
the taller and more concentrated the normal curve is around its mean. The
larger the standard deviation, the shorter and less concentrated the normal
curve is around its mean.

\item A \termni{standard normal distribution} is a normal distribution with mean $\mu = 0$ and
standard deviation $\sigma =1$.

\item For a normal distribution, approximately 68\%
of observations are within 1 standard deviation of the mean, approximately
95\% of observations are within 2 standard deviations of the mean, and
approximately 99.7\% of observations are within 3 standard deviations of the
mean. This is called the \termni{empirical rule}, or the 689599.7 rule.  The empirical rule is useful for estimating the area of a region under an approximately normal distribution.

\item If the distribution of a random variable is approximately normal, the probability
that the random variable takes on values within a particular interval of the
random variable is determined by the area under the normal curve within that
interval. The total probability or area under the normal curve is 1.

\item The boundaries of an interval associated with a given area in a normal distribution can be determined using technology or using z-scores and a standard normal table.

\item Two type of normal approximation problems involve (1) finding a probability or percent, which requires finding an area under a normal distribution given one ore more boundary values and (2) finding an \textit{x}-value that bounds a given area or percentile under the normal distribution.  For both types of problems, first draw a normal distribution and shade the area of interest.  Then, identify the distribution and its parameters, write the relevant probability statement, and answer the question in context.

\item Percentiles and proportions may be used to compare relative positions of
individual values within a normal distribution or between normal distributions.

\end{itemize}


%%%%%%%%Section exercises
{\input{ch_probability/TeX/normal_distributions.tex}}



%%
\section[Sampling distributions and the central limit theorem]{Sampling distributions and the CLT}
\label{CLTintro}
\label{clt}

\sectionintro{
\noindent%
How unlikely is it to get a sample proportion a certain distance from the population proportion based on a random sample of a certain size?  In an experiment, how large does an observed difference need to be for it to provide convincing evidence that one treatment is more effective than another treatment?  Formally answering these question requires the tools that we will encounter in the next two chapters. However, we take a first look at them here using simulation methods.
\subsection*{Learning objectives}
\begin{enumerate}
\setlength{\itemsep}{0mm}

\item Explain the concept of a sampling distribution and a randomization distribution.

\item Describe sampling distributions with simulations.

\item  Explain the central limit theorem and its importance.

\end{enumerate}
}


\newcommand{\pewsolarpollsize}{1000}
\newcommand{\pewsolarparprop}{0.88}
\newcommand{\pewsolarparpropcomplement}{0.12}
\newcommand{\pewsolarparpercent}{88\%}
\newcommand{\pewsolarparpercentcomplement}{12\%}
\newcommand{\pewsolarpollprop}{0.887}
\newcommand{\pewsolarpollpropcomplement}{0.113}
\newcommand{\pewsolarpollpercent}{88.7\%}
\newcommand{\pewsolarpollpercentcomplement}{11.3\%}
\newcommand{\pewsolarpollcount}{887}
\newcommand{\pewsolarpollexpcount}{880}
\newcommand{\pewsolarpollcountcomplement}{113}
\newcommand{\pewsolarpollexpcountcomplement}{120}
\newcommand{\pewsolarpollse}{0.010}

\subsection{Visualizing a sampling distribution through simulation}
\label{cltpropsimulation}
 

Suppose the proportion of American adults who support
the expansion of solar energy is \pewsolarparprop{}.\footnote{We haven't
  actually conducted a census to measure this value perfectly.
  However, a very large sample has suggested the actual
  level of support is about \pewsolarparpercent{}.}. We consider this our parameter of interest and label it $p$.
If we were to take a poll of \pewsolarpollsize{} American adults
on this topic, the estimate would not be perfect,
but how close might we expect the sample proportion
in the poll would be to \pewsolarparpercent{}?
We want to understand, how does the
\emph{sample proportion} behave when the \emph{true population
proportion is \pewsolarparprop{}}.
%\footnote{Note: \pewsolarparpercent{} written as a proportion would be \pewsolarparprop{}. It is common to switch between proportion and percent.}
Let's find out!
We can simulate responses we would get from a simple
random sample of 1000 American adults,
which is only possible because we know the actual
support expanding solar energy to be \pewsolarparprop{}.  Here's how we might go about constructing such a simulation:
%simulate it:
\begin{enumerate}
\item There were about 250 million American adults in 2018.
    On 250 million pieces of paper, write ``support''
    on \pewsolarparpercent{} of them and ``not'' on
    the other \pewsolarparpercentcomplement{}.
\item Mix up the pieces of paper and pull out \pewsolarpollsize{}
    pieces to represent our sample of \pewsolarpollsize{}
    American adults.
\item Compute the fraction of the sample that say ``support''.
\end{enumerate}
Any volunteers to conduct this simulation? Probably not. While this physical simulation is totally impractical, we can simulate it thousands, even millions, of times using computer code.  We've written a short computer simulation and run it 10,000 times.  The results are show in 
Figure~\ref{solarPollSimulationCodeR}
in case you are curious what the computer code looks like.  We use $\hat{p}$ to represent a sample proportion.
In this simulation, the sample proportion was $\hat{p}_1 = 0.894$. We~know the population proportion
for the simulation was $p = \pewsolarparprop{}$, so we know
the estimate had an error of
$0.894 - \pewsolarparprop{} = \text{+0.014}$.


%\setlength\textwidth{\officialtextwidth-10mm}
\begin{figure}[h]
\texttt{\# 1.\ Create a set of 250 million entries,
where \pewsolarparpercent{} of them are "support" \\
\#\ \ \ \ and \pewsolarparpercentcomplement{} are "not". \\
pop\us{}size <- 250000000 \\
possible\_entries <- c(rep("support", \pewsolarparprop{} * pop\us{}size), rep("not", \pewsolarparpropcomplement{} * pop\us{}size))
\\[3mm]
\# 2.\ Sample \pewsolarpollsize{} entries without replacement. \\
sampled\_entries <- sample(possible\_entries, size = \pewsolarpollsize{}) \\[3mm]
\# 3.\ Compute p-hat:~count the number that are "support",
then divide by \\
\#\ \ \ \ the sample size. \\
sum(sampled\_entries == "support") / \pewsolarpollsize{}}
\caption{This is code for
    a single $\hat{p}$ simulation using the
    statistical software called R\index{R}.
    Each line that starts with \texttt{\#} is a
    \term{code comment},
    which is used to describe in regular language what the
    code is doing. We've provided software labs in R at
    \oiRedirect{ahss}{openintro.org/book/statlabs}
    for anyone interested in learning more.}
\label{solarPollSimulationCodeR}
\end{figure}
% \setlength\textwidth{\officialtextwidth}

One simulation isn't enough to get a great sense of the
distribution of estimates we might expect in the simulation,
so we should run more simulations.
In a second simulation,
we get $\hat{p}_2 = 0.885$, which has an error of~+0.005.
In another, $\hat{p}_3 = 0.878$ for an error of -0.002.
And in another,
an estimate of $\hat{p}_4 = 0.859$ with an error of -0.021.
With the help of a computer, we've run the simulation 10,000 times
and created a histogram of the results from all 10,000 simulations
in Figure~\ref{sampling_10k_prop_88p}. This graph of many, many values of the sample statistic $\hat{p}$ approximates what is called the \emph{sampling distribution} of the statistic.  The \term{sampling distribution} of a sample statistic is the distribution of values of the statistic for all possible random samples of a given size from a given population.

\D{\newpage}

\begin{figure}[h]
   \centering
   \Figure[A histogram is shown for 10,000 sample proportions where each sample is taken from a population where the population proportion is \pewsolarparprop{} and the sample size is $n = \pewsolarpollsize{}$. The distribution is bell-shaped (appears nearly normal), is centered at 0.88 and has a standard deviation of about 0.01.]
{0.65}{sampling_10k_prop_88p}
   \caption{A histogram of 10,000 sample proportions sampled from a population where the population
       proportion is \pewsolarparprop{} and the sample size is
       $n = \pewsolarpollsize{}$.}
   \label{sampling_10k_prop_88p}
\end{figure}



\begin{onebox}{The sampling distribution of a sample statistic}
  The sampling distribution of a sample statistic is the distribution of values of the statistic for all possible random samples of a given size from a given population.\\

It is useful to think of sample statistics as coming from the theoretical sampling distribution.
\end{onebox}


\begin{examplewrap}
\begin{nexample}{Based on the simulated sampling distribution in Figure~\ref{sampling_10k_prop_88p} above, what would be your estimate for the typical variability among sample proportions for random samples of size $n$=1000 from this population? }
The typical variability is given by the standard deviation.  Because the distribution appears approximately normal, we can use the empirical rule.  About 68\% of the sample proportions lie between 0.87 and 0.89 and about 95\% of the sample proportions lie between 0.86 and 0.90.  Therefore, we estimate the standard deviation of the sample proportions as 0.01.
\end{nexample}
\end{examplewrap}

\begin{exercisewrap}
\begin{nexercise}Assuming the true population proportion is 0.88 as it was in our simulation, would you be surprised to get a sample proportion as large as 0.92 in a random sample of size $n=1000$?  Explain your reasoning.\footnotemark
\end{nexercise}
\end{exercisewrap}
\footnotetext{Yes, this would be surprising, because when the true population proportion is 0.88, we almost never got a value as large as 0.92 among our simulated sample proportions.}

%%%%%%
\subsection{Randomization distributions}
\label{randomizationdist}

We consider a study on a new malaria vaccine
called PfSPZ.
In this study, volunteer patients were randomized
into one of two experiment groups:
14 patients received an experimental vaccine
or 6 patients received a placebo vaccine.
Nineteen weeks later, all 20 patients were exposed
to a drug-sensitive malaria parasite strain;
the motivation of using a drug-sensitive strain
of parasite here is for ethical considerations,
allowing any infections to be treated effectively.
The results are summarized in
Figure~\ref{malaria_vaccine_20_exp_summary},
where 9 of the 14 treatment patients remained free
of signs of infection while all of the~6 patients
in the control group patients showed some baseline
signs of infection.


\newcommand{\malariaAA}{5}
\newcommand{\malariaAB}{9}
\newcommand{\malariaAD}{14}
\newcommand{\malariaBA}{6}
\newcommand{\malariaBB}{0}
\newcommand{\malariaBD}{6}
\newcommand{\malariaDA}{11}
\newcommand{\malariaDB}{9}
\newcommand{\malariaDD}{20}
\newcommand{\malariaVIR}{0.357}
\newcommand{\malariaVIRPerc}{35.7\%}
\newcommand{\malariaPIR}{1.000}
\newcommand{\malariaPIRPerc}{100\%}
\newcommand{\malariaIRDiff}{0.643}
\newcommand{\malariaIRDiffPerc}{64.3\%}

\begin{figure}[ht]
\centering
\begin{tabular}{l l cc rr}
  & & \multicolumn{2}{c}{\var{outcome}} \\
  \cline{3-4}
  &  &  {infection} & {no infection} & Total & \hspace{3mm}  \\ 
  \cline{2-5}
  & {vaccine} &
      \malariaAA{} &
      \malariaAB{} &
      \malariaAD{} \\ 
  \raisebox{1.5ex}[0pt]{\var{treatment}}
  & {placebo} & 
      \malariaBA{} &
      \malariaBB{} &
      \malariaBD{} \\ 
  \cline{2-5}
  & Total & 
      \malariaDA{} &
      \malariaDB{} &
      \malariaDD{} \\ 
  \cline{2-5}
\end{tabular}
\caption{Summary results for the malaria vaccine experiment.}
\label{malaria_vaccine_20_exp_summary}
\end{figure}


However, the sample is very small,
and it is unclear whether the difference provides
\emph{convincing evidence} that the vaccine is
effective.

\begin{examplewrap}
\begin{nexample}{How do the proportions that developed an infection compare between those in the vaccine group and those in the placebo group?}
  \label{malaria_vaccine_20_what_is_convincing}
In this study, a smaller proportion of patients
who received the vaccine showed signs of an infection: 
$\frac{\malariaAA{}}{\malariaAD{}}= \malariaVIRPerc{}$ for those that received the vaccine versus $\frac{\malariaBA{}}{\malariaBD{}}$= \malariaPIRPerc{} for those that received the placebo.
\end{nexample}
\end{examplewrap}


 The observed infection rates
  (\malariaVIRPerc{} for the treatment group versus
  \malariaPIRPerc{} for the placebo group)
  suggest the vaccine may be effective at preventing infection.
  However, we cannot be sure if the observed difference
  represents the vaccine's efficacy or is just from
  random chance.
  Generally there is a little bit of fluctuation
  in sample data, and we wouldn't expect the sample
  proportions to be \emph{exactly} equal,
  even if the truth was that the vaccine did not work. Additionally, with such small samples,
  perhaps it's common to observe such large differences
  when we randomly split a group due to chance alone!

How much variation would we expect between the infection rates of the two groups \emph{if the vaccine had no effect}?  To answer this, we implement a simulation,
where we will pretend we know that the malaria
vaccine being tested does \emph{not} work.
Ultimately, we want to understand if the large
difference we observed is common or uncommon in these
simulations.
If it is common, then maybe the difference
we observed was purely due to chance.
If it is very uncommon, then the claim that the vaccine was helpful seems more plausible.

Figure~\ref{malaria_vaccine_20_exp_summary}
shows that in this overall study, 11 patients developed infections and 9 did not.
For our simulation, we will suppose the vaccine does not work and that we are able to
\emph{rewind} back to when the researchers randomized
the patients in the study.
If we happened to randomize the patients differently,
we may get a different result in this hypothetical
world where the vaccine doesn't influence the infection.
Let's perform another \emph{randomization} to treatment groups using a simulation.

To simulate this scenario, we take 20 notecards to
represent the 20 patients, where we write down ``infection''
on 11 cards and ``no infection'' on 9 cards.
In this hypothetical world, we believe each patient
that got an infection was going to get it regardless
of which group they were in, so let's see what happens
if we randomly assign the patients to the treatment
and control groups again.
We thoroughly shuffle the notecards and deal 14 into
a \resp{vaccine} pile and 6 into a \resp{placebo} pile.
Finally, we tabulate the results, which are shown in
Figure~\ref{malaria_vaccine_20_exp_summary_rand_1}.

\D{\newpage}

\begin{figure}[ht]
\centering
\begin{tabular}{l l cc rr}
  & & \multicolumn{2}{c}{\var{outcome}} \\
  \cline{3-4}
  &  &  {infection} & {no infection} & Total & \hspace{3mm}  \\ 
  \cline{2-5}
  treatment & {vaccine} & 7 & 7 & 14 \\ 
  (simulated) & {placebo} & 4 & 2 & 6 \\ 
  \cline{2-5}
  & Total & 11 & 9 & 20 \\
  \cline{2-5}
\end{tabular}
\caption{Simulation results, assuming the vaccine does not work and that any difference
    in infection rates is due to chance.}
\label{malaria_vaccine_20_exp_summary_rand_1}
\end{figure}

\begin{exercisewrap}
\begin{nexercise}
\label{malaria_vaccine_20_exp_summary_rand_1_diff}
What is the difference in infection rates between
the two simulated groups in
Figure~\ref{malaria_vaccine_20_exp_summary_rand_1}?
How does this compare to the observed
\malariaIRDiffPerc{} difference (\malariaVIRPerc{} $-$ \malariaPIRPerc{})
in the actual data?\footnotemark{}
\end{nexercise}
\end{exercisewrap}
\footnotetext{$4 / 6 - 7 / 14 = 0.167$
  or about 16.7\% in favor of the vaccine.
  This difference due to chance is much smaller than the
  difference observed in the actual groups.}




We computed one possible difference under the assumption that the vaccine does not work in Guided
Practice~\ref{malaria_vaccine_20_exp_summary_rand_1_diff},
which represents one difference due to chance.
While in this first simulation, we physically dealt
out notecards to represent the patients,
it is more efficient to perform this simulation
using a computer.
Repeating the simulation on a computer, we get another
difference due to chance:
\begin{align*}
\frac{2}{\malariaBD{}} - \frac{9}{\malariaAD{}} = -0.310
\end{align*}
And another:
\begin{align*}
\frac{3}{\malariaBD{}} - \frac{8}{\malariaAD{}} = -0.071
\end{align*}
And so on until we repeat the simulation enough times
that we have a good idea of what represents the
\emph{distribution of differences from chance alone}.
Figure~\ref{malaria_rand_dot_plot} shows a stacked dot plot
of the differences found from 100 simulations,
where each dot represents a simulated difference between
the infection rates (control rate minus treatment rate).  

This distribution represents a randomization distribution, which is analogous to a sampling distribution in the context of experiments.   A \term{randomization distribution} of a statistic, for example the difference in infection rates between two treatment groups, is the distribution of a statistic generated by a simulation that repeatedly reassigns response values to treatment groups and recalculates the resulting statistic.  The resulting distribution of the statistic approximates the sampling distribution of the statistic and provides a range of expected values assuming no difference in the treatments.  

The distribution of these simulated differences
is centered around 0.
We simulated these differences assuming that the vaccine did not work, and under this condition,
we expect the difference to be near zero with random
fluctuation.  The fluctuation is pretty large here because the treatment group sizes are so small in this study.  

\begin{figure}[ht]
  \centering
  \Figure[A stacked dot plot is shown. The horizontal axis represents "difference in infection rates" and has a range of -0.6 to 0.8. There are six stacks of dots shown in the plot, with 3 points shown at -0.55, 20-25 points shown at -0.32, 30-35 points shown at -0.08, 25-30 points shown at 0.18, 10-12 points shown at 0.41, and 2 points shown at 0.64.]
{0.74}{malaria_rand_dot_plot}
  \caption{A stacked dot plot of differences from
      100 simulated values produced under the assumption that the vaccine does not work.}
  \label{malaria_rand_dot_plot}
\end{figure}


\begin{examplewrap}
\begin{nexample}{Given the results of the simulation shown in Figure~\ref{malaria_rand_dot_plot}, about how often would you expect to observe a result as large as \malariaIRDiffPerc{} if the vaccine does not work?} 
  Because a result this large happened 2 times out the 100 simulations, we would expect such a large value only 2\% of the time if the vaccine does not work.  
\end{nexample}
\end{examplewrap}

Based on our simulation, we might be led to believe that the vaccine works, because assuming that it doesn't work, there is only about a 2\% chance of getting a difference as big as we got in our study.  In the next chapter, we will see how to calculate this conditional probability, known as the p-value, using a normal model when certain conditions are met.

\index{data!malaria vaccine|)}


\D{\newpage}

\subsection{The Central Limit Theorem}

We can characterize the sampling distribution in Figure~\ref{sampling_10k_prop_88p} as symmetric and bell-shaped,
    and it \emph{resembles a normal distribution}.  The randomization distribution shown in Figure~\ref{malaria_rand_dot_plot} also looks somewhat normal in shape.  This is not an accident; it~is the result
of a general principle called the
\index{Central Limit Theorem!proportion|textbf}
\term{Central Limit Theorem}.  The Central Limit Theorem tells us that the sampling distribution of certain statistics, specifically the sample proportion and sample mean, become more normal in shape as the sample size increases.


\begin{onebox}{Central Limit Theorem (CLT)}
For any population with a fixed mean and standard deviation, the shape of the sampling distribution of the proportion and of the mean of a random sample becomes more normal as the sample size $n$ gets larger.
\end{onebox}

The Central Limit Theorem is fundamental to statistics and will form the foundation for working with sampling distributions and inference procedures encountered in the next two chapters.  In any sample or experiment, we would like to know if the result we observe is significant or if the result is within the realm of expected variation.  Sampling distributions and randomization distributions help us visualize and understand the likelihood of getting a result as extreme as we got, assuming the distribution is centered on a certain value.  The Central Limit Theorem will enable us to calculate this likelihood using a normal model.  


\D{\newpage}

%%
\subsection*{Section summary}

\begin{itemize}

\item A \termni{sampling distribution} of a statistic is the distribution of values of the statistic for all possible random samples of a given size from a given population.

\item The \termni{sampling distribution} of a statistic can be simulated by repeatedly
generating a large number of random samples from the population assuming
known value(s) for the parameter(s). The value of the statistic is determined
and recorded for each sample. The resulting distribution of the sample statistic
values approximates the sampling distribution of the statistic.

\item  A \termni{randomization distribution} is the distribution of a statistic generated by simulation from repeatedly randomly reallocating, or reassigning, the response
values to treatment groups. The value of the statistic is determined and
recorded for each reallocation, or reassignment. The resulting distribution of
the statistic values approximates the sampling distribution of the statistic.

\item  The \termni{Central Limit Theorem} (CLT) states that the sampling distribution of a sample proportion and a sample mean become more normal in shape as the sample size increases.

\end{itemize}


{\input{ch_probability/TeX/sampling_distributions_and_the_central_limit_theorem.tex}}

%______________________________________________
\reviewchapterheader{}

\noindent This chapter focused on understanding likelihood and chance variation, first by solving individual probability questions and then by investigating probability distributions. 
\\
\\The main probability techniques covered in this chapter are as follows:
\begin{itemize}
\item The \textbf{Conditional Probability Rule}.  
\item The \textbf{General Multiplication Rule} for \textbf{and} (intersection) probabilities, along with the special case when events are \term{independent}.
\item The \textbf{General Addition Rule} for \textbf{or} (union) probabilities, along with the special case when events are \textbf{mutually exclusive}.  
\end{itemize}
Fundamental to all of these problems is understanding when events are independent and when they are mutually exclusive.  Two events are \textbf{independent} when the outcome of one does not affect the outcome of the other, i.e. $P(A\ | \ B) = P(A)$.  Two events are \textbf{mutually exclusive} when they cannot both happen together, i.e. $P(A \cap B) = 0$.
\\ 
\\
Moving from solving individual probability questions to studying probability distributions helps us better understand chance processes and quantify expected chance variation. 
\begin{itemize}
\item For a \term{discrete probability distribution}, the \textbf{sum} of the probabilities must equal 1.  
\item As with any distribution, one can calculate the mean and standard deviation of a probability distribution.  In the context of a probability distribution, the \textbf{mean} and \textbf{standard deviation} describe the average and the typical  deviation of values from the average, respectively, in the long run, or after many, many repetitions of the chance process.  

\item A probability distribution can be summarized by its \textbf{center} (mean, median), \textbf{spread} (SD, IQR), and \textbf{shape} (right skewed, left skewed, approximately symmetric).  


\item The \textbf{binomial distribution} is a discrete probability distribution which provides a model for the number of successes in $n$ independent trials.

\item The \textbf{normal distribution} is a continuous probability distribution which can be used to model various empirical and probability distributions.

\item The \textbf{Central Limit Theorem} is a powerful theorem thats tells us that as the sample size $n$ increases, the sampling distribution of a sample proportion and a sample mean become more normal in shape.  For large enough $n$, we can model sampling distributions using a normal distribution.  


\end{itemize}
The study of probability is useful for measuring uncertainty and assessing risk.  In addition, probability serves as the foundation for inference, providing a framework for evaluating when an outcome falls outside of the range of what would be expected by chance alone.

