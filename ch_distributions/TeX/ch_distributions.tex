\begin{chapterpage}{Sampling distributions}
  \chaptertitle[30]{Sampling distributions}
  \label{ch_distributions}
  \chaptersection{normalDist}
  \chaptersection{distributionphat}
\chaptersection{diffofprops}
\chaptersection{distributionofxbar}
\chaptersection{diffofmeans}


\end{chapterpage}
\renewcommand{\chapterfolder}{ch_distributions}
\index{distribution!normal|(}
\index{normal distribution|}

\Comment{ update intro}

\chapterintro{In this chapter, we discuss statistical distributions that frequently arise in the context of data analysis or statistical
  inference.  We start with the normal distribution in the first section,
  and we find that it is useful for approximating many of the other distributions introduced in the sections that follow. \vspace{6mm}

  \noindent%
  We also introduce the fundamental concept of a sampling distribution.  The sampling distribution of a sample proportion and of a sample mean underlie the inference procedures encountered in next chapters.}


%_______________________________________
\section[Continuous distributions]{Continuous distributions }
\label{contDist}

\sectionintro{
\noindent%
So far we have looked only at cases where the random variable takes on integer values.
What happens when we consider random variables that produce a continuous numerical variable, such as wait time for a bus?
In this section, we introduce the concept of a continuous distribution.
In the next chapter, you will encounter the most famous continuous distribution of all.\footnote{It's the normal distribution!}


%%
\subsection*{Learning objectives}
\begin{enumerate}
\setlength{\itemsep}{0mm}
\item Understand the difference between a discrete random variable and a continuous random variable.

\item Recognize that when working with continuous probability distributions area represents probability and the total area under the curve must equal 1. 

\end{enumerate}
}

%%
\subsection{From histograms to continuous distributions}

\index{data!FCID|(}
\index{hollow histogram|(}
\begin{examplewrap}
\begin{nexample}{Figure~\ref{fdicHistograms} shows a few different hollow histograms of the variable \var{height} for 3 million US adults from the mid-90's.\footnotemark\, How does changing the number of bins allow you to make different interpretations of the data?}\label{usHeights}
Adding more bins provides greater detail. This sample is extremely large, which is why much smaller bins still work well. Usually we do not use so many bins with smaller sample sizes since small counts per bin mean the bin heights are very volatile.
\end{nexample}
\end{examplewrap}
\footnotetext{This sample can be considered a simple random sample from the US population. It relies on the USDA Food Commodity Intake Database.} 

\begin{figure}[ht]
\centering
\includegraphics[width=\textwidth]{ch_probability/figures/fdicHistograms/fdicHistograms}
\caption{Four hollow histograms of US adults heights with varying bin widths.}
\label{fdicHistograms}
\end{figure}

\begin{examplewrap}
\begin{nexample}{What proportion of the sample is between 180 cm and 185 cm tall (about 5'11" to 6'1")?}\label{contDistProb}
We can add up the heights of the bins in the range 180 cm and 185 and divide by the sample size. For instance, this can be done with the two shaded bins shown in Figure~\ref{usHeightsHist180185}. The two bins in this region have counts of 195,307 and 156,239 people, resulting in the following estimate of the probability:
\begin{eqnarray*}
\frac{195307+156239}{\text{3,000,000}} = 0.1172
\end{eqnarray*}
This fraction is the same as the proportion of the histogram's area that falls in the range 180 to 185~cm.
\end{nexample}
\end{examplewrap}

\begin{figure}
\centering
\includegraphics[width=0.95\textwidth]{ch_probability/figures/usHeightsHist180185/usHeightsHist180185}
\caption{A histogram with bin sizes of 2.5 cm. The shaded region represents individuals with heights between 180 and 185 cm.}
\label{usHeightsHist180185}
\end{figure}

\D{\newpage}

Examine the transition from a boxy hollow histogram in the top-left of Figure~\ref{fdicHistograms} to the much smoother plot in the lower-right. In this last plot, the bins are so slim that the hollow histogram is starting to resemble a smooth curve. This suggests the population height as a \emph{continuous} numerical variable might best be explained by a curve that represents the outline of extremely slim bins.

This smooth curve represents a \term{continuous distribution}, also called a \textbf{density curve}.  Such a distribution is shown in Figure~\ref{fdicHeightContDist} overlaid on a histogram of the sample. A  continuous distribution has a special property: the total area under the curve is 1.

\begin{figure}[tbh]
\centering
\includegraphics[width=0.87\textwidth]{ch_probability/figures/fdicHeightContDist/fdicHeightContDist}
\caption{The continuous probability distribution of heights for US adults.}
\label{fdicHeightContDist}
\end{figure}

\index{hollow histogram|)}


%%
\subsection{Probabilities from continuous distributions}

We computed the proportion of individuals with heights 180 to 185 cm in Example~\ref{contDistProb} as a fraction:
\begin{eqnarray*}
\frac{\text{number of people between 180 and 185}}{\text{total sample size}}
\end{eqnarray*}
We found the number of people with heights between 180 and 185 cm by determining the fraction of the histogram's area in this region. Similarly, we can use the area in the shaded region under the curve to find a probability (with the help of a computer):
\begin{eqnarray*}
P(\text{\var{height} between 180 and 185})
	= \text{area between 180 and 185}
	= 0.1157
\end{eqnarray*}
The probability that a randomly selected person is between 180 and 185 cm is 0.1157. This is very close to the estimate from Example~\ref{contDistProb}: 0.1172.


\begin{exercisewrap}
\begin{nexercise}
Three US adults are randomly selected. The probability a single adult is between 180 and 185 cm is 0.1157.\footnotemark \vspace{-1.5mm}
\begin{enumerate}
\setlength{\itemsep}{0mm}
\item[(a)] What is the probability that all three are between 180 and 185 cm tall?
\item[(b)] What is the probability that none are between 180 and 185 cm?
\end{enumerate}
\end{nexercise}
\end{exercisewrap}
\footnotetext{Brief answers: (a) $0.1157 \times 0.1157 \times 0.1157 = 0.0015$. (b) $(1-0.1157)^3 = 0.692$}

\D{\newpage}

\begin{examplewrap}
\begin{nexample}{What is the probability that a randomly selected person is \textbf{exactly} 180~cm? Assume you can measure perfectly.}
\label{probabilityOfExactly180cm}
This probability is zero. A person might be close to 180 cm, but not exactly 180 cm tall. This also makes sense with the definition of probability as area; there is no area captured between 180~cm and 180~cm.
\end{nexample}
\end{examplewrap}

\begin{exercisewrap}
\begin{nexercise}
Suppose a person's height is rounded to the nearest centimeter. Is there a chance that a random person's \textbf{measured} height will be 180~cm?\footnotemark
\end{nexercise}
\end{exercisewrap}
\footnotetext{This has positive probability. Anyone between 179.5 cm and 180.5 cm will have a \emph{measured} height of 180 cm. This is probably a more realistic scenario to encounter in practice versus Example~\ref{probabilityOfExactly180cm}.}

\index{data!FCID|)}


\D{\newpage}

%%
\subsection*{Section summary}
\begin{itemize}
\item Histograms use bins with a specific width to display the distribution of a variable.  When there is enough data and the data does not have gaps, as the bin width gets smaller and smaller, the histogram begins to resemble a smooth curve, or a \term{continuous distribution}. 

\item Continuous distributions are often used to approximate relative frequencies and probabilities.  In a continuous distribution, the \emph{area under the curve} corresponds to relative frequency or probability.  The total area under a continuous probability distribution must equal 1.  

\item Because the area under the curve for a single point is zero, the probability of any specific value is zero.  This implies that, for example, $P(X < 5) = P(X \le 5)$ for a continuous probability distribution.

\item Finding areas under curves is challenging; it is common to use distribution tables, calculators, or other technology to find such areas.

\end{itemize}



%%%%%%Section Exercises
{\input{ch_probability/TeX/continuous_distributions.tex}}



\D{\newpage}

\D{\newpage}

%____________________________________
\section[Sampling distribution of a sample mean]{Sampling distribution of a sample mean }
\label{distributionofxbar}

\sectionintro{
\noindent%
If bags of chips are produced with an average weight of 15~oz and a standard deviation of 0.1~oz, what is the probability that the average weight of 30 bags will be within 0.1~oz of the mean?  The answer is not 68\%!
To answer this question we must visualize and understand what is called the \emph{sampling distribution} of a sample mean.


%%
\subsection*{Learning objectives}
\begin{enumerate}
\setlength{\itemsep}{0mm}
\item Understand the concept of a sampling distribution.

\item Describe the center, spread, and shape of the sampling distribution of a sample mean.


\item Distinguish between the standard deviation of a population and the standard deviation of a sampling distribution.

\item Explain the content and importance of the Central Limit Theorem.

\item Identify and explain the conditions for using normal approximation involving a sample mean.

\item Verify that the conditions for normal approximation are met and carry out normal approximation involving a sample mean or sample sum.

\end{enumerate}
}


%%
\subsection[The mean and standard deviation of $\bar{x}$]{The mean and standard deviation of $\pmb{\bar{x}}$}


In this section we consider a data set called \data{run17}, which represents all 19,961 runners who finished the 2017 Cherry Blossom 10 mile run in Washington, DC.\footnote{\oiRedirect{textbook-cherryblossom_org}{www.cherryblossom.org}} Part of this data set is shown in Figure~\ref{run17DF}, and the variables are described in Figure~\ref{run17Variables}.

\begin{figure}[h]
\centering
\begin{tabular}{rrrrr}
  \hline
ID & time & age & gender & state \\ 
  \hline
1 & 92.25 & 38.00 & M & MD \\ 
2 & 106.35 & 33.00 & M & DC \\ 
%3 & 89.33 & 55.00 & F & VA \\ 
%4 & 113.50 & 24.00 & F & VA \\ 
$\vdots$ & $\vdots$ & $\vdots$ & $\vdots$ & $\vdots$ \\
16923 & 122.87 & 37.00 & F & VA \\ 
16924 & 93.30 & 27.00 & F & DC \\ 
   \hline
\end{tabular}
\caption{Four observations from the \data{run17} data set.}
\label{run17DF}
\end{figure}
% library(openintro); library(xtable); data(run10); xtable(run10[c(1,2,3,4, nrow(run10)-1:0), c("time", "age", "gender", "state")])

\begin{figure}[h]
\centering\small
\begin{tabular}{l p{65mm}}
\hline
{\bf variable} & {\bf description} \\
\hline
\var{time} & Ten mile run time, in minutes \\
\var{age} & Age, in years \\
\var{gender} & Gender (\resp{M} for male, \resp{F} for female) \\
\var{state} & Home state (or country if not from the US) \\
\hline
\end{tabular}
\caption{Variables and their descriptions for the \data{run17} data set.}
\label{run17Variables}
\end{figure}

\index{data!run17samp|(}

These data are special because they include the results for the entire population of runners who finished the 2017 Cherry Blossom Run. We took a simple random sample of this population, which is represented in Figure~\ref{run17sampDF}. A histogram summarizing the time variable in the \data{run17samp} data set is shown in Figure~\ref{run17sampHistograms}.

\begin{figure}[h]
\centering
\begin{tabular}{rrrrr}
  \hline
ID & time & age & gender & state \\ 
  \hline
1983 & 88.31 & 59 & M & MD \\ 
8192 & 100.67 & 32 & M & VA \\ 
%11020 & 109.52 & 33 & F & VA \\ 
  $\vdots$ &   $\vdots$ &   $\vdots$ &   $\vdots$ &   $\vdots$ \\ 
1287 & 89.49 & 26 & M & DC \\ 
   \hline
\end{tabular}
\caption{Three observations for the \data{run17samp} data set, which represents a simple random sample of 100 runners from the 2017 Cherry Blossom Run.}
\label{run17sampDF}
%library(openintro); library(xtable); data(run10); data(run10samp); xtable(run10samp[c(1,2,3,100),])
\end{figure}

% WARNING: This figure is referenced in Section 4.2

\begin{figure}[h]
\centering
\includegraphics[width=0.75\textwidth]{ch_distributions/figures/run17sampHistograms/run17sampHistograms} 
\caption{Histogram of \var{time} for a single sample of size 100. The average of the sample is in the mid-90s and the standard deviation of the sample $s\approx 17$ minutes.
\index{skew!example: moderate}}
\label{run17sampHistograms}
\end{figure}

From the random sample represented in \data{run17samp}, we guessed the average time it takes to run 10 miles is 95.61 minutes. Suppose we take another random sample of 100 individuals and take its mean: 95.30 minutes. Suppose we took another (93.43 minutes) and another (94.16 minutes), and so on. If we do this many many times -- which we can do only because we have the entire population data set -- we can build up a \term{sampling distribution} for the sample mean when the sample size is 100, shown in Figure~\ref{netTime1000SamplingDistribution}.

\begin{figure}[h]
   \centering
   \includegraphics[width=\textwidth]{ch_distributions/figures/netTime1000SamplingDistribution/netTime1000SamplingDistribution}
   \caption{A histogram of 1000 sample means for run time, where the samples are of size $n=100$. This histogram approximates the true sampling distribution of the sample mean, with mean $\mu_{\bar{x}}$ and standard deviation $\sigma_{\bar{x}}$.}
   \label{netTime1000SamplingDistribution}
\end{figure}

\begin{onebox}{Sampling distribution}
The sampling distribution represents the distribution of the point estimates based on samples of a fixed size from a certain population. It is useful to think of a point estimate as being drawn from such a distribution. Understanding the concept of a sampling distribution is central to understanding statistical inference.\end{onebox}


The sampling distribution shown in Figure~\ref{netTime1000SamplingDistribution} is unimodal and approximately symmetric. It is also centered exactly at the true population mean: $\mu=94.52$. Intuitively, this makes sense. The sample mean should be an unbiased estimator of the population mean. Because we are considering the distribution of the sample mean, we will use $\mu_{\bar{x}} = 94.52$ to describe the true mean of this distribution.

\D{\newpage}

We can see that the sample mean has some variability around the population mean, which can be quantified using the standard deviation of this distribution of sample means. The standard deviation of the sample mean tells us how far the typical estimate is away from the actual population mean, 94.52 minutes. It also describes the typical \term{error} of a single estimate, and is denoted by the symbol $\sigma_{\bar{x}}$. 

\begin{onebox}{Standard deviation of an estimate}
The standard deviation associated with an estimate describes the typical error or uncertainty associated with the estimate.\end{onebox}

\begin{examplewrap}
\begin{nexample}{Looking at Figures~\ref{run17sampHistograms} and \ref{netTime1000SamplingDistribution}, we see that the standard deviation of the sample mean with $n=100$ is much smaller than the standard deviation of a single sample. Interpret this statement and explain why it is true.}The variation from one sample mean to another sample mean is much smaller than the variation from one individual to another individual. This makes sense because when we average over 100 values, the large and small values tend to cancel each other out. While many individuals have a time under 90 minutes, it would be unlikely for the \emph{average} of 100 runners to be less than 90 minutes.
\end{nexample}
\end{examplewrap}

\D{\newpage}

\begin{exercisewrap}
\begin{nexercise}
(a) Would you rather use a small sample or a large sample when estimating a parameter? Why? (b) Using your reasoning from (a), would you expect a point estimate based on a small sample to have smaller or larger standard deviation than a point estimate based on a larger sample?\footnotemark
\end{nexercise}
\end{exercisewrap}
\footnotetext{(a) Consider two random samples: one of size 10 and one of size 1000. Individual observations in the small sample are highly influential on the estimate while in larger samples these individual observations would more often average each other out. The larger sample would tend to provide a more accurate estimate. (b) If we think an estimate is better, we probably mean it typically has less error. Based on (a), our intuition suggests that a larger sample size corresponds to a smaller standard deviation.}

When considering how to calculate the standard deviation of a sample mean, there is one problem: there is no obvious way to estimate this from a single sample. However, statistical theory provides a helpful tool to address this issue.

In the sample of 100 runners, the standard deviation of the sample mean is equal to one-tenth of the population standard deviation: $15.93/10 = 1.59$. In other words, the standard deviation of the sample mean based on 100 observations is equal to
\begin{eqnarray*}
SD_{\bar{x}} = \sigma_{\bar{x}} = \frac{\sigma_{x}}{\sqrt{n}} = \frac{15.93}{\sqrt{100}} = 1.59
\end{eqnarray*}
where $\sigma_{x}$ is the standard deviation of the individual observations. This is no coincidence. We can show mathematically that this equation is correct when the observations are independent  using the probability tools of Section~\ref{randomVariablesSection}.

\D{\newpage}

\begin{onebox}{Computing SD for the sample mean}
Given $n$ independent observations from a population with standard deviation $\sigma$, the standard deviation of the sample mean is equal to \vspace{-1mm}
\begin{eqnarray}
SD_{\bar{x}} = \sigma_{\bar{x}} =  \frac{\sigma}{\sqrt{n}}
\label{seOfXBar}
\end{eqnarray}\vspace{-3mm}

A reliable method to ensure sample observations are independent is to conduct a simple random sample consisting of less than 10\% of the population.\index{standard error!single mean}\end{onebox}

\begin{exercisewrap}
\begin{nexercise}
The average of the runners' ages is 35.05 years with a standard deviation of $\sigma = 8.97$. A simple random sample of 100 runners is taken. (a)~What is the standard deviation of the sample mean? (b)~Would you be surprised to get a sample of size 100 with an average of 36~years?\footnotemark\end{nexercise}
\end{exercisewrap}
\footnotetext{(a) Use Equation~(\ref{seOfXBar}) with the population standard deviation to compute the standard deviation of the sample mean: $SD_{\bar{y}} = 8.97/\sqrt{100} = 0.90$ years. (b) It would not be surprising. 36 years is about 1 standard deviation from the true mean of 35.05. Based on the 68, 95 rule, we would get a sample mean at least this far away from the true mean approximately $100\% - 68\% = 32\%$ of the time.}

%library(openintro); library(xtable); data(run10); data(run10samp); mean(run10samp$age); sd(run10samp$age); sd(run10$age, na.rm=TRUE)

\begin{exercisewrap}
\begin{nexercise}
(a) Would you be more trusting of a sample that has 100 observations or 400 observations? (b) We want to show mathematically that our estimate tends to be better when the sample size is larger. If the standard deviation of the individual observations is 10, what is our estimate of the standard deviation of the mean when the sample size is 100? What about when it is 400? (c) Explain how your answer to (b) mathematically justifies your intuition in part~(a).\footnotemark
\end{nexercise}
\end{exercisewrap}
\footnotetext{(a) Extra observations are usually helpful in understanding the population, so a point estimate with 400 observations seems more trustworthy. (b) The standard deviation of the mean when the sample size is 100 is given by $SD_{100} = 10/\sqrt{100} = 1$. For 400: $SD_{400} = 10/\sqrt{400} = 0.5$. The larger sample has a smaller standard deviation of the mean. (c) The standard deviation of the mean of the sample with 400 observations is lower than that of the sample with 100 observations. The standard deviation of $\bar{x}$ describes the typical error, and since it is lower for the larger sample, this mathematically shows the estimate from the larger sample tends to be better -- though it does not guarantee that every large sample will provide a better estimate than a particular small sample.}


\D{\newpage}

%%
\subsection{Examining the Central Limit Theorem}
\label{cltSection}

\index{Central Limit Theorem|(}

In Figure~\ref{netTime1000SamplingDistribution}, the sampling distribution of the sample mean looks approximately normally distributed. Will the sampling distribution of a mean always be nearly normal? To address this question, we will investigate three cases to see roughly when the approximation is reasonable.

We consider three data sets: one from a \emph{uniform} distribution, one from an \emph{exponential} distribution, and the other from a \emph{normal} distribution. These distributions are shown in the top panels of Figure~\ref{cltSimulations}. The uniform distribution is symmetric, and the exponential distribution may be considered as having moderate skew since its right tail is relatively short (few outliers).\index{skew!example: moderate}

\begin{figure}
   \centering
   \includegraphics[width=\textwidth]{ch_distributions/figures/cltSimulations/cltSimulations}
   \caption{Sampling distributions for the mean at different sample sizes and for three different distributions. The dashed red lines show normal distributions.}
   \label{cltSimulations}
\end{figure}

The left panel in the $n=2$ row represents the sampling distribution of $\bar{x}$ if it is the sample mean of two observations from the uniform distribution shown. The dashed line represents the closest approximation of the normal distribution. Similarly, the center and right panels of the $n=2$ row represent the respective distributions of $\bar{x}$ for data from exponential and log-normal distributions.

\begin{exercisewrap}
\begin{nexercise}
Examine the distributions in each row of Figure~\ref{cltSimulations}. What do you notice about the sampling distribution of the mean as the sample size, $n$, becomes larger?\footnotemark
\end{nexercise}
\end{exercisewrap}
\footnotetext{The normal approximation becomes better as larger samples are used. However, in the case when the population is normally distributed, the normal distribution of the sample mean is normal for all sample sizes.}

\begin{examplewrap}
\begin{nexample}{In general, would normal approximation for a sample mean be appropriate when the sample size is at least 30?}
Yes, the sampling distributions when $n = 30$ all look very much like the normal distribution.

However, the more non-normal a population distribution, the larger a sample size is necessary for the sampling distribution to look nearly normal.
\end{nexample}
\end{examplewrap}

\begin{onebox}{Determining if the sample mean is normally distributed}
If the population is normal, the sampling distribution of $\bar{x}$ will be normal for any sample size. \\[2mm]
The less normal the population, the larger $n$ needs to be for the sampling distribution of $\bar{x}$ to be nearly normal. However, a good rule of thumb is that for almost all populations, the sampling distribution of $\bar{x}$ will be approximately normal if $n \ge 30$.\end{onebox}

This brings us to the \term{Central Limit Theorem}, the most fundamental theorem in Statistics.

\begin{onebox}{Central Limit Theorem}
When taking a random sample of independent observations from a population with a fixed mean and standard deviation, the distribution of $\bar{x}$ approaches the normal distribution as $n$ increases.\end{onebox}

\D{\newpage}

\begin{examplewrap}
\begin{nexample}{Sometimes we do not know what the population distribution looks like. We have to infer it based on the distribution of a single sample. Figure~\ref{pokerProfitsCanApplyNormalToSampMean} shows a histogram of 20 observations. These represent winnings and losses from 20 consecutive days of a professional poker player. Based on this sample data, can the normal approximation be applied to the distribution of the sample mean?}
We should consider each of the required conditions.
\begin{itemize}
\setlength{\itemsep}{0mm}
\item[(1)] These are referred to as \term{time series data}, because the data arrived in a particular sequence. If the player wins on one day, it may influence how she plays the next. To make the assumption of independence we should perform careful checks on such data.
\item[(2)] The sample size is 20, which is smaller than 30.
\item[(3)] There are two outliers in the data, both quite extreme, which suggests the population may not be normal and instead may be very strongly skewed or have distant outliers. Outliers can play an important role and affect the distribution of the sample mean and the estimate of the standard deviation of the sample mean.
\end{itemize}
Since we should be skeptical of the independence of observations and the extreme upper outliers pose a challenge, we should not use the normal model for the sample mean of these 20 observations. If we can obtain a much larger sample, then the concerns about skew and outliers would no longer apply.
\end{nexample}
\end{examplewrap}

\begin{figure}[ht]
   \centering
   \includegraphics[height=58mm]{ch_distributions/figures/pokerProfitsCanApplyNormalToSampMean/pokerProfitsCanApplyNormalToSampMean}
   \caption{Sample distribution of poker winnings. These data include two very clear outliers. These are problematic when considering the normality of the sample mean. For example, outliers are often an indicator of very strong skew\index{skew!example: very strong}.}
   \label{pokerProfitsCanApplyNormalToSampMean}
\end{figure}

\begin{onebox}{Examine data structure when considering independence}
{Some data sets are collected in such a way that they have a natural underlying structure between observations, e.g. when observations occur consecutively. Be especially cautious about independence assumptions regarding such data sets.}
\end{onebox}

\begin{onebox}{Watch out for strong skew and outliers}
{Strong skew in the population is often identified by the presence of clear outliers in the data. If a data set has prominent outliers, then a larger sample size will be needed for the sampling distribution of $\bar{x}$ to be normal. There are no simple guidelines for what sample size is big enough for each situation. However, we can use the rule of thumb that, in general, an $n$ of at least 30 is sufficient for most cases.}
\index{skew!strongly skewed guideline}
\end{onebox}
\index{Central Limit Theorem|)}


\D{\newpage}

%%
\subsection[Normal approximation for the sampling distribution of $\bar{x}$]{Normal approximation for the sampling distribution of \pmb{$\bar{x}$}}

At the beginning of this chapter, we used normal approximation for populations or for data that had an approximately normal distribution. When appropriate conditions are met, we can also use the normal approximation to estimate probabilities about a sample average. We must remember to verify that the conditions are met and use the mean $\mu_{\bar{x}}$ and standard deviation $\sigma_{\bar{x}}$ for the sampling distribution of the sample average.

\begin{onebox}{Three important facts about the distribution of a sample mean \pmb{\MakeLowercase{$\bar{x}$}}}
Consider taking a simple random sample from a large population.
\begin{enumerate}
\setlength{\itemsep}{0mm}
\item The mean of a sample mean is denoted by $\mu_{\bar{x}}$, and it is equal to $\mu$.
\item The SD of a sample mean is denoted by $\sigma_{\bar{x}}$, and it is equal to $\frac{\sigma}{\sqrt{n}}$.
\item When the population is normal or when $n\ge 30$, the sample mean closely follows a normal distribution. 
\end{enumerate}\end{onebox}

\begin{examplewrap}
\begin{nexample}{
In the 2012 Cherry Blossom 10 mile run, the average time for all of the runners is 94.52 minutes with a standard deviation of 8.97 minutes. The distribution of run times is approximately normal. Find the probabiliy that a randomly selected runner completes the run in less than 90 minutes.}Because the distribution of run times is approximately normal, we can use normal approximation.
\begin{align*}
&Z = \frac{x - \mu}{\sigma}=\frac{90-94.52}{8.97}=-0.504 \\
&P(Z < -0.504) = 0.3072
\end{align*}
There is a 30.72\% probability that a randomly selected runner will complete the run in less than 90~minutes.
\end{nexample}
\end{examplewrap}

\begin{examplewrap}
\begin{nexample}{
Find the probabiliy that the average of 20 runners is less than 90~minutes.}
Here, $n=20<30$, but the distribution of the population, that~is, the distribution of run times is stated to be approximately normal. Because of this, the sampling distribution will be normal for any sample size.
\begin{align*}
&\sigma_{\bar{x}}=\frac{\sigma}{\sqrt{n}}=\frac{8.97}{\sqrt{20}}=2.01 \\
&Z = \frac{\bar{x} - \mu_{\bar{x}}}{\sigma_{\bar{x}}}=\frac{90-94.52}{2.01}=-2.25\\
&P(Z < -2.25) = 0.0123
\end{align*}
There is a 1.23\% probability that the average run time of 20 randomly selected runners will be less than 90~minutes.
\end{nexample}
\end{examplewrap}

\D{\newpage}

\begin{examplewrap}
\begin{nexample}{
The average of all the runners' ages is 35.05 years with a standard deviation of $\sigma = 8.97$. The distribution of age is somewhat skewed. What is the probability that a randomly selected runner is older than 37 years?}Because the distribution of age is skewed and is not normal, we cannot use normal approximation for this problem. In order to answer this question, we would need to look at all of the data.
\end{nexample}
\end{examplewrap}

\begin{exercisewrap}
\begin{nexercise}
What is the probability that the average of 50 randomly selected runners is greater than 37 years?\footnotemark
\end{nexercise}
\end{exercisewrap}
\footnotetext{Because $n=50\ge 30$, the sampling distribution of the mean is approximately normal, so we can use normal approximation for this problem. The mean is given as 35.05 years.
\begin{align*}
&\sigma_{\bar{x}}
	= \frac{\sigma}{\sqrt{n}}
	= \frac{8.97}{\sqrt{50}}=1.27
&&z=\frac{\bar{x}-\mu_{\bar{x}}}{\sigma_{\bar{x}}} = \frac{37-35.05}{1.27}=1.535
&&P(Z > 1.535) = 0.062
\end{align*}
There is a 6.2\% chance that the average age of 50 runners will be greater than 37.} 

\begin{onebox}{Remember to divide by $\pmb{\sqrt{\MakeLowercase{n}}}$}
When finding the probability that an \emph{average} or mean is greater or less than a particular value, remember to divide the standard deviation of the population by $\sqrt{n}$ to calculate the correct~SD.\end{onebox}


\D{\newpage}

%%
\subsection*{Section summary}

\begin{itemize}
\item The symbol $\bar{x}$ denotes the sample average.  $\bar{x}$ for any particular sample is a number.  However, $\bar{x}$ can vary from sample to sample.  The distribution of all possible values of $\bar{x}$ for repeated samples of a fixed size from a certain population is called the \term{sampling distribution} of $\bar{x}$.

\item The standard deviation of $\bar{x}$ describes the typical error or distance of the sample mean from the population mean.  It also tells us how much the sample mean is likely to vary from one random sample to another.  

\item The standard deviation of $\bar{x}$ will be \textit{smaller} than the standard deviation of the population by a factor of $\sqrt{n}$.  The larger the sample, the better the estimate tends to be.

\item Consider taking a simple random sample from a population with a fixed mean and standard deviation.  The \term{Central Limit Theorem} ensures that regardless of the shape of the original population, as the sample size increases, the distribution of the sample average $\bar{x}$ becomes more normal.  

\item Three important facts about the sampling distribution of the sample average $\bar{x}$:
\begin{itemize}\vspace{-1mm}
\setlength{\itemsep}{0mm}
\item The mean of a sample mean is denoted by $\mu_{\bar{x}}$, and it is equal to $\mu$. (\textit{center})
\item The SD of a sample mean is denoted by $\sigma_{\bar{x}}$, and it is equal to $\frac{\sigma}{\sqrt{n}}$.  (\textit{spread})
\item When the population is normal or when $n\ge 30$, the sample mean closely follows a normal distribution.   (\textit{shape})
\end{itemize}

\item These facts are used when solving the following two types of \textbf{normal approximation} problems involving a \emph{sample mean} or a \emph{sample sum}.  
\begin{itemize}
\item[A:] \textit{Find the probability that a sample average will be greater/less than a certain value}.
\begin{enumerate}\vspace{-1mm}
\setlength{\itemsep}{0mm}
\item Verify that the population is approximately normal or that $n \ge 30$.
\item Calculate the Z-score.  Use $\mu_{\bar{x}}=\mu$ and $\sigma_{\bar{x}}=\frac{\sigma}{\sqrt{n}}$ to standardize the sample average.  
\item Find the appropriate area under the normal curve.  
\end{enumerate}

\item[B:] \textit{Find the probability that a sample sum/total will be greater/less than a certain value}.
\begin{enumerate}\vspace{-1mm}
\setlength{\itemsep}{0mm}
\item Convert the sample sum into a sample average, using $\bar{x} = \frac{sum}{n}$.  
\item Do steps 1-3 from Part A above.
\end{enumerate}
\end{itemize}
\end{itemize}

%%%%%%%%%%Section exercises
{\input{ch_distributions/TeX/sampling_distribution_of_a_sample_mean.tex}}




%______________________________________________
\section[Sampling distribution of a sample proportion]{Sampling distribution of a sample proportion }
\label{distributionphat}

\sectionintro{
\noindent%
Often, instead of the number of successes in $n$ trials, we are interested in the \emph{proportion} of successes in $n$ trials.  We can use the sampling distribution of a sample proportion to answer questions such as the following:

\begin{itemize}
\item Given a population that is 50\% male, what is the probability that a random sample of 200 people would consist of less than 45\% males?

\item In a particular state, 48\% support a controversial measure.  When estimating the percent through polling, what is the probability that a random sample of size 200 will mistakenly estimate the percent support to be greater than 50\%?

\end{itemize}


%%
\subsection*{Learning objectives}
\begin{enumerate}
\setlength{\itemsep}{0mm}
\item Describe the center, spread, and shape of the sampling distribution of a sample proportion.


\item Recognize the relationship between the distribution of a sample proportion and the corresponding binomial distribution. 

\item Identify and explain the conditions for using normal approximation involving a sample proportion. Recognize that the Central Limit Theorem applies in the case of proportions/counts as well as means/sums.

\item Verify that the conditions for normal approximation are met and carry out normal approximation involving a sample proportion or sample count.

\end{enumerate}
}


%%
\subsection[The mean and standard deviation of $\hat{p}$]{The mean and standard deviation of \pmb{$\hat{p}$}}

To answer these questions, we investigate the distribution of the sample proportion $\hat{p}$. In the last section we saw that the \emph{number} of people with blood type O+ in a random sample of size 40 follows a binomial distribution with $n=40$ and $p=0.35$ that is centered on 14 and has standard deviation 3.0. What does the distribution of the \emph{proportion} of people with blood type O+ in a sample of size 40 look like?  To convert from a count to a proportion, we divide the count (i.e.~number of~yeses) by the sample size, $n = 40$. For example, 6 becomes $8/40 = 0.20$ as a proportion and 11 becomes $11/40 = 0.275$. 

We can find the general formula for the mean (expected value) and standard deviation of a sample proportion $\hat{p}$ using our tools that we've learned so far. To get the sample mean for $\hat{p}$, we divide the binomial mean $\mu_{binomial} = np$ by $n$:
\begin{align*}
\mu_{\hat{p}} = \frac{\mu_{binomial}}{n} = \frac{np}{n} = p
\end{align*}
As one might expect, the sample proportion $\hat{p}$ is centered on the true proportion $p$. Likewise, the standard deviation of $\hat{p}$ is equal to the standard deviation of the binomial distribution divided by $n$:
\begin{align*}
\sigma_{\hat{p}}
	= \frac{\sigma_{binomial}}{n}
	= \frac{\sqrt{np(1-p)}}{n}
	= \sqrt{\frac{p(1-p)}{n}}
\end{align*}

\begin{onebox}{Mean and standard deviation of a sample proportion}
The mean and standard deviation of the sample proportion describe the center and spread of the distribution of all possible sample proportions $\hat{p}$ from a random sample of size $n$ with true population proportion $p$.
\begin{align*}
\mu_{\hat{p}} &= p
	& \sigma_{\hat{p}}&= \sqrt{\frac{p(1-p)}{n}}
	\vspace{1mm}
\end{align*}\end{onebox}

%Because the distribution of $\hat{p}$ is centered at $p$, the sample proportion is said to be an \hiddenterm{unbiased estimator} of $p$.

In analyses, we think of the formula for the standard deviation of a sample proportion, $\sigma_{\hat{p}}$, as describing the uncertainty associated with the estimate $\hat{p}$. That is, $\sigma_{\hat{p}}$ can be thought of as a way to quantify the typical \hiddenterm{error} in our sample estimate $\hat{p}$ of the true proportion $p$. Understanding the variability of statistics such as $\hat{p}$ is a central component in the study of statistics.

Here, $n=40$ and $p=0.35$, $\sigma_{\hat{p}} = \sqrt{\frac{0.35(1-0.35)}{40}}=0.075$.
We see in Figure~\ref{oPositive40prop} that the distribution of number of people in a sample with blood type O+ out of 40 is equivalent to the distribution of proportion of people in a sample of size 40 with blood type O+, but with a change of scale.
Instead of counts along the horizontal axis, we have proportions.  

\begin{figure}[ht]
\centering
\subfigure[]{
\includegraphics[width=0.475\textwidth]{ch_distributions/figures/oPositive40/oPositive40}
}
\subfigure[]{
\includegraphics[width=0.475\textwidth]{ch_distributions/figures/oPositive40/oPositive40prop}
}
\caption{Two distributions where $p=0.35$ and $n=40$:  the binomial distribution for the \emph{number} with blood type O+ and the sampling distribution for the \emph{proportion} with blood type O+. }
\label{oPositive40prop}
\end{figure}


%\begin{enumerate}
%\setlength{\itemsep}{0mm}
%\item The average spread of the distribution of all possible values of $\hat{p}$ 
%\item The average \emph{error} of the sample proportion $\hat{p}$, that~is, the average deviation between a particular sample $\hat{p}$ and the true population $p$. 
%\end{enumerate}

\begin{examplewrap}
\begin{nexample}{If the proportion of people in the county with blood type O+ is really 35\%, find and interpret the mean and standard deviation of the sample proportion for a random sample of size 400.}
The mean of the sample proportion is the population proportion: 0.35. That is, if we took many, many samples and calculated $\hat{p}$, these values would average out to $p = 0.35$.

The standard deviation of $\hat{p}$ is described by the standard deviation for the proportion:
\begin{align*}
\sigma_{\hat{p}}
	= \sqrt{\frac{p(1-p)}{n}}
	= \sqrt{\frac{0.35(0.65)}{400}}
	= 0.024
\end{align*}
The sample proportion will typically be about 0.024 or 2.4\% away from the true proportion of $p = 0.35$. We'll become more rigorous about quantifying how close $\hat{p}$ will tend to be to $p$ in Chapter~\ref{foundationsForInference}.
\end{nexample}
\end{examplewrap}

%%
\subsection{The Central Limit Theorem revisited}

In section ~\ref{distributionofxbar}, we saw the Central Limit Theorem, which states that for large enough $n$, the sample mean $\bar{x}$ is normally distributed.

A natural question is, what does this have to do with sample proportions? In~fact, a~lot! A sample proportion can be written down as a sample mean. For example, suppose we have 3 successes in 10 trials. If we label each of the 3 success as a 1 and each of the 7 failures as a 0, then the sample proportion is the same as the sample mean:
\begin{align*}
\hat{p}
	= \frac{1 + 0 + 0 + 1 + 1 + 0 + 0 + 0 + 0 + 0}{10}
	= \frac{3}{10}
	= 0.3
\end{align*}
That is, the distribution of the sample proportion is governed by the Central Limit Theorem, and the Central Limit Theorem is what ties together much of the statistical theory we will see.


\begin{onebox}{Three important facts about the distribution of a sample proportion \pmb{$\hat{\MakeLowercase{p}}$}}
Consider taking a simple  random sample from a large population.
\begin{enumerate}
\setlength{\itemsep}{0mm}
\item The mean of a sample proportion is $p$.
\item The SD of a sample proportion is $\sqrt{\frac{p(1-p)}{n}}$.
\item When $np \geq 10$ and $n(1-p) \geq 10$, the sample proportion closely follows a normal distribution. 
\end{enumerate}\end{onebox}

Using these facts, we can now answer the question posed at the beginning of this section.



%%
\subsection[Normal approximation for the distribution of $\hat{p}$]{Normal approximation for the distribution of \pmb{$\hat{p}$}}

\begin{examplewrap}
\begin{nexample}{Find the probability that less than 30\% of a random sample of 400 people will be blood type O+ if the population proportion is 35\%.}
In the previous section we verified that $np$ and $n(1-p)$ are at least 10. The mean of the sample proportion is 0.35 and the standard deviation for the sample proportion is given by $\sqrt{\frac{0.35(1-0.35)}{400}}=0.024$. We can find a Z-score and use our calculator to find the probability:
\begin{align*}
Z &= \frac{\hat{p} - \mu_{\hat{p}}}{\sigma_{\hat{p}}} = \frac{0.30 - 0.35}{0.024} = -2.1 \\
P(&Z < -2.1) = 0.0179
\end{align*}
We leave it to the reader to construct a figure for this example.
\label{smokers}
\end{nexample}
\end{examplewrap}


\begin{examplewrap}
\begin{nexample}{The probability 0.0179 is the same probability we calculated when we found the probability of getting fewer than 120 with blood type O+ out of 400! Why is this?}
Notice that $120/400=0.30$. Using the binomial distribution to find the probability of fewer than 120 with blood type O+ in the sample is equivalent to using the distribution of $\hat{p}$ to find the probability of a sample proportion less than 0.30.
\end{nexample}
\end{examplewrap}


\begin{exercisewrap}
\begin{nexercise}Given a population that is 50\% male, what is the probability that a sample of size 200 would have greater than 55\% males?  Remember to verify that conditions for normal approximation are met.\footnotemark
\end{nexercise}
\end{exercisewrap}
\footnotetext{First, verify the conditions: $np = 200(0.5) = 100 \ge 10$ and $n(1-p) = 200 (0.5) = 100 \ge 10$, so the normal approximation is reasonable. Next we find the mean and standard deviation of $\hat{p}$:
\begin{align*}
\mu_{\hat{p}} &= p = 0.50
	& \sigma_{\hat{p}} &= \sqrt{\frac{p(1-p)}{n}}
		= \sqrt{\frac{0.5(0.5)}{200}}
		= 0.0354
\end{align*}
Then we find a Z-score and find the upper tail of the normal distribution:
\begin{align*}
Z = \frac{\hat{p} - \mu_{\hat{p}}}{\sigma_{\hat{p}}} = \frac{0.55 - 0.5}{0.0354} = 1.412
\qquad \rightarrow \qquad
P(Z > 1.412) = 0.07
\end{align*}
The probability of getting a sample proportion of 55\% or greater is about 0.07.}

%%
\subsection*{Section summary}

\noindent The binomial distribution shows the distribution of the number of successes in $n$ trials.  Often, we are interested in the \textit{proportion} of successes rather than the \textit{number} of successes.
\begin{itemize}
\item To convert from "number of yeses" to "proportion of yeses" we simply divide the number by $n$.  The sampling distribution of the sample proportion $\hat{p}$ is identical to the binomial distribution with a change of scale, i.e. different mean and different SD, but same shape.

\item The same \term{success-failure condition} for the binomial distribution holds for a sample proportion $\hat{p}$.

\item Three important facts about the sampling distribution of the sample proportion $\hat{p}$:
\begin{itemize}\vspace{-1mm}
\item The mean of a sample proportion is denoted by $\mu_{\hat{p}}$, and it is equal to $p$.  (\textit{center})
\item The SD of a sample proportion is denoted by $\sigma_{\hat{p}}$, and it is equal to $\sqrt{\frac{p(1-p)}{n}}$.  (\textit{spread})
\item When $np\ge 10$ and $n(1-p)\ge 10$, the distribution of the sample proportion will be approximately normal.   (\textit{shape})
\end{itemize}

\item We use these properties when solving the following type of \term{normal approximation} problem involving a sample proportion.  
\emph{Find the probability of getting more / less than $x$\% yeses in a sample of size $n$}.
\begin{enumerate}\vspace{-1mm}
\setlength{\itemsep}{0mm}
\item Identify $n$ and $p$. Verify than $np\ge 10$ and $n(1-p)\ge 10$, which implies that normal approximation is reasonable. 
\item Calculate the Z-score.  Use $\mu_{\hat{p}} = p$ and $\sigma_{\hat{p}} = \sqrt{\frac{p(1-p)}{n}}$ to standardize the sample proportion.  
\item Find the appropriate area under the normal curve.  \end{enumerate}

\end{itemize}

%%%%%%%%%%Section exercises
{\input{ch_distributions/TeX/sampling_distribution_of_a_sample_proportion.tex}}



%______________________________________________
\reviewchapterheader{}

\noindent This chapter began by introducing the normal distribution.  A common thread that ran through this chapter is the use of the \term{normal approximation} in various contexts.  
The key steps are included for each of the normal approximation scenarios below.

\begin{enumerate}
\item Normal approximation for \textbf{data}:  
\\- Verify that population is approximately normal.
\\- Use the given mean $\mu$ and SD $\sigma$ to find the Z-score for the given $x$ value.
\item Normal approximation for a \termsub{sample mean/sum}{sample mean}\index{sample sum|textbf}:  
\\Verify that population is approximately normal or that $n\ge 30$.
\\Use $\mu_{\bar{x}}=\mu$ and $\sigma_{\bar{x}}=\frac{\sigma}{\sqrt{n}}$ to find the Z-score for the given/calculated sample mean.
\item Normal approximation for the \term{number of successes} (binomial):  
\\- Verify that $np\ge 10$ and $n(1-p)\ge 10$.
\\- Use $\mu_{\scriptscriptstyle{X}} = np$ and $\sigma_{\scriptscriptstyle{X}} = \sqrt{np(1-p)}$ to find the Z-score for the given number of successes.  
\item Normal approximation for a \term{sample proportion}:  
\\- Verify that $np\ge 10$ and $n(1-p)\ge 10$.
\\- Use $\mu_{\hat{p}} = p$ and $\sigma_{\hat{p}} = \sqrt{\frac{p(1-p)}{n}}$ to find the Z-score for the given sample proportion.
\item Normal approximation for the \term{sum of two independent random variables}:
\\- Verify that each random variable is approximately normal.
\\- Use $E(X+Y)=E(X)+E(Y)$ and $SD(X+Y)=\sqrt{(SD(X))^2+(SD(Y))^2}$ to find the Z-score for the given sum.
\end{enumerate}
Cases 1 and 2 apply to \term{numerical} variables, while cases 3 and 4 are for \term{categorical} yes/no variables.  Case 5 applies to both numerical and categorical variables.
\\
\\Note that in the binomial case and in the case of proportions, we never look to see if the \emph{population} is normal.  That would not make sense because the ``population" is simply a bunch of no/yes, 0/1 values and could not possibly be normal.
\\
\\The \term{Central Limit Theorem} is the mathematical rule that ensures that when the sample size is sufficiently large, the sample mean/sum and sample proportion/count will be approximately normal.  

