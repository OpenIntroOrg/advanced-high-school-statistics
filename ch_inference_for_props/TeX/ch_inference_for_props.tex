\begin{chapterpage}{Inference for categorical data:  proportions}
  \chaptertitle{Inference for categorical \titlebreak{} data:  proportions}

  \label{inferenceForCategoricalData}
  \label{ch_inference_for_props}
 \chaptersection[\large]{pointEstimates}
 \chaptersection[\large]{distributionphat}
  \chaptersection[\large]{singleProportionCI}
  \chaptersection[\large]{singleProportionTest}
\chaptersection[\large]{distributionofdifference}
  \chaptersection[\large]{differenceOfTwoProportionsCI}
 \chaptersection[\large]{differenceOfTwoProportionsTest}
  \chaptersection[\large]{oneWayChiSquare}
  \chaptersection[\large]{twoWayTablesAndChiSquare}
\end{chapterpage}
\renewcommand{\chapterfolder}{ch_inference_for_props}

\chapterintro{Statistical inference is primarily concerned with
  understanding and quantifying the uncertainty of estimates of parameters.
  While the equations and details change
  depending on the setting, the foundations for inference
  are the same throughout all of statistics.\\

  \noindent We start with a familiar topic:
  the idea of using a sample proportion to estimate a population proportion.
  Next, we create what's called a
  \emph{\hiddenterm{confidence interval}}, which is a range of plausible values for the true population value.
  Then, we introduce a \index{hypothesis test|textbf}%
  \emph{hypothesis testing framework},
  which allows us to use data to formally evaluate claims about the
  population, such as whether a survey provides strong
  evidence against a claim that a candidate has the support of a majority
  of the voting population.\\

\noindent After developing inference techniques for a population proportion, we apply
these same techniques to analyze the difference of two population proportions.  Lastly, we develop a hypothesis test for  categorical variables arranged in two-way tables; while we will use a different distribution in this
context, the core ideas of hypothesis testing remain the same.

}



%______________________________________________
\section[Point estimators]{Point estimators}
\label{pointEstimates}

\sectionintro{
\noindent%
Companies such as Gallup and Pew Research frequently conduct
polls as a way to understand the state of public opinion
or knowledge on many topics, including politics,
scientific understanding, brand recognition, and more.  What quantities can these polls use to estimate the opinion or knowledge of the
broader population?  What does it mean for their estimate to be biased, and how can they attempt to minimize such bias?


\subsection*{Learning objectives}
\begin{enumerate}

\item Describe the purpose and use of a point estimator.

\item Justify why an estimator is or is not unbiased.

\item Calculate estimates for a population parameter.

\item Recognize that point estimators have variability.

\end{enumerate}
}

%%%
\subsection{Introducing point estimators}
\index{point estimate|(}



Suppose we want to estimate the approval rating of the governor of a particular state among adult residents of that state.  We generally estimate unknown quantities such as this by collecting a sample.  Let's say that in a sample of 500 adult residents of that state,  225 of the sampled individuals report that they approve of the governor.  We calculate the sample proportion as $\frac{225}{500} = 0.45$ and  we consider 45\% to be a
point estimate of the approval rating we might see if we collected responses from adults in the
entire state.  

This entire-population response proportion is
generally referred to as the \term{parameter}
of interest,
and when the parameter is a proportion,
we denote it with the letter $p$.   An estimate calculated from a sample is called a sample \term{statistic}.  The sample proportion, denoted $\hat{p}$, is an example of a statistic.  Unless we collect responses from every individual in the population, the parameter remains unknown, and we use the sample statistic as our \term{point estimator}, or just \textbf{estimator}, for the parameter.  For example, the sample proportion $\hat{p}$ is a point estimator for the population proportion $p$.  

The strategy of using a sample statistic to estimate
a parameter is quite common, and it's a strategy that
we can apply to other statistics besides a proportion.
For instance, if we want to estimate the average
difference in product prices for two websites,
we might take a random sample of products available
on both sites, check the prices on each,
and then compute the average of the differences in price;
this strategy certainly wouldn't give us a perfect
measurement of the average difference in price for all the products, but it would
give us a point estimate.

\begin{examplewrap}
\begin{nexample}{
Consider the summary statistics for the number of characters in 50 randomly selected emails.  These values are summarized below.
\begin{center}
\begin{tabular}{l r }
$\bar{x}$ & 11,160 \\
median & 6,890 \\
$s_x$ & 13,130
\end{tabular}
\end{center}
What quantity should we use as a point estimator for the \term{population mean} $\mu$.  What is the point estimate for the population mean based on this sample?}We use the sample mean $\bar{x}$ as our point estimator for the population mean $\mu$.  Based on this sample, the point estimate for $\mu$ is $\bar{x} = $11,160.
\end{nexample}
\end{examplewrap}

\begin{exercisewrap}
\begin{nexercise}Using the email data, what quantity should we use as a point estimator for the population standard deviation $\sigma$?  What is the point estimate for $\sigma$ based on this sample?\footnotemark
\end{nexercise}
\end{exercisewrap}
\footnotetext{Intuitively we would use the sample standard deviation $s$ as a point estimator for $\sigma$.  Based on this sample, the point estimate for $\sigma$ is $s = $13,130.}\vspace{-4mm}





\subsection{Biased and unbiased estimators}
When estimating a parameter such as the approval rating of a governor, we aim to use an \emph{unbiased} estimator. \termsub{Bias}{bias} describes a systematic tendency
to overestimate or underestimate the true population parameter.
 For instance, if we took a political poll but our sample
  didn't include a roughly representative distribution of
  the political parties, the sample would likely skew
  in a particular direction and be biased.  Taking a truly random sample from the entire population of interest avoids sampling bias.  However, as we saw in Chapter~\ref{ch_collecting_data}, even with a random sample, nonresponse bias and various types of response bias can still be present.  


\begin{examplewrap}
\begin{nexample}{
Consider a student poll designed to estimate support for a new college stadium.  Say that a random sample of students is taken and asked the question: \emph{Do you support your school by supporting funding
  for the new stadium?} Do expect to get a biased or an unbiased estimate?  If biased, do you expect to overestimate or underestimate the true proportion of students that support a new college stadium? }
Because the wording of the questions is leading, we would expect a biased estimate.   In this case our estimate would likely \emph{overestimate} the true parameter, as the wording of the question invites a positive response.
\end{nexample}
\end{examplewrap}

When estimating a population parameter, an estimator is \term{unbiased} if, on
average, the value of the estimator does not underestimate or overestimate the
population parameter.  When an estimator is unbiased, the distribution of values of the estimator for all random samples of a given size, known as the sampling distribution, will be \emph{centered} on the true value.  


\begin{examplewrap}
\begin{nexample}
{Figure~\ref{fourSamplingDistributions} shows the sampling distributions associated with four different estimators of a parameter, whose value is indicated.  Which of the estimators is biased?  Which of the estimators is unbiased?  Also, order the estimators from lowest variability to highest variability).}
The estimators in (a) and (c) are biased, because those sampling distributions are not centered on the parameter (true value).  The estimators in (b) and (d) are centered on the parameter, so those estimators are unbiased.  From lowest to greatest variability, we have (a), (b), (c), (d).
\end{nexample}
\end{examplewrap}

\begin{figure}[h]
   \centering
\oiRedirect{desmos-biasvariability}{
\Figure[The sampling distributions associated with four different estimators are shown in different colors and labeled a, b, c, and d.  The estimators in (a) and (c) are biased, because those sampling distributions are not centered on the parameter (true value).  The estimators in (b) and (d) are centered on the parameter, so those estimators are unbiased.  From lowest to greatest variability, we have (a), (b), (c), (d).]
{0.55}{fourSamplingDistributions}}
   \caption{The sampling distribution of four different estimators of a parameter.  This is a screenshot from the interactive Desmos Activity: Bias and Variability in Sampling Distributions.  Find it at \oiRedirect{openintro-ahss-desmos}{\small{openintro.org/ahss/desmos}}.}
   \label{fourSamplingDistributions}
\end{figure}


%%
%\subsection{The variability of a point estimator (special topic)}
%
%
%\renewcommand{\pewsolarpollsize}{1000}
%\renewcommand{\pewsolarparprop}{0.88}
%\renewcommand{\pewsolarparpropcomplement}{0.12}
%\renewcommand{\pewsolarparpercent}{88\%}
%\renewcommand{\pewsolarparpercentcomplement}{12\%}
%\renewcommand{\pewsolarpollprop}{0.887}
%\renewcommand{\pewsolarpollpropcomplement}{0.113}
%\renewcommand{\pewsolarpollpercent}{88.7\%}
%\renewcommand{\pewsolarpollpercentcomplement}{11.3\%}
%\renewcommand{\pewsolarpollcount}{887}
%\renewcommand{\pewsolarpollexpcount}{880}
%\renewcommand{\pewsolarpollcountcomplement}{113}
%\renewcommand{\pewsolarpollexpcountcomplement}{120}
%\renewcommand{\pewsolarpollse}{0.010}
%
%A poll suggested that a governor's approval rating is 45\%.  However, a different sample would include different people and would likely yield a different estimate.  So how good of an estimate do we think 45\% is of the governor's approval rating among all US adults in the state?  We first want to know how the poll was taken.  If adults were randomly selected can we estimate the \term{sampling error}, which is the uncertainty in a point estimate that happens naturally from one sample to the next and is usually reported along with a point estimate.  Much of statistics, including much of this book, is focused on understanding and quantifying sampling error. 
%
%To visualize the sampling error, we should imagine the \term{sampling distribution}, that is, the distribution of sample proportions for all random samples of this size from this population.  The standard deviation of this distribution gives us the sampling error.  In the next section we will see how to calculate this standard deviation.  For now, let us ask what key piece of information we would need to be able to calculate this.  How good a sample estimate is seems to depend on the sample size $n$.  If we sample 10 people, there is a lot of variability in what we might get for the sample proportion and that sample proportion could, by chance, be far from the true proportion.  
%
%
%\begin{examplewrap}
%\begin{nexample}{If we used a much larger sample size of, say, $n = 100$,
%would you guess that the standard deviation for the sample proportion would be larger
%or smaller than if we used $n = 10$?}
%\label{smallerSampleWhatHappensToPropErrorExercise}
%Intuitively, it seems like more data is better
%than less data, and generally that is correct!  The standard deviation using $n=100$ would be smaller, meaning that the sampling distribution would be narrower and the possible sample proportions would vary less.  However, the standard deviation with $n=100$ would not be 10x smaller than with $n=10$ as we will see in the next section.
%\end{nexample}
%\end{examplewrap}
%
%\noindent
%Example~\ref{smallerSampleWhatHappensToPropErrorExercise}
%highlights an important property we will see again and again:
%a bigger sample tends to provide a more precise point estimate
%than a smaller sample.
%Remember though, that this is only true for \emph{random} samples.
%Additionally, a~bigger sample cannot correct for response bias or other types of bias that may be present.
%
%
%%
%\subsection{Basic properties of point estimators (special topic)}
%
%We achieved three goals in this section. First, we determined that we can use sample statistics as estimators of population parameters. Next, we considered what it means for an estimator to be biased.  Then, we observed that estimators vary from one sample to another and that we can use the standard deviation as a measure of variability.
%
%
%When our sampling method produces estimates in an unbiased way, the sampling distribution will be \emph{centered} on the true value and we call the method \term{accurate}.  When the sampling method  produces estimates that have \emph{low variability}, the sampling distribution will have a low standard deviation, and we call the method \term{precise}.
%
%
%\begin{examplewrap}
%\begin{nexample}
%{Using Figure~\ref{fourSamplingDistributions}, which of the distributions were produced by methods that are biased?  That are accurate?  Order the distributions from most precise to least precise (that is, from lowest variability to highest variability).}
%The methods that produced distributions (a) and (c) are biased, because those distributions are not centered on the parameter.  Distributions (b) and (d) are centered on the parameter (the true value), so those methods are accurate.  From most precise to least precise, we have (a), (b), (c), (d).
%\end{nexample}
%\end{examplewrap}
%
%\begin{figure}[h]
%   \centering
%\oiRedirect{desmos-biasvariability}{
%\Figure[Four sampling distributions are shown in different colors and labeled a, b, c, and d.  Distributions b and d are accurate, centered on the labeled parameter.  Distribution b is narrower than distribution d, making it more precise.  Distributions a and c are biased and are not centered on the labeled parameter.  Distribution a is narrower than distribution c, making it more precise.]
%{0.5}{fourSamplingDistributions}}
%   \caption{A screenshot from an interactive Desmos Activity (find it  at \oiRedirect{openintro-ahss-desmos}{\small{openintro.org/ahss/desmos}}) comparing four sampling distributions, given the identified parameter. }
%   \label{fourSamplingDistributions}
%\end{figure}
%
%\begin{examplewrap}
%\begin{nexample}
%{Why do we want a point estimator to be both precise and accurate?} If the point estimator is precise, but highly biased, then we will consistently get a bad estimate.  On the other hand, if the point estimator is unbiased but not at all precise, then by random chance, we may get an estimate far from the true value.  
%
%Remember, when taking a sample, we generally get only one chance.  It is the properties of the sampling distribution that tell us how much confidence we can have in the estimate. \end{nexample}
%\end{examplewrap}
%
%The strategy of using a sample statistic to estimate
%a parameter is quite common, and it's a strategy that
%we can apply to other statistics besides a proportion.
%For instance, if we want to estimate the average salary
%for graduates from a particular college, we could
%survey a random sample of recent graduates;
%in that example, we'd be using a sample mean $\bar{x}$
%to estimate the population mean~$\mu$ for all graduates.
%As another example, if we want to estimate the average
%difference in product prices for two websites,
%we might take a random sample of products available
%on both sites, check the prices on each,
%and then compute the average of the differences in price;
%this strategy certainly wouldn't give us a perfect
%measurement of the average difference in price for all the products, but it would
%give us a point estimate.
%
%We start with inference techniques for a single proportion, then we apply these methods in various other contexts.  The principles and general ideas are the same, even if the details change a little.
%


\D{\newpage}

%%
\subsection*{Section summary}
\begin{itemize}
\item In this section we laid the groundwork for our study of \termni{inference}.  Inference involves using sample statistics as point estimators to estimate or justify claims about unknown population parameters.

\item A sample statistic is a point estimator of the corresponding population
parameter and can be thought of as an estimate of the population parameter.
For example, the sample mean $\bar{x}$ is a point estimator for an unknown population mean $\mu$, and the sample proportion $\hat{p}$ is a point estimator for an unknown population proportion $p$.

\item It is helpful to imagine point estimates as being drawn from the sampling distribution of the statistic or point estimator.  

\item A \termni{point estimator}, or just estimator, is \term{unbiased} if, on average, the values of the estimator do not underestimate or overestimate the population parameter.  For an unbiased estimator, the sampling distribution of the estimator (i.e., the distribution of values of the estimator for all random samples of the same size from the same population) is \textit{centered} on the population parameter.  


\end{itemize}


%%%%%%Section exercises
{\input{ch_inference_for_props/TeX/point_estimators.tex}}



%______________________________________________
\section[Sampling distribution of a sample proportion]{Sampling distribution of a sample proportion}
\label{distributionphat}

\sectionintro{
\noindent%
Given a fair coin, what is the probability that in 200 tosses you would get greater than 52\% tails just by random variation?  In a particular state, 48\% support a controversial measure.  When estimating the percent through polling, what is the probability that a random sample of size 200 will mistakenly estimate the percent support to be greater than 50\%?  In general, how far do we expect our sample proportion to be from the population proportion?  In this section, we consider the sampling distribution of the sample proportion in order to answer questions such as these.



%%
\subsection*{Learning objectives}
\begin{enumerate}
\setlength{\itemsep}{0mm}
\item Interpret and apply the concept of a sampling distribution in the context of a sample proportion.

\item Calculate the mean and standard deviation of a sampling distribution of a sample proportion.

\item Justify whether conditions for independence are met when sampling from a population.  

\item Determine whether or not the shape of the sampling distribution of a sample proportion is approximately normal.

\item Interpret the mean, standard
deviation, and probabilities for
a sampling distribution of a
sample proportion.


\end{enumerate}
}


%%
\subsection{Visualizing a sampling distribution of a sample proportion}

In a large population, the proportion of people with blood type O+ is 0.35.  If we take a random sample of size 40 from this population, how far off do we expect our sample proportion to be from the true proportion?  To answer this question we wish to understand and visualize the sampling distribution of the proportion of people with blood type O+ in a random sample of size 40.  Recall that the \term{sampling distribution} of a sample statistic is the distribution of values of the statistic for all random samples of a given size from a given population.   


\begin{onebox}{The sampling distribution of a sample proportion}
The sampling distribution of a sample proportion $\hat{p}$ is the distribution of $\hat{p}$ values for all random samples of a given size from a given population.
\end{onebox}

In Section~\ref{binomDist}, we saw that the distribution for the \emph{number} of people with blood type O+ in a random sample of size 40 follows a binomial distribution with $n=40$ and $p=0.35$.  What do we expect the sampling distribution for the \emph{proportion} of people with blood type O+ in a random sample of size 40 to look like? 

\newpage
In this scenario, we can actually calculate the probability of each of the possible sample proportions and draw the exact sampling distribution.  The right panel of Figure~\ref{oPositive40} shows the distribution for the \emph{proportion} of people with blood type O+ in a random sample of size 40, given a population proportion $p=0.35$, and the left panel of Figure~\ref{oPositive40} shows the distribution for the \emph{number} of people with blood type O+ in a random sample of size 40, given a population proportion $p=0.35$.

We can see that the distribution for number with blood type O+ and the distribution for proportion with blood type O+ look the same, but with a change of scale.  Instead of showing counts along the horizontal axis, the graph of the sampling distribution of the sample proportion shows proportions.  To convert from a count to a proportion, we divide the count (number of~successes) by the sample size, $n = 40$. For example, 8 becomes $8/40 = 0.20$ and 14 becomes $14/40 = 0.35$.   

\begin{figure}[ht]
\centering
\Figure [A histogram is shown for ``Number With Blood Type O+ in a Random Sample of Size 40".  The distribution is centered on 14 with a standard deviation of 3 and is approximately normal.  The vertical axis is Probability, which ranges from 0 to about 0.15. ] {0.475}{oPositive40}
\quad
\Figures [A histogram is shown for ``Proportion With Blood Type O+ in a Random Sample of Size 40".  This distribution looks identical to the previous distribution, except instead of graphing Number, it is graphing the corresponding Proportion.  This distribution is centered on 0.35 (which equals 14 divided by 40) with a standard deviation of 0.075 (which equals 3 divided by 40).  The distribution has the same vertical axis and the same shape as the previous distribution.] {0.475}{oPositive40}{oPositive40prop}

\caption{Two distributions where $p=0.35$ and $n=40$:  the binomial distribution for the \emph{number} with blood type O+ and the sampling distribution of the \emph{proportion} with blood type O+. }
\label{oPositive40}
\end{figure}

To better understand what a sampling distribution of $\hat{p}$ represents, we can also conduct a simulation just as we did in Section~\ref{cltpropsimulation}. Here we will simulate drawing a sample of size 40 from a population where $p$ = 0.35.  We calculate the number of successes in the sample and the proportion of successes in the sample.  We repeat this 300 times.  The results are graphed in Figure~\ref{oPositive40simulation}.

\begin{figure}[ht]
\centering
\Figures[300 simulation values for the sample number.] {.35}{oPositive40}{oPositive40sim}
\qquad \qquad \qquad \quad
\Figures[300 simulated values for sample proportion.] {.35}{oPositive40}{oPositive40simprop}

\caption{300 simulated values for the number of successes (left) and the proportion of successes (right) in a random sample of size 40 from a population with $p$=0.35.}
\label{oPositive40simulation}
\end{figure}

\begin{examplewrap}
\begin{nexample}
{What does the graph in the right panel of Figure~\ref{oPositive40simulation} represent?  What does each dot represent?}
The graph represents an approximation of the sampling distribution of $\hat{p}$.  While the theoretical sampling distribution of $\hat{p}$ is the distribution of $\hat{p}$ values for \emph{all} random samples of size 40 from this population, this simulated distribution represents the distribution of $\hat{p}$ values for 300 random samples of size 40 from this population.  Each dot represents the value of a sample proportion $\hat{p}$ calculated from \emph{one} random sample of size 40.
\end{nexample}
\end{examplewrap}

\begin{exercisewrap}
\begin{nexercise}
Why do the graphs in Figure~\ref{oPositive40simulation} look different than the graphs in Figure~\ref{oPositive40}?\footnotemark
\end{nexercise}
\end{exercisewrap}
\footnotetext{The graphs in Figure~\ref{oPositive40simulation} include only 300 simulated values, whereas the graphs in Figure~\ref{oPositive40} show the theoretical sampling distributions.  If we used a much larger number of trials in our simulation, we would expect the simulation graphs to look more like the theoretical sampling distributions.}

\newpage

\subsection[The mean and standard deviation of $\hat{p}$]{The mean and standard deviation of \pmb{$\hat{p}$}}
\label{meansdphat}

Looking at Figure~\ref{oPositive40}, we see that the sampling distribution for the proportion of people with blood type O+ in a random sample of size 40 is centered on 0.35 (the population proportion) and has a standard deviation of approximately 0.075.  

If we were to look at more sampling distributions for proportions, we'd eventually find that there are some patterns that depend on $n$ and $p$, and these patterns can be characterized mathematically.  As one might expect, the distribution of $\hat{p}$ is centered on the true proportion $p$, assuming the sample is random and the estimator is unbiased.  When the observations are independent, the standard deviation of $\hat{p}$ is given by: $\sigma_{\hat{p}} = \sqrt{\frac{p(1-p)}{n}}$.

\begin{onebox}{Mean and standard deviation of a sample proportion}
The mean and standard deviation of the sampling distribution of a sample proportion describe the center and spread of the distribution of sample proportions $\hat{p}$ for all random samples of size $n$ from a population with size $N$.  Let $p$ represent the population proportion.  We find the mean and standard deviation of the sampling distribution of $\hat{p}$ as follows:  
\begin{align*}
\mu_{\hat{p}} &= p \\
 \sigma_{\hat{p}} &= \sqrt{\frac{p(1-p)}{n}} \quad \text{ when } n<0.10(N) \text{ if sampling without replacement}
 	\vspace{1mm}
\end{align*}
\end{onebox}

When sampling without replacement, independence of observations is technically not met, and the standard deviation formula will overestimate the true standard deviation.  However, as we saw in Examples~\ref{comparewithvswithoutrepl} and \ref{binex}, if the sample size is small compared to the population size, then the observations can be treated \emph{as if} they were independent.  In this case, the standard deviation formula will provide a good estimate.  A rule of thumb is that if the sample size is less than 10\% of the population size, or equivalently, the population size is at least 10 times larger than the sample size, then the standard deviation formula will provide a good estimate and can be safely used.

The standard deviation of a sample proportion, $\sigma_{\hat{p}}$, tells us about the ``typical'' deviation in the sample proportions from the true population proportion.  In analyses, we think of the standard deviation of a sample proportion as describing the uncertainty associated with the estimate $\hat{p}$. That is, $\sigma_{\hat{p}}$ can be thought of as a way to quantify the typical \hiddenterm{error} in our sample estimate $\hat{p}$ of the true proportion $p$. Understanding the variability of statistics such as $\hat{p}$ is a central component in the study of statistics.

 %\begin{enumerate}
%\setlength{\itemsep}{0mm}
%\item The average spread of the distribution of all possible values of $\hat{p}$ 
%\item The average \emph{error} of the sample proportion $\hat{p}$, that~is, the average deviation between a particular sample $\hat{p}$ and the true population $p$. 
%\end{enumerate}

\D{\newpage}

\begin{examplewrap}
\begin{nexample}{If the proportion of people in the county with blood type O+ is really 35\%, find and interpret the mean and standard deviation of the sample proportion for a random sample of size 400.}

The mean of the sample proportion $\mu_{\hat{p}}$ is calculated as follows:
\begin{align*}
\mu_{\hat{p}} = p = 0.35.
\end{align*}
For all random samples of size 400 from this population, the sample proportions with blood type O+ will have a mean of 0.35.  In other words, if we took many, many random samples of size 400 from this population and calculated $\hat{p}$ for each sample, the average of all the $\hat{p}$ values would be about $0.35$.  

We will assume that the sample size of 400 is less than 10\% of the population size, i.e. that the number of people in the county is at least 4000. The standard deviation of $\hat{p}$ is calculated as follows:
\begin{align*}
\sigma_{\hat{p}}
	= \sqrt{\frac{p(1-p)}{n}}
	= \sqrt{\frac{0.35(0.65)}{400}}
	= 0.024.
\end{align*}
For all random samples of size 400 from this population, the sample proportions with blood type O+ would typically vary from the population proportion of 0.35 by about 0.024. 
\end{nexample}
\end{examplewrap}

\begin{examplewrap}
\begin{nexample}
{Would you be surprised in you took a random sample of size 400 from this population and 37\% of the sample had blood type O+?  That is, would you be surprised to get a $\hat{p}$ value of 0.37?}
The value 0.37 is less than one standard deviation from the mean, so it would not be surprising to have 37\% with blood type O+ in a random sample of size 400 from this population.
\end{nexample}
\end{examplewrap}

\begin{exercisewrap}
\begin{nexercise}
Would you be surprised in you took a random sample of size 400 from this population and 27\% of the sample had blood type O+?  That is, would you be surprised to get a $\hat{p}$ value of 0.27?\footnotemark
\end{nexercise}
\end{exercisewrap}
\footnotetext{0.27 is more than three standard deviations below the mean, so it would be surprising to have only 27\% with blood type O+ in a random sample of size 400 from this population.}

\begin{exercisewrap}
\begin{nexercise}
If instead of taking a random sample of size 400 from this population, you took a random sample of size 100, how would the mean and standard deviation of the sample proportion change?\footnotemark
\end{nexercise}
\end{exercisewrap}
\footnotetext{The mean is just $p$ so the mean would not change.  The standard deviation would be larger because the sample size is smaller.  The standard deviation gets smaller by a factor of $1/\sqrt{n}$, so the standard deviation would be twice as large (not four times as large).}

\D{\newpage}

\subsection{The Central Limit Theorem revisited}

The sampling distribution for the sample proportion in
Figure~\ref{oPositive40} looks an awful lot like
a normal distribution. This is not surprising and is a result of the Central Limit Theorem, which was introduced in Section~\ref{CLTintro}.

\begin{onebox}{Central Limit Theorem for sample proportions}
  When observations are independent and the sample size is
  sufficiently large, the sample proportion $\hat{p}$ will tend
  to follow a normal distribution.\\

  In order for the Central Limit Theorem to hold,
  the sample size is typically considered sufficiently large
  when $np \geq 10$ and $n(1-p) \geq 10$, where $n$ is the sample size and $p$ is the population proportion.  This is called the
  \term{large counts condition}, or the success-failure condition.
\end{onebox}


The Central Limit Theorem is incredibly important, and it provides
a foundation for much of statistics.
As we begin applying
the Central Limit Theorem in the context of a sample proportion, be mindful of the two
technical conditions:
the observations must be independent, and the sample size must
be sufficiently large such that the expected number of successes, $np$, and the expected number of failures, $n(1-p)$, are both at least 10.    

\begin{onebox}{How to verify sample observations are independent}
  If the observations are from a random process such as tossing a coin, then they are independent.\stdvspace{}

  If the observations are from a random sample with replacement,
  then they are independent.\stdvspace{}

  If the observations are from a simple random sample (without replacement), we can treat them as independent if the sample size is less than 10\% of the population size.\stdvspace{}

  If a sample is from a seemingly random process,
  e.g. an occasional error on an assembly line,
  checking independence is more difficult. In~this case,
  use your best judgement.
\end{onebox}

When the sample exceeds 10\% of the population size,
the methods we discuss tend to overestimate the sampling error
slightly versus what we would get using more advanced
methods.\footnote{For example, we could use what's called the
  \term{finite population correction factor}:
  if the sample is of size $n$ and the population size is $N$,
  then we can multiply the typical standard deviation formula by
  $\sqrt{\frac{N-n}{N-1}}$
  to obtain a smaller, more precise estimate of the
  actual standard deviation.
  When $n < 0.1 \times N$, this correction factor is relatively close to 1.}


An interesting question to answer is, \emph{what happens when
$np < 10$ or $n(1-p) < 10$}? We can simulate drawing samples of different sizes where,
say, the true proportion is $p = 0.25$.
Here's a sample of size~10:
\begin{center}
% paste(sample(c("yes", "no"), 10, TRUE, c(.25, .75)), collapse = ", ")
no, no, yes, yes, no, no, no, no, no, no
\end{center}
In this sample, we observe a sample proportion of yeses
of $\hat{p} = \frac{2}{10} = 0.2$. We can simulate many such
proportions to understand the sampling distribution of
$\hat{p}$ when $n = 10$ and $p = 0.25$, which we've plotted
in Figure~\ref{sampling_10_prop_25p}
alongside a normal distribution with the
same mean and variability.
These distributions have a number of important differences.

\begin{figure}[h]
   \centering
   \Figure[There are two plots. The first plot is a histogram of 10,000 simulations of p-hat when the sample size is n equals 10 and the population proportion is p equals 0.25. The possible values are 0.0, 0.1, 0.2, and so on up to 1.0, though the graph only shows values up to 0.8. The distribution is centered at about 0.25, and is slightly right skewed. The frequencies are about 500 for 0.0, 1900 for 0.1, 2800 for 0.2, 2400 for 0.3, 1500 for 0.4, 500 for 0.5, 100 for 0.6, and the bin heights for the remaining values have bin heights that are not visually distinguishable from zero. The second plot shows a normal distribution centered at 0.25 with a standard deviation of 0.137. The plot has a vertical line located at 0.0, which makes it more visually evident that a portion of the area under the normal distribution -- about 5\% of this area -- represents values below 0.0.] {0.97}{sampling_10_prop_25p}
   \caption{Left: simulations of $\hat{p}$ when the sample size
       is $n = 10$ and the population proportion is $p = 0.25$.
       Right: a normal distribution with the same mean (0.25)
       and standard deviation (0.137).}
   \label{sampling_10_prop_25p}
\end{figure}

\begin{figure}
   \centering
  \Figures[Sampling distributions are shown for several scenarios for parameters p and n. The graphs are arranged in a grid of 5 rows representing proportions 0.1, 0.2, 0.5, 0.8, and 0.9 and 2 columns of sample sizes n equals 10 and 25. In each graph, the distribution is centered at the proportion. Given that these are proportions based on relatively small sample sizes, the bins do look relatively discrete (jumpy from one to the next), though less so for the distributions based on n equals 25. In cases where the true underlying proportion is near the lower bound of 0 or the upper bound of 1, the distribution tends to skew away from that boundary. This is most noticeable for both the distributions representing proportions closer to either boundary and for the smaller sample size. One distribution stands out among the 10 shown: the sample with p equals 0.5 and n equals 25, which shows a bell-shaped distribution resembling the normal distribution, though the data are still somewhat discrete.] {}{clt_prop_grid}{clt_prop_grid_1}
   \caption{Sampling distributions for several scenarios
       of $p$ and $n$. \\
       Rows: $p = 0.10$, $p = 0.20$, $p = 0.50$,
       $p = 0.80$, and $p = 0.90$. \\
       Columns: $n = 10$ and $n = 25$.}
   \label{clt_prop_grid_1}
\end{figure}

\begin{figure}
   \centering
  \Figures[Sampling distributions are shown for several scenarios for parameters p and n. The graphs are arranged in a grid of 5 rows representing proportions 0.1, 0.2, 0.5, 0.8, and 0.9 and 3 columns of sample sizes n equals 50, 100, and 250. Relative to the previous figure, which considered similar proportion scenarios but with n equals 10 and 25, the data in these graphs looks less discrete -- that is, they appear to almost be continuous. This is most evident for the largest sample sizes. Nearly all of the graphs shown also closely resemble the normal distribution, in some cases with the larger sample sizes that it resembles it so closely that there are not substantial visual differences. One aspect less evident -- but still present -- in the last figure but that continues into and becomes much more obvious in this figure, is that the distributions of the sample proportions tend to have a much smaller standard deviation with the larger sample sizes. That is, the sample proportion distributions for larger sample sizes tend to be smaller than they were for smaller sample sizes. Also, the variability within a graph also appears to be largest for the proportion p equals 0.5 than it is for the other proportions when considering a single proportion -- and this property is apparent upon inspection of a distribution based on any of the considered sample sizes.] {}{clt_prop_grid}{clt_prop_grid_2}
   \caption{Sampling distributions for several scenarios
       of $p$ and $n$. \\
       Rows: $p = 0.10$, $p = 0.20$, $p = 0.50$,
       $p = 0.80$, and $p = 0.90$. \\
       Columns: $n = 50$, $n = 100$, and $n = 250$.}
   \label{clt_prop_grid_2}
\end{figure}

\begin{center}
\begin{tabular}{lccc}
\hline
    &  Unimodal?  &  Smooth?  &  Symmetric? \\
\hline
Normal: $N(0.25, 0.14)$  &
    \highlightO{Yes}  &
    \highlightO{Yes}  &
    \highlightO{Yes} \\
$n = 10$, $p = 0.25$  &
    \highlightO{Yes}  &
    \highlightT{No}  &
    \highlightT{No} \\
\hline
\end{tabular}
\end{center}
Notice that the large counts condition
was not satisfied when $n = 10$ and $p = 0.25$:
\begin{align*}
n p = 10 \times 0.25 = 2.5 &&
    n (1 - p) = 10 \times 0.75 = 7.5
\end{align*}
This single sampling distribution does not show that
the large counts condition is the perfect guideline,
but we have found that the guideline did correctly
identify that a normal distribution might not be appropriate.

\D{\newpage}

We can complete several additional simulations,
shown in
Figures~\ref{clt_prop_grid_1}
and~\ref{clt_prop_grid_2},
and we can see some trends:
\begin{enumerate}
\item When either $np$ or $n(1 - p)$ is small, the
    distribution is more \term{discrete},
    i.e. \emph{not continuous}.
\item When $np$ or $n(1-p)$ is smaller than~10,
    the skew in the distribution is more noteworthy.
\item The larger both $np$ \emph{and} $n(1 - p)$,
    the more normal the distribution.
    This may be a little harder to see for the larger
    sample size in these plots as the variability
    also becomes much smaller.
\item When $np$ and $n(1 - p)$ are both very large,
    the distribution's discreteness is hardly evident,
    and the distribution looks much more
    like a normal distribution.
\end{enumerate}


\noindent So far we've only focused on the skew and discreteness
of the distributions.
We haven't considered how the mean and standard deviation
of the distributions change.
Take a moment to look back at the graphs,
and pay attention to three things:
\begin{enumerate}
\item The centers of the distribution are always at
    the population proportion, $p$, that was used to
    generate the simulation. Because the sampling
    distribution for $\hat{p}$ is always centered at
    the population parameter $p$, it means the sample
    proportion $\hat{p}$ is \term{unbiased} when
    the data are independent and drawn from such
    a population.
\item For a particular population proportion $p$,
    the variability in the sampling distribution
    decreases as the sample size~$n$ becomes larger.
    This will likely align with your intuition:
    an estimate based on a larger sample size will
    tend to be more accurate.
\item For a particular sample size, the variability
    will be largest when $p = 0.5$. The differences
    may be a little subtle, so take a close look.
    This reflects the role of the proportion
    $p$ in the standard deviation formula:
    $SD = \sqrt{\frac{p (1 - p)}{n}}$.
    The standard deviation is largest when $p = 0.5$.
\end{enumerate}

At no point will the distribution of $\hat{p}$ look
\emph{perfectly} normal, since $\hat{p}$ will always
be take discrete values ($x / n$).
It is always a matter of degree, and we will use
the standard large counts condition with minimums
of 10 for $np$ and $n (1 - p)$ as our guideline
within this~book.
%
%\begin{onebox}{Three important facts about the distribution of a sample proportion \pmb{$\hat{\MakeLowercase{p}}$}}
%When the observations can be considered independent, such as from a random sample of less than 10\% of the population, the distribution of the sample proportion can be described as follows.\begin{enumerate}
%\setlength{\itemsep}{0mm}
%\item CENTER:  The mean of a sample proportion is $p$.
%\item SPREAD:  The SD of a sample proportion is $\sqrt{\frac{p(1-p)}{n}}$.
%\item SHAPE:  When $np \geq 10$ and $n(1-p) \geq 10$, the sample proportion closely follows a normal distribution. 
%\end{enumerate}\end{onebox}

\newpage



%%
\subsection[Using a normal model for the sampling distribution of $\hat{p}$]
           {Using a normal model for the sampling distribution of $\pmb{\hat{p}}$}

We can now answer a question posed at the beginning of this section.

\begin{examplewrap}
\begin{nexample}{Assume that in a particular state, 48\% support a controversial measure.  When estimating the percent through polling, what is the probability that a random sample of size 200 will mistakenly estimate the percent support to be at least 50\%?}
$\hat{p}$ is the proportion in a random sample of size 200 that support the controversial measure, and the mean of $\hat{p}$ is: $\mu_{\hat{p}} = p = 0.48$.

Because 200 $<$ 10\% of all people in the state, we can calculate the standard deviation of $\hat{p}$ as follows:
\begin{center}
$\sigma_{\hat{p}} = \sqrt{\frac{p(1-p)}{n}} = \sqrt{\frac{0.48(1-0.48)}{200}}= 0.035$.
\end{center}
Because $200(0.48) \ge 10$ and $200(0.52) \ge 10$,  $\hat{p}$ is approximately Normal.  Using a technology option from Section~\ref{technormal} and the fact that $\hat{p}$ is approximately Normal($\mu = 0.48$, $\sigma = 0.035$), we find that $P(\hat{p} \ge 0.50) = 0.286$.\\
\begin{center}
\Figure[A normal distribution with mean 0.48 and standard deviation 0.353 is shaded from 0.50 to the right which makes the area equal 0.286.]
{.4}{opinionAbove50} 
\end{center}
There is a 28.6\% chance that a random sample of size 200 will mistakenly estimate the percent support for the controversial measure to be at least 50\%, assuming the true proportion who support it is 48\%.
\label{opinionabove50}
\end{nexample}
\end{examplewrap}



It is common to calculate a Z-score and use the standard normal distribution ($\mu=0$, $\sigma=1$) to solve problems similar to the one above. In Section~\ref{singleProportionTest}, we will see a direct parallel between the calculation of the Z-score and the calculation of a Z~test~statistic.  To use the Z-score method, we do the following:  
\begin{center}
$Z = \frac{\hat{p} - \mu_{\hat{p}}}{\sigma_{\hat{p}}} = \frac{\hat{p} - p}{\sqrt{\frac{p(1-p)}{n}}} =  \frac{0.50 - 0.48}{\sqrt{\frac{0.48(1-0.48)}{200}}} = 0.566$\\\vspace{3mm}
\Figures[A normal distribution with mean 0.48 and standard deviation 0.353 is shaded from 0.50 to the right which makes the area equal 0.286.]
{.4}{opinionAbove50}{opinionAbove50Z} \\
$P(Z \ge 0.566) = 0.286$.
\end{center}
We arrive at the same answer because we simply changed units to standard units -- compare the shaded area in the normal distribution above to the shaded area in the normal distribution shown in Example~\ref{opinionabove50}.


\begin{exercisewrap}
\begin{nexercise}
In the example above, the probability of mistakenly thinking that a majority support the measure is quite high (more than 1 in 4 chance).  What could be done differently to lower this probability?\footnotemark
\end{nexercise}
\end{exercisewrap}
\footnotetext{To lower this tail probability, we would want to take a larger sample, which would reduce the standard devation of the sampling distribution.}



\D{\newpage}

%%
\subsection*{Section summary}

\begin{itemize} 


\item The symbol $\hat{p}$ denotes a sample proportion.  $\hat{p}$ for any particular sample is a number.  However, $\hat{p}$ can vary from sample to sample.  The \termni{sampling distribution of a sample proportion $\hat{p}$} is the distribution of values of $\hat{p}$ for all random samples of size $n$ from a given population.  

\item When the observations can be considered independent, such as from a \emph{random} sample:
\begin{itemize}
\item The \textbf{mean} of the sampling distribution of a sample proportion $\hat{p}$ is given by:  \\
$\mu_{\hat{p}}=p$, where $p$ is the population proportion.  

\item The \textbf{standard deviation} of the sampling distribution of a sample proportion $\hat{p}$ is: \\
$\sigma_{\hat{p}} = \sqrt{\frac{p(1-p)}{n}}$.  When sampling without replacement, the sample size $n$ should be than 10\% of the population size $N$, i.e. $n<0.10(N)$, in order for the standard deviation formula to be used.  

\item The \textbf{shape} of the sampling distribution of a sample proportion $\hat{p}$ is approximately normal when the sample size is large enough that the expected number of success, $np$, and the expected number of failures, $n(1-p)$, are both at least 10, i.e.  $np\ge 10$ and $n(1-p)\ge 10$.  This is sometimes called the large counts condition or the success-failure condition.
\end{itemize}

\item $\mu_{\hat{p}}$, the mean of $\hat{p}$, describes the average of the sample proportions among all random samples of size $n$ from a given population.  

\item $\sigma_{\hat{p}}$, the standard deviation of $\hat{p}$, measures how far the sample proportions typically vary from the population proportion $p$ for all random samples of size $n$ from a given population.  

\item To use a normal model to find probabilities involving a sample proportion, first verify that the conditions for independence are met and that the large counts condition is met.   Identify the distribution and its parameters, write the relevant probability statement, and answer the question in context.

\item The mean, standard deviation, and probabilities for a sampling distribution
of a sample proportion should be interpreted in the context of a specific population.


\end{itemize}

%%%%%%%%%%Section exercises
{\input{ch_inference_for_props/TeX/sampling_distribution_of_a_sample_proportion.tex}}



%____________________________________
\section[Confidence intervals for a population proportion]{Confidence intervals for a population proportion }
\label{singleProportionCI}
\label{ConfidenceIntervals}
\label{confidenceIntervals}

\sectionintro{
\noindent%
%%%%
What percent of adults in the US approve of the way the Supreme Court is handling its job?  Do greater than half of adults in the US believe in intelligent life on other planets? When polling companies report point estimates, they usually also report a margin of error and an interval estimate.   In this section we discuss margin of error and how to construct and interpret what is called a confidence interval for a population proportion.

%%
\subsection*{Learning objectives}
\begin{enumerate}
\setlength{\itemsep}{0mm}
\item Identify and set up an appropriate confidence interval procedure for estimating a population proportion $p$.

\item Justify the appropriateness of constructing a confidence interval for a population proportion by verifying that the conditions are met.

\item Calculate a confidence interval for a population proportion.

\item Calculate the standard error and margin of error of a sample proportion, and
estimate a sample size from the margin of error.  

\item Interpret a confidence interval for a population proportion in context.

\item Justify a claim about a population proportion based on an appropriate confidence interval.

\item Identify the relationships among sample size, confidence interval width, confidence level, and margin
of error.

\item Recognize that margin of error calculations only measure sampling error, and that other types of errors such as bias may be present.

\end{enumerate}
}

\newpage
%%
\subsection{Introducing confidence intervals and margin of error}
In Section~\ref{pointEstimates}, we saw that a point estimate provides a single estimate for a parameter.  However, a point estimate isn't perfect and we do not expect it to hit the parameter exactly.  To increase our confidence, we provide a \emph{range} of plausible values, called an interval estimate or \term{confidence interval}.  

 %Using only a point estimate is like fishing in a murky lake with a spear, and using a confidence interval is like fishing with a net. We can throw a spear where we saw a fish, but we will probably miss. On the other hand, if we toss a net in that area, we have a good chance of catching the fish.  If we report a point estimate, we don't  will not hit the exact population parameter. On the other hand, if we report a range of plausible values -- a confidence interval -- we have a good shot at capturing the parameter.

\begin{onebox}{Confidence interval}
A confidence interval is an interval estimate and provides a range of plausible values for a parameter based on sample data.
\end{onebox}

A point estimate is our best estimate for the value of the parameter, so it makes sense to build the confidence interval around that value.  How can we quantify the expected variability or error in a point estimate?  We use a quantity called the \term{standard error} of the estimate.  The standard error of an estimate, as we will see later in this section, is closely related to the standard deviation of an estimate.

\begin{examplewrap}
\begin{nexample}{How many standard errors should we extend above and below the point estimate if we want to be 95\% confident of capturing the true value?  }
First, we observe that the area under the standard normal distribution between -1.96 and 1.96 is 95\%.  When conditions for a normal model are met, the point estimate we observe will be within 1.96 standard deviations of the true value about 95\% of the time.  Thus, if we want to be 95\% confident of capturing the true value, we should go 1.96 standard errors on either side of the point estimate.
\end{nexample}
\end{examplewrap}

\begin{onebox}{Constructing a 95\% confidence interval using a normal model}
When the sampling distribution of a point estimate can reasonably be modeled as normal, a 95\% confidence interval for the unknown parameter can be constructed as: \vspace{-2mm}
\begin{align*}
\text{point estimate}\ \pm\ 1.96 \times SE\text{ of estimate}\vspace{-2mm}
\end{align*}
We can be \textbf{95\% confident} that this interval captures the true value.\end{onebox}
\label{95PercentConfidenceIntervalFormula}

\begin{examplewrap}
\begin{nexample}{In Section~\ref{pointEstimates}, we considered a point estimate for the proportion in the population that approve of a particular governor.  The point estimate was 45\% based on a sample size of~500.
    The standard error of this estimate is $SE = 0.02$.
    Assuming that conditions for a normal model are met,
    construct a 95\% confidence interval.  }
\begin{align*}
\text{point estimate}\ &\pm \ 1.96\times SE \text{ of estimate} \\
0.45\  &\pm \ 1.96 \times 0.02\\
0.45\  &\pm \ 0.039\\
(0.41&1\text{, } 0.489)
\end{align*}
\label{governorci}
\end{nexample}
\end{examplewrap}



%\begin{examplewrap}
%\begin{nexample}{Suppose the level of support at the state level for the
%    ballot measure has been precisely estimated at 0.20 (20\%).
%    Based on the confidence interval above,
%    is there evidence that a smaller proportion support the ballot measure
%    in the specific county we're looking at relative to the state as a whole?}
%While the point estimate of 0.15 is lower than 0.20, it appears this deviation
%may be due to random chance.
%Because the confidence interval \emph{includes} the value 0.20,
%the value of 0.20 is a reasonable value for the proportion of the county
%population that support the ballot measure.
%Therefore, based on this confidence interval, we do not have evidence that
%a smaller proportion support the ballot measure in this county than in the
%state as a whole.
%\end{nexample}
%\end{examplewrap}

\D{\newpage}

Based on our calculations, we can be 95\% confident that the interval (0.411, 0.489) contains the true proportion of the population who approve of the governor. In general, we can be 95\% confident that a 95\% confidence interval captures the true population parameter. However, confidence intervals are imperfect. About 1-in-20 (5\%) properly constructed 95\% confidence intervals will fail to capture the parameter of interest. Figure~\ref{95PercentConfidenceInterval} shows 25 confidence intervals for a proportion that were constructed from simulations where the true proportion was $p = 0.3$. However, 1 of these 25 confidence intervals happened not to include the true value.

\begin{figure}[h]
\centering
  \Figure[Twenty-five point estimates and confidence intervals for a proportion from a simulation in which the true proportion p = 0.3 are shown.  The point estimates vary around the true population proportion of 0.3, but most of their confidence intervals overlap the value p equals 0.3. Only one of the 25 intervals does not have a confidence interval that overlaps the population proportion, and this interval has been highlighted in red. We might say that this confidence interval did not "capture" the parameter p equals 0.3.]
{0.95}{95PercentConfidenceInterval}
\caption{Twenty-five samples of size $n=300$ were simulated when $p = 0.30$. For each sample, a confidence interval was created to try to capture the true proportion $p$. However,~1~of these~25 intervals did not capture $p = 0.30$.  View this simulation in an interactive Desmos calculator \oiRedirect{desmos-cisimulation}{here}, or find it at \oiRedirect{openintro-ahss-desmos}{\small{openintro.org/ahss/desmos}}.}
\label{95PercentConfidenceInterval}
\end{figure}

Using this simulation, we can better understand what we mean by 95\% confidence.  In the long run, about 95\% of the 95\% confidence intervals, based on random samples of the same size from the same population, will capture the true value.  This is why we can say that we are 95\% confident that an individual interval captures the true value.

\begin{exercisewrap}
\begin{nexercise}
In Figure~\ref{95PercentConfidenceInterval}, one interval does not contain the true proportion, $p = 0.3$. Does this imply that there was a problem with the simulations?\footnotemark
\end{nexercise}
\end{exercisewrap}
\footnotetext{No. Just as some observations occur more than 1.96 standard deviations from the mean, some point estimates will be more than 1.96 standard errors from the parameter. A confidence interval only provides a plausible range of values for a parameter. While we might say other values are implausible based on the data, this does not mean they are impossible.}

%%

\noindent Confidence intervals are also often reported as:
\begin{align*}
\text{point estimate} \ \pm \ \text{margin of error}
\end{align*}

In Example~\ref{governorci} the 95\% confidence interval was calculated as $0.45 \pm 0.039$.  For this interval, the point estimate is 0.45 and the margin of error of the estimate is 0.039.  This tells us that we can be 95\% confident that our estimate is within 0.039 of the true proportion in the population who approve of the governor.  

In Figure~\ref{95PercentConfidenceInterval}, we see the point estimates represented by the dot in the middle of each interval.  For each confidence interval, the $\pm$ margin of error is represented by the line extending to the right of the point estimate and to the left of the point estimate.   Numerically, the margin of error corresponds to the distance between the point estimate and the lower or upper bound of a confidence interval, and thus is half of the total width of the interval.   

\begin{onebox}{Margin of error}\label{marginOfErrorTermBox1}
When using a normal model, the margin of error of a 95\% confidence interval is given by \\
$$1.96 \ \times SE \text{ of estimate}$$\\
The margin of error of a 95\% confidence interval tells us that we can be 95\% confident that our point estimate is within that margin of error of the true value.  
\end{onebox}

\begin{exercisewrap}
\begin{nexercise}For a 95\% confidence interval given by: (0.035, 0.145), find the point estimate and the margin of error of the estimate.\footnotemark
\end{nexercise}
\end{exercisewrap}
\footnotetext{The point estimate is the middle value of the interval and can be calculated as: $(0.035+0.145)/2=0.09$. The margin of error is \emph{half} of the total width of the interval and can be calculated as:  $\frac{0.145 - 0.035}{2}=0.055$, or as $0.145 - 0.9 = 0.055$ }



%%
\subsection{Changing the confidence level}
\label{changingTheConfidenceLevelSection}

\index{confidence level|(}

A researcher chooses a confidence level, and then calculates the margin of error of the estimate at that confidence level.  Suppose we want to construct a confidence interval with a confidence level somewhat greater than 95\%: perhaps we would like a confidence level of 99\%. 

\begin{examplewrap}
\begin{nexample}{Other things being equal, would a 99\% confidence interval have a larger margin or error or a smaller margin of error than a 95\% confidence interval?}All other things being equal, a 99\% confidence interval will have a larger margin of error than a 95\% confidence interval; to be more confident we will need a wider interval and a wider interval corresponds to a larger margin of error.
\end{nexample}
\end{examplewrap}

The 95\% confidence interval structure provides guidance in how to make intervals with new confidence levels. Below is a general 95\% confidence interval for a point estimate that comes from a nearly normal distribution:
\begin{align*}
\text{point estimate}\ \pm\ 1.96\times SE \text{ of estimate}
\end{align*}
There are three components to this interval: the point estimate, ``1.96'', and the standard error of the estimate. The choice of $1.96\times SE$ was based on capturing 95\% of the distribution since the estimate is within 1.96 standard deviations of the true value about 95\% of the time. The choice of 1.96 corresponds to a 95\% confidence level. 

\begin{exercisewrap}
\begin{nexercise} \label{leadInForMakingA99PercentCIExercise}
If $X$ is a normally distributed random variable, how often will $X$ be within 2.58 standard deviations of the mean?\footnotemark
\end{nexercise}
\end{exercisewrap}
\footnotetext{This is equivalent to asking how often the Z-score will be larger than -2.58 but less than 2.58. (For a picture, see Figure~\ref{choosingZForCI}.) There is $\approx$ 0.99 probability that a normally distributed random variable $X$ will be within 2.58 standard deviations of the mean.}


\begin{figure}[ht]
\centering
\Figure[A standard normal distribution is shown.  The area from -1.96 to 1.96 is shaded and labeled as capturing 95\% of the area.  The area from -2.58 to 2.58 is shaded a different color and labeled as capturing 99\% of the area.]
{0.98}{choosingZForCI}
\caption{The area between -$z^{\star}$ and $z^{\star}$ increases as $|z^{\star}|$ becomes larger. If the confidence level is 99\%, we choose $z^{\star}$ such that 99\% of the normal distribution is between -$z^{\star}$ and $z^{\star}$, which corresponds to 0.5\% in the lower tail and 0.5\% in the upper tail: $z^{\star}=2.58$.}
\label{choosingZForCI}
\index{confidence level|)}
\end{figure}

\D{\newpage}

Guided Practice~\ref{leadInForMakingA99PercentCIExercise} highlights that 99\% of the time a normal random variable will be within 2.58 standard deviations of its mean. To create a 99\% confidence interval, change 1.96 in the 95\% confidence interval formula to be $2.58$. Thus, the formula for a 99\% confidence interval is
\begin{align*}
\text{point estimate}\ \pm\ 2.58\times SE \text{ of estimate}
\end{align*}


In the interval above, the value 2.58 is called the \term{critical value}.  When the critical value is determined based on a normal model, we label the critical value $z^{\star}$.  Figure~\ref{choosingZForCI} provides a picture of how to identify $z^{\star}$ based on a confidence level.  We use the $z^{\star}$ value such that the area under the standard normal distribution between $-z^{\star}$ and $z^{\star}$  corresponds to our confidence level of C\%.

\begin{onebox}{Confidence interval for any confidence level}
If the point estimate follows a normal model, then a C\% confidence interval for the population parameter is
\begin{eqnarray*}
\text{point estimate}\ \pm\ z^{\star} \times SE \text{ of estimate}
\end{eqnarray*}
$z^{\star}$ is the value such that the area under the standard normal curve between \mbox{$-z^{\star}$ and $z^{\star}$ is C\%.}
\end{onebox}

Finding the value of $z^{\star}$ that corresponds to a particular confidence level can be accomplished by using a new table, called the $t$-table. For now, what is noteworthy about this table is that the bottom row corresponds to confidence levels. The numbers inside the table are the critical values, but which row should we use? When finding $z^{\star}$, we use the $t$-table at row $\infty$.  The reason for this will be explained in the next chapter.

\begin{figure}[hht]
\centering
\begin{tabular}{r | rrr rr}
one tail & \hspace{1.5mm}  0.100 & \hspace{1.5mm} 0.050 & \hspace{1.5mm} 0.025 & \hspace{1.5mm} 0.010 & \hspace{1.5mm} 0.005  \\
\hline
{$df$} \hfill 1  &  {\normalsize  3.078} & {\normalsize  6.314} & {\normalsize 12.71} & {\normalsize 31.82} & {\normalsize 63.66}  \\ 
2  &  {\normalsize  1.886} & {\normalsize  2.920} & {\normalsize  4.303} & {\normalsize  6.965} & {\normalsize  9.925}  \\ 
3  &  {\normalsize  1.638} & {\normalsize  2.353} & {\normalsize  3.182} & {\normalsize  4.541} & {\normalsize  5.841}  \\ 
$\vdots$ & $\vdots$ &$\vdots$ &$\vdots$ &$\vdots$ & \\
1000  &  {\normalsize  1.282} & {\normalsize  1.646} & {\normalsize  1.962} & {\normalsize  2.330} & {\normalsize  2.581}  \\ 
$\infty$   &  {\normalsize  1.282} & {\normalsize  1.645} & {\normalsize  1.960} & {\normalsize  2.326} & {\normalsize  2.576}   \\
\hline
Confidence level C  &  {\normalsize  80\%} & {\normalsize 90\%} & {\normalsize 95\%} & {\normalsize  98\%} & {\normalsize  99\%}  \\
\hline
\end{tabular}
\caption{An abbreviated look at the $t$-table. The columns correspond to confidence levels. Row $\infty$ corresponds to the normal distribution.}
\label{tTableSample}
\end{figure}

Another way to find the value of $z^{\star}$ for a C\% confidence interval is to use technology to find the boundary value such that C\% of the standard normal distribution falls between $-z^{\star}$ and $z^{\star}$.  We encountered problems such as this in the Normal distribution section.  See problem (ii)(b) on page~\pageref{zstarcalc} for a technology refresher.

%\begin{onebox}{Finding \pmb{$\MakeLowercase{z}^{\star}$ }for a particular confidence level}
%We select $z^{\star}$ so that the area between -$z^{\star}$ and $z^{\star}$ in the normal model corresponds to the confidence level. Use technology or use the $t$-table at row $\infty$ to find the critical value $z^{\star}$.\end{onebox}

\D{\newpage}

\begin{exercisewrap}
\begin{nexercise} \label{find90CIForRun10AgeExercise}
Find the $z^{\star}$ critical value for an 80\% confidence interval.\footnotemark
\end{nexercise}
\end{exercisewrap}
\footnotetext{Using technology or using row $\infty$ on the $t$-table, we find that the $z^{\star}$ critical value that corresponds to an 80\% confidence level is 1.282.}


We now see how to determine the margin error for a any confidence level, not just a 95\% confidence level.

\begin{onebox}{Margin of error}\label{marginOfErrorTermBox2}
When using a normal model, the margin of error for a C\% confidence interval is given by
\begin{align*}
z^{\star} \times SE \text{ of estimate}
\end{align*}
$z^{\star}$ is the value such that the area under the standard normal curve between \mbox{$-z^{\star}$ and $z^{\star}$ is C\%.} The margin of error for a C\% confidence interval tells us that we can be C\% confident that our point estimate is within that margin of error of the true value.  
\end{onebox}

Choosing a higher confidence level, for example 95\% instead of 90\%, increases the margin of error, as it requires a larger $z^{\star}$ to capture the desired percent between $-z^{\star}$ and $z^{\star}$.  We can also think about this as: to be more confident, we need to cast a wider net.  For a given sample, increasing the confidence level will result in the following:
\begin{itemize}
\item[i.] The critical value will increase.
\item[ii.] The margin of error will increase.
\item[iii.] The width of the confidence interval will increase.
\end{itemize}

The normal approximation is crucial to the precision of these confidence intervals. In this chapter, we provide detailed discussions about when a normal model can safely be applied to a variety of situations. When a normal model is not a good fit, we will use alternate distributions that better characterize the sampling distribution.

\D{\newpage}

%%
\subsection[Verifying conditions for a confidence interval for a proportion]{Verifying conditions for a confidence interval for a proportion}

When the sampling distribution of a sample proportion, $\hat{p}$, is approximately normal, we can estimate a population proportion using confidence intervals based on a normal distribution.  We call these intervals ``Z-intervals" for short.  We check that $\hat{p}$ can be modeled using a normal distribution by assessing the independence assumption and verifying that the large counts condition is met. 

\begin{description}
\setlength{\itemsep}{0mm}
\item[Independence.] Observations can be considered independent when the data are collected from a \emph{random process}, such as tossing a coin, or from a \emph{random sample}.  When sampling without replacement from a finite population, the observations can be considered independent when sampling less than 10\% of the population.\footnote{When sampling without replacement and sampling greater than 10\% of the population, a modified standard error formula should be used.}
\item[Large counts.] In Section~\ref{distributionphat}, we applied a version of the large counts condition.  Here, because $p$ is unknown, we check that the number of observed success and failures in the sample is at least 10, that is, that $n\hat{p} \ge 10$ and $n(1-\hat{p}) \ge 10$.
\end{description}

When these conditions are met, we can use what is called a \termni{one-sample Z-interval for p}, where p is a population proportion.\D{\vspace{8mm}}


%%
\subsection[Carrying out a one-sample Z-interval for p]{Carrying out a one-sample \pmb{$Z$}-interval for p}
\label{confIntForPropSection}

\index{data!supreme court|(}
\index{point estimate!single proportion}
\index{Z-interval!for a proportion|(}

The Gallup organization began measuring the public's view of the Supreme Court's job performance in 2000, and has measured it every year since then with the question: ``Do you approve or disapprove of the way the Supreme Court is handling its job?".  In 2025, the Gallup poll randomly sampled 1,033 adults in the US and found that 42\% of them approved.
We know that 42\% is just a point estimate.  What range of values are reasonable or plausible estimates for the percent of the population that approved of the job the Supreme Court is doing?  We can use the confidence interval procedure introduced in the previous section to answer this question, but first we must clearly identify the parameter we're trying to estimate and be sure that a Z-interval will be appropriate.  The following examples walk through the various steps for carrying out a confidence interval procedure using the Gallup poll data.

\begin{examplewrap}
\begin{nexample}{Identify the population of interest and the parameter of interest for the Gallup poll about the US Supreme Court. }
Gallup sampled from US adults, therefore the population of interest, and the population to which we can make an inference, is US adults.  We know the percent of the sample who said they approve of the job the Supreme Court is doing.  However, we do not know what percent of the population would approve.  The parameter of interest, which is unknown, is the percent of \emph{all} US adults that approve of the job the Supreme Court is doing.  This is the quantity that we seek to estimate with the confidence interval.
\end{nexample}
\end{examplewrap}


\D{\newpage}

\begin{examplewrap}
\begin{nexample}{Can the sample proportion $\hat{p}$ be modeled using a normal distribution?}
In order to construct a Z-interval, the sample statistic must be able to be modeled using a normal distribution.  Gallup took a random sample of adults in the US. The sample is random and the sample size is much less than 10\% of the population size, so the first condition (the independence condition) is satisfied.  We must also test the second condition (the large counts condition) to ensure that the sample~size is large enough for the Central Limit Theorem to apply.  The large counts condition is met when $np$ and $n(1-p)$ are at least 10. Because $p$ is always unknown when constructing a confidence interval for $p$, we use the sample proportion $\hat{p}$ to check this condition.  Here we have:
\begin{align*}
n\hat{p} = 1033(0.42) = 434\text{ (``successes'')} \\
 n(1-\hat{p}) = 1033(1 - 0.42) = 599\text{ (``failures'')}
\end{align*}
The second condition is satisfied since 434 and 599 are both at least 10. With the two conditions satisfied, we can model the sample proportion $\hat{p}$ using a normal model and we can construct a Z-interval.
\end{nexample}
\end{examplewrap}


\begin{examplewrap}
\begin{nexample}{Calculate the point estimate and the $SE$ of the estimate.}
\label{supremeCourtCISEExample}
The point estimate for the unknown parameter $p$ (the proportion of all US adults that approve of the job the Supreme Court is doing) is the sample proportion. The point estimate here is $\hat{p} = 0.42$.

We now want to find the $SE$ of the estimate, which is the $SE$ of $\hat{p}$.  
In Section~\ref{distributionphat}, we learned that the formula for the standard deviation of $\hat{p}$ is
\begin{align*}
\sigma_{\hat{p}} = \sqrt{\frac{\ p(1-p)\ }{n}} 
\end{align*}
Because $p$ is unknown, we use the sample proportion $\hat{p}$ as our best estimate for $p$, and we call the estimate of the standard deviation of $\hat{p}$ the standard error (SE) of $\hat{p}$. The SE of $\hat{p}$ is calculated as
\begin{align*}
SE_{\hat{p}} = \sqrt{\frac{\ \hat{p}(1-\hat{p})\ }{n}}
\end{align*}
Here $\hat{p}=0.42$ and $n=$1,033, so the $SE$ of the sample proportion is:
\begin{align*}
SE_{\hat{p}} = \sqrt{\frac{\ 0.42(1-0.42)\ }{1033}}=0.015
\end{align*}
\end{nexample}
\end{examplewrap}

The notation $s_{\hat{p}}$ is sometimes used to refer to the standard error of a sample proportion.  However, for clarity, we will use $SE_{\hat{p}}$ or $SE$ of $\hat{p}$ in this book.

\begin{examplewrap}
\begin{nexample}{Interpret the standard error of 0.015 calculated above.}
The standard error of 0.015 tells us that for random samples of size $n=1,033$ from this population, the typical amount that a sample proportion varies from the true proportion of all US adults that approve of the job to Supreme Court is doing is 1.5\%.
\end{nexample}
\end{examplewrap}

\begin{examplewrap}
\begin{nexample}{Construct a 90\% confidence interval for $p$, the proportion of all US adults that approve of the job the Supreme Court is doing.}
\label{90CIForJobSupremeCourtDoingExample}
Recall that the general form of a confidence interval is:
\begin{align*}
\text{point estimate}\ \pm\ \text{critical value} \times SE\ \text{of estimate}\vspace{-2mm}
\end{align*}
We have already found the point estimate and the $SE$ of the estimate.  Because we previously verified that $\hat{p}$ can be modeled using a normal distribution, the critical value is a $z^{\star}$ value.  The $z^{\star}$ value can be found using technology (see the Technology: normal probabilities and boundary values problem (ii)(b) on page~\pageref{zstarcalc}) or using the $t$-table on page~\pageref{tDistributionTable} at row $\infty$.  For a confidence level of 90\%, $z^{\star}$=1.645.  We can now construct the 90\% confidence interval as follows.  
\begin{align*}
\text{point estimate}\ \pm&\  z^{\star} \times SE\ \text{of estimate} \\
0.42\ \pm&\ 1.645 \sqrt{\frac{\ 0.42(1-0.42)\ }{1033}}\\
(0.39&5,\ 0.445)
\end{align*}
\end{nexample}
\end{examplewrap}

\begin{examplewrap}
\begin{nexample}{Interpret the calculated confidence interval in context.}
Here, we are trying to estimate the true proportion of US adults who approve of the job the Supreme Court is doing, so that context is an important component of our interpretation.  A correct interpretation is:  We are 90\% confident that the interval (0.395, 0.445) contains the true proportion of US adults who approve of the job the Supreme Court is doing. 
\end{nexample}
\end{examplewrap}


\begin{examplewrap}
\begin{nexample}
{The calculated confidence interval may or may not provide evidence to justify a claim.  Based on this interval, is there evidence to justify a claim that less than half of US adults approve of the job the Supreme Court is doing?}
\label{JobSupremeCourtDoingEvidenceExample}
The 90\% confidence interval (0.395,\ 0.445) provides an interval of plausible values for the parameter.  The interval does not contain 0.50 or values higher than 0.50, therefore those can be considered implausible, based on the sample.  Because the \emph{entire} interval is below 0.50, we do have evidence, at the 90\% confidence level, that less than half of US adults (at the time of this poll) approve of the job the Supreme Court is doing.
\end{nexample}
\end{examplewrap}

\begin{exercisewrap}
\begin{nexercise}
Using a 90\% confidence level, calculate the margin of error for the estimate in Example~\ref{90CIForJobSupremeCourtDoingExample}. Interpret this quantity in context.\footnotemark
\end{nexercise}
\end{exercisewrap}
\footnotetext{Using a 90\% confidence level, the margin of error is $1.645 \times \sqrt{\frac{\ 0.42(1-0.42)\ }{1033}} = 0.025$.  This can also be calculated by finding half of the width of the 90\% confidence interval (0.395, 0.445): $(0.445-0.395)/2 = 0.025$.  We are 90\% confident that our estimate is within 0.025 of the true proportion of US adults who approve of the job the Supreme Court is doing. }

\D{\newpage}

\begin{examplewrap}
\begin{nexample}{All other things being equal, when estimating a population proportion, what would we have to do to the sample size in order to halve the margin of error (decrease it by a factor of 2)?}
To decrease the error, we would need to increase the sample size.  We note that $\sqrt{n}$ is in the denominator of the $SE$ formula, so we would have to \emph{quadruple} the sample size in order to decrease the $SE$ by a factor of 2. For a confidence interval for a population proportion with a given confidence level, the margin of error as well as the width of the confidence interval is approximately proportional to $\frac{1}{\sqrt{n}}$.
\end{nexample}
\end{examplewrap}


%\begin{examplewrap}
%\begin{nexample}{Do we have evidence at the 95\% confidence level that more than half of US adults approve of the job the Supreme Court is doing?}
%\label{JobSupremeCourtDoingWrapUpExample}
%First, we observe that a 95\% confidence interval will be \emph{wider} than a 90\% confidence interval.  For a 95\% Z-interval, $z^{\star}=1.96$.  The 95\% confidence interval is:
%\begin{align*}
%&0.42\ \pm\  1.96 \times 0.015 \\
%&= (0.391,\ 0.)
%\end{align*}
%Now, we see that 0.50 is just barely inside the interval, making it within the range of reasonable values.  Therefore, we do not have evidence, at the 95\% confidence level, that more than half of US adults (at the time of this poll) approve of the job the Supreme Court is doing.
%
%\end{nexample}
%\end{examplewrap}


%Notice that we come to a different conclusion based on different confidence levels, which may feel a little jarring.  However, this will happen with real data, and it highlights why it is important to be explicit in identifying the confidence level being used.
%


%%
\subsection{Interpreting confidence levels and intervals revisited}
\label{interpretingCIs}

\index{confidence interval!interpretation|(}

What do we really mean when we say we are 95\% confident an interval contains the true value?  As we saw in Figure~\ref{95PercentConfidenceInterval}, the 95\% confidence interval \emph{method} has a 95\% probability of producing an interval that will capture the population parameter. A correct interpretation of a 95\% confidence \emph{level} is that in repeated random sampling with the same sample size, approximately 95\% of confidence intervals calculated will capture the population proportion. 

\begin{onebox}{Interpreting the confidence level}
The correct way to interpret a C\% confidence level is:\\

In repeated random sampling with the same sample size, approximately C\% of confidence intervals calculated will capture the population parameter.
\end{onebox}

While 95\% of all 95\% confidence intervals should contain the population parameter, each individual interval either does or does not.  This is why we cannot say that there is a 95\% probability that our calculated interval contains the true value.\footnote{To see that this interpretation is incorrect, imagine taking two random samples and constructing two 95\% confidence intervals for an unknown proportion. If these intervals are disjoint, can we say that there is a 95\%+95\%=190\% chance that the first or the second interval captures the true value?}  Applying the language of probability to a fixed interval or to a fixed parameter is one of the most common errors when interpreting confidence intervals. 

\begin{onebox}{Interpreting a confidence interval}
The correct way to interpret a particular confidence interval is:\\

We are C\% \emph{confident} that the interval (\underline{\ \ \ \ }, \underline{\ \ \ \ }) contains the population parameter.
\end{onebox}

It is also correct to describe the parameter first.  For example, we could say we are C\% confident that the true proportion of US adults who approve of the job the Supreme Court is doing is between \underline{\ \ \ \ } and \underline{\ \ \ \ }.  Referencing the interval first is sometimes seen as preferable as it more clearly attributes the variability to the interval, not to the fixed parameter.  However, both interpretations are valid.  The three important elements when interpreting a particular confidence interval are: use the word ``confident" not ``probability", describe the parameter in the context of the problem, and provide the interval or interval endpoints.

Another especially important consideration of confidence intervals is that they only try to capture the \emph{population parameter}. Our intervals say nothing about the confidence of capturing individual observations, a proportion of the observations, or point estimates. Confidence intervals only attempt to capture population parameters.

\index{confidence interval!interpretation|)}
\index{confidence interval|)}

\newpage
\subsection{A four-step framework for confidence interval procedures}

Having worked through the examples in Section~\ref{confIntForPropSection}, we see that a complete confidence interval procedure involves multiple steps.  We will find it useful to have a framework for summarizing and remembering the relevant steps.  Throughout the textbook we will use the following four-step framework for confidence interval procedures.  

\begin{itemize}
\setlength{\itemsep}{0mm}
\item \inferencestep{Identify}  Identify the appropriate interval procedure, the parameter, and the confidence level.
\item  \inferencestep{Check}  Check that the conditions for the interval procedure are met. 
\item \inferencestep{Calculate} Calculate the confidence interval and record it in interval form.  
\begin{align*}
\text{point estimate}\ \pm\  \text{critical value}\times SE \text{ of estimate}
\end{align*}
\item \inferencestep{Conclude} Interpret the interval and, if applicable, draw a conclusion based on whether the interval is entirely above, is entirely below, or contains the value of interest.
\end{itemize}


\noindent We will apply this four-step framework to confidence intervals for a proportion as follows.

\begin{onebox}{Constructing a confidence interval for a proportion}
To carry out a complete confidence interval procedure to estimate a single population proportion,
\\
\\
%\inferencestep{Identify} Use a \termsub{one-sample Z-interval for \pmb{$p$}}{Z-interval!for a proportion}, where $p$ is a population proportion.  Define $p$ in the context of the problem.  Choose a confidence level (C\%) for estimating the parameter.  \\
\inferencestep{Identify} Identify the interval procedure, parameter, and confidence level.\vspace{-1mm}
\begin{itemize}
\item[] Use a \termsub{one-sample Z-interval for \pmb{$p$}}{Z-interval!for a proportion}.  Define the (unknown) population parameter $p$ in words, referencing the population of interest.  Choose a confidence level (C\%).  
\end{itemize}
\inferencestep{Check} Check conditions for constructing a confidence interval using a normal distribution.  \vspace{-1mm}
{\setlength{\leftmargini}{13mm}
\begin{itemize}
\setlength{\itemsep}{0mm}
\item[1.] Independence:  Data come from a random sample or random process.  When sampling 
without replacement, check that sample size is less than 10\% of the population size.
\item[2.] Large counts:  $n\hat{p}\ge 10$ and $n(1-\hat{p})\ge 10$.
\end{itemize}
}
\inferencestep{Calculate} Calculate the confidence interval and record it in interval form.
\begin{itemize}
\item[] $\text{point estimate}\ \pm\ z^{\star} \times SE\ \text{of estimate}$
\begin{itemize}
\item[] point estimate: $\hat{p}$, the sample proportion
\item[] $SE$ of estimate:  $\sqrt{\frac{\ \hat{p}(1-\hat{p})\ }{n}}$
\item[] $z^{\star}$: use technology or a $t$-table at row $\infty$ and confidence level C\%
\end{itemize}
\item[] (\underline{\ \ \ \ \ }, \underline{\ \ \ \ \ })
\end{itemize}
\inferencestep{Conclude} Interpret the interval and, if applicable, draw a conclusion in context.\vspace{-1mm}
\begin{itemize}
\item[] We are C\% confident that the interval (\underline{\ \ \ \ \ }, \underline{\ \ \ \ \ }) contains the true \emph{proportion} of [...].  If applicable, draw a conclusion based on whether the interval is entirely above, is entirely below, or contains the value of interest. 
\end{itemize}\end{onebox}



\begin{examplewrap}
\begin{nexample}{A Marist Poll reports:
    ``Many Americans (68\%) think there is intelligent life on other planets."
    The results were based on a random sample of 1,033 adults in the US.
    Does this poll provide evidence at the 95\% confidence level that greater
    than half of all US adults think there is intelligent life on
    other planets?
    Carry out a confidence interval procedure to answer this question.
    Use the four-step framework to organize your work.}
\label{IntelligentLife}
\begin{description}
\item[\inferencestep{Identify}]  Because the parameter to be estimated is a single proportion, we will use a one-sample Z-interval for $p$.   Here, the parameter $p$ is the true proportion of US adults that think there is intelligent life on other planets.  We will estimate this at the 95\% confidence level.  
\item[\inferencestep{Check}] We must check that a Z-interval is appropriate.    The problem states that the data come from a random sample, and since the population is adults in the US, the population size is much more than 10 times larger than the sample size of 1,033.  Next we must check the large counts condition.  Here, we have that $1033(.68)\ge 10$ and $1033(1-0.68)\ge 10$.  The nearly normal sampling distribution conditions are met, so we can proceed with a \mbox{one-sample Z-interval for $p$.}
\item[\inferencestep{Calculate}]  We will calculate the interval:
\begin{align*}
 \text{point estimate}\ \pm\ z^{\star} \times SE\ \text{of estimate}
\end{align*}
The point estimate is the sample proportion: $\hat{p} = 0.68$. \\

$SE$ of $\hat{p}$ = $\sqrt{\frac{\ \hat{p}(1-\hat{p})\ }{n}} = \sqrt{\frac{0.68(1-0.68)}{1033}}=0.015$.  \\

For a 95\% confidence level, $z^{\star}$ = 1.96, which can be found using technology or using the $t$-table at row $\infty$. The 95\% confidence interval is given by:\vspace{-1mm}
\begin{align*}
0.68\ \pm\  &1.96 \times \sqrt{\frac{0.68(1-0.68)}{1033}} \\
0.68\ \pm\  &1.96 \times 0.015 \\
 (0.6&51,\  0.709)
\end{align*}
\item[\inferencestep{Conclude}]  We are 95\% confident that the interval (0.651, 0.709) contains the true \emph{proportion} of US adults that think there is intelligent life on other planets.  Because the entire interval is above 0.5 we have evidence that greater than half of all US adults think there is intelligent life on other planets.
\end{description}
\end{nexample}
\end{examplewrap}

\begin{exercisewrap}
\begin{nexercise}
True or False:  There is a 95\% probability that between 65.1\% and 70.9\% of US adults think that there is intelligent life on other planets.\footnotemark
\end{nexercise}
\end{exercisewrap}
\footnotetext{False.  The true percent of US adults that think there is intelligent life on other planets either falls in that interval or it doesn't.  A correct interpretation of the confidence level would be that if we were to repeat this process over and over, about 95\% of the 95\% confidence intervals constructed would contain the true value.  }



\D{\newpage}

%%
\subsection{Choosing a sample~size when estimating a proportion}
\label{moeproportion}
\index{margin of error|(}

Planning a sample~size before collecting data is important. If researchers collect too little data, the standard error of the point estimate may be so large that the estimate is not very useful. On the other hand, collecting data in some contexts is time-consuming and expensive, so researchers don't want to waste resources on collecting more data than they need.

When considering the sample~size, we want to put an upper bound on the margin of error. Recall that the margin of error is calculated as: critical value $\times$ $SE$ of estimate.  For a sample proportion, the margin of error is given by:
\begin{align*}
z^{\star}\times \sqrt{\frac{\hat{p}(1-\hat{p})}{n}}
\end{align*}


\begin{examplewrap}
\begin{nexample}{Suppose we are conducting a university survey to determine whether students support a \$200 per year increase in fees to pay for a new football stadium.  Find the smallest sample~size $n$ so that the margin of error of the point estimate $\hat{p}$ will be no larger than 0.04 when using a 95\% confidence level.}
We want the margin of error to be less than or equal to 0.04, so we want:
\begin{align*}
z^{\star}\times \sqrt{\frac{\hat{p}(1-\hat{p})}{n}} \leq 0.04
\end{align*}
We know that $z^{\star}$ for a 95\% confidence interval is 1.96.  There are still two unknown quantities in the inequality: $n$ and $\hat{p}$. We haven't taken a sample yet, so we do not have a value for $\hat{p}$.  If we have an estimate of what we are expecting for $\hat{p}$, perhaps from a similar survey, we could use that value. If we have no such estimate, we use 0.50 as a conservative estimate. It turns out that the margin of error is largest when $\hat{p}$ is 0.5, so we typically use this \emph{worst case estimate} of $\hat{p}$ = 0.5 if no other estimate is available.
\begin{align*}
	1.96\times \sqrt{\frac{0.5(1-0.5)}{n}} &\leq 0.04 \\
	1.96^2\times \frac{0.5(1-0.5)}{n} &\leq 0.04^2 \\
	1.96^2\times \frac{0.5(1-0.5)}{0.04^2} &\leq n \\
	600.25 &\leq n \\
	n=601
\end{align*}
The sample~size must be an integer and we round up because $n$ must be greater than or equal to 600.25. We need at least 601 participants to ensure the sample proportion is within 0.04 of the true proportion with 95\% confidence, so 601 is the smallest sample size that will suffice.
\end{nexample}
\end{examplewrap}

In sample~size computations for a proportion, if we have a reliable estimate of the proportion, we should use it.  If not, we use the conservative estimate of~0.5.


\index{data!Congress approval rating|(}

 


\begin{examplewrap}
\begin{nexample}{A recent estimate of Congress' approval rating was 17\%.
    If another poll were taken, what minimum sample~size does this estimate
    suggest should be used to have a margin of error no greater than 0.04
    with 95\% confidence?}

We complete the same computations as before, except now we use $0.17$ instead of $0.5$ for the proportion:
\begin{align*}
1.96\times \sqrt{\frac{0.17(1-0.17)}{n}} &\leq 0.04\\
	1.96^2\times \frac{0.17(1-0.17)}{n} &\leq 0.04^2 \\
	1.96^2\times \frac{0.17(1-0.17)}{0.04^2} &\leq n \\
338.8 &\leq n\\
n &= 339
\end{align*}
If the true proportion is 0.17, then 339 is the minimum sample~size that will ensure a margin of error no greater than 0.04 with 95\% confidence.

\index{data!Congress approval rating|)}

\end{nexample}
\end{examplewrap}

\begin{onebox}{Identify a sample~size for a particular margin of error}
When estimating a single proportion at a given confidence level, we find the minimum \mbox{sample~size} $n$ to have no greater than a certain margin of error $MOE$ as follows:
\begin{align*}
z^{\star}\times \sqrt{\frac{\hat{p}(1-\hat{p})}{n}} \leq MOE\\ \\
(z^{\star})^2\times \frac{\hat{p}(1-\hat{p})}{(MOE)^2} \leq n
\end{align*}
where $z^{\star}$ depends on the confidence level.   If no rough expected value for $\hat{p}$ exists, use $\hat{p} = 0.5$.  	
\end{onebox}


\begin{exercisewrap}
\begin{nexercise}
A manager is about to oversee the mass production of a new tire model in her factory, and she would like to estimate the proportion of these tires that will be rejected through quality control. The quality control team has previously found that about 6.2\% of tires fail inspection.
\begin{itemize}
\setlength{\itemsep}{0mm}
\item[(a)] How many tires should the manager examine to estimate the failure rate of the new tire model to within 2\% with a 90\% confidence level?\footnotemark
\item[(b)] What if the estimate of $p$ is 1.7\% rather than 6.2\%?\footnotemark
 
\index{margin of error|)}
\end{itemize}
\end{nexercise}
\end{exercisewrap}
\addtocounter{footnote}{-1}
\footnotetext{The $z^{\star}$ corresponding to a 90\% confidence level is 1.645.  Since we have an estimate for $p$ of 6.2\%, we use it.  So we have:  $1.645\times \sqrt{\frac{0.062(1-0.062)}{n}} \leq 0.02 $.  Rearranging for $n$ gives: $n \geq 393.4$, so she should use $n =394$.}
\addtocounter{footnote}{1}
\footnotetext{Substituting 0.017 for $p$ gives an $n$ of 114.  We can note that in this case $n\times p = 114 \times 0.017 = 1.9 <10$.  Since the large counts condition is not met, the use of $z^{\star} = 1.645$ based on a normal model is not appropriate.  We would need additional methods than what we've covered so far to get a good estimate for the minimum sample~size in this scenario.}




\subsection[Technology: the one-sample Z-interval for $p$]{Technology: the one-sample Z-interval for \pmb{$p$}}

\noindent  Section~\ref{tech1Z} demonstrates how to calculate the one-sample Z-interval for $p$ and the one-sample Z-test for $p$ (introduced in the next section) using Desmos, R, and the NumWorks, TI-83/84 and Casio calculators. 


\D{\newpage}

%%
\subsection*{Section summary}
\begin{itemize} 

\item A confidence interval is an interval estimate for a population parameter based on a sample statistic.  The appropriate confidence interval procedure to estimate a single population proportion $p$ is a \termni{one-sample Z-interval for p}.  The parameter $p$ should be identified in context.

\item A one-sample $Z$-interval for a population proportion requires the following conditions be met:
\begin{itemize}
\item[1.] Independence:  The data should come from a random sample or random process.  When sampling without replacement, check that the sample size $n$ is less than 10\% of the population size.
\item[2.] Large counts :  $n\hat{p}\ge 10$ and $n(1-\hat{p})\ge 10$.   
\end{itemize}

\item The general form for a C\% confidence interval is:
\begin{center}
$\text{point estimate}\ \pm\ \text{margin of error} , \text{ or } $\\
$\ \ \ \ \ \ \ \ \ \ \ \ \ \ \text{point estimate}\ \pm\ \text{critical value} \times SE\ \text{of estimate}. $
\end{center}
\item A one-sample $Z$-interval for a population proportion $p$ can be written as: 
$$\hat{p}\  \pm \  z^{\star}\sqrt{\frac{\hat{p}(1-\hat{p})}{n}}$$
where $z^{\star}$ denotes the critical value, such that C\% of the standard normal distribution is enclosed between $-z^{\star}$ and $+z^{\star}$.  C\% represents the confidence level, e.g. 95\%.


\item The \termni{standard error ($SE$)} of an estimate/statistic is an estimate of the standard deviation of
the sampling distribution of the statistic.  The $SE$ quantifies the typical amount that a statistic will vary from the value of the corresponding population parameter.  $SE$ of $\hat{p}$ = $\sqrt{\frac{\hat{p}(1-\hat{p})}{n}}$.

\item The \termni{margin of error} of $\hat{p}$ is: $z^{\star}\sqrt{\frac{\hat{p}(1-\hat{p})}{n}}$, and is half of the width of the confidence interval.

\item To find the \term{minimum sample~size} needed to estimate a proportion with a given confidence level and no greater than a certain margin of error $MOE$ , set up an inequality of the form:
\begin{align*}
z^{\star}\sqrt{\frac{\hat{p}(1-\hat{p})}{n}} \le MOE\text{, which can be rewritten as: }(z^{\star})^2\frac{\hat{p}(1-\hat{p})}{(MOE)^2} \le n
\end{align*}
$z^{\star}$ depends on the desired confidence level.  Unless an approximate proportion is available, use \mbox{$\hat{p}=0.5$.}  Solve for the sample~size $n$.  The final answer for $n$ should be an \textit{integer}.

\item Because the confidence interval is based on a sample, the point estimate has associated error and the confidence interval may or may not contain the true value of the population proportion.  

\item The interpretation of a C\% \termni{confidence level} is that in repeated random
sampling with the same sample size, approximately
C\% of confidence intervals calculated will capture the population proportion.

\item We say we are C\% confident that a \emph{particular} interval (\underline{\ \ }, \underline{\ \ }) contains the \mbox{population proportion.}

\item A confidence interval provides a range of plausible values for a parameter and can be used as evidence to justify a claim about a population proportion.  At a particular confidence level, values are considered plausible if they are inside the confidence interval and values are considered implausible if they are outside the confidence interval. 

\item For a given sample, increasing the confidence level will result in a larger critical value, a larger margin of error, and a wider confidence interval.

\item Increasing the sample size $n$ decreases the standard error of $\hat{p}$ and, when all other things remain the same, decreases the width of a confidence interval for $p$.  The width of the interval is approximately proportional to $\frac{1}{\sqrt{n}}$.


\end{itemize}


%%%%%%%Section Exercises
{\input{ch_inference_for_props/TeX/confidence_intervals_for_a_population_proportion.tex}}

%_________________________________
\section[Hypothesis testing for a population proportion]{Hypothesis testing for a population proportion }
\label{hypothesisTesting}
\label{singleProportionTest}

\index{hypothesis testing|(}

\sectionintro{
\noindent%
A consultant carries out a random sample and finds support for a particular candidate for office to be 52\%.  Is this convincing evidence that the candidate's support is really above 50\% in the overall population?  If so, how much evidence is there for this claim?  In this section, we will set up a framework for answering questions such as this and will look at the different types of decision errors that researchers can make when drawing conclusions based on data.


%%

\subsection*{Learning objectives}
\begin{enumerate}
\setlength{\itemsep}{0mm}

\item Identify an appropriate testing method for a population proportion $p$ and describe the parameter in context.

\item Identify the null and alternative hypotheses for a population proportion.

\item Justify the appropriateness of a hypothesis test for a population proportion using a normal distribution by verifying conditions are met.

\item Interpret the p-value of a hypothesis test for a population proportion.

\item Calculate an appropriate test statistic and p-value for testing a hypothesis about a population proportion.

\item Justify a claim about the population proportion based on the results of the hypothesis test.

\item Identify Type I and Type II errors.

\item Find the probability of
Type I and Type II errors.

\item Identify the factors that affect
the probability of errors in
hypothesis testing.

\item Interpret Type I and Type II errors.

\end{enumerate}

}

%%
\subsection{Case study: medical consultant}

\index{data!medical consultant|(}
People providing an organ for donation sometimes seek the help of a special medical consultant. These consultants assist the patient in all aspects of the surgery, with the goal of reducing the possibility of complications during the medical procedure and recovery. Patients might choose a consultant based in part on the historical complication rate of the consultant's clients.

One consultant tried to attract patients by noting the overall complication rate for liver donor surgeries in the US is about 10\%, but her clients have had only 9 complications in the 142 liver donor surgeries she has facilitated. She claims this is strong evidence that her work meaningfully contributes to reducing complications (and therefore she should be~hired!).

\begin{examplewrap}\begin{nexample}{We will let $p$ represent the true complication rate for liver donors working with this consultant. Calculate the best estimate for $p$ using the data.  Label the point estimate as $\hat{p}$.}
The sample proportion for the complication rate is 9~complications divided by the 142~surgeries the consultant has worked on: $\hat{p} = 9 / 142 = 0.063$.
\end{nexample}\end{examplewrap}

\begin{examplewrap}\begin{nexample}{Is it possible to prove that the consultant's work reduces complications?}
No. The claim implies that there is a causal connection, but the data are observational. For example, maybe patients who can afford a medical consultant can afford better medical care, which can also lead to a lower complication rate.
\end{nexample}\end{examplewrap}

\begin{examplewrap}\begin{nexample}{While it is not possible to assess the causal claim, it is still possible to ask whether the low complication rate of $\hat{p} = 0.063$ provides evidence that the consultant's true complication rate is different than the US complication rate. Why might we be tempted to immediately conclude that the consultant's true complication rate is different than the US complication rate? Can we draw this conclusion?}
Her sample complication rate is $\hat{p} = 0.063$, which is 0.037 lower than the US complication rate of 10\%. However, we cannot yet be sure if the observed difference represents a real difference or is just the result of random variation. We wouldn't expect the sample proportion to be \emph{exactly} 0.10, even if the truth was that her real complication rate was 0.10.
\end{nexample}\end{examplewrap}


%%
\subsection{Setting up the null and alternative hypothesis}

We can set up two competing hypotheses about the consultant's true complication rate. The first is call the \term{null hypothesis} and represents either a skeptical perspective or a perspective of no difference. The second is called the \term{alternative hypothesis} (or alternate hypothesis) and represents a new perspective such as the possibility that there has been a change or that there is a treatment effect in an experiment.

\begin{onebox}{Null and alternative hypotheses}
The \term{null hypothesis} is abbreviated $H_0$. It represents a skeptical perspective and is often a claim of no change or no difference. \vspace{3mm}

The \term{alternative hypothesis} is abbreviated $H_A$. It is the claim researchers hope to prove or find evidence for, and it often asserts that there has been a change or an effect. \vspace{3mm}

Our job as data scientists is to play the skeptic: before we buy into the alternative hypothesis, we need to see strong supporting evidence.
\end{onebox}

\begin{examplewrap}\begin{nexample}{Identify the null and alternative claim regarding the consultant's complication rate.}
\label{complication}
\begin{itemize}
\item[$H_0$:] The true complication rate for the consultant's clients is equal to 10\%.
\item[$H_A$:] The true complication rate for the consultant's clients is not equal to 10\%.  
\end{itemize}
\label{hypp}
\end{nexample}\end{examplewrap}

Often it is convenient to write the null and alternative hypothesis in abbreviated mathematical or numerical terms. To do so, we first identify the parameter of interest. The parameter in a hypothesis test is a true but unknown value regarding the population of interest.  When the parameter is a proportion, as in Example~\ref{hypp}, we label it $p$. For this example, we would define $p$ and write the hypotheses as:

\begin{itemize}
\item[] $p$:  the true complication rate for the consultant's clients
\item[] $H_0$: $p=0.10$ 
\item[] $H_A$: $p \neq 0.10$
\end{itemize}

The true complication rate for this consultant's clients is unknown, but the null hypothesis is that it equals 0.10, the overall proportion of complications. This hypothesized value is called the \term{null value}.

\begin{onebox}{Null value of a hypothesis test}
The \term{null value} is the value hypothesized for the parameter in $H_0$, and it is sometimes represented with a~subscript 0, e.g.~$p_0$ (just like $H_0$).\end{onebox}

The null claim is always framed as an equality: it tells us what quantity we should use for the parameter when carrying out calculations for the hypothesis test. There are three choices for the alternative hypothesis, depending upon whether the researcher is trying to prove that the value of the parameter is greater than, less than, or not equal to the null value.

\begin{onebox}{Always write the null hypothesis as an equality}
We will find it most useful if we always list the null hypothesis as an equality (e.g.~$p = 0.1$) while the alternative always uses an inequality (e.g. $p \neq 0.1$, $p>0.1$, or~$p<0.1$).\end{onebox}


These hypotheses are part of what is called a \term{hypothesis test}. A hypothesis test is a statistical technique used to evaluate competing claims based on data. Often times, the null hypothesis takes a stance of \emph{no difference} or \emph{no effect}. If the null hypothesis and the data notably disagree, then we will reject the null hypothesis in favor of the alternative hypothesis.  

\begin{exercisewrap}
\begin{nexercise}
According to the 2020 US Census, 6.6\% of residents in the state of Alaska were under 5 years old.\footnotemark  A researcher plans to take a random sample of residents from Alaska to test whether or not this is still the case. Identify the parameter of interest and write the hypotheses that the researcher should test in both plain and statistical language.\footnotemark
\end{nexercise}
\end{exercisewrap}
\footnotetext{\url{www.census.gov/library/visualizations/interactive/exploring-age-groups-in-the-2020-census.html}}
\footnotetext{p: the \emph{current} proportion of residents in Alaska that are under 5 years old.  \\
$H_0$: $p=0.066$; The proportion is \emph{unchanged} from 2020.\\ 
$H_A$: $p \neq 0.066$; The proportion has changed from 2020. It could have increased or decreased.}

When the alternative claim uses a $\neq$, we call the test a \term{two-sided} test, because either extreme provides evidence against $H_0$. When the alternative claim uses a $<$ or a $>$, we call it a \term{one-sided} test.

\begin{onebox}{One-sided and two-sided tests}
If the researchers are only interested in showing an increase or a decrease, but not both, use a one-sided test. If the researchers would be interested in any difference from the null value -- an increase or decrease -- then the test should be two-sided.\vspace{0.5mm}\end{onebox}


\begin{examplewrap}
\begin{nexample}{Let's re-examine hypothesis test for the consultant's complication rate from Example~\ref{hypp}. The hypotheses were $H_0$: $p=0.10$ versus $H_A$: $p \neq 0.10$.  We knew that her sample complication rate was 0.063, which was lower than the US complication rate of 0.10. Why did we conduct a two-sided hypothesis test for this setting?}
The setting was framed in the context of the consultant being helpful, but what if the consultant actually performed worse than the US complication rate? Would we care? More than ever! Since we care about a finding in either direction, we should run a two-sided~test.
\end{nexample}
\end{examplewrap}

\D{\newpage}

\begin{onebox}{One-sided hypotheses are allowed only \emph{before} seeing data}
{After observing data, it is tempting to turn a two-sided test into a one-sided test. Avoid this temptation. Hypotheses must be set up \emph{before} observing the data. If~they are not, the test must be two-sided.}
\end{onebox}

%\begin{onebox}{Point estimates vs parameter}\index{point estimate}\index{parameter}
%Point estimates are calculated based on a sample. For example, the \emph{observed} complication rate for the medical consultant's patients is $\hat{p} = 0.048$. This point estimate is our best guess at the probability $p$ a randomly selected client of hers has a complication. This probability is the parameter and its precise value is never known. However, we can estimate it using the point estimate $\hat{p}$.}
%\end{termBox}

%%
\subsection{Evaluating the hypotheses with a p-value}

\begin{examplewrap}
\begin{nexample}
{If the null claim is true, what proportion would we expect to have had a complication?  }If the null claim is true, we would expect about 10\% of the patients to have a complication.
\end{nexample}
\end{examplewrap}

The consultant's complication rate for her 142 clients was $9/142 = 0.063$. What is the probability that a sample of size 142 would produce a complication rate this far from the expected rate of 0.10, assuming $H_0$ were true?  We call this probability the \term{p-value}.  When conditions are met, the p-value can be estimated using a a normal model as shown in Figure~\ref{MedConsNullNormal}.  When a normal model is not appropriate the p-value can be estimated using a simulation technique as described in Section~\ref{calcPValueUsingSimulationSubSection} on page~\pageref{calcPValueUsingSimulationSubSection}.

\begin{figure}[ht]
\centering
\Figure[A normal distribution with mean 0.1 and standard deviation 0.03 is shown.  This distribution represents the distribution of sample proportions under the null hypothesis that the true proportion is 0.1.  The two tail areas, to the left of 0.063 and the the right of 0.137 are shaded.  This shaded area represents the p-value for this test.]
{0.6}{MedConsNullNormal}
\caption{The shaded area represents the p-value. We observed $\hat{p} = 0.063$.  Any observations smaller than this are at least as extreme relative to the null value, $p_0 = 0.10$, and so the lower tail is shaded. However, since this is a two-sided test, values above 0.137 are also at least as extreme as 0.063 (relative to 0.10), and so they are also shaded. The tail areas together represent the p-value.}
\label{MedConsNullNormal}
\end{figure}

When working with proportions, we can say that the p-value is the probability of getting a sample proportion as far from or farther from the null proportion in the direction of $H_A$ if the null hypothesis is true.  In general, we calculate and interpret a p-value under one of three scenarios.

\D{\newpage}

\begin{figure}[ht]
\centering
\Figure[Three normal distributions are shown.  In the first, the left tail is shaded corresponding to an alternative hypothesis of p < null value.  In the second, the right tail is shaded, corresponding to an alternative hypothesis of p > null value.  In the third, both tails are shaded, corresponding to a two-sided alternative hypothesis of p \ne null value.]
{1}{sidedness_example_figures}
\caption{When the alternative hypothesis takes the form $p <$ null value, the p-value is represented by the lower tail. When it takes the form $p >$ null value, the p-value is represented by the upper tail. When using $p \neq$ null value, then the p-value is represented by both tails.}
\label{sidedness_example_figures}
\end{figure}

\begin{onebox}{Finding and interpreting the p-value}
We find and interpret the \term{p-value}\index{hypothesis testing!p-value|textbf} according to the nature of the alternative hypothesis.\vspace{-1mm}
\begin{description}
\setlength{\itemsep}{0mm}

\item[$H_A$: parameter $>$ null value.] The p-value corresponds to the area in the \emph{upper} tail and is probability of getting a test statistic as large or larger than the observed test statistic if the null hypothesis is true.  

\item[$H_A$: parameter $<$ null value.] The p-value corresponds to the area in the \emph{lower} tail and is the probability of observing a test statistic as small or smaller than the observed test statistic if the null hypothesis is true. 

\item[$H_A$: parameter $\ne$ null value.] The p-value corresponds to the area in \emph{both} tails and is the probability of observing a test statistic as extreme or more extreme than the observed test statistic if the null hypothesis is true. 
\end{description}
\noindent More generally, we can say that the p-value is the probability of getting a test statistic as extreme or more extreme than the observed test statistic in the direction of $H_A$ if the null hypothesis is true.
\end{onebox}



When the p-value is small, i.e. less than or equal to a previously set threshold, we say the results are \termni{statistically significant}. This means the data provide such strong evidence against $H_0$ that we reject the null hypothesis in favor of the alternative hypothesis. The threshold is called the \term{significance level}\index{hypothesis testing!significance level}\index{significance level} and is represented by $\alpha$ (the Greek letter \emph{alpha}\label{alphadiscussion}).  The significance level is typically set to $\alpha = 0.05$, but it can vary depending on the field or the application. %Using a significance level of $\alpha = 0.05$ in the discrimination study, we can say that the data did not provide statistically significant evidence against the null hypothesis, because the p-value of 0.1754 was larger than the $\alpha$ of 0.05.

\begin{onebox}{Statistical significance}
If the p-value is less than or equal to the significance level $\alpha$ (usually 0.05), we say that the result is \term{statistically significant}\index{hypothesis testing!statistically significant|textbf}. We reject $H_0$, and we have strong evidence favoring~$H_A$. \\[2mm]
If the p-value is greater than the significance level $\alpha$, we say that the result is not statistically significant. We do not reject $H_0$, and we do not have sufficient evidence for $H_A$.\end{onebox}

Recall that the null claim is the claim of no difference. If we reject $H_0$, we are asserting that there is strong evidence of a real difference. If we do not reject $H_0$, we are saying that the null claim is not unreasonable based on the data analyzed, but we are not saying that the null claim has been proven.

\begin{exercisewrap}
\begin{nexercise} \label{plainLanguageExplanationOfHTConclusionForLiverDonorSurgicalConsultant}
In our consultant's complication rate example the p-value is 0.1754.  This is larger than the significance level 0.05, so we do not reject the null hypothesis. Explain what this means in the context of the problem using plain language.\footnotemark
\end{nexercise}
\end{exercisewrap}
\footnotetext{The data do not provide evidence that the consultant's complication rate is significantly lower or higher than the US complication rate of 10\%.}

\D{\newpage}

\begin{examplewrap}
\begin{nexample}{In the previous exercise, we did not reject $H_0$. This means that we did not disprove the null claim. Is this equivalent to proving the null claim is~true?}
No. We did not prove that the consultant's complication rate is \emph{exactly} equal to 10\%. Recall that the test of hypothesis starts by \emph{assuming the null claim is true}. That~is, the test proceeds as an argument by contradiction. \emph{If the null claim is true}, there is a 0.1754 chance of seeing sample data as divergent from 10\% as we saw in our sample. Because 0.1754 is large, it is within the realm of chance error, and we cannot say the null hypothesis is unreasonable.\footnotemark
\end{nexample}
\end{examplewrap}
\footnotetext{The p-value is a conditional probability. It is P(getting data at least as divergent from the null value as we observed $|$ $H_0$ is true). It is NOT P( $H_0$ is true $|$ we got data this divergent from the null value).}


\begin{onebox}{Double negatives can sometimes be used in statistics}
In many statistical explanations, we use double negatives. For instance, we might say that the null hypothesis is \emph{not implausible} or we \emph{failed to reject} the null hypothesis. Double negatives are used to communicate that while we are not rejecting a position, we are also not saying that we know it to be true.\end{onebox}

\begin{examplewrap}
\begin{nexample}{Does the conclusion in Guided Practice~\ref{plainLanguageExplanationOfHTConclusionForLiverDonorSurgicalConsultant} ensure that there is no real association between the surgical consultant's work and the risk of complications? Explain.}
No. It is possible that the consultant's work is associated with a lower or higher risk of complications.
If this was the case, the sample may have been too small
to reliable detect this effect.
\index{data!medical consultant|)}
\end{nexample}
\end{examplewrap}

%The 2-in-100 chance is what we call a \term{p-value}, which is a probability quantifying the strength of the evidence against the null hypothesis and in favor of the alternative. %Formally the p-value is a conditional probability, which is basically\footnote{Want to learn more probability? Check out~Appendix~\ref{probability}.}


%\begin{onebox}{Significance level}
%If the null hypothesis is true, the significance level $\alpha$ defines the probability that we will make a Type~I Error.}
%\end{termBox}

\begin{examplewrap}
\begin{nexample}{An experiment was conducted where study participants were randomly divided into two groups. Both were given the opportunity to purchase a DVD, but one half was reminded that the money, if not spent on the DVD, could be used for other purchases in the future, while the other half was not. The half that was reminded that the money could be used on other purchases was 20\% less likely to continue with a DVD purchase. We determined that such a large difference would only occur about 1-in-150 times if the reminder actually had no influence on student decision-making. What is the p-value in this study? Was the result statistically significant?}
The p-value was 0.006 (about 1/150). Since the p-value is less than 0.05, the data provide statistically significant evidence that US college students were actually influenced by the reminder.
\end{nexample}
\end{examplewrap}

\begin{onebox}{What's so special about 0.05?}
We often use a threshold of 0.05 to determine whether a result is statistically significant. But why 0.05? Maybe we should use a bigger number, or maybe a smaller number. If you're a little puzzled, that probably means you're reading with a critical eye -- good job! We've made a video to help clarify \emph{why 0.05}:
\begin{center}
\oiRedirect{textbook-why05}{www.openintro.org/why05}
\end{center}
Sometimes it's a good idea to deviate from the standard. We'll discuss when to choose a threshold different than 0.05 in Section~\ref{significanceLevel}.\vspace{0.5mm}\end{onebox}

Statistical inference is the practice of making decisions and conclusions from data in the context of uncertainty. Just as a confidence interval may occasionally fail to contain the true value of the parameter, a test of hypothesis may occasionally lead us to an incorrect conclusion. While a given data set may not always lead us to a correct conclusion, statistical inference gives us tools to control and evaluate how often these errors occur.


\D{\newpage}

%%
\subsection{Calculating the p-value by simulation}
\label{calcPValueUsingSimulationSubSection}

When conditions for the applying a normal model are met, we use a normal model to find the p-value of a test of hypothesis. A more general approach, though, for calculating p-values when a normal model does not apply is to use what is known as \term{simulation}, the idea of which was introduced in Section~\ref{CLTintro}. While performing this procedure is outside of the scope of the course, we provide an example here that will help us better understand the concept of a p-value.

We simulate 142 new patients to see what result might happen if the complication rate really is 0.10. To do this, we could use a deck of cards. Take one red card, nine black cards, and mix them up. If the cards are well-shuffled, drawing the top card is one way of simulating the chance a patient has a complication if the true rate is 0.10: if the card is red, we say the patient had a complication, and if it is black then we say they did not have a complication. If we repeat this process 142 times and compute the proportion of simulated patients with complications, $\hat{p}_{sim}$, then this simulated proportion is exactly a draw from the null distribution.

There were 12 simulated cases with a complication and 130 simulated cases without a complication: $\hat{p}_{sim} = 12 / 142 = 0.085$.

One simulation isn't enough to get a sense of the null distribution, so we repeated the simulation 10,000 times using a~computer. Figure~\ref{MedConsNullSim} shows the randomization distribution from these 10,000 simulations. The simulated proportions that are less than or equal to $\hat{p}=0.063$ are shaded. There were 0.0877 simulated sample proportions with $\hat{p}_{sim} \leq 0.063$, which represents a fraction 0.0877 of our simulations:
\begin{align*}
\text{left tail }
	= \frac{\text{Number of observed simulations with }\hat{p}_{sim}\leq\text{ 0.063}}{10000}
	= \frac{877}{10000} = 0.0877
\end{align*}
However, this is not our p-value! Remember that we are conducting a two-sided test, so we should double the one-tail area to get the p-value:\footnote{This doubling approach is preferred even when the distribution isn't symmetric, as in this case.}
\begin{align*}
\text{p-value} = 2 \times \text{left tail} = 2 \times 0.0877 = 0.1754
\end{align*}

\begin{figure}[ht]
\centering
\Figure[A histogram with mean 0.10 and standard deviation of 0.05 is shown.  It is a graph of the sample proportions from a simulation run 10,000 times with samples of size 142 from a population with p = 0.1.  A normal approximation is overlaid and fits the histogram quite well.  The area to the left of 0.0877 and to the right of 0.1754 are shaded, corresponding to the p-value for the test with a two-sided alternative hypothesis.]
{0.8}{MedConsNullSim}
\caption{The null distribution or randomization distribution for $\hat{p}$, created from 10,000 simulated studies. The left tail contains 8.77\% of the simulations. For a two-sided test, we double the tail area to get the p-value. This doubling accounts for the observations we might have observed in the upper tail, which are also at least as extreme (relative to 0.10) as what we observed, $\hat{p} = 0.063$.}
\label{MedConsNullSim}
\end{figure}

\newpage
\subsection{Checking conditions and carrying out a test for a proportion}

Now that we have discussed the basic logic and framework for hypothesis testing, we consider the conditions and calculations necessary for a hypothesis test for a proportion.

\begin{examplewrap}
\begin{nexample}{Deborah Toohey is running for Congress.  A large campaign donor will choose to support Toohey if they are confident that she has a majority of support from the district's electorate and so is more likely to win.   A research team collects a random sample of 500 likely voters in the district and estimates Toohey's support to be 52\%.  Identify the parameter of interest and the hypotheses to be tested. What value should we use as the null value, $p_{0}$?}
\label{TooheyTestNameAndConditionExample}
%(a) The name of the test we will use is the \emph{1-proportion Z-test}. \\[2mm]
The parameter of interest is $p$:  the true proportion of support for Deborah Toohey among likely voters in the district.  The alternative hypothesis, the one that bears the burden of proof, argues that Toohey has more than 50\% support. Therefore, $H_A$ will be one-sided and the null value will be $p_0 = 0.5$. So we have:
\begin{itemize}
\item[] $H_0$: $p = 0.5$
\item[] $H_A$: $p > 0.5$. 
\end{itemize}
Note that the hypotheses are about a population parameter.  The hypotheses are never about the sample.
\end{nexample}
\end{examplewrap}

To calculate the p-value for this test, we will first calculate a test statistic, which takes the general form:
\begin{align*}
\text{test statistic} = \frac{\text{point estimate} - \text{null value}}{SE \text{ of estimate}}
\end{align*}

When conditions for a normal model are met, the test statistic is called a Z-statistic and the test is called a Z-test.  The conditions for a normal model for a \termni{one-sample Z-test for p}, a population proportion, are:
\begin{description}
\setlength{\itemsep}{0mm}
\item[Independence.] Data should be collected using a random sample or process.  If sampling without replacement, the sample size must be less than 10\% of the population size, i.e. $n < 0.10(N)$.  
\item[Large counts.] The expected number of success and expected number of failures, assuming $H_0$ is true must be at least 10, i.e. $np_0 \ge 10$ and $n(1-p_0) \ge 10$. 
\end{description}


These conditions will look familiar: they are very similar to the ones we used for the confidence interval for a proportion.  The only difference is that for the confidence interval we use the sample proportion for the large counts check, whereas for the hypothesis test we use the null proportion for the large counts check.  

\begin{examplewrap}
\begin{nexample}{Check whether conditions for using a normal model are met in the Deborah Toohey example.}
First, we observe that the problem states that a random sample was chosen.  We will assume that the size of the electorate in Toohey's district is more than 10 times the size of the sample, that is will assume that the size of the electorate in her district is greater than $10\times 500=5,000$.  Next, we check the large counts condition.    Because we assume that $p = p_0$ for the calculations of the hypothesis test, we use the hypothesized value $p_0$ rather than the sample value $\hat{p}$ when verifying the large counts condition.  
\begin{align*}
np_0 &\geq 10 \quad \rightarrow \quad 500(0.5) \geq 10 \\
n(1-p_0) &\geq 10 \quad \rightarrow \quad 500(1-0.5) \geq 10
\end{align*}
The conditions for a normal model are met.
\end{nexample}
\end{examplewrap}

\begin{onebox}{Confidence intervals versus hypothesis tests for a single proportion}
one-sample Z-interval for p:
\begin{align*}
\text{Check:  } n\hat{p}\ge 10 \text{ and }n(1-\hat{p})\ge 10 \qquad \text{Use:  }SE_{\hat{p}} = \sqrt{\frac{\ \hat{p}(1-\hat{p})\ }{n}}
\end{align*}
one-sample Z-test for p:
\begin{align*}
\text{Check:  } np_0\ge 10 \text{ and } n(1-p_0)\ge 10 \qquad \text{Use:  }SE_{\hat{p}} = \sqrt{\frac{\ p_0(1-p_0)\ }{n}}
\end{align*}
\end{onebox}


With the conditions met, we can calculate the test statistic. 
\begin{align*}
\text{test statistic} = \frac{\text{point estimate} - \text{null value}}{SE \text{ of estimate}}
\end{align*}
\begin{itemize}
\item The test statistic here is a Z-statistic.
\item The point estimate is the sample proportion $\hat{p}$ (same as for a confidence interval).
\item The null value is $p_0$.
\item We compute the test statistic assuming the null hypothesis is true, that is that $p = p_0$.  Because we have a hypothesized value $p_0$, we use it in place of $\hat{p}$ for the standard error calculation as follows: $\sqrt{\frac{p_0(1-p_0)}{n}}$.  This is essentially $\sigma_{\hat{p}}$, with $p_0$ substituted in for $p$.  For a one-sample Z-test, we compute the test statistic as follows:
\begin{align*}
Z = \frac{\hat{p} - p_0}{\sqrt{\frac{p_0(1-p_0)}{n}}}
\end{align*}
\end{itemize}

\begin{examplewrap}
\begin{nexample}{(Continues previous example). A large campaign donor will choose to support Toohey for Congress if they are confident that she has a majority of support from the district's electorate.   A research team collects a random sample of 500 likely voters in the district and finds that 52\% of 500 likely voters who were sampled support Toohey. Does this provide convincing evidence, at the 5\% significance level, that Tahooey has more than 50\% support among all likely voters in the district?}\label{TooheyInferenceExample}
We will use a one-sample Z-test for $p$, where\\
$p$:  the true proportion of support for Deborah Toohey among likely voters in the district.
\begin{itemize}
\item[$H_0$:] $p = 0.5$. Toohey's support is 50\%.
\item[$H_A$:] $p > 0.5$. Toohey's support is higher than 50\%.
\end{itemize}
We will use a significance level of $\alpha = 0.05$ for the test. 
%\begin{align*}
%\text{Assuming }p = 0.5, \ SE_{\hat{p}} = \sqrt{\frac{\ 0.5 (1 - 0.5\ )}{500}} = 0.022
%\end{align*}
The test statistic can be computed as:
\begin{align*}
Z = \frac{\hat{p} - p_0}{\sqrt{\frac{p_0(1-p_0)}{n}}} =\frac{0.52 - 0.5}{\sqrt{\frac{0.5(0.5)}{500}}}= \frac{0.52 - 0.5}{0.022} = 0.89
\end{align*}
Because the alternative hypothesis uses a greater than sign ($>$), this is an upper-tail test.  We find the area under the standard normal distribution to the \emph{right} of $Z=0.89$.  Figure~\ref{pValueForCampaignManagerClaimOfMoreThan50PercentSupport} shows the p-value as the shaded region. 
\end{nexample}
\end{examplewrap}


\begin{figure}[h]
\centering
\Figure[A standard normal distribution is shown, with the area to the right of 0.89 shaded.  The shaded area appears to be about 20\% of the area under the distribution.]
{.48}{pValueForCampaignManagerClaimOfMoreThan50PercentSupport}
\caption{Sampling distribution of the sample proportion if the null hypothesis is true for Example~\ref{TooheyInferenceExample}. The p-value for the test with $H_A$: $p > 0.5$ is shaded.}
\label{pValueForCampaignManagerClaimOfMoreThan50PercentSupport}
\end{figure}

\D{\newpage}

The p-value, which is the area under the standard normal distribution to the right of Z = 0.89, equals 0.19.  This p-value of 0.19 is greater than $\alpha = 0.05$, so we do not reject $H_0$. That is, we do not have sufficient evidence to support the claim that Tahooey has more than 50\% support within the district.  The campaign donor will not support her.

\begin{examplewrap}
\begin{nexample}{Based on the result above, do we have evidence that Toohey's support equals 50\%?}
No.  In a hypothesis test we look for degrees of evidence \emph{against} the null hypothesis.  We cannot ever prove the null hypothesis directly.  The value 0.5 is reasonable, but many other values are reasonable as well.  There are many values that would not get rejected by this test.
\end{nexample}
\end{examplewrap}

\begin{examplewrap}
\begin{nexample}{Interpret the p-value of 0.19 in the context of this problem}
There is a 19\% chance of getting a test statistic as large or larger than 0.89 assuming that the true proportion who support Toohey is 0.50 (i.e. assuming the null hypothesis is true).  Equivalently, we could say:  there is a 19\% chance of getting a sample proportion as large or larger than 0.52 assuming that the true proportion who support Toohey is 0.50. 
\end{nexample}
\end{examplewrap}

\newpage
\subsection{A four-step framework for hypothesis testing procedures}
When carrying out a formal hypothesis testing procedure, we will find it useful to use the same four-step framework introduced previously for confidence interval procedures.  The general framework is as follows:

\begin{itemize}
\setlength{\itemsep}{0mm}
\item \inferencestep{Identify}  Identify the appropriate test procedure, parameter, significance level, and \mbox{hypotheses.}
\item  \inferencestep{Check}  Check that the conditions for the test procedure are met. 
\item \inferencestep{Calculate} Calculate the test statistic and the p-value.  
\begin{align*}
\text{test statistic} = \frac{\text{point estimate } - \text{ null value}}{SE\ \text{of estimate}}
\end{align*}
\item \inferencestep{Conclude} Compare the p-value to the significance level to determine whether to reject $H_0$ or not reject $H_0$.  Draw a conclusion in the context of $H_A$.  
\end{itemize}

\noindent We will apply this framework to hypothesis testing for a single proportion as follows.

\begin{onebox}{Hypothesis testing for a proportion}
To carry out a complete hypothesis test to evaluate a claim about a population proportion,
\\
\\
%\inferencestep{Identify} Use a \termsub{one-sample Z-test for \pmb{$p$}}{Z-test!for a proportion}, where $p$ is a population proportion.  Define $p$ in the context of the problem.  Choose a significance level ($\alpha$) and test the following hypotheses.
%\vspace{1mm}\vspace{-1mm}
%\begin{itemize}
%\setlength{\itemsep}{0mm}
%\item[] \quad $H_0$: \,$p = p_0$  \quad ($p_0$ is the null or hypothesized value)
%\item[]  \quad $H_A$: $p \ne p_0$;  \; $p > p_0$; \; or \; $p < p_0$ 
%\end{itemize} 
\inferencestep{Identify} Identify the test procedure, parameter, significance level, and hypotheses.\vspace{-1mm}
\begin{itemize}
\item[] Use a \termsub{one-sample Z-test for \pmb{$p$}}{Z-test!for a proportion}.  Define the (unknown) population proportion $p$ in words, referencing the population of interest.  Choose a significance level ($\alpha$) and test the following hypotheses.
\end{itemize}\vspace{-4mm}
\begin{itemize}
\setlength{\itemsep}{0mm}
\item[]  \quad \ $H_0$: \,$p = p_0$
\item[]  \quad \ $H_A$: $p \ne p_0$;  \; $p > p_0$; \; or \; $p < p_0$ \qquad   ($p_0$ is the null or hypothesized proportion)
\end{itemize}
 \inferencestep{Check} Check conditions for the test statistic to be nearly normal, assuming $H_0$ is true.\vspace{-1mm}
{\setlength{\leftmargini}{13mm}
\begin{itemize}
\setlength{\itemsep}{0mm}
\item[1.]  Independence:  Data come from a random sample or random process.  When sampling 
without replacement, check that sample size is less than 10\% of the population size.
\item[2.] Large counts:  $np_0\ge 10$ and $n(1-p_0)\ge 10$
\end{itemize}
}
 \inferencestep{Calculate} Calculate the Z-statistic and p-value.
\begin{itemize}
\item[] $Z = \frac{\text{point estimate } - \text{ null value}}{SE \text{ of estimate}}$
\begin{itemize}
\item[] point estimate: $\hat{p}$, the sample proportion 
\item[] null value: $p_0$
\item[] $SE$ of estimate: $\sqrt{\frac{ p_0(1-p_0) }{n}}$ (use $p_0$ because we are assuming assuming $p=p_0$)
\end{itemize}
\item[] p-value = (based on the Z-statistic and the direction of $H_A$)
\end{itemize}
 \inferencestep{Conclude} Compare the p-value to $\alpha$, and draw a conclusion in context.  \vspace{-1mm}
\begin{itemize}
\item[] If the p-value is $\le \alpha$, reject $H_0$; there is sufficient evidence that [$H_A$ in context]. 
\item[] If the p-value is $> \alpha$, do not reject $H_0$; there is not sufficient evidence that [$H_A$ in context].
\end{itemize}\end{onebox}


%\begin{examplewrap}
%\begin{nexample}{A Gallup poll has been investigating each year since 1994 whether people favor or oppose nuclear energy.  Their poll conducted in 2025 found that 61\%
%    of respondents favor nuclear energy. (This was up from a low of 44\% that said they favor nuclear energy in 2016.)   
%    The survey was based on telephone interviews from a random sample of
%    1,019 adults in the United States.
%    Does this poll provide evidence that greater than half of US adults
%    favor nuclear energy?
%    Carry out an appropriate test at the 0.10 significance level.
%    Use the four-step framework to organize your work.}
%\label{NuclearEnergy}
%\begin{description}
%\item[\inferencestep{Identify}]  Because the hypotheses are about a single proportion, we choose the one-sample Z-test for $p$.  Here, $p$ is the proportion of all US adults that favor nuclear energy.  We will test the following hypotheses at the $\alpha=10\%$ significance level.
%\begin{itemize}
%\setlength{\itemsep}{0mm}
%\item[] $H_0$:\, $p = 0.5$  
%\item[]  $H_A$: $p > 0.5$ \quad Greater than half of all US adults favor nuclear energy.
%\end{itemize} 
%Note: $p>0.5$ is what we want to find evidence for; this bears the burden of proof, so this corresponds to $H_A$.
%\item[\inferencestep{Check}]  We must check the independence and success-failure conditions to show that the sample proportion can be modeled using a normal distribution.  The problem states that the data come from a random sample.  Again, the population is adults in the US, so the sample size of 1,019 is much smaller than 10\% of the population size.  Also, $1019(0.5)\geq10$ and $1019(1-0.5)\geq10$.  (Remember to use the hypothesized proportion, not the sample proportion, when checking the conditions for this test.)
%\item[ \inferencestep{Calculate} ]  We will calculate the Z-statistic and the p-value.
%\begin{align*}
%Z = \frac{\text{point estimate } - \text{ null value}}{SE \text{ of estimate}}
%\end{align*}
%
%The point estimate is the sample proportion: $\hat{p} = 0.61.$\\
%\\
%The value hypothesized for the parameter in $H_0$ is the null value: $p_0 = 0.5$\\
%\\
%The $SE$ of the sample proportion, assuming $H_0$ is true, is: $\sqrt{\frac{p_0(1-p_0)}{n}}= \sqrt{\frac{0.5(1-0.5)}{1019}}$ \\
%\begin{align*}
%Z = \frac{0.61 - 0.5}{\sqrt{\frac{0.5(1-0.5)}{1019}}} = 7.02
%\end{align*}
%Because $H_A$ uses a greater than sign ($>$), meaning that it is an upper-tail test, the \mbox{p-value} is the area to the \emph{right} of $Z=7.2$ under the standard normal distribution.  This area can be found using technology or a standard normal table.  The area or p-value $\approx 0$.  
%\item[\inferencestep{Conclude}]  The p-value of $\approx 0$ is $< 0.10$, so we reject $H_0$; there is sufficient evidence that greater than half of US adults favor nuclear energy (in 2025).  
%\end{description}
%\end{nexample}
%\end{examplewrap}




\begin{examplewrap}
\begin{nexample}{A certain convenience store currently stocks RC Cola (among other colas).  The manager is considering replacing RC Cola with Shasta Cola, but only if there is sufficient evidence that customers like Shasta Cola better.  To test this, the manager randomly chooses 30 customers from the store and offers each one a free can of either RC Cola or Shasta Cola and records which they choose.  Out of the 30 customers, 20 choose Shasta Cola.  At the 5\% significance level is there sufficient evidence that the customers at this convenience store prefer Shasta Cola to RC Cola?}
\label{NuclearEnergy}
\begin{description}
\item[\inferencestep{Identify}]  Because the hypotheses are about a single proportion, we choose the one-sample Z-test for $p$.  Here, $p$ is the proportion of all customers of this convenience store that prefer Shasta Cola to RC Cola.   We will test the following hypotheses at the $\alpha=0.05$ significance level.
\begin{itemize}
\setlength{\itemsep}{0mm}
\item[] $H_0$:\, $p = 0.5$ 
\item[]  $H_A$: $p > 0.5$ 
\end{itemize} 
\item[\inferencestep{Check}]  We must check the independence and large counts conditions.\\
- We will need to assume that the sample can be considered a random sample of all customers at this convenience store.  \\
- The sample size of 30 should be less than 10\% of all customers at this convenience store.   \\
- $30(0.5) = 15 \geq 10$ and $30(1-0.5) = 15 \geq 10$, so conditions for a normal model are met.  
\item[ \inferencestep{Calculate} ]  First we calculate the Z-statistic: $Z = \frac{\text{point estimate } - \text{ null value}}{SE \text{ of estimate}}$\\

The point estimate is the sample proportion: $\hat{p} = \frac{20}{30} = 0.667$, and the null value is: $p_0 = 0.5$. \\

The $SE$ of $\hat{p}$, assuming $H_0$ is true, is: $\sqrt{\frac{p_0(1-p_0)}{n}}= \sqrt{\frac{0.5(1-0.5)}{30}} = 0.0913$.
\begin{align*}
Z = \frac{0.667 - 0.5}{\sqrt{\frac{0.5(1-0.5)}{30}}} = 1.83
\end{align*}
 \begin{center}
  \Figure[A normal distribution with a mean of 0 and standard deviation of 1 has the area below the distribution shaded for horizontal values greater than 1.83.]
{0.3}{colas}
\end{center}
The p-value = 0.034, which corresponds to the area $\ge$ 1.83 under the standard normal distribution.
\item[\inferencestep{Conclude}]  The p-value = 0.034 $< 0.05$, so we reject $H_0$; there is sufficient evidence that customers of this convenience store prefer Shasta Cola to RC Cola.  
\end{description}
\end{nexample}
\end{examplewrap}



\begin{exercisewrap}
\begin{nexercise}
In context, interpret the p-value of 0.034 from the previous example.\footnotemark
\end{nexercise}
\end{exercisewrap}
\footnotetext{There is a 3.4\% chance of getting a test statistic as big or bigger than $1.83$ assuming the null hypothesis is true, i.e. that the proportion of all customers at this convenience store that prefer Shasta Cola to RC Cola is 50\%.}

\begin{exercisewrap}
\begin{nexercise}
If we had used a significance level of $\alpha=0.01$, would our conclusion be the same or would it be different?\footnotemark
\end{nexercise}
\end{exercisewrap}
\footnotetext{Because our p-value = 0.034 $>$ 0.010, we would not reject $H_0$ and we would not have sufficient evidence to conclude that customers of this convenience store prefer Shasta Cola to RC Cola.  With this stricter significance level, our p-value does not provide enough evidence for $H_A$ and we come to a different conclusion.  The choice of significance level is important and should be decided before seeing the data.}



%%
\subsection{Decision errors and power}
\index{hypothesis testing!decision errors|(}
The hypothesis testing framework is a very general tool, and we often use it without a second thought. If a person makes a somewhat unbelievable claim, we are initially skeptical. However, if there is sufficient evidence that supports the claim, we set aside our skepticism. The hallmarks of hypothesis testing are also found in the US court system. 

\begin{examplewrap}
\begin{nexample}{A US court considers two possible claims about a defendant: she is either innocent or guilty. If we set these claims up in a hypothesis framework, which would be the null hypothesis and which the alternative?}\label{hypTestCourtExample}
The jury considers whether the evidence is so convincing (strong) that there is evidence beyond a reasonable doubt of the person's guilt. That is, the starting assumption (null hypothesis) is that the person is innocent until evidence is presented that convinces the jury that the person is guilty (alternative hypothesis). In statistics, our evidence comes in the form of data, and we use the significance level to decide what is beyond a reasonable doubt.
\end{nexample}
\end{examplewrap}

Jurors examine the evidence to see whether it convincingly shows a defendant is guilty. Notice that a jury finds a defendant either guilty or not guilty. They either reject the null claim or they do not reject the null claim. They never prove the null claim, that is, they never find the defendant innocent. If a jury finds a defendant \emph{not guilty}, this does not necessarily mean the jury is confident in the person's innocence. They are simply not convinced of the alternative that the person is guilty.

This is also the case with hypothesis testing: \emph{even if we fail to reject the null hypothesis, we typically do not accept the null hypothesis as truth}. Failing to find strong evidence for the alternative hypothesis is not equivalent to providing evidence that the null hypothesis is true.


Hypothesis tests are not flawless. Just think of the court system: innocent people are sometimes wrongly convicted and the guilty sometimes walk free. Similarly, data can point to the wrong conclusion. However, what distinguishes statistical hypothesis tests from a court system is that our framework allows us to quantify and control how often the data lead us to the incorrect conclusion.

There are two competing hypotheses: the null and the alternative. In a hypothesis test, we make a statement about which one might be true, but we might choose incorrectly. There are four possible scenarios in a hypothesis test, which are summarized in Figure~\ref{fourHTScenarios}.

\begin{figure}[ht]
\centering
\begin{tabular}{l l c c c}
& & \multicolumn{2}{c}{\textbf{Test conclusion}} \\
  \cline{3-4}
\vspace{-3.7mm} \\
& & do not reject $H_0$ &  reject $H_0$ in favor of $H_A$ &
\ \hspace{7mm} \  \\
  \cline{2-4}
\vspace{-3.7mm} \\
& $H_0$ true & correct conclusion &  Type~I error \\
\raisebox{1.5ex}{\textbf{Truth}} & $H_A$ true & Type~II error & correct conclusion \\
  \cline{2-4}
\end{tabular}
\caption{Four different scenarios for hypothesis tests.}
\label{fourHTScenarios}
\end{figure}

\begin{onebox}{Type~I and Type~II errors}
A \term{Type~I error} is rejecting $H_0$ when $H_0$ is actually true. When we reject the null hypothesis, it is possible that we make a Type~I error. \\[2mm]
A \term{Type~II error} is failing to reject $H_0$ when $H_A$ is actually true. When we do not reject the null hypothesis, it is possible that we make a Type~II error.\end{onebox}



\begin{examplewrap}
\begin{nexample}{In a US court, the defendant is either innocent ($H_0$) or guilty ($H_A$). What does a Type~I error represent in this context? What does a Type~II error represent? Figure~\ref{fourHTScenarios} may be useful.}
If the court makes a Type~I error, this means the defendant is innocent ($H_0$ true) but wrongly convicted. A~Type~II error means the court failed to reject $H_0$ (i.e. failed to convict the person) when they were in fact guilty ($H_A$ true).
\end{nexample}
\end{examplewrap}

\begin{examplewrap}
\begin{nexample}{How could we reduce the Type~I error rate in US courts? What influence would this have on the Type~II error rate?}
To lower the Type~I error rate, we might raise our standard for conviction from ``beyond a reasonable doubt'' to ``beyond a conceivable doubt'' so fewer people would be wrongly convicted. However, this would also make it more difficult to convict the people who are actually guilty, so we would make more Type~II errors.
\end{nexample}
\end{examplewrap}

\begin{exercisewrap}
\begin{nexercise} \label{howToReduceType2ErrorsInUSCourts}
How could we reduce the Type~II error rate in US courts? What influence would this have on the Type~I error rate?\footnotemark
\end{nexercise}
\end{exercisewrap}
\footnotetext{To lower the Type~II error rate, we want to convict more guilty people. We could lower the standards for conviction from ``beyond a reasonable doubt'' to ``beyond a little doubt''. Lowering the bar for guilt will also result in more wrongful convictions, raising the Type~I error rate.}

\begin{exercisewrap}
\begin{nexercise}
A group of women bring a class action lawsuit that claims discrimination in promotion rates. What would a Type~I error represent in this context?\footnotemark
\end{nexercise}
\end{exercisewrap}
\footnotetext{We must first identify which is the null hypothesis and which is the alternative. The alternative hypothesis is the one that bears the burden of proof, so the null hypothesis is that there was no discrimination and the alternative hypothesis is that there was discrimination. Making a Type~I error in this context would mean we concluded that women were discriminated against when in fact there was no discrimination. Notice that this does \emph{not} necessarily mean something was wrong with the data or that we made a computational mistake. Sometimes data simply point us to the wrong conclusion, which is why scientific studies are often repeated to check initial findings.}

\index{hypothesis testing!decision errors|)}

These examples provide an important lesson: if we reduce how often we make one type of error, we generally make more of the other type.

%Hypothesis testing is built around rejecting or failing to reject the null hypothesis. That is, we do not reject $H_0$ unless the data provide strong evidence against it. But what precisely does \emph{strong evidence} mean? As a general rule of thumb, for those cases where the null hypothesis is actually true, we do not want to incorrectly reject $H_0$ more than 5\% of the time. This corresponds to our default significance level of $\alpha = 0.05$, which we use as a comparison with the p-value. In the next section, we discuss the appropriateness of different significance levels.



\label{significanceLevel}

\index{hypothesis testing!significance level|(}
\index{significance level|(}

If $H_0$ is true, what is the probability that we will incorrectly reject it? In hypothesis testing, we perform calculations under the premise that $H_0$ is true, and we reject $H_0$ if the p-value is less than or equal to the significance level $\alpha$. That is, $\alpha$ \emph{is} the probability of making a Type~I error. The choice of what to make $\alpha$ is not arbitrary. It depends on the gravity of the consequences of a Type~I error.

\begin{onebox}{Relationship between Type~I and Type~II errors}
The probability of a Type~I error is called $\alpha$ and corresponds to the significance level of a test.  If we make $\alpha$ smaller (P(Type~I error) smaller), P(Type~II error) gets larger; if we make  $\alpha$ larger (P(Type~I error) larger), P(Type~II error) gets smaller  .\end{onebox}

\begin{examplewrap}
\begin{nexample}{If making a Type~I error is especially dangerous or especially costly, should we choose a smaller significance level or a higher significance level?}
Under this scenario, we want to be very cautious about rejecting the null hypothesis, so we demand very strong evidence before we are willing to reject the null hypothesis. Therefore, we want a smaller significance level, maybe $\alpha = 0.01$.
\end{nexample}
\end{examplewrap}

\begin{examplewrap}
\begin{nexample}{If making a Type~II error is especially dangerous or especially costly, should we choose a smaller significance level or a higher significance level?}
We should choose a higher significance level (e.g. 0.10). Here we want to be cautious about failing to reject $H_0$ when the null is actually false.
\end{nexample}
\end{examplewrap}

\begin{onebox}{Significance levels should reflect consequences of errors}
The significance level selected for a test should reflect the real-world consequences associated with making a Type~I or Type~II error. If a Type~I error is very dangerous, make $\alpha$ smaller.\end{onebox}

\index{hypothesis testing!significance level|)}
\index{significance level|)}


The power of a test is an important concept in hypothesis testing.  The \term{power} of a test is the probability that a hypothesis test will correctly reject a false null hypothesis.  Stated another way, the power of a test is the probability of correctly detecting an effect of a particular size when it is present.  It is common for researchers to perform a \hiddenterm{power analysis} to ensure their study collects enough data to detect the effects they anticipate finding. As you might imagine, if the effect they care about is small or subtle, the researchers will need to collect a large sample size in order to have a good chance of detecting the effect if it is real. However, if the effect they are interested in is large, they do not need to collect as much data.


\begin{onebox}{The power of a  test and the probability of a Type~II error are complements }
P(Type~II error) = 1 $-$ power; \quad power = 1 $-$ P(Type~II error)
\end{onebox}

The Type~II error rate and the magnitude of the error for a point estimate are controlled by the sample size. As the sample size $n$ goes up, the Type~II error rate goes down, and power goes up. Real differences from the null value, even large ones, may be difficult to detect with small samples. However, if we take a very large sample, we might find a statistically significant difference but the size of the difference might be so small that it is of no practical value.  The size of the effect and the standard error also affect the probability of a Type~II error.  We can summarize this as follows.

\begin{onebox}{Factors that affect the probability of a Type~II error and power}
The probability of a Type II~error decreases and the power increases
when any one of the following occurs, provided the others do not change:
\begin{itemize}\vspace{-1mm}
\setlength{\itemsep}{0mm}
\item[i. ] Sample size(s) increase.
\item[ii. ] Standard error decreases.
\item[iii. ] True parameter value is farther from the null hypothesis.
\item[iv. ] Significance level $\alpha$ of a test increases.  
\end{itemize}
\end{onebox}


The role of a data scientist in conducting a study often includes planning the size of the study. The data scientist might first consult experts or scientific literature to learn what would be the smallest meaningful difference from the null value. She also would obtain some reasonable estimate for the standard deviation. With these important pieces of information, she would choose a sufficiently large sample size so that the power for the meaningful difference is perhaps 80\% or 90\%. While larger sample sizes may still be used, she might advise against using them in some cases, especially in sensitive areas of research, such as a high-risk clinical trial where a new drug is being tested.

When a result is statistically significant at the $\alpha=0.05$ level, we have evidence that the result is real.
However, when there is no difference or effect, we can expect that 5\% of the time the test conclusion will lead to a Type~I error and incorrectly reject the null hypothesis.
Therefore we must beware of what is called p-hacking, in which researchers may test many, many hypotheses and then publish the ones that come out statistically significant.
As we noted, we can expect 5\% of the results to be significant when the null hypothesis is true even if there is no difference or effect.\footnote{
The problem is even greater than p-hacking.  In what has been called the ``reproducibility crisis", researchers have failed to reproduce a large proportion of results that were found significant and were published in scientific journals.
This problem highlights the importance of research that
reproduces earlier work. Ideally, one would be familiar with multiple studies on a topic, rather than taking the word of
a single study.

}
\index{hypothesis testing|)}

\newpage
%%%%

\subsection[Technology: the one-sample Z-interval and Z-test for $p$]{Technology: the one-sample Z-interval and Z-test for \pmb{$p$}}
\label{tech1Z}

\noindent Evaluate the 95\% confidence interval from Example~\ref{IntelligentLife} to estimate the proportion of US adults who think there is intelligent life on other planets.  Also find the test statistic and p-value for a test to see if there is evidence that the true proportion differs from 0.70.  The sample percent was 68\% and the sample~size was 1,033.  Conditions were verified to be met.
\\

\noindent \textbf{Desmos}:  Use the \texttt{zproptest(x, n)} function as explained below.
\begin{enumerate}
\setlength{\itemsep}{0mm}
\item Click \calctext{+} in the upper left, then choose \calctext{inference}.  
\item Choose \calctext{$z$-test for proportions} in the pop-up window.
\begin{center}
\fbox{\Figures[A Desmos calculator screen is shown. The + and inference option are highlighted. ]
{0.3}{technologyInferenceProps}{desmosInference}}\hspace{10mm}
\fbox{\Figures[A Desmos calculator screen is shown with the inference pop-up box. z-test for proportions is highlighted. ]
{0.3}{technologyInferenceProps}{desmosInferenceZTest}}
\end{center}

\item Enter \calctext{successes} (x) and \calctext{sample size} (n).  Here, successes $= 0.68 * 1,033 = 702.44$, and we need to round this to an integer.  So we enter 702 for successes and 1033 for sample size.  Click \calctext{Create Test}.
\begin{center}
\fbox{\Figures[A Desmos calculator screen shows a z-test for proportions box with 702 entered for successes and 1033 entered for sample size.  ]
{0.55}{technologyInferenceProps}{desmos1PropData}}
\end{center}

\indent\hspace{-4mm} * You can type \calctext{zproptest(702, 1033)} in place of steps 1-3 above.
\vspace{1mm}
\item Click the triangle next to \calctext{Confidence Interval} and input the desired \calctext{Confidence level}.  Here we use 0.95, which is entered by default.  Click the \calctext{\vdots } to the right of the confidence interval to see more information.  Hover over the dot in the middle of the confidence interval to see the point estimate.  
\item Click the triangle next to \calctext{Significance Test}.  Enter the hypothesized value for \calctext{p} and select \calctext{Tails} to be \calctext{Left}, \calctext{Right} or \calctext{Both} depending on the direction of the alternative hypothesis.  Here the hypothesized value of p is 0.70 and $H_A$ uses a $\ne$, so we select Tails to be Both.  
\begin{center}
\fbox{\Figures[A Desmos calculator screen is shown.  zproptest(702, 1033) is entered.  Confidence interval is selected with Confidence level: 0.95.  The three vertical dots are also clicked showing Lower bound = 0.65112, Upper bound = 0.70803, Point estimate = 0.67957, and Standard error = 0.01452.]
{0.35}{technologyInferenceProps}{desmos1PropCI}}\hspace{5mm}
\fbox{\Figures[A Desmos calculator screen is shown with zproptest(702, 1033) entered. Significance Test is selected with $p=0.70$ and Tails set to Both.  The Z-statistic is -1.433 and the p-value is 0.152.  A normal distribution is shown with the area to the left of -1.433 and to the right of 1.433 shaded.]
{0.35}{technologyInferenceProps}{desmos1PropTest}}
\end{center}
\end{enumerate}
\newpage
%%
\noindent \R{}:  1-sample Z-interval/test for $p$\\
\\
\noindent CONFIDENCE INTERVAL.\\
\texttt{> \calctext{prop.test(x = 702, n = 1033, correct = FALSE, conf.level = 0.95)}\footnote{R uses a different formula for calculating the one proportion interval/test than what is presented in this textbook.  Results may differ slightly from Desmos and handheld calculators.}\\
	1-sample proportions test without continuity correction\\
data:  702 out of 1033, null probability 0.5\\
X-squared = 133.24, df = 1, p-value < 0.00000000000000022\\
alternative hypothesis: true p is not equal to 0.5\\
95 percent confidence interval:\\
\fbox{ 0.6504973 0.7073202}\\
sample estimates:\\
        p \\
0.6795741\\ 
}\\ 

\noindent HYPOTHESIS TEST.\\
\noindent Make sure to specify \texttt{p}, the hypothesized or null proportion. \\
 \texttt{alternative} can be \texttt{"two.sided"}, \texttt{"greater"}, or \texttt{"less"}.\\

\noindent \texttt{> \calctext{prop.test(x = 702, n = 1033, p = 0.70, correct = FALSE, alternative = "two.sided")}\\
	1-sample proportions test without continuity correction\\
data:  702 out of 1033, null probability 0.7\\
\fbox{X-squared = 2.0523}, df = 1, \fbox{p-value = 0.152}\\
alternative hypothesis: true p is not equal to 0.7\\
95 percent confidence interval:\\
 0.6504973 0.7073202\\
sample estimates:\\
        p \\
0.6795741\\ 
}\\ 
This test returns X-squared instead of Z.   
\\Z = $+\sqrt{\texttt{X-squared}}$ or $-\sqrt{\texttt{X-squared}}$, depending on if \mbox{\texttt{(sample p $-$ null p)}} is $+$. or $-$. 
\\ Here (0.6504973 $-$ 0.70) is negative, so Z = $-\sqrt{2.0523}$.\\ \\
\texttt{> \calctext{Z = $-$sqrt(2.0523)}}\\
\texttt{> \calctext{Z}}\\
\texttt{[1] $-$1.432585}\\ \\

\noindent A note on default values:
\begin{itemize}
\setlength{\itemsep}{0mm}
\item If \texttt{p} is omitted a default null value of 0.5 is used.  
\item If \texttt{correct = FALSE} is omitted, what is called the ``continuity correction" will be applied.
\item If \texttt{alternative} is omitted, a default value of \texttt{"two.sided"} is used.  
\item If \texttt{conf.level} is omitted, a default value of 0.95 is used.
\end{itemize}

\newpage
%%

\noindent \textbf{Calculator}:  NumWorks calculator instructions and example output are included.  For the TI-83/84 and Casio calculators, general instructions are provided, and worked example videos can be accessed via the \includegraphics[height=3mm]{extraTeX/icons/video_camera.png} icon or at \oiRedirect{ti84_playlist}{\textbf{openintro.org/ti}} and \oiRedirect{casio-9750-playlist}{\textbf{openintro.org/casio}}.\\ 
\\
\label{1PropZInt}

\begin{onebox}{NumWorks: 1-proportion Z-interval}
\label{normalnumworks}
Use \calctext{OK} or \calctext{EXE} to make a selection.
\begin{enumerate}
\setlength{\itemsep}{0mm}
\item From the home screen, select \calcbutton{Inference}, then \calctext{Intervals}, then \calctext{One proportion}.  If these options do not appear, click the \calcbutton{$\lhookleftarrow$} button in the upper right as many times as needed. 
\item Enter the values of \calctext{x}, \calctext{n}, and \calctext{Confidence level}.  Hit the down arrow and choose \calcbutton{Next}. 
\item Note the quantities returned.  Click the down arrow and choose \calctext{Next}.
\item In addition to seeing the confidence interval displayed in two ways, you can press the up and down arrows to quickly change confidence level and see the resulting interval and margin of error.
\begin{center}
\Figures[ ]
{0.35}{technologyInferenceProps}{numworks1PropCI1}\hspace{10mm}
\Figures[ ]
{0.35}{technologyInferenceProps}{numworks1PropCI2}
\end{center}
\vspace{-1.5mm}
\end{enumerate}
\end{onebox}
%
\begin{onebox}{NumWorks: 1-proportion Z-test}
\label{normalnumworks}
Use \calctext{OK} or \calctext{EXE} to make a selection.
\begin{enumerate}
\setlength{\itemsep}{0mm}
\item From the home screen, select \calcbutton{Inference}, then \calctext{Tests}, then \calctext{One proportion}.  If these options do not appear, click the \calcbutton{$\lhookleftarrow$} button in the upper right as many times as needed. 
\item Enter the value of the hypothesized proportion for the Null hypothesis.  Press the down arrow.  Press \calcbutton{OK} and choose \calctext{$<$}, \calctext{$\ne$} , or \calctext{$>$}  for the Alternative hypothesis.  Press the down arrow and choose \calcbutton{Next}. 
\item Enter the values of \calctext{x}, \calctext{n}, and \calctext{$\alpha$}.  Hit the down arrow and choose \calcbutton{Next}. 
\item Note the quantities returned.  Click the down arrow and choose \calctext{Next}.
\item On this screen, the p-value and alpha are shaded on the normal distribution and can be visually compared.
\begin{center}
\fbox{\Figures[ ]
{0.35}{technologyInferenceProps}{numworks1PropTest2}}\hspace{10mm}
\Figures[ ]
{0.35}{technologyInferenceProps}{numworks1PropTest2}
\end{center}
\vspace{-1.5mm}
\end{enumerate}
\end{onebox}
%%

\begin{onebox}{\videohref{ti84_1_prop_CI} TI-83/84: 1-proportion Z-interval}
Use \calcbutton{STAT}, \calctext{TESTS}, \calctext{1-PropZInt}.
\begin{enumerate}
\setlength{\itemsep}{0mm}
\item Choose \calcbutton{STAT}.
\item Right arrow to \calctext{TESTS}.
\item Down arrow and choose \calctext{A:1-PropZInt}.
\item Let \calctext{x} be the \emph{number} of yeses (must be an integer).
\item Let \calctext{n} be the sample~size.
\item Let \calctext{C-Level} be the desired confidence level.
\item Choose \calctext{Calculate} and hit \calcbutton{ENTER}, which returns\\[1mm]
\begin{tabular}{l l}
\calctext{(\underline{\ \ },\underline{\ \ })} & the confidence interval \\
$\calctextmath{\hat{p}}$ & the sample proportion \\
\calctext{n} & the sample~size
\end{tabular}
\end{enumerate}
\end{onebox}
%

\begin{onebox}{\videohref{ti84_1_prop_HT} TI-83/84: 1-proportion Z-test}
Use \calcbutton{STAT}, \calctext{TESTS}, \calctext{1-PropZTest}.
\begin{enumerate}
\setlength{\itemsep}{0mm}
\item Choose \calcbutton{STAT}.
\item Right arrow to \calctext{TESTS}.
\item Down arrow and choose \calctext{5:1-PropZTest}.
\item Let $\calctextmath{p_0}$ be the null or hypothesized value of p.
\item Let \calctext{x} be the \emph{number} of yeses (must be an integer).
\item Let \calctext{n} be the sample~size.
\item Choose $\calctextmath{\ne}$, $\calctextmath{<}$, or $\calctextmath{>}$ to correspond to $H_A$.
\item Choose \calctext{Calculate} or \calctext{Draw} and hit \calcbutton{ENTER}.  \calctext{Draw} shows the Z-statistic and p-value as well as a graph of the normal curve with p-value shaded.  \calctext{Calculate} returns: \\[1mm]
\begin{tabular}{l l}
\calctext{z} & Z-statistic \\
\calctext{p} & p-value \\
$\calctextmath{\hat{p}}$ &  the sample proportion \\
\calctext{n} & the sample~size
\end{tabular}
\end{enumerate}
\end{onebox}

\newpage
%%
\begin{onebox}{\videohref{casio_1_prop_inference} Casio fx-9750GII: 1-proportion Z-interval}
\ \vspace{-5mm} \
% Quick navigation: \calctext{STAT} (via \calcbutton{MENU} button), \calctext{INTR}, \calctext{Z}, and \calctext{1-P}.
\begin{enumerate}
\setlength{\itemsep}{0mm}
\item Navigate to \calctext{STAT} (\calcbutton{MENU} button, then hit the \calcbutton{2} button or select \calctext{STAT}).
\item Choose the \calctext{INTR} option (\calcbutton{F4} button).
\item Choose the \calctext{Z} option (\calcbutton{F1} button).
\item Choose the \calctext{1-P} option (\calcbutton{F3} button).
\item Specify the interval details:\vspace{-1.5mm}
  \begin{itemize}
  \setlength{\itemsep}{0mm}
  \item Confidence level of interest for \calctext{C-Level}.
  \item Enter the number of successes, \calctext{x}.
  \item Enter the sample~size, \calctext{n}.
  \end{itemize}
\item Hit the \calcbutton{EXE} button, which returns \\[1mm]
  \begin{tabular}{ll}
  \calctext{Left}, \calctext{Right} & ends of the confidence interval \\
  $\calctextmath{\hat{p}}$ & sample proportion \\
  \calctext{n} & sample~size
  \end{tabular}
\end{enumerate}
\end{onebox}
%

\begin{onebox}{\videohref{casio_1_prop_inference} Casio fx-9750GII: 1-proportion Z-test}
%Quick navigation: \calctext{STAT} (via \calcbutton{MENU} button), \calctext{TEST}, \calctext{Z}, and \calctext{1-P}.
The steps closely match those of the 1-proportion confidence interval.
\begin{enumerate}
\setlength{\itemsep}{0mm}
%\item Navigation is nearly the same as for the 1-proportion confidence interval: \\
\item Navigate to \calctext{STAT} (\calcbutton{MENU} button, then hit the \calcbutton{2} button or select \calctext{STAT}).
\item Choose the \calctext{TEST} option (\calcbutton{F3} button).
\item Choose the \calctext{Z} option (\calcbutton{F1} button).
\item Choose the \calctext{1-P} option (\calcbutton{F3} button).
%  navigate to \calctext{STAT} using the \calcbutton{MENU} button,
%  then go to \calctext{TEST} (instead of \calctext{INTR}),
%  choose \calctext{Z}, and
%  then choose \calctext{1-P}.
\item Specify the test details:
  \begin{itemize}
  \setlength{\itemsep}{0mm}
  \item Specify the sidedness of the test using the \calcbutton{F1}, \calcbutton{F2}, and \calcbutton{F3} keys.
  \item Enter the null value, \calctext{p0}.
  \item Enter the number of successes, \calctext{x}.
  \item Enter the sample~size, \calctext{n}.
  \end{itemize}
\item Hit the \calcbutton{EXE} button, which returns \\[1mm]
  \begin{tabular}{ll}
  \calctext{z} &  Z-statistic \\
  \calctext{p} &  p-value \\
  $\calctextmath{\hat{p}}$ &  the sample proportion \\
  \calctext{n} &  the sample~size
  \end{tabular}
\end{enumerate}
\end{onebox}

\index{Z-test!for a proportion|)}







\newpage	

%%%%%%%%
\subsection*{Section summary}

\begin{itemize} 

\item A \termni{hypothesis test} is a statistical inference procedure used to evaluate competing claims based on data in order to make a decision.

\item The appropriate hypothesis test for a population proportion $p$ is a 
\mbox{\termni{one-sample $Z$-test for p}.}  The parameter $p$ should be identified in context.

\item The competing claims are called \term{hypotheses}.   \vspace{-1mm}
\begin{itemize}
\item The \termni{null hypothesis} is abbreviated $H_0$ and is a statement
about a parameter that is assumed to be correct unless there is convincing
statistical evidence suggesting otherwise. It is the status quo condition.
\item The \termni{alternative hypothesis} is abbreviated $H_A$ and is the claim or belief about a parameter for which evidence is being collected. A researchers claim or belief about the population parameter is represented by the alternative hypothesis.
\end{itemize}

\item The null hypotheses for a one-sample $Z$-test for a population proportion $p$ is:  
\begin{itemize}
\setlength{\itemindent}{3mm}
\item[$H_0$:] $p=p_0$, where $p_0$ is the null hypothesized value for the population mean.
\end{itemize}
\item[]The null hypothesis is sometimes written using a $\le$ or a $\ge$, but we will always use the equality.


\item The alternative hypothesis may be one-sided ($<$ or $>$) or two-sided ($\ne$).
\begin{itemize}
\setlength{\itemindent}{3mm}
\item[$H_A$:] $p<p_0$.  The p-value will correspond to a lower tail.
\item[$H_A$:] $p>p_0$.   The p-value will correspond to an upper tail.
\item[$H_A$:]$p\ne p_0$.  The p-value will correspond to both tails.
\end{itemize}

\item We set a \term{significance level}, denoted $\alpha$, that determines the probability of rejecting the null hypothesis given that it is true.  The most common significance level is $\alpha = 0.05$.  If we want to require more evidence to reject the null hypothesis, we use a smaller $\alpha$.

\item The \term{logic of a hypothesis test}\index{hypothesis test!logic of}:  In a hypothesis test, we begin by \textit{assuming that the null hypothesis is true}.  Then, we calculate how unlikely it would be to get a sample value as extreme as we actually got in our sample, in the direction of $H_A$, assuming that the null value is correct.  If this likelihood is too small (below our $\alpha$ threshold), it casts doubt on the null hypothesis and provides evidence for the alternative hypothesis.

\item The one-sample $Z$-test for a population proportion requires the following \termni{conditions} be met:  \vspace{-3mm}
\begin{itemize}
\item[1.] Independence:  The data come from a random sample or random process.  When sampling without replacement, check that the sample size is less than 10\% of the population size ($n<0.10(N)$).
\item[2.] Large counts: the expected number of successes and failures assuming the null hypothesis is true is at least 10.  $np_0\ge 10$ and $n(1-p_0)\ge 10$.
\end{itemize}

\item A \termni{test statistic} has the form: test statistic $= \frac{\text{point estimate } - \text{ null value}}{SE \text{ of estimate}}$.  \\

The test statistic for a one-sample $Z$-test for $p$ is: $Z = \frac{\hat{p} - p_0}{\sqrt{\frac{p_0(1-p_0)}{n}}}$.\\
The $SE$ is calculated under the assumption that $H_0$ is true and uses $p_0$.


\item The \termni{p-value} for a one-sample $Z$-test for $p$ is the probability of obtaining a $Z$-statistic as small or smaller, as large or larger, or as extreme or more extreme than the $Z$-statistic that was observed, depending on whether the direction of the alternate hypothesis is $<$, $>$, or $\ne$, assuming the null hypothesis is true (i.e. that the population proportion really equals $p_0$).  

\item Small p-values indicate that the observed value of the test statistic would be
unusual if the null hypothesis were true and therefore provide evidence for
the alternative hypothesis. The lower the p-value, the more convincing the
statistical evidence for the alternative hypothesis.

\item p-values that are not small indicate that the observed value of the test statistic
would not be unusual if the null hypothesis were true and therefore do not
provide convincing statistical evidence for the alternative hypothesis, nor do
they provide evidence that the null hypothesis is true.



\item The conclusion or decision of a hypothesis test is based on whether the p-value is smaller or larger than the preset significance level $\alpha$. \vspace{-1mm}
\begin{itemize}
\item When the  p-value $\le \alpha$, we reject $H_0$ and have convincing statistical evidence for $H_A$.  We say the results are \emph{statistically significant} at the $\alpha$ level.
\item When the  p-value $> \alpha$, we fail to reject $H_0$ and we do not have convincing statistical evidence for $H_A$.  We say the results are not statistically significant at the $\alpha$ level. 
\end{itemize}

\item A hypothesis test can lead to rejecting or not rejecting the null hypothesis but
can never lead to concluding or proving that the null hypothesis is true. Lack of
statistical evidence for the alternative hypothesis is not the same as evidence
for the null hypothesis.

\item The results of a hypothesis test for a population proportion can serve as the
statistical reasoning to support the answer to an investigative question about
the population that was sampled. The conclusion of a hypothesis test should be stated in terms of the alternative hypothesis and in context using non-causal language.  


\item \termni{Decision errors}.  In a hypothesis test, there are two types of decision errors that could be made.  These are called Type~I and Type~II errors. \vspace{-1mm}
\begin{itemize}
\item A \term{Type~I error} is rejecting $H_0$, when $H_0$ is actually true.  We commit a Type~I error if we call a result significant (find enough evidence for $H_A$) when there is \emph{no} real difference or effect. 
\item A \term{Type~II error} is not rejecting $H_0$, when $H_A$ is actually true.  We commit a Type~II error if we call a result not significant (do not find enough evidence for $H_A$) when there \emph{is} a real difference or effect. 
\end{itemize}

\item The \termni{power} of a hypothesis test is the probability that a hypothesis test will
correctly reject the false null hypothesis.  Stated another way, the power of a test is the probability of correctly detecting an effect of a particular size when it is present.
 

\item Probabilities of Type~I and Type~II errors:  \vspace{-1mm}
\begin{itemize}
\item The probability of making a Type I error is defined as the significance level $\alpha$. For a given study and hypothesis test, the probability of making a Type~I error is
typically set to a small value (e.g., 0.01, 0.05, 0.10) prior to collecting the data.
\item The probability of making a Type II error is 1 $-$ power.
\end{itemize}

\item For a given study and hypothesis test, the probability of a Type~II error should
ideally be small, and thus, the power will be large (e.g., P(Type~II error) = 0.20 and
power = 0.80). 

\item The probability of a Type II~error decreases and the power increases
when any one of the following occurs, provided the others do not change:
\begin{itemize}\vspace{-1mm}
\setlength{\itemsep}{0mm}
\item[i. ] Sample size(s) increase
\item[ii. ] Standard error decreases.
\item[iii. ] True parameter value is farther from the null hypothesis.
\item[iv. ] Significance level $\alpha$ of a test increases.  
\end{itemize}

\item In some studies, making a Type~I error may have more serious consequences
than making a Type~II error. In other studies, making a Type~II error may have
more serious consequences than making a Type~I error. The consequences of
each error should be considered prior to conducting the study.

\item Because the significance level, $\alpha$, is the probability of making a Type~I error, the
consequences of a Type~I error influence decisions about a significance level.

\item Because sample size influences the probability of making a Type II error, the consequences of a Type II error influence decisions about how large the
sample size should be.

\end{itemize}

%%%%%%%Section Exercises
{\input{ch_inference_for_props/TeX/hypothesis_testing_for_a_population_proportion.tex}}




%______________________________________________
\section[Sampling distribution for a difference in sample proportions]{Sampling distribution for \pmb{$\hat{p}_1-\hat{p}_2$}}
\label{distributionofdifference}

\sectionintro{
\noindent%
If two treatments work equally well, how much variation in their success rates would we expect due to random variation?  How different are the voting rates between two adjacent counties?  Often, researchers are interested in comparing the proportion of individuals with a certain characteristic between two treatment groups or populations.  In this section, we lay the groundwork for these types of questions by investigating the sampling distribution for a difference in sample proportions.  

%%
\subsection*{Learning objectives}
\begin{enumerate}
\setlength{\itemsep}{0mm}

\item Calculate the mean and standard deviation of a sampling distribution for a difference in sample proportions.

\item Justify whether the independence condition is satisfied when considering properties of the sampling distribution for a difference in sample proportions.

\item Determine whether or not the shape of the sampling distribution for a difference in sample proportions is 
approximately normal.

\item Interpret the mean, standard
deviation, and probabilities for
the sampling distribution for
the difference between two
sample proportions.


\end{enumerate}
}

\newpage
%%
\subsection{Visualizing a distribution for a difference in sample proportions}
In Section~\ref{randomizationdist}, we looked at a randomization distribution for the difference in proportion that would contract malaria if given the PfSPZ vaccine versus given a placebo.  Understanding the expected variation in the difference helps us determine whether an observed difference should be considered surprising or not.  

Imagine that the owners of a new specialty grocery store are deciding which of two equally-sized counties, which we'll call County 1 and County 2, they should open their store in.  They hire a market researcher to help them collect data to inform their decision.  Unknown to the researcher, 45\% of the people County 1 would be interested in the new specialty grocery store, while 35\% of the people in County 2 would be interested.  The researcher uses random digit dialing to select a random sample of adults from each county and asks the each person whether they would be interested in the new specialty grocery store.  

Let $\hat{p}_1$ be the proportion of adults in a random sample of size 50 from County 1 who answer yes, they are interested, and let $\hat{p}_2$ be the  proportion of adults in a random sample of size 60 from County 2 who answer yes, they are interested.  How large of a difference do we expect in the sample proportions:  $\hat{p}_1-\hat{p}_2$?  What is the likelihood that this difference is negative, meaning that the proportion in the sample from County 2 is larger than from County 1, even though in the populations it is not?  

First, we want to visualize the sampling distribution of the difference: $\hat{p}_1-\hat{p}_2$. To do this we run a simulation.  We randomly select 50 people from County 1 where $p_1=0.45$ and calculate the sample proportion $\hat{p}_1$ and we randomly select 60 people from County 2 where $p_2=0.35$ and calculate the sample proportion $\hat{p}_2$, then we calculate the difference $\hat{p}_1-\hat{p}_2$.  We do this 300 times, giving us 300 values for $\hat{p}_1-\hat{p}_2$.  These 300 sample differences are graphed in Figure~\ref{simdifferenceprop}.  

%First, we will find the mean and standard deviation of the sample proportion for each county.  For County 1, the proportion with blood type O+ is $p_1=0.35$.  For County 2, the proportion with blood type O+ is $p_2=0.25$. For a random sample of size $n_1=40$ from County 1 and $n_2=50$ from County 2, we can calculate:  
%\begin{align*}
%\mu_{\hat{p}_1} &=  p_1 = 0.35 & \mu_{\hat{p}_2} &=p_2 = 0.25 \\
%\sigma_{\hat{p}_1} &=  \sqrt{\frac{p_1(1-p_1)}{n_1}} =  \sqrt{\frac{0.35(0.65)}{40}} = 0.075 &\sigma_{\hat{p}_2} &=  \sqrt{\frac{p_2(1-p_2)}{n_2}}= \sqrt{\frac{0.25(0.75)}{50}} = 0.061.
%\end{align*}
%
%Our standard deviation formula will provide a good estimate as long as our sample sizes are less than 10\% of the County sizes.  We will assume that the county sizes are in the thousands, so the 10\% condition is easily met.  
%
%Let $\hat{p}_1$ represent the proportion with blood type O+ from a random sample of size 40 from County 1, and let $\hat{p}_2$ represent the proportion of people with blood type O+ in a random sample of size 50 from County 2.  To visualize the sampling distributions of $\hat{p}_1$ and $\hat{p}_2$, we conduct a simulation, where we sample fromFigure~\ref{simpops} shows a simulation of the distribution of $\hat{p}_1$ and a simulation of the distribution of  $\hat{p}_2$.  
%\begin{figure}[h]
%\centering
%\Figures[Difference in sample proportions]
%{0.45}{oPositive40}{oPositive40county1}
%\Figures[Difference in sample proportions]
%{0.45}{oPositive40}{oPositive50county2}
%\caption{Simulated sample poportions for County 1 and for County 2.}
%\label{simpops}
%\end{figure}
%
%Now, we want to consider the sampling distribution of $\hat{p}_1-\hat{p}_2$, which will represent the distribution of $\hat{p}_1-\hat{p}_2$ for all random samples of size 40 from County 1 and size 50 from County 2.  To visualize this, we can carry out a a simulation:  we will take a random sample of size 40 from County 1 and random sample of size 50 from County 2 and take the difference in the sample proportions.  Then we will repeat this until we have 300 differences and we make a dot plot of the differences (rounded to the nearest 0.10).  The simulation is shown in Figure~\ref{simdifferenceprop}.  


\begin{figure}[h]
\centering
\Figures[Difference in sample proportions]
{0.9}{grocerystore}{grocerystoredifferencedotplot}
\caption{300 simulated differences in sample proportions}
\label{simdifferenceprop}
\end{figure}

The distribution of sample differences in Figure~\ref{simdifferenceprop} seems to be centered on 0.10.  This makes sense because the mean of possible sample differences should be centered on the difference in the true proportions of 0.45 and 0.35.  Each dot in Figure~\ref{simdifferenceprop} represents a difference in sample proportions.  We can count that 49 of the 300 dots have a value less than 0 so, based on the simulation, we estimate that there is a $\frac{49}{300}$, or about a 16\% chance that the sample proportion from County 2 will be higher, misleading the market researcher.


\D{\newpage}

\subsection[The mean and standard deviation for a difference in sample proportions]{The mean and standard deviation for \pmb{$\hat{p}_1-\hat{p}_2$}}
\label{distributionofdifference_diff_samp_props}

We saw that the mean of $\hat{p}_1-\hat{p}_2$ for our grocery store example is centered on 0.10, which is $p_1-p_2$.  In general, for two random variables $X$ and $Y$, the mean of the difference is the difference of the individual means:
\begin{align*}
\mu_{X - Y} = \mu_X - \mu_Y.
\end{align*}

To calculate the mean of a sampling distribution of $\hat{p}_1-\hat{p}_2$, we apply this property to find that:  
\begin{align*}
\mu_{\hat{p}_1 - \hat{p}_2} &= \mu_{\hat{p}_1} - \mu_{\hat{p}_2} = p_1-p_2.
\end{align*}

The situation is a little more complex when looking at the
variability of the difference in $X$ and $Y$.
Here we're going to require a condition be met, specifically that
$X$ and $Y$ are independent random variables.
When that independence condition is met, then the following formula
for the standard deviation of the difference, $X - Y$, holds:
\begin{align*}
\sigma_{X-Y} =  \sqrt{\sigma_{X}^2 + \sigma_{Y}^2}.
\end{align*}

The two samples are random and independent of each other so, assuming that the sample sizes are less then 10\% of the county population sizes, we can apply this property as follows:  
\begin{align*}
\sigma_{\hat{p}_1 - \hat{p}_2} &=  \sqrt{(\sigma_{\hat{p}_1})^2 + (\sigma_{\hat{p}_2})^2}=  \sqrt{\frac{p_1(1-p_1)}{n_1} + \frac{p_2(1-p_2)}{n_2}}.
\end{align*}

\begin{onebox}{Mean and standard deviation of a difference in sample proportions}
The mean and standard deviation of the sampling distribution for a difference in sample proportions describe the center and spread of the distribution of differences $\hat{p}_1-\hat{p}_2$ for all random samples of size $n_1$ and $n_2$ from the given populations.  Given population proportions $p_1$ and $p_2$, population sizes $N_1$ and $N_2$, and independent random samples of size $n_1$ and $n_2$, we have the following:
\begin{align*}
\mu_{\hat{p}_1-\hat{p}_2} &= p_1-p_2\\
 \sigma_{\hat{p}_1-\hat{p}_2}&=  \sqrt{\frac{p_1(1-p_1)}{n_1} + \frac{p_2(1-p_2)}{n_2}} \quad \text{ when } n_1<0.10(N_1) \text{ and } n_2<0.10(N_2) 
	\vspace{1mm}
\end{align*}
\end{onebox}

%
%\begin{examplewrap}
%\begin{nexample}{For a random sample of size 50 from County 1, where it is known that 35\% of people have blood type O+, and a random sample of size 50 from County 2, where it is known that 25\% of people have blood type O+, calculate the mean and the standard deviation for the difference in sample proportions with blood type O+.}
%Let $\hat{p}_1-\hat{p}_2$ represent the difference (County 1 $-$ County 2) in sample proportions with blood type O+.  Calculate the mean of $\hat{p}_1-\hat{p}_2$ as follows:
%\begin{align*}
%\mu_{\hat{p}_1-\hat{p}_2} &= p_1-p_2 = 0.35 - 0.25 = 0.10 
%\end{align*}
%We will assume that the sample sizes of 50 are less than 10\% of the population sizes, that is, that County 1 and County 2 each contain at least 500 people, which seems reasonable, and we calculate the standard deviation of $\hat{p}_1-\hat{p}_2$ as follows:
%\begin{align*}
%\sigma_{\hat{p}_1-\hat{p}_2}
%  &= \sqrt{\frac{p_1(1-p_1)}{n_1} + \frac{p_2(1-p_2)}{n_2}}
%  =\sqrt{\frac{0.35(1-0.35)}{40} + \frac{0.25(1-0.75)}{50}}
%  = 0.097
%\end{align*}
%\end{nexample}
%\end{examplewrap}

\begin{examplewrap}
\begin{nexample}{In our grocery store example, 45\% of County 1 is interested in the new specialty grocery store, and 35\% of County 2 is interested.  Calculate the mean and standard deviation for the difference in sample proportions if the market researcher takes a random sample of size 60 from County 1 and a random sample of size 50 from County 2. }
\begin{align*}
\mu_{\hat{p}_1 - \hat{p}_2} &= p_1 - p_2 =0.45 - 0.35 = 0.10.\\
 \sigma_{\hat{p}_1-\hat{p}_2}&=  \sqrt{\frac{p_1(1-p_1)}{n_1} + \frac{p_2(1-p_2)}{n_2}} =\sqrt{\frac{0.45(1-0.45)}{50} + \frac{0.35(1-0.35)}{60}}=0.093.
\end{align*}
\label{calcmeansddiffprop}
\end{nexample}
\end{examplewrap}

\begin{examplewrap}
\begin{nexample}{Interpret the mean and standard deviation calculated in Example~\ref{calcmeansddiffprop}.}
For all random samples of 50 people from County 1 and 60 people from County 2, the difference in sample proportions of people with an interest in the new specialty grocery store (County 1 $-$ County 2) will have a mean of 0.10 and will typically vary by 0.093 from the mean of 0.10.
\end{nexample}
\end{examplewrap}


\subsection[Using a normal model for the sampling distribution of $\hat{p}_1-\hat{p}_2$]{Using a normal model for the sampling distribution of \pmb{$\hat{p}_1-\hat{p}_2$}}

We used the simulation shown in Figure~\ref{simdifferenceprop} to estimate a probability involving the sampling distribution of $\hat{p}_1-\hat{p}_2$, the difference in sample proportions who have an interest in the new specialty store.  We would like a method for estimating such probabilities that does not depend on a simulation.  Fortunately, when certain conditions are met, the distribution of $\hat{p}_1-\hat{p}_2$ can be modeled with a normal distribution and we can use a normal approximation to estimate probabilities based on this sampling distribution.  

When looking at the sum or difference of two random variables, if each variable is nearly normal, then the sum and difference are also nearly normal random variables.  This property will be very useful, as it says that when each sample proportion has a nearly normal distribution, then the difference in sample proportions will also be nearly normal.   The sampling distribution for $\hat{p}_1-\hat{p}_2$ can be modeled with a normal distribution when the following two conditions are met:  
\begin{description}
\setlength{\itemsep}{0mm}
\item[Independence.]
  The observations within and between groups should be independent.
  The independence condition is satisfied if the data is collected from 2 independent random samples, where each sample size is less than 10\% of the population size if done without replacement.  We also consider the independence condition satisfied if the data is collected from an experiment with two randomly assigned treatments (in this case the 10\% condition is not relevant and does not need to be checked).
\item[Large counts.]
  In the two-sample case, the number of expected successes and failures
  should be at least 10 for \emph{both} groups.  We must check that the following four inequalities are satisfied:  $n_1p_1 \ge 10$, $n_1(1-p_1) \ge 10$, $n_2p_2 \ge 10$, and $n_2(1-p_2) \ge 10$.
\end{description}

\begin{examplewrap}
\label{diffpropsex}
\begin{nexample}{
  Let's return to our original question about sampling from County 1 and County 2.   In County 1, it is true that 45\% of the people have an interest in the new specialty grocery store .  In County 2, it is true that 35\% of the people have an interest in the new specialty grocery store.  If we take a random sample of size 50 from County 1 and a random sample of size 60 from County 2, what is the probability that we will get a \emph{higher} proportion with an interest in the store in sample 2 than in sample 1?}

Here $p_1 = 0.45$, $n_1=50$, $p_2=0.35$, and $n_2=60$.  Define $\hat{p}_1 - \hat{p}_2$ as follows:\\

\ \ \ \ \ \  $\hat{p}_1 - \hat{p}_2$:  difference in sample proportions (County 1 $-$County 2) with an interest in the new \\
\vspace{-3mm}
 \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ specialty grocery store.  \\

We want to find $P(\hat{p}_1-\hat{p}_2<0)$, which is equivalent to $P(\hat{p}_1<\hat{p}_2)$.  We have already found:  
\begin{align*}
\mu_{\hat{p}_1-\hat{p}_2} &= 0.45 - 0.35 = 0.10 \\
\sigma_{\hat{p}_1-\hat{p}_2}
  &=\sqrt{\frac{0.45(1-0.45)}{50} + \frac{0.35(1-0.35)}{60}}
  = 0.093
\end{align*}
Our random samples are independent and we are assuming sample sizes are less than 10\% of the county populations.  We now check the large counts condition for each group to determine if the distribution of $\hat{p}_1-\hat{p}_2$ can be modeled by a normal distribution. 
\begin{align*}
n_1 p_1 &= 50 \times 0.45 = 22.5\ge 10 &&
    n_1 (1 - p_1) = 50 \times (1-0.45) = 27.5\ge 10\\
n_2 p_2 &= 60 \times 0.35 = 21\ge 10 &&
    n_2 (1 - p_2) = 60 \times (1-0.35) = 39\ge 10
\end{align*}


All four inequalities are satisfied, so we can use a normal model for the difference in sample proportions.  Given that $\hat{p}_1-\hat{p}_2$ is approximately Normal($\mu$ = 0.10, $\sigma$ = 0.093), we can use technology to find that \mbox{$P(\hat{p}_1-\hat{p}_2 < 0) = 0.141$.}  

Alternately,  we can find the Z-score that corresponds to the boundary value of 0 and use the standard normal distribution.  In Section~\ref{differenceOfTwoProportionsTest} we will see a parallel between the calculation of this Z-score and the calculation of a Z test statistic for a test for a difference of population proportion.
\begin{align*}
Z &= \frac{x - \mu}{\sigma} =\frac{0-(0.45-0.35)}{\sqrt{\frac{0.45(1-0.45)}{50} + \frac{0.35(1-0.35)}{60}}} =  \frac{0 - 0.10}{0.093}=-1.075
\end{align*}
\begin{center}
\Figures [A normal distribution is shown with mean 0 and standard deviation 1.  The area to the left of $-1.075$ is shaded and is approximately 14\% of the total area. ] {0.35}{groceryStoreNormal}{groceryStoreComparison}\hspace{5mm}
\Figures [A normal distribution is shown with mean 0.10 and standard deviation 0.097.  The area to the left of 0 is shaded and is approximately 14\% of the total area. ] {0.35}{groceryStoreNormal}{groceryStoreComparisonZ}
\end{center}
Using technology and the Normal($\mu$ = 0, $\sigma$ = 1) distribution, we find $P(Z < -1.075) = 0.141$.  

Even though County 1 has a higher proportion of people with an interest in the new specialty grocery store, with these small sample sizes, there is still about a 14.1\% chance that the sample from County 2 has a higher proportion with an interest in the new specialty grocery store than the sample from County 1.
\end{nexample}
\end{examplewrap}

\begin{examplewrap}
\begin{nexample}{What could the market researcher have done to lower the probability of mistakenly thinking that a higher proportion in County 2 are interested in the new specialty grocery store?}
If the sample sizes were larger, the sampling distribution of the difference in sample proportions would the same mean but smaller spread, resulting in a lower probability of $\hat{p}_1-\hat{p}_2<0$. 
\end{nexample}
\end{examplewrap}

\newpage
%%%%%%%%
\subsection*{Section summary}

\begin{itemize} 

\item $\hat{p_1} -\hat{p_2}$ represents a difference in sample proportions and can take on different values for different samples.  For two independent populations, the \termni{sampling distribution for a difference in sample proportions}, $\hat{p}_1 -\hat{p}_2$, is the distribution of $\hat{p}_1 -\hat{p}_2$ values for all random samples of size $n_1$ and $n_2$ from the given populations.

\item When the observations can be treated as independent, such as from two independent random samples or two randomly assigned treatments:

\begin{itemize}
\item The \textbf{mean} of the sampling distribution of $\hat{p}_1 -\hat{p}_2$ is given by:\\
 $\mu_{\hat{p}_1 - \hat{p}_2} = p_1 - p_2$, where $p_1$ and $p_2$ are population proportions.

\item The \textbf{standard deviation} of the sampling distribution of $\hat{p}_1 -\hat{p}_2$ is given by: 
\\$\sigma_{\hat{p}_1 - \hat{p}_2} =  \sqrt{\frac{p_1(1-p_1)}{n_1} + \frac{p_2(1-p_2)}{n_2}}$.  If sampling is done without replacement, both sample sizes should be less than 10\% of the size of their corresponding populations, i.e. $n_1<0.10(N_1)$ and $n_2<0.10(N_2)$, in order for this standard deviation formula to used.  If the data come from an experiment with two randomly assigned treatments, the 10\% condition does not need to be checked.

\item The \textbf{shape} of the sampling distribution for a difference between sample proportions, $\hat{p_1} -\hat{p_2}$, will be approximately normal when both sample sizes are large enough to satisfy the large counts condition: $n_1p_1 \ge 10$, $n_1(1-p_1)\ge10$, $n_2p_2 \ge 10$, and $n_2(1-p_2)\ge10$.
\end{itemize}

\item $\mu_{\hat{p}_1 - \hat{p}_2}$, the mean of $\hat{p}_1 -\hat{p}_2$, describes the average of values of $\hat{p}_1 -\hat{p}_2$ among all random samples of size $n_1$ and $n_2$ from the given populations.  

\item $\sigma_{\hat{p}_1 - \hat{p}_2}$, the standard deviation of $\hat{p}_1 -\hat{p}_2$, describes the typical variation in values of $\hat{p}_1 -\hat{p}_2$ from $p_1-p_2$ for all random samples of size $n_1$ and $n_2$ from the given populations.  

\item To use a normal model to find probabilities involving a difference in sample proportions, first verify that the conditions for independence are met and that the large counts condition is met for both groups.   Identify the distribution and its parameters, write the relevant probability statement, and answer the question in context.

\item The mean, standard deviation, and probabilities for the sampling distribution
for a difference between two sample proportions should be interpreted
within the context of two specific populations.
\end{itemize}
%%%%%%%Section Exercises

{\input{ch_inference_for_props/TeX/sampling_distribution_for_a_difference_in_sample_proportions.tex}}

%____________________________________________

\section[Confidence intervals for a difference in population proportions]{Confidence intervals for \pmb{$p_1-p_2$}}
\label{differenceOfTwoProportionsCI}

\sectionintro{
\noindent%
How much more effective is a blood thinner than a placebo for those who undergo CPR for a heart attack?  Researchers often wish to estimate how large a difference there is between two treatments or populations.  In this section we develop a framework for confidence intervals for a difference in proportions by combining what we learned about confidence intervals for a single proportion with our understanding of the sampling distribution for a difference in proportions.  While some of the details change, the general confidence interval framework remains the same.


%%
\subsection*{Learning objectives}
\begin{enumerate}
\setlength{\itemsep}{0mm}

\item Identify and set up an appropriate confidence interval procedure for estimating the difference in population proportions $p_1-p_2$.
\item Justify the appropriateness of constructing a confidence interval for a difference between two population proportions by verifying conditions.
\item Calculate an appropriate confidence interval for a difference in population proportions.  
\item Calculate the standard error and margin of error for a confidence interval for a difference in population proportions.  
\item Interpret a confidence interval in context for a difference in population proportions.
\item Justify a claim about the difference in population proportions based on an appropriate confidence interval.
\end{enumerate}
}


\D{\newpage}

%%
\subsection{Conditions for a confidence interval for a difference of proportions}
\index{two-proportion Z-interval|see{Z-interval for a difference of proportions}}
\index{Z-interval!for a difference of proportions|(}

We consider an experiment for patients who underwent CPR for a heart attack and were subsequently admitted to a hospital. These patients were randomly divided into a treatment group where they received a blood thinner or the control group where they did not receive a blood thinner. The outcome variable of interest was whether the patients survived for at least 24 hours.
    The results are shown in  Figure~\ref{resultsForCPRStudyInSmallSampleSection}.

\begin{figure}[ht]
\centering
\begin{tabular}{lccccc}
\hline
			&& Survived 	& Died 	&& Total \\
\hline
Treatment		&& 14		& 26		&& 40 \\
Control		&& 11		& 39		&& 50 \\

\hline
Total			&& 25		& 65		&& 90 \\
\hline
\end{tabular}
\caption{Results for the CPR study.
    Patients in the treatment group were given
    a blood thinner, and patients in the control
    group were not.}
\label{resultsForCPRStudyInSmallSampleSection}
\end{figure}

\index{data!CPR and blood thinner|)}

Here, the parameter of interest is a difference in population proportions, specifically, the difference in the proportion of similar patients that would survive for at least 24 hours if in the treatment group versus if in the control group.  Let:
\begin{align*}
p_1:& \text{ proportion who would survive in treatment group, and} \\
p_2:& \text{ proportion who would survive in control group}
\end{align*}
Then the parameter of interest is $p_1 - p_2$, which is the difference in proportions (treatment $-$ control) that would survive.  In order to use a Z-interval to estimate this difference, we must see if the point estimate, $\hat{p}_{1} - \hat{p}_{2}$, follows a normal distribution.  Because the patients were randomly assigned to one of the two groups and one heart attack patient is unlikely to influence the next that was in the study, the observations are considered independent, both within the groups and between the groups (since there is no sampling, there is no need to check the 10\% condition).  Next, the large counts condition should be verified for each group.  Here, we do not know the true proportions, so we must use the sample proportions along with the sample~sizes to check the condition.
\begin{align*}
n_1\hat{p}_1&\ge 10 & n_1(1-\hat{p}_1)&\ge 10 & n_2\hat{p}_2&\ge 10 & n_2(1-\hat{p}_2)&\ge 10 \\
40 \times \frac{14}{40} &\ge 10
	&40 \times (1-\frac{14}{40}) &\ge 10
	&50 \times \frac{11}{50} &\ge 10
	&50 \times (1-\frac{11}{50}) &\ge 10
\end{align*}
Because all conditions are met, the normal model can be used for difference in survival rates, and we can apply a \termni{two-sample Z-interval for \pmb{$p_1-p_2$}}.\\

The conditions for a two-sample Z-interval for a difference in proportions are the same as the conditions for a two-sample Z-test for a difference in proportions with one modification: instead of using the pooled proportion to check the large counts condition, we use the sample proportions $\hat{p}_1$ and $\hat{p}_2$.    For the two-sample Z-interval for $p_1-p_2$, the following conditions should be met:
\begin{description}
\setlength{\itemsep}{0mm}
\item[Independence.]
  The data is collected from 2 independent random samples, where each sample size is less than 10\% of the population size if done without replacement, or the data is collected from an experiment with two randomly assigned treatments (in this case the 10\% condition is not relevant and does not need to be checked).
\item[Large counts.]
 We check the large counts condition for each sample separately using the observed sample proportions:  $n_1\hat{p}_1 \ge 10$, $n_1(1-\hat{p}_1) \ge 10$, $n_2\hat{p}_2 \ge 10$, and $n_2(1 -\hat{p}_2) \ge 10$.
\end{description}


\D{\newpage}

\subsection{Calculating a confidence interval for a difference in proportions}
To calculate a confidence interval for a difference in proportions, we apply the same confidence interval structure from the single-proportion context but with a different point estimate and SE.

The point estimate for the difference in population proportions is:
  \begin{align*}
  \hat{p}_{1} - \hat{p}_{2}
    = \frac{14}{40} - \frac{11}{50}
    = 0.35 - 0.22
    = 0.13
  \end{align*}


Because the point estimate is a difference in sample proportions, we now computer the standard error for a difference in sample proportions.  We compute this in the same way that we compute the standard deviation for a difference in sample proportions --  the only difference is that we use the sample proportions in place of the population proportions:

\begin{align*}
SE_{\hat{p}_1-\hat{p}_2} &= \sqrt{\frac{\hat{p}_1(1-\hat{p}_1)}{n_1} + \frac{\hat{p}_2(1-\hat{p}_2)}{n_2}}= \sqrt{\frac{0.35 (1 - 0.35)}{40} +
      \frac{0.22 (1 - 0.22)}{50}}
    = 0.095
  \end{align*}

The standard error tells us about the typical error when using the difference in sample proportions as an estimate for the  difference in population proportions.  Sometimes the error will be higher and sometimes it will be lower, but this gives us a sense of how large we expect it to be on average.   

\begin{examplewrap}
\begin{nexample}{Estimate the true difference in survival rate with 90\% confidence.}
For a 90\% confidence level, we use $z^{\star} = 1.645$.  The 90\% confidence interval is calculated as:
  \begin{align*}
  \text{point estimate} \ \pm&\ z^{\star} \times SE\ \text{of estimate}\\
(0.35 - 0.22) \ \pm&\ 1.65 \times \sqrt{\frac{0.35 (1 - 0.35)}{40} +
      \frac{0.22 (1 - 0.22)}{50}}\\
     0.13 \ \pm&\ 1.65\times 0.095\\
  0.13 \ \pm&\ 0.157\\
 (-0.027&,\  0.287)
  \end{align*}
\end{nexample}
\end{examplewrap}


In this example, we see that the standard error (SE) is 0.095 and the margin of error for the 90\% confidence interval is 0.157.   Unlike the standard error, the margin of error depends on the \emph{confidence level}.  The margin of error of 0.157 in this problem tells us that we can be 90\% confident that our estimate is within 0.157 of the true difference (treatment $-$ control) in the proportions that would survive at least 24 hours.  

The general form of a two-sample Z-interval for $p_1 - p_2$ is given by:
\begin{align*}
(\hat{p}_{1} - \hat{p}_{2}) \ \pm&\ z^{\star} \times \sqrt{\frac{\hat{p}_1(1-\hat{p}_1)}{n_1} + \frac{\hat{p}_2(1-\hat{p}_2)}{n_2}}
\end{align*}
where $\hat{p}_{1} - \hat{p}_{2}$ is the point estimate and $z^{\star} \times \sqrt{\frac{\hat{p}_1(1-\hat{p}_1)}{n_1} + \frac{\hat{p}_2(1-\hat{p}_2)}{n_2}}$ is the margin of error.


\D{\newpage}

\subsection{Interpreting and applying a confidence interval for a difference of proportions}

In this problem, we calculated the 90\% two-sample Z-interval as: ($-$0.027, 0.287).  The interpretation of this interval is analogous to the interpretation of a one-sample Z-interval, instead here we are estimating a difference in population proportions rather than a single population proportion.  We can interpret the interval as follows:  We are 90\% confident that the interval ($-$0.027, 0.287) contains the difference in the true proportions of patients like the ones in this study that would survive at least 24 hours after receiving blood thinner versus not (treatment $-$ control).  That is, we are 90\% confident that, for patients like those in the study, the survival rate for those who would receive blood thinners (treatment) is 2.7\% \emph{lower} to +28.7\% \emph{higher} than the survival rate for those who would not receive the blood thinner (control).  

\begin{examplewrap}
\begin{nexample}{Based on this confidence interval of ($-$0.027, 0.287), do we have evidence at the 90\% confidence level that blood thinners help or harm heart attack patients who have been admitted after they have undergone CPR?}
Recall that we took the difference as (treatment $-$ control).  If the entire interval were greater than 0, we would have evidence that the true difference is positive, meaning that we would have evidence that the survival rate for those who would be in the treatment group would be \emph{higher}.  This would mean that we have evidence that the blood thinners would help patients such as these.  

On the other hand, if the entire interval was less than 0, we would have evidence that the true difference is negative, meaning that we would have evidence that the survival rate for those who would be in the treatment group would be \emph{lower}.  This would mean that we have evidence that the blood thinners would hurt patients such as these.    

What can we say based on the interval we calculated?  Because the interval contains both negative and positive values, we do not have evidence and we cannot say
  with confidence whether blood thinners would harm or help
  heart attack patients who have been admitted after
  they have undergone CPR.

\end{nexample}
\end{examplewrap}


  
In general, when using a confidence interval for a difference, we justify claims about the true difference based on whether the interval is entirely above 0 (evidence the first is greater), entirely below 0 (evidence the first is less), or contains 0 (not enough evidence of a real difference).


\D{\newpage}

%%%
\subsection[Technology: the two-sample Z-interval for $p_1 - p_2$]{Technology: the two-sample Z-interval for \pmb{$p_1 - p_2$}}
\label{2propZint}

\noindent  Section~\ref{tech2Z} demonstrates how to calculate the two-proportion Z-interval and the two-proportion Z-test (introduced in the next section) using Desmos, R, and the NumWorks, TI-83/84 and Casio calculator. 


\subsection[Summary and worked example]{Summary and worked example} 

\begin{onebox}{Constructing a confidence interval for a difference in proportions}
To carry out a complete confidence interval procedure to estimate the difference in population proportions,
\\
\\
 \inferencestep{Identify}   Identify the interval procedure, parameter, and confidence level.\vspace{-1mm}
\begin{itemize}
\item[] Use a \termsub{two-sample Z-interval for \pmb{$p_1 - p_2$}}{Z-interval!for a difference of proportions}.  Define the difference in population proportions $p_1 - p_2$ in words, referencing the populations of interest.  Choose a confidence level (C\%).  
\end{itemize}
 \inferencestep{Check} \mbox{Check conditions for constructing a confidence interval using a normal distribution.}\vspace{-1mm}
{\setlength{\leftmargini}{13mm}
\begin{itemize}
\setlength{\itemsep}{0mm}
\item[1.] Independence:  Data come from 2 independent random samples or from a randomized experiment with two treatments.  When sampling without replacement, check that the 
sample size is less than 10\% of the population size for both samples.
\item[2.] Large counts:  $n_1\hat{p}_1\geq10$, $n_1(1-\hat{p}_1)\geq10$,  $n_2\hat{p}_2\geq10$, and $n_2(1-\hat{p}_2)\geq10$.
\end{itemize}
}
 \inferencestep{Calculate}  Calculate the confidence interval and record it in interval form.
\begin{itemize}
\item[] $\text{point estimate}\ \pm\ z^{\star} \times SE\ \text{of estimate}$
\begin{itemize}
\item[] point estimate:  $\hat{p}_1 - \hat{p}_2$, the difference in sample proportions 
\item[] $SE$ of estimate:  $\sqrt{\frac{\hat{p}_1(1-\hat{p}_1)}{n_1} + \frac{\hat{p}_2(1-\hat{p}_2)}{n_2}}$
\item[] $z^{\star}$: use technology or a $t$-table at row $\infty$ and confidence level C\%
\end{itemize}
\item[] (\underline{\ \ \ \ \ }, \underline{\ \ \ \ \ })
\end{itemize}
 \inferencestep{Conclude}  Interpret the interval and, if applicable, draw a conclusion in context.\vspace{-1mm}
\begin{itemize}
\item[] We are C\% confident that the interval (\underline{\ \ \ \ \ }, \underline{\ \ \ \ \ }) contains the \emph{difference} (specify order) in the true proportions that [...].   If applicable, draw a conclusion based on whether the interval is entirely above, is entirely below, or contains the value 0.  

\end{itemize}\end{onebox}


\begin{examplewrap}
\begin{nexample}{A remote control car company is considering a new manufacturer for wheel gears. The new manufacturer would be more expensive but their higher quality gears are more reliable, resulting in happier customers and fewer warranty claims. However, management must be convinced that the more expensive gears are worth the conversion before they approve the switch. The quality control engineer collects a sample of gears from each supplier, examining 1000 gears from each company, and finds that 879 gears pass inspection from the current supplier and 958 pass inspection from the prospective supplier. Using these data, construct a 95\% confidence interval for a difference in the proportion from each supplier that would pass inspection.  Use the four-step framework described above to organize your work.}
\label{RemoteControl}
\begin{description}
\item[\inferencestep{Identify}] Because the parameter to be estimated is a difference of proportions, we will use a two-sample Z-interval for $p_1 - p_2$.  We can define $p_1$ and $p_2$ separately as: 
\begin{itemize}
\item[] $p_1$:  true proportion that would pass inspection from  current supplier 
\item[] $p_2$:  true proportion that would pass inspection from prospective supplier
\end{itemize}
Alternately, we can define the difference $p_1-p_2$ as follows:
\begin{itemize}
\item[] $p_1-p_2$: the difference (current $-$ prospective) in the true proportions that would pass inspection between current and prospective supplier
\end{itemize}
We will estimate the difference at the 95\% confidence level.  
\item[\inferencestep{Check}] The samples are independent, but not necessarily random, so to proceed we must assume the gears are all independent. For this sample we will suppose this assumption is reasonable, but the engineer would be more knowledgeable as to whether this assumption is appropriate. We will also assume that the 1000 gears represents less than 10\% of the total gears from each supplier. Next, we verify the minimum sample~size conditions:
\begin{align*}
1000 \times \frac{879}{1000} &\ge 10
	&1000 \times \frac{121}{1000} &\ge 10
	&1000 \times \frac{958}{1000} &\ge 10
	&1000 \times \frac{42}{1000} &\ge 10
\end{align*}
The large counts condition is met for both samples.
\item[\inferencestep{Calculate}]  We will calculate the interval: 
\begin{align*}
\text{point estimate}\ \pm\ z^{\star} \times SE\ \text{of estimate}
\end{align*}
The point estimate is the difference in sample proportions: $\hat{p}_1-\hat{p}_2 = 0.879 - 0.958 = -0.079$.  \\

$SE$ of $\hat{p}_1-\hat{p}_2$ = $\sqrt{\frac{\ \hat{p}_1(1-\hat{p}_1)\ }{n_1}+ \frac{\hat{p}_2(1-\hat{p}_2)}{n_2}\ } = \sqrt{\frac{0.879(1-0.879)}{1000} +\frac{0.958(1-0.958)}{1000}}= 0.0121$.  \\

The 95\% confidence interval is given by:
\begin{align*}
(0.879 - 0.958) \ \pm \ &1.96 \times  \sqrt{\frac{0.879(1-0.879)}{1000} +\frac{0.958(1-0.958)}{1000}}\\
-0.079\ \pm\ &1.96 \times 0.0121 \\
(-0.1&03,\ -0.055)
\end{align*}

\item[\inferencestep{Conclude}]  We are 95\% confident that the interval ($-$0.103, $-$0.055) contains the difference (current $-$ prospective) in the true proportions that would pass inspection between the current and prospective supplier, meaning that we are 95\% confident that the current supplier would have between a 10.3\% and 5.5\% \emph{lower} rate of passing inspection.  Because the entire interval is below zero, the data provide sufficient evidence that the prospective gears pass inspection more often than the current gears. The remote control car company should go with the new manufacturer.
\end{description}
\end{nexample}
\end{examplewrap}



%\index{Z-interval!for a difference of proportions|)}

\D{\newpage}

%%%%%%%Section Exercises
\subsection*{Section summary}

\begin{itemize}
\item Based on the sample data, a confidence interval can be calculated to
estimate the difference between two population proportions. The appropriate
confidence interval procedure is a \termni{two-sample \pmb{$Z$}-interval for \pmb{$p_1 - p_2$}}.  The parameters $p_1$ and $p_2$ should be identified in context.

\item A two-sample $Z$-interval for a difference in population proportion requires the following conditions be met:
\begin{itemize}
\item[1.] Independence:  The data come from two independent random samples, each with sample size $<10\%$ of its corresponding population size if sampling without replacement OR the data come from an experiment with two randomly assigned treatments.
\item[2.] Large counts: the number of successes and failures for both samples is at least 10, that is, $n_1\hat{p}_1\ge 10$, $n_1(1-\hat{p}_1)\ge 10$, $n_2\hat{p}_2\ge 10$, and $n_2(1-\hat{p}_2)\ge 10$.
\end{itemize}

\item The general form for a C\% confidence interval is: 
\begin{align*}
\text{point estimate}\ &\pm\ \text{margin of error}, \ \text{or}\\
\text{point estimate}\ &\pm\ \text{critical value} \times SE\ \text{of estimate}.
\end{align*}

\item A two-sample $Z$-interval for a difference of populations proportion $p_1-p_2$ can be written as:
\begin{align*}
(\hat{p}_1-\hat{p}_2)\  \pm \  z^{\star}\sqrt{\frac{\hat{p}_1(1-\hat{p}_1)}{n_1} + \frac{\hat{p}_2(1-\hat{p}_2)}{n_2}}
\end{align*}
where $z^{\star}$ is the critical value for the middle C\% of a standard normal distribution.  

\item The $SE$ of $\hat{p}_1-\hat{p}_2$ is:  $\sqrt{\frac{\hat{p}_1(1-\hat{p}_1)}{n_1} + \frac{\hat{p}_2(1-\hat{p}_2)}{n_2}}$.

\item The margin of error of $\hat{p}_1-\hat{p}_2$ is:  $z^{\star}\sqrt{\frac{\hat{p}_1(1-\hat{p}_1)}{n_1} + \frac{\hat{p}_2(1-\hat{p}_2)}{n_2}}$.

\item Because the confidence interval is based on a samples, the point estimate has associated error and the confidence interval may or may not contain the true value of the population proportion.  


\item The interpretation of the confidence level C\% is that in repeated random
sampling with the same sample size from the same populations, approximately
C\% of confidence intervals created will capture the true difference between the population proportions.

\item We say we are C\% confident that a particular interval (\underline{\ \ \ \ }, \underline{\ \ \ \ }) contains the difference in population proportions.  The parameter and the populations should be stated in the context of the study.

\item A confidence interval provides a range of plausible values for a parameter and can be used as evidence to justify a claim about a difference in population proportions.  For example, if the interval contains 0, there is not sufficient evidence to conclude that there is a difference between the population proportions. If the interval does not contain 0, there is sufficient evidence to conclude that there is a difference between the two population proportions.  


\end{itemize}

%%%%%%%Section Exercises
{\input{ch_inference_for_props/TeX/confidence_intervals_for_a_difference_in_population_proportions.tex}}

%%
\section[Hypothesis testing for a difference in population proportions]{Hypothesis testing for \pmb{$p_1-p_2$}}
\label{pooledHTForProportionsSection}
\label{differenceOfTwoProportionsTest}
\index{two-proportion Z-test|see{Z-test for a difference of proportions}}
\index{Z-test!for a difference of proportions|(}

\sectionintro{
\noindent%
    Does the approval rate of the 2010 healthcare
    law differ when asked in two different ways?  Does the use of fish oils reduce heart attacks better than a placebo?  How much evidence is there for each of these claims?  In this section, we apply the hypothesis testing framework to a difference in population proportions.  

%%
\subsection*{Learning objectives}
\begin{enumerate}
\setlength{\itemsep}{0mm}


\item Identify and set up an appropriate testing method for a difference in population proportions $p_1-p_2$.

\item Identify the null and alternative hypotheses for a difference between population proportions.

\item Justify the appropriateness of a hypothesis test for a difference between two
population proportions by verifying conditions.

\item Calculate an appropriate test statistic and p-value for a hypothesis test for a difference in population proportions.

\item Interpret the p-value of a hypothesis test for a difference in population proportions.

\item Justify a claim about the difference in population proportions based on the results of the test.  

\item Explain why the large counts condition and the standard error calculation are different for a hypothesis test and a confidence interval for a difference in population proportions.

\end{enumerate}
}

\subsection{Introducing hypothesis testing for a difference of proportions}

Here we use a new example to examine a special estimate of the standard error when the null hypothesis is that two population proportions equal each other, i.e. $H_0$: $p_1 = p_2$. We investigate 
whether a survey question's phrasing can affect responses. Pew Research Center conducted a survey of adults in the US with the following question:
\begin{quote}
As you may know, by 2014 nearly all Americans will be required to have health insurance. [People who do not buy insurance will pay a penalty] while [People who cannot afford it will receive financial help from the government]. Do you approve or disapprove of this policy?
\end{quote}
\index{data!health care|(}For each randomly sampled respondent, the statements in brackets were randomized: either they were kept in the original order given above, or they were reversed. Results are presented in Figure~\ref{pewPollResultsForRandomizedStatementOrdering}.


\begin{figure}[h]
\centering
\begin{tabular}{p{50mm}c p{13mm}p{14mm}p{16.5mm}c}
	&\ & sample size & Approve law (\%)	& Disapprove law (\%)	& Other \\
\hline
``People who do not buy insurance will pay a penalty'' is given first (original order) \vspace{2.5mm}
	& & 771	& 47	& 49	& 3 \\
``People who cannot afford it will receive financial help from the government" is given first (reversed order) 
	& & 732	& 34	& 63	& 3 \\
\hline
\end{tabular}
\caption{Results for a Pew Research Center poll where the ordering of two statements in a question regarding healthcare were randomized.}
\label{pewPollResultsForRandomizedStatementOrdering}
\end{figure}



\begin{exercisewrap}
\begin{nexercise}
Is this study an experiment or an observational study?\footnotemark
\end{nexercise}
\end{exercisewrap}
\footnotetext{There is a random sample involved, but there are also two treatments.  Half of the respondents are given the original statement order and the other half, randomly, are given the reversed statement order.  This is an experiment because there are randomly assigned treatments.  }

\D{\newpage}

\noindent The approval percents of 47\% and 34\% seem far apart.  However, could this difference be due to random chance?  We will answer this question using a hypothesis test.  

\begin{examplewrap}
\begin{nexample}{Set up hypotheses to test whether the two statement orders produce different responses. }
Define the parameters of interest as follows:\\
$p_1 $: proportion of adults in the US that would approve of policy with original statement ordering.\\
$p_2$: proportion of adults in the US that would approve of policy with reversed statement ordering.\\

The null claim is that the question order does not matter and the two proportions should be equal. The alternative claim, the one that bears the burden of proof, is that the question ordering does matter.  
\begin{itemize}
\setlength{\itemsep}{0mm}
\item[$H_0$:] $p_1 =  p_2$ 
\item[$H_A$:] $p_1 \ne  p_2$
\end{itemize}
\end{nexample}
\end{examplewrap}

\noindent%
It is important to notice that:
\vspace{-2mm}
\begin{align*}
p_1=p_2 &\text{ is equivalent to } p_1-p_2=0\text{, and} \\
p_1\ne p_2 &\text{ is equivalent to } p_1-p_2\ne 0.  
\end{align*}
We can now see that the hypotheses are really about a difference of proportions: $p_1-p_2$.  In the last section, we used a two-sample Z-interval to estimate the parameter $p_1-p_2$; here, we will use a \termni{two-sample Z-test for \pmb{$p_1 - p_2$}}, with null hypothesis: $p_1-p_2=0$, i.e. $p_1=p_2$.  We will elaborate on the conditions needed for this test after introducing the concept of the pooled proportion.  


\D{\newpage}

\subsection{Calculations and conditions for a test for a difference of proportions}

For a Z-test for the survey question wording example, we will compute a $Z$-test statistic, which takes the familiar form:
\begin{align*}
Z = \frac{\text{point estimate} - \text{null value}}{SE\ \text{of estimate}}
\end{align*}
The parameter of interest is $p_1-p_2$, so the point estimate will be the observed difference in sample proportions:  $\hat{p}_{1} - \hat{p}_{2} = 0.47 - 0.34 = 0.13$.  The null value depends on the null hypothesis.  The null hypothesis is that the approval rate would be the same for both statement orderings, i.e. that the difference is 0, therefore, the null value is 0. 

The $SD$ of a difference in sample proportions has the form:
\begin{align*}
\sigma_{\hat{p}_1-\hat{p}_2} = \sqrt{\frac{p_1(1-p_1)}{n_1} + \frac{p_2(1-p_2)}{n_2}}
\end{align*}
However, in a hypothesis test, the distribution of the point estimate is always examined assuming the null hypothesis is true, i.e. in this case, $p_1 = p_2$. Both the large counts check and the standard error formula should reflect this equality in the null hypothesis. We will use $p_c$ to represent the common or combined proportion that support the healthcare law regardless of statement order:
\begin{align*}
\sigma_{\hat{p}_1-\hat{p}_2} &= \sqrt{\frac{p_c(1-p_c)}{n_1} + \frac{p_c(1-p_c)}{n_2}} \\
	&= \sqrt{p_c(1-p_c)\left(\frac{1}{n_1} + \frac{1}{n_2} \right)}
\end{align*}
We don't know the true proportion $p_c$, but we can obtain a good estimate of it, $\hat{p}_c$, by \emph{pooling} the results of both samples.  We find the total number of ``yeses" or ``successes" and divide that by the total number of cases.  This is equivalent to taking a weighted average of $\hat{p}_1$ and $\hat{p}_2$.  We call $\hat{p}_c$ the \term{pooled sample proportion}, and we use it to check the large counts condition and to compute the standard error when the null hypothesis is $p_1 = p_2$.  Here:

$$\hat{p}_c =  \frac{771(0.47) + 732(0.34)}{771+732}= 0.407$$

\begin{onebox}{Pooled sample proportion}
When the null hypothesis is $p_1 = p_2$, it is useful to find the pooled sample proportion:
\begin{eqnarray*}
\hat{p}_c = \frac{\text{number of ``successes''}}{\text{number of cases}} = \frac{\text{x}_1+\text{x}_2}{n_1+n_2}=\frac{n_1\hat{p}_1 + n_2\hat{p}_2}{n_1 + n_2}
\end{eqnarray*}
Here $\text{x}_1$ represents the number of successes in sample 1. If $\text{x}_1$ is not given, it can be computed as $n_1\times \hat{p}_1$. Similarly, $\text{x}_2$ represents the number of successes in sample~2 and can be computed as $n_2\times \hat{p}_2$.
\end{onebox}


\begin{examplewrap}
\begin{nexample}{Verify that conditions for using the normal distribution are met and find the $SE$ of estimate for this hypothesis test.  Recall that the pooled proportion $\hat{p}_c=0.407$, $n_1 = 771$, and $n_2=732$.}
The data do come from an experiment with two randomly assigned treatments.  Here the treatments are the two different orderings of the question regarding healthcare.  Because this is an experiment, the 10\% condition does not need to be checked.  Also, the large counts condition (minimums of 10) easily holds for each group.
\begin{align*}
771 \times 0.407 &\ge 10
	&771 \times (1-0.407) &\ge 10
	&732 \times 0.407 &\ge 10
	&732 \times (1-0.407) &\ge 10
\end{align*}
Because $H_0: p_1=p_2$, we compute the $SE$ for the difference in sample proportions as:
$$SE_{\hat{p}_1-\hat{p}_2} =\sqrt{\hat{p}_c(1-\hat{p}_c)\left(\frac{1}{n_1} + \frac{1}{n_2} \right)}=\sqrt{0.407(1-0.407)\left(\frac{1}{771} + \frac{1}{732}\right)}=0.025$$
\end{nexample}
\end{examplewrap}


To verify conditions are met for the two-sample Z-test for a difference in population proportions, check the following.
\begin{description}
\setlength{\itemsep}{0mm}
\item[Independence.]
  The data is collected from 2 independent random samples, where each sample size is less than 10\% of the population size if done without replacement, or the data is collected from an experiment with two randomly assigned treatments (in this case the 10\% condition is not relevant and does not need to be checked).
\item[Large counts.]
 The expected number of successes and failures should be at least 10 for both groups using the sample pooled proportion $\hat{p}_c$:
 $n_1\hat{p}_c \ge 10$, $n_1(1-\hat{p}_c) \ge 10$, $n_2\hat{p}_c \ge 10$, and $n_2(1 -\hat{p}_c) \ge 10$
\end{description}


\begin{examplewrap}
\begin{nexample}{Complete the hypothesis test using a significance level of 0.01.}
We have already set up the hypotheses and verified that the difference of proportions can be modeled using a normal distribution.  We can now calculate the test statistic and p-value.  
\begin{eqnarray*}
Z = \frac{\text{point estimate} - \text{null value}}{SE\ \text{of estimate}}= \frac{(0.47-0.34) - 0}{0.025} = 5.2
\end{eqnarray*}
This is a two-tailed test as $H_A$ is that $p_1\ne p_2$.  We can find the area in one tail and double it.  Here, the p-value $\approx$ 0.  Because the p-value is smaller than $\alpha = 0.01$, we reject the null hypothesis and we have evidence that the order of the statements affects how likely a respondent is to support the 2010 healthcare law.
\end{nexample}
\end{examplewrap}

It might be unclear about when to use the pooled sample proportion versus the individual sample proportions for checking conditions for inference for a difference in proportions and computing the standard error. For confidence intervals, we use the individual sample proportions ($\hat{p}_1$ and $\hat{p}_2$) for these calculations, while for hypothesis tests use the pooled sample proportion, $\hat{p}_c$.

%\begin{onebox}{Large counts condition and SE for two-sample Z test and interval}
%
%\termni{two-sample Z-interval} for $p_1-p_2$:
%\begin{align*}
%\text{Check:  } n_1\hat{p}_1\ge 10, n_1(1-\hat{p}_1)\ge 10,  &\quad \qquad \text{Use:  }SE_{\hat{p}_1-\hat{p}_2} = \sqrt{\frac{\hat{p}_1(1-\hat{p}_1)}{n_1} + \frac{\hat{p}_2(1-\hat{p}_2)}{n_2}}\\
%n_2\hat{p}_2\ge 10, n_2(1-\hat{p}_2)\ge 10&
%\end{align*}
%\termni{two-sample Z-test} with $H_0: p_1-p_2 = 0$: 
%\begin{align*}
%\text{Check:  } n_1\hat{p}_c\ge 10, n_1(1-\hat{p}_c)\ge 10, &\quad \qquad \text{Use:  }SE_{\hat{p}_1-\hat{p}_2} =\sqrt{\hat{p}_c(1-\hat{p}_c)\left(\frac{1}{n_1} + \frac{1}{n_2} \right)}\\
% n_2\hat{p}_c\ge 10, n_2(1-\hat{p}_c)\ge 10& 
%\end{align*}
%\end{onebox}

\newpage
 
 \subsection[Summary and worked example]{Summary and worked example}

\begin{onebox}{Hypothesis testing for a difference in proportions}
To carry out a complete hypothesis test to compare two population proportions,
\\
\\
\inferencestep{Identify} Identify the test procedure, parameter, significance level, and hypotheses.\vspace{-1mm}
\begin{itemize} 
\item[] Use a \termsub{two-sample Z-test for \pmb{$p_1 - p_2$}}{Z-test!for a difference of proportions}.  Define the population proportions $p_1$ and $p_2$ in the context of the problem.  Choose a significance level ($\alpha$) and test the following hypotheses.
\end{itemize} \vspace{-3mm}
\begin{itemize}
\setlength{\itemsep}{0mm}
\item[]  \quad \ $H_0$: \,$p_1 = p_2 $ \qquad  \qquad  \qquad  \qquad \qquad \quad \:  \:  ($p_1 - p_2 = 0$)
\item[]  \quad \ $H_A$: $p_1 \ne p_2$;  \; $p_1  > p_2$; \; or \; $p_1 <  p_2$ \qquad($p_1 - p_2 \ne 0$; \;  $p_1  - p_2  > 0$; \; or \;   $p_1 -  p_2 < 0$)
\end{itemize}
 \inferencestep{Check} Check conditions for the test statistic to be nearly normal, assuming $H_0$ is true.  \vspace{-1mm}
{\setlength{\leftmargini}{13mm}
\begin{itemize}
\setlength{\itemsep}{0mm}
\item[1.]  Independence:  Data come from 2 independent random samples or from a randomized 
experiment with two treatments.  When sampling without replacement, check that the 
sample size is less than 10\% of the population size for both samples.
\item[2.] Large counts: $n_1\hat{p}_c\geq 10$, $n_1(1-\hat{p}_c)\geq 10$, $n_2\hat{p}_c\geq 10$, and $n_2(1-\hat{p}_c)\geq 10$
\end{itemize}
}
 \inferencestep{Calculate}  Calculate the Z-statistic and p-value.
\begin{itemize}
\item[] $Z = \frac{\text{point estimate } - \text{ null value}}{SE \text{ of estimate}}$
\begin{itemize}
\item[] point estimate: $\hat{p}_1 - \hat{p}_2$,  the difference in sample proportions 
\item[] null value: 0
\item[] $SE$ of estimate: $\sqrt{\hat{p}_c(1-\hat{p}_c)\left(\frac{1}{n_1} + \frac{1}{n_2} \right)}$, where $\hat{p}_c$ is the pooled proportion
\end{itemize}
\item[] p-value = (based on the Z-statistic and the direction of $H_A$)
\end{itemize}
 \inferencestep{Conclude} Compare the p-value to $\alpha$, and draw a conclusion in context.\vspace{-1mm}
\begin{itemize}
\item[] If the p-value is $\le \alpha$, reject $H_0$; there is sufficient evidence that [$H_A$ in context]. 
\item[] If the p-value is $> \alpha$, do not reject $H_0$; there is not sufficient evidence that [$H_A$ in context].
\end{itemize}\end{onebox}


\begin{examplewrap}
\begin{nexample}
{ A 5-year experiment
was conducted to evaluate the effectiveness
of fish oils on reducing heart attacks,
where each subject was randomized into one of two
treatment groups.
We'll consider heart attack outcomes in these patients:
\begin{center}
\begin{tabular}{l ccc}
  \hline
  & heart\us{}attack &
      no\us{}event & Total \\
  \hline
  fish\us{}oil & 145 & 12788 & 12933 \\
  placebo & 200 & 12738 & 12938 \\
  \hline
\end{tabular}
\end{center}
% library(openintro); library(xtable); xtable(fish_oil_18[[3]], digits = 0)
Carry out a complete hypothesis test at the 10\% significance level to test whether the use of fish oils is effective in reducing heart attacks.}

\begin{description}
\item[\inferencestep{Identify}]  Because we are testing whether the difference in proportions is 0, we choose the two-sample Z-test for $p_1 - p_2$, where  
\begin{itemize}\vspace{-1mm}
\item[] $p_1$ is the true proportion who would suffer a heart attack if given fish oil. 
\item[] $ p_2$ is the true proportion who would suffer a heart attack if given placebo.
\end{itemize}
We will test the following hypotheses at the $\alpha=0.10$ significance level.
\begin{itemize}\vspace{-1mm}
\item[] $H_0$: \,$p_1 = p_2$   \quad Fish oil and placebo are equally effective. 
\item[] $H_A$: $p_1 < p_2$ \quad Fish oil is more effective in reducing heart attacks.
\end{itemize}
 
\item[\inferencestep{Check}]  We must verify that the difference in sample proportions can be modeled using a normal distribution.  First we note that there is a randomized experiment with two treatments: fish oil and placebo.  Since we have randomly assigned treatments, we do not need to check the 10\% condition.  Next, we calculate the pooled proportion as follows:
$$\hat{p}_c = \frac{\text{x}_1+\text{x}_2}{n_1+n_2}=\frac{145 + 200}{12933 + 12938}=0.0133$$

We can now verify: $12933(0.0133)\geq10$, $12933(1-0.0133)\geq10$, $12938(0.0133)\geq10$, and $12938(1-0.0133)\geq10$,  so both conditions are met. 
\item[ \inferencestep{Calculate} ]  We will calculate the Z-statistic and the p-value.
\begin{align*}
Z = \frac{\text{point estimate } - \text{ null value}}{SE \text{ of estimate}}
\end{align*}

The point estimate is the difference in sample proportions: $\hat{p}_1-\hat{p}_2 = 0.0112 - 0.0155 = -0.0043$. \\

$SE$ of $\hat{p}_1-\hat{p}_2$, assuming $H_0$ is true, is: \\
$\sqrt{\hat{p}_c(1-\hat{p}_c)\left(\frac{1}{n_1} + \frac{1}{n_2} \right)}= \sqrt{0.0133(1-0.0133)\left(\frac{1}{12933} + \frac{1}{12938}\right)}=0.00142$. \\

The null value is the hypothesized difference in population proportions, which is 0. 
\begin{align*}
Z =\frac{(0.0112 - 0.0155) - 0}{\sqrt{0.0133(1-0.0133)\left(\frac{1}{12933} + \frac{1}{12938}\right)}} = \frac{-0.0043 - 0}{0.00142} = -3.0
\end{align*}
Because $H_A$ uses a less than, meaning that it is a lower-tail test, the \mbox{p-value} is the area to the \emph{left} of $Z=-3.0$ under the standard normal distribution.  This area can be found using technology or a normal table.  The p-value = $0.0013$.  
\item[\inferencestep{Conclude}]  The p-value of 0.0013 is $< 0.10$, so we reject $H_0$; there is sufficient evidence that fish oil is effective in reducing heart attacks.  Note that we are only allowed to use causal language here because there was an experiment. 
\end{description}
\end{nexample}
\end{examplewrap}


\D{\newpage}

%%%%%%%%%%%%%%%%%%%%
\subsection[Technology: the two-sample Z-interval and Z-test for $p_1 - p_2$]{Technology: the two-sample Z-interval and Z-test for \pmb{$p_1 - p_2$}}
\label{tech2Z}

\noindent Figure~\ref{resultsForCPRStudyInSmallSampleSection}, summarizes an experiment involving patients admitted to a hospital for a heart attack.  14 out of the 40 patients assigned to the treatment (blood thinner) group survived versus 11 out of 50 assigned to the control group. Calculate a 95\% confidence interval for a difference in the proportion (treatment $-$ control) that would survive.  Also calculate the test statistic and p-value to test whether there is evidence that the true proportions \textit{differ}.  Conditions have been verified.\\


\noindent \textbf{Desmos}:  Use the \texttt{zproptest(x1, n1, x2, n2)} function as explained below.
\begin{enumerate}
\setlength{\itemsep}{0mm}
\item Click \calctext{+} in the upper left, then choose \calctext{inference}.  
\item Choose \calctext{$z$-test for proportions} in the pop-up window.
\begin{center}
\fbox{\Figures[A Desmos calculator screen is shown. The + and inference option are highlighted. ]
{0.3}{technologyInferenceProps}{desmosInference}}\hspace{10mm}
\fbox{\Figures[A Desmos calculator screen is shown with the inference pop-up box. z-test for proportions is highlighted. ]
{0.3}{technologyInferenceProps}{desmosInferenceZTest}}
\end{center}
\item Under \calctext{SAMPLE 1}, enter \calctext{successes} (x$_1$) and \calctext{sample size} (n$_1$) for group 1.  Click\\
 \calctext{SAMPLE 2}, enter \calctext{successes} (x$_2$) and \calctext{sample size} (n$_2$) for group 2.  Click \calctext{Create Test}.
\begin{center}
\fbox{\Figures[A Desmos calculator screen is shown with the inference pop-up box for z-test for proportions shown.  Under Sample 1 is 14 for successes and 40 for sample size.  Under Sample 2 is 11 for successes and 15 for sample size.  The Creat Test button is highilghted. ]
{0.55}{technologyInferenceProps}{desmos2PropData}}
\end{center}

\indent\hspace{-4mm} * You can type \calctext{zproptest(14, 40, 11, 50)} in place of steps 1-3 above.
\vspace{1mm}
\item Click the triangle next to \calctext{Confidence Interval} and input the desired \calctext{Confidence level}.  Click the \calctext{\vdots } to the right of the confidence interval to see additional information.  Hover over the dot in the middle of the confidence interval to see the point estimate.  
\item Click the triangle next to \calctext{Significance Test}.  Enter the hypothesized value for the difference.  Usually this will be 0.  Select a value for \calctext{Tails} based on the direction of H$_A$.  
\begin{center}
\fbox{\Figures[A Desmos calculator screen is shown.  zproptest(14, 40, 11, 50) is entered.  Confidence Interval is selected with Confidence level: 0.95.  The three vertical dots are clicked showing Lower bound = -0.05717, Upper bound = 0.31717, Point estimate = 0.13, and Standard error = 0.0955. ]
{0.3}{technologyInferenceProps}{desmos2PropCI}}\hspace{5mm}
\fbox{\Figures[A Desmos calculator screen is shown.  zproptest(14, 40, 11, 50) is entered.  Significance Test is selected.  A null difference of 0 is entered and Tails is Both.  Z = 1.368 and p-value = 0.171.]
{0.3}{technologyInferenceProps}{desmos2PropTest}}
\end{center}
\end{enumerate}
 
\newpage
%%%%
\noindent \R{}:  2-proportion Z-interval/test for $p_1-p_2$\\

\noindent Here we use \texttt{prop.test()} with \texttt{x = c(x$_1$, x$_2$)} and \texttt{n = c(n$_1$, n$_2$)}.  \\

\noindent 	CONFIDENCE INTERVAL.

\noindent \texttt{> \calctext{prop.test(x=c(14, 11), n=c(40, 50), correct = FALSE, conf.level = 0.95)}}\\
\texttt{
	2-sample test for equality of proportions without continuity correction\\
data:  c(14, 11) out of c(40, 50)\\
X-squared = 1.872, df = 1,  p-value = 0.1712\\
alternative hypothesis: two.sided\\
95 percent confidence interval:\\
\fbox{-0.05716886  0.31716886}\\
sample estimates:\\
prop 1 prop 2 \\
  0.35   0.22 }\\ \\

\noindent HYPOTHESIS TEST.

\noindent \texttt{> \calctext{prop.test(x = c(14, 11), n=c(40, 50), correct = FALSE, alternative = "two.sided")}}\\
\texttt{
	2-sample test for equality of proportions without continuity correction\\
data:  c(14, 11) out of c(40, 50)\\
\fbox{X-squared = 1.872}, df = 1,  \fbox{p-value = 0.1712}\\
alternative hypothesis: two.sided\\
95 percent confidence interval:\\
-0.05716886  0.31716886\\
sample estimates:\\
prop 1 prop 2 \\
  0.35   0.22 }\\ \\
This test returns X-squared instead of Z.   
\\Z = $+\sqrt{\texttt{X-squared}}$ or $-\sqrt{\texttt{X-squared}}$, depending on if sample \texttt{(prop 1 $-$ prop 2)} is $+$ or $-$. 
\\ Here (0.35 $-$ 0.22) is positive, so Z = $\sqrt{1.872}$.\\ \\
\texttt{> \calctext{Z = sqrt(1.872)}}\\
\texttt{> \calctext{Z}}\\
\texttt{[1] 1.368211}\\ \\


\newpage
%%%%%
\noindent \textbf{Calculator}: NumWorks calculator instructions and example output are included.  For the TI-83/84 and Casio calculators, general instructions are provided, and worked example videos can be accessed via the \includegraphics[height=3mm]{extraTeX/icons/video_camera.png} icon or at \oiRedirect{ti84_playlist}{\textbf{openintro.org/ti}} and \oiRedirect{casio-9750-playlist}{\textbf{openintro.org/casio}}.
\\
\\

\begin{onebox}{NumWorks: 2-proportion Z-interval}
\label{normalnumworks}
Use \calctext{OK} or \calctext{EXE} to make a selection.
\begin{enumerate}
\setlength{\itemsep}{0mm}
\item From the home screen, select \calcbutton{Inference}, then \calctext{Intervals}, then \calctext{Two proportions}.  If these options do not appear, click the \calcbutton{$\lhookleftarrow$} button in the upper right as many times as needed. 
\item Enter \calctext{x$_1$}, \calctext{n$_1$}, \calctext{x$_2$}, \calctext{n$_2$}, and \calctext{Confidence level}, then choose \calcbutton{Next}. 
\item Click the down arrow to see all quantities returned and then choose \calctext{Next}.
\item In addition to seeing the confidence interval displayed in two ways, you can press the up and down arrows to quickly change confidence level and see the resulting interval and margin of error.
\begin{center}
\Figures[ ]
{0.35}{technologyInferenceProps}{numworks2PropCI1}\hspace{10mm}
\Figures[ ]
{0.35}{technologyInferenceProps}{numworks2PropCI2}
\end{center}
\vspace{-1.5mm}
\end{enumerate}
\end{onebox}
%
\begin{onebox}{NumWorks: 2-proportion Z-test}
\label{normalnumworks}
Use \calctext{OK} or \calctext{EXE} to make a selection.
\begin{enumerate}
\setlength{\itemsep}{0mm}
\item From the home screen, select \calcbutton{Inference}, then \calctext{Tests}, then \calctext{Two proportions}.  If these options do not appear, click the \calcbutton{$\lhookleftarrow$} button in the upper right as many times as needed. 
\item  Enter the hypothesized difference.  Usually this will be 0.  Press the down arrow.  Press \calcbutton{OK} and choose \calctext{$<$}, \calctext{$\ne$} , or \calctext{$>$}  for the Alternative hypothesis.  Press the down arrow and choose \calcbutton{Next}. 
\item Enter the values of \calctext{x$_1$}, \calctext{n$_1$}, \calctext{x$_2$}, \calctext{n$_2$}, and \calctext{$\alpha$}.  Hit the down arrow and choose \calcbutton{Next}. 
\item Note the quantities returned.  Click the down arrow to see all of the values, including the p-value, then choose \calctext{Next}.
\item On this screen, the p-value and alpha are shaded on the normal distribution and can be visually compared.
\begin{center}
\Figures[ ]
{0.35}{technologyInferenceProps}{numworks2PropTest1}\hspace{10mm}
\Figures[ ]
{0.35}{technologyInferenceProps}{numworks2PropTest2}
\end{center}
\vspace{-1.5mm}
\end{enumerate}
\end{onebox}

\newpage
%%
\begin{onebox}{\videohref{ti84_2_prop_CI} TI-83/84: 2-proportion Z-interval}
Use \calcbutton{STAT}, \calctext{TESTS}, \calctext{2-PropZInt}.
\begin{enumerate}
\setlength{\itemsep}{0mm}
\item Choose \calcbutton{STAT}.
\item Right arrow to \calctext{TESTS}.
\item Down arrow and choose \calctext{B:2-PropZInt}.
\item Let \calctext{x1} be the \emph{number} of yeses (must be an integer) in sample 1 and let \calctext{n1} be the size of sample 1.
\item Let \calctext{x2} be the \emph{number} of yeses (must be an integer) in sample 2 and let \calctext{n2} be the size of sample 2.
\item Let \calctext{C-Level} be the desired confidence level.
\item Choose \calctext{Calculate} and hit \calcbutton{ENTER}, which returns: \\[1mm]
\begin{tabular}{ll l ll}
\calctext{(\underline{\ \ },\underline{\ \ })} & the confidence interval \\
$\calctextmath{\hat{p}_1}$ & sample 1 proportion &\quad&
	$\calctextmath{n_1}$ & size of sample 1 \\
$\calctextmath{\hat{p}_2}$ & sample 2 proportion &&
	$\calctextmath{n_2}$ &  size of sample 2
\end{tabular}
\end{enumerate}
\end{onebox}
%
\begin{onebox}{\videohref{ti84_2_prop_HT} TI-83/84: 2-proportion Z-test}
Use \calcbutton{STAT}, \calctext{TESTS}, \calctext{2-PropZTest}.
\begin{enumerate}
\setlength{\itemsep}{0mm}
\item Choose \calcbutton{STAT}.
\item Right arrow to \calctext{TESTS}.
\item Down arrow and choose \calctext{6:2-PropZTest}.
\item Let \calctext{x1} be the \emph{number} of yeses (must be an integer) in sample 1 and let \calctext{n1} be the size of sample 1.
\item Let \calctext{x2} be the \emph{number} of yeses (must be an integer) in sample 2 and let \calctext{n2} be the size of sample 2.
\item Choose $\calctextmath{\ne}$, $\calctextmath{<}$, or $\calctextmath{>}$ to correspond to $H_A$.
\item Choose \calctext{Calculate} or \calctext{Draw} and hit \calcbutton{ENTER}.  \calctext{Draw} shows the Z-statistic and p-value as well as a graph of the normal distribution with p-value shaded.  \calctext{Calculate} returns: \\[1mm]
\begin{tabular}{ll l ll}
\calctext{z} & Z-statistic &\quad&
	\calctext{p} & p-value \\
$\calctextmath{\hat{p}_1}$ & sample 1 proportion &&
	$\calctextmath{\hat{p}}$ & pooled sample proportion \\
$\calctextmath{\hat{p}_2}$ & sample 2 proportion
\end{tabular}
\end{enumerate}
\end{onebox}

\newpage
%%
\begin{onebox}{\videohref{casio_2_prop_inference} Casio fx-9750GII: 2-proportion Z-interval}
\ \vspace{-5mm} \
\begin{enumerate}
\setlength{\itemsep}{0mm}
\item Navigate to \calctext{STAT} (\calcbutton{MENU} button, then hit the \calcbutton{2} button or select \calctext{STAT}).
\item Choose the \calctext{INTR} option (\calcbutton{F4} button).
\item Choose the \calctext{Z} option (\calcbutton{F1} button).
\item Choose the \calctext{2-P} option (\calcbutton{F4} button).
\item Specify the interval details:
  \begin{itemize}
  \item Confidence level of interest for \calctext{C-Level}.
  \item Enter the number of successes for each group, \calctext{x1} and \calctext{x2}.
  \item Enter the sample~size for each group, \calctext{n1} and \calctext{n2}.
  \end{itemize}
\item Hit the \calcbutton{EXE} button, which returns \\[1mm]
  \begin{tabular}{ll}
  \calctext{Left}, \calctext{Right}  &  the ends of the confidence interval \\
  $\calctextmath{\hat{p}1}$, $\calctextmath{\hat{p}2}$ &
  				the sample proportions \\
  \calctext{n1}, \calctext{n2} & sample~sizes
  \end{tabular}
\end{enumerate}
\end{onebox}
%
\begin{onebox}{\videohref{casio_2_prop_inference} Casio fx-9750GII: 2-proportion Z-test}
\ \vspace{-5mm} \
\begin{enumerate}
\setlength{\itemsep}{0mm}
\item Navigate to \calctext{STAT} (\calcbutton{MENU} button, then hit the \calcbutton{2} button or select \calctext{STAT}).
\item Choose the \calctext{TEST} option (\calcbutton{F3} button).
\item Choose the \calctext{Z} option (\calcbutton{F1} button).
\item Choose the \calctext{2-P} option (\calcbutton{F4} button).
\item Specify the test details:
  \begin{itemize}
  \setlength{\itemsep}{0mm}
  \item Specify the sidedness of the test using the \calcbutton{F1}, \calcbutton{F2}, and \calcbutton{F3} keys.
  \item Enter the number of successes for each group, \calctext{x1} and \calctext{x2}.
  \item Enter the sample~size for each group, \calctext{n1} and \calctext{n2}.
  \end{itemize}
\item Hit the \calcbutton{EXE} button, which returns \\[1mm]
  \begin{tabular}{ll ll l}
  \calctext{z} & Z-statistic & \hspace{3mm} &
  	$\calctextmath{\hat{p}1}$, $\calctextmath{\hat{p}2}$ & sample proportions \\
  \calctext{p} & p-value && $\calctextmath{\hat{p}}$ & pooled proportion \\
  &&& \calctext{n1}, \calctext{n2} &  sample~sizes
  \end{tabular}
\end{enumerate}\end{onebox}






\D{\newpage}

%%
\subsection*{Section summary}
\begin{itemize}
\item The appropriate hypothesis testing procedure for a difference between two population proportions is a \termni{two-sample \pmb{$Z$}-test for \pmb{$p_1-p_2$}}.  The parameters $p_1$ and $p_2$ should be identified in context.

\item The parameters for a hypothesis test for a difference between two
population proportions should reference the population parameters, the
response variables, and the populations in context.

\item The null hypotheses for a two-sample $Z$-test for a difference in population proportion indicates no difference and is written as:  
\begin{itemize}
\setlength{\itemindent}{3mm}
\item[$H_0$:] $p_1=p_2$ (or equivalently $H_0$: $p_1-p_2 = 0$).  
\end{itemize}
\item A one-sided alternative hypothesis is written as: 
\begin{itemize}
\setlength{\itemindent}{3mm}
\item[$H_A$:] $p_1<p_2$ (or equivalently $H_A$: $p_1-p_2<0$), or
\item[$H_A$:] $p_1>p_2$ (or equivalently $H_A$: $p_1-p_2>0$).
\end{itemize}

\item[] A two-sided alternative hypothesis is written as: 
\begin{itemize}
\setlength{\itemindent}{3mm}
\item[$H_A$:] $p_1\ne p_2$ (or equivalently $H_A$: $p_1-p_2\ne 0$).
\end{itemize}

\item  The combined or pooled proportion is denoted $\hat{p}_c$ and is calculated as $\frac{x_1 + x_2}{n_1 + n_2}$ or $\frac{n_1\hat{p}_1 + n_2\hat{p}_2}{n_1+n_2}$.

\item The two-sample $Z$-test for $p_1-p_2$ requires the following conditions be met:
\begin{itemize}
\item[1.] Independence:  The data come from two independent random samples, each with sample size $<$ 10\% of its corresponding population size if sampling without replacement OR the data come from an experiment with two randomly assigned treatments.
\item[2.] Large counts: the expected number of successes and failures for both samples, assuming $H_0$ is true, is at least 10, that is,
$n_1\hat{p}_c\ge 10$, $n_1(1-\hat{p}_c)\ge 10$, $n_2\hat{p}_c\ge 10$ and $n_2(1-\hat{p}_c)\ge 10$.  
\end{itemize}


\item A \termni{test statistic} has the form: test statistic $= \frac{\text{point estimate } - \text{ null value}}{SE \text{ of estimate}}$.  \\

The test statistic for a two-sample $Z$-test for $p_1-p_2$ is: $Z = \frac{(\hat{p}_1 - \hat{p}_2)-0}{\sqrt{\hat{p}_c(1-\hat{p}_c)\left(\frac{1}{n_1}+\frac{1}{n_2}\right)}}$.\\

\noindent The $SE$ is calculated under the assumption that the $H_0$ is true and uses $\hat{p}_c$.


\item The p-value for a $Z$-test corresponds to a lower tail, upper tail, or both tails of the standard normal distribution, depending on whether the direction of the alternate hypothesis is $<$, $>$, or $\ne$.

\item The p-value for a two-sample $Z$-test for $p_1-p_2$ is the probability of obtaining a $Z$-statistic as small or smaller, as large or larger, or as extreme or more extreme than the $Z$-statistic that was observed, depending on whether the direction of the alternate hypothesis is $<$, $>$, or $\ne$., assuming the null hypothesis is true (i.e. that the population proportions are equal).  

\item A formal decision explicitly compares the p-value to the significance level.  If the \mbox{p-value $\le \alpha$,} then reject the null hypothesis; if the \mbox{p-value $> \alpha$,} then fail to reject the null hypothesis.   The conclusion should be stated in terms of the alternative hypothesis and should include context, referencing the parameters and the populations.  Use non-causal language unless a well-designed experiment was conducted.


\item The results of a hypothesis test for a difference between two population
proportions can serve as the statistical reasoning to support the answer to an
investigative question about the two populations that were sampled.

\end{itemize}

%%%%%%%Section Exercises
{\input{ch_inference_for_props/TeX/hypothesis_testing_for_a_difference_in_population_proportions.tex}}


%________________________________________
\section[Goodness of fit using chi-square (special topic)]{Goodness of fit using chi-square (special topic) }

\label{oneWayChiSquare}

\sectionintro{
\noindent%
Are juries representative of the population in terms of race/ethnicity, or is there a bias in jury selection?  Is the color distribution of actual M\&M's consistent with what was reported on the Mars website? Do people choose rock, paper, scissors with the same likelihood, or is one choice favored over another?  To answer such questions, we develop a method for assessing a null model when the data take on more than two categories.  

%%
\subsection*{Learning objectives}
\begin{enumerate}
\setlength{\itemsep}{0mm}

\item Describe chi-square distributions.

\item Identify and set up an appropriate testing method for assessing goodness of fit using a one-way table with a single categorical variable.

\item Calculate the expected counts and degrees of freedom for a one-way table, assuming the null hypothesis is true.

\item Verify whether the conditions for the chi-square goodness of fit are met.

\item Calculate the $\chi^2$-test statistic, degrees of freedom and p-value for a goodness of fit test.

\end{enumerate}
}

%%
\subsection{Creating a test statistic for one-way tables}
\index{chi-square goodness of fit test@$\chi^2$ goodness of fit test|(}

Data is collected from a random sample of 275 jurors in a small county. Jurors identified their racial/ethnic group, as shown in Figure~\ref{juryRepresentationAndCityRepresentationForRace}, and we would like to determine if these jurors are representative of the population with respect to race/ethnicity. If the jury is representative of the population, then the proportions in the sample should roughly reflect the population of eligible jurors, i.e. registered voters.

\begin{figure}[h]
\centering
\begin{tabular}{ll ccc c ll}
\hline
Race/Ethnicity	 & \hspace{2mm} & White & Black & Hispanic & Other & \hspace{2mm} & Total \\
\hline
Representation in juries &	& 205 & 26 & 25 & 19 & & 275 \\
Registered voters	 & 		& 0.72 & 0.07 & 0.12 & 0.09 & & 1.00 \\
\hline
\end{tabular}
\caption{Representation by race in a city's juries and population.}
\label{juryRepresentationAndCityRepresentationForRace}
\end{figure}

While the proportions in the juries do not precisely represent the population proportions, it is unclear whether these data provide convincing evidence that the sample is not representative. If the jurors really were randomly sampled from the registered voters, we might expect small differences due to chance. However, unusually large differences may provide convincing evidence that the juries were not representative.

\begin{examplewrap}
\begin{nexample}{Of the people in the city, 275 served on a jury. If the individuals are randomly selected to serve on a jury, about how many of the 275 people would we expect to be White? How many would we expect to be Black?}
About 72\% of the population is White, so we would expect about 72\% of the jurors to be White: $0.72\times 275 = 198$.

Similarly, we would expect about 7\% of the jurors to be Black, which would correspond to about $0.07\times 275 = 19.25$ Black jurors.
\end{nexample}
\end{examplewrap}

\begin{exercisewrap}
\begin{nexercise}
Twelve percent of the population is Hispanic and 9\% represent other racial/ethnic groups. How many of the 275 jurors would we expect to be Hispanic or from another racial/ethnic group? Answers can be found in Figure~\ref{expectedJuryRepresentationIfNoBias}.
\end{nexercise}
\end{exercisewrap}

\begin{figure}[h]
\centering
\begin{tabular}{ll ccc c ll}
\hline
Race/Ethnicity	 & \hspace{2mm} & White & Black & Hispanic & Other & \hspace{2mm} & Total \\
\hline
Observed data			&	& 205 & 26	& 25 & 19	&	& 275 \\
Expected counts	 &	& 198 & 19.25 & 33 & 24.75 & & 275 \\
\hline
\end{tabular}
\caption{Actual and expected make-up of the jurors.}
\label{expectedJuryRepresentationIfNoBias}
\end{figure}

The sample proportion represented from each race/ethnicity among the 275 jurors was not a precise match for any ethnic group. While some sampling variation is expected, we would expect the sample proportions to be fairly similar to the population proportions if there is no bias on juries. We need to test whether the differences are strong enough to provide convincing evidence that the jurors are not a random sample. These ideas can be organized into hypotheses:
\begin{itemize}
\setlength{\itemsep}{0mm}
\item[$H_0$:] The jurors are a random sample, i.e. there is no racial/ethnic bias in who serves on a jury, and the observed counts reflect natural sampling fluctuation.
\item[$H_A$:] The jurors are not randomly sampled, i.e. there is racial/ethnic bias in juror selection.
\end{itemize}
To evaluate these hypotheses, we quantify how different the observed counts are from the expected counts. Strong evidence for the alternative hypothesis would come in the form of unusually large deviations in the groups from what would be expected based on sampling variation alone.


%%
\subsection{The chi-square test statistic}
\label{chiSquareTestStatistic}

In previous hypothesis tests, we constructed a test statistic of the following form:
$$ Z = \frac{\text{point estimate} - \text{null value}}{SE \text{ of point estimate}} $$
This construction was based on (1) identifying the difference between a point estimate and an expected value if the null hypothesis was true, and (2) standardizing that difference using the standard error of the point estimate. These two ideas will help in the construction of an appropriate test statistic for count data.

In this example we have four categories: White, Black, Hispanic, and other. Because we have four values rather than just one or two, we need a new tool to analyze the data. Our strategy will be to find a test statistic that measures the overall deviation between the observed and the expected counts. 

\D{\newpage}

We first find the difference between the observed and expected counts for the four groups:
\begin{align*}
&&\text{White} && \text{Black} && \text{Hispanic} && \text{Other} \\
\text{observed - expected }&& 205-198 && 26-19.25
	&& 25-33
	&& 19-24.75
\end{align*}
Next, we square the differences:
\begin{align*}
&&\text{White} && \text{Black} && \text{Hispanic} && \text{Other} \\
\text{(observed - expected)}^2 && (205-198)^2 && (26-19.25)^2
	&& (25-33)^2
	&& (19-24.75)^2
\end{align*}
We must standardize each term. To know whether the squared difference is large, we compare it to what was expected. If the expected count was 5, a squared difference of 25 is very large. However, if the expected count was 1,000, a squared difference of 25 is very small. We will divide each of the squared differences by the corresponding expected count.
\begin{align*}
&&\text{White} && \text{Black} && \text{Hispanic} && \text{Other} \\
\frac{\text{(observed - expected)}^2}{\text{expected}} && \frac{(205-198)^2}{198} && \frac{(26-19.25)^2 }{19.25}
	&& \frac{(25-33)^2}{33}
	&& \frac{(19-24.75)^2}{24.75}
\end{align*}
Finally, to arrive at the overall measure of deviation between the observed counts and the expected counts, we add up the terms.  This gives us a new test statistic called $\chi^2$ (read as chi-square).
\begin{align*}
\chi^2 &= \sum{\frac{\text{(observed - expected)}^2}{\text{expected}}} \\
	&= \frac{(205-198)^2}{198}
		+ \frac{(26-19.25)^2 }{19.25}
		+ \frac{(25-33)^2}{33}
		+ \frac{(19-24.75)^2}{24.75}
\end{align*}
%\Comment{The following sentence: The test statistic chii-sq is generally used for these reasons seems out of place. What reasons?}
% David: I am guessing the explanations were cut out during the development of the Preliminary Edition, but this sentence was accidentally left in.
We can write an equation for $\chi^2$ using the observed counts and expected counts:
\index{data!racial make-up of jury|)}
{\begin{align*}
\chi^2 &=
	\frac
	{\text{\footnotesize$(\text{observed count}_1 - \text{expected count}_1)^2$}}
	{\text{\footnotesize$\text{expected count}_1$}}
	+ \dots + \frac
	{\text{\footnotesize$(\text{observed count}_4 - \text{expected count}_4)^2$}}
	{\text{\footnotesize$\text{expected count}_4$}}
\end{align*}
}The final number $\chi^2$ summarizes how strongly the observed counts tend to deviate from the null counts.

Next, we will see that if the null hypothesis is true, then $\chi^2$ follows a distribution called a \emph{chi-square distribution}. Using this distribution, we will be able to obtain a p-value to evaluate whether there appears to be racial/ethnic bias in the juries for the city we are considering.



%%
\subsection{The chi-square distribution and finding areas}

The \term{chi-square distribution} is sometimes used to characterize data sets and statistics that are always positive and typically right skewed. Recall a normal distribution had two parameters -- mean and standard deviation -- that could be used to describe its exact characteristics. The chi-square distribution has just one parameter called \termsub{degrees of freedom (df)}{degrees of freedom (df)!chi-square}, which influences the shape, center, and spread of the distribution.

%\begin{exercisewrap}
%\begin{nexercise}\label{exerChiSquareDistributionDescriptionWithMoreDOF}
%Figure~\ref{chiSquareDistributionWithInceasingDF} shows three chi-square distributions. (a) How does the center of the distribution change when the degrees of freedom is larger? (b) What about the variability (spread)? (c) How does the shape change?\footnotemark
%\end{nexercise}
%\end{exercisewrap}
%\footnotetext{(a)~The center becomes larger. If we look carefully, we can see that the center of each distribution is equal to the distribution's degrees of freedom. (b)~The variability increases as the degrees of freedom increases. (c)~The distribution is very strongly right skewed for $df=2$, and then the distributions become more symmetric for the larger degrees of freedom $df=4$ and $df=9$. In fact, as the degrees of freedom increase, the $\chi^2$ distribution approaches a normal distribution. }
%

\begin{figure}[h]
\centering
\Figure[Three chi-square distributions are shown with degrees of freedom 2, 4, and 9 on the same plot. The horizontal axis ranges from 0 to 25 -- recall that the chi-square distributions never take values smaller than 0. The chi-square distribution with 2 degrees of freedom starts at a peak at zero and then quickly declines more than halfway by the value of 2 and trails off after a value of about 5. The chi-square distribution with 4 degrees of freedom starts at 0 and quickly rises to a peak at about 2, before gradually declining and then more steeply declining starting at 3, before starting to flatten at about 5 or 6. The distribution has fallen very close to the horizontal axis by a value of 10. The chi-square distribution with 9 degrees of freedom starts at zero before gradually rising up to a peak at about 7 before declining again and trailing off between at around 15.]
{0.7}{chiSquareDistributionWithInceasingDF}
\caption{Three chi-square distributions with varying degrees of freedom.  The distributions are non-negative and right skewed.  As the degrees of freedom increase, chi-square distributions become less skewed and have a larger center and spread.}
\label{chiSquareDistributionWithInceasingDF}
\end{figure}

Figure~\ref{chiSquareDistributionWithInceasingDF} illustrates three general properties of chi-square distributions as the degrees of freedom increases: the distribution becomes more symmetric, the center moves to the right, and the variability inflates.

\D{\newpage}

Our principal interest in the chi-square distribution is the calculation of p-values, which (as we have seen before) is related to finding the relevant area in the tail of a distribution. %To do so, a new table is needed: the \term{chi-square table}, partially shown in Figure~\ref{chiSquareProbabilityTableShort}. A more complete table is presented in Appendix~\vref{chiSquareProbabilityTable}. We identify a range for the area, and we examine a particular row for distributions with different degrees of freedom. One important difference from the $t$-table is that the chi-square table only provides upper tail values.

%\begin{figure}[h]
%\centering
%\begin{tabular}{r | rrrr | rrrr |}
%  \hline
%Upper tail & 0.3 & 0.2 & 0.1 & 0.05 & 0.02 & 0.01 & 0.005 & 0.001 \\
%  \hline
%df \hfill 1 & \footnotesize 1.07 & \footnotesize 1.64 & \footnotesize 2.71 & \footnotesize 3.84 & \footnotesize 5.41 & \footnotesize 6.63 & \footnotesize 7.88 & \footnotesize 10.83 \\
% \hfill 2 & \footnotesize 2.41 & \footnotesize \highlightO{3.22} & \footnotesize \highlightO{4.61} & \footnotesize 5.99 & \footnotesize 7.82 & \footnotesize 9.21 & \footnotesize 10.60 & \footnotesize 13.82 \\
%  \em3 & \em\footnotesize 3.66 & \em\footnotesize 4.64 & \em\footnotesize \em\highlightT{6.25} & \em\footnotesize 7.81 & \em\footnotesize 9.84 & \em\footnotesize 11.34 & \em\footnotesize 12.84 & \em\footnotesize 16.27 \\
%  4 & \footnotesize 4.88 & \footnotesize 5.99 & \footnotesize 7.78 & \footnotesize 9.49 & \footnotesize 11.67 & \footnotesize 13.28 & \footnotesize 14.86 & \footnotesize 18.47 \\
%  5 & \footnotesize 6.06 & \footnotesize 7.29 & \footnotesize 9.24 & \footnotesize 11.07 & \footnotesize 13.39 & \footnotesize 15.09 & \footnotesize 16.75 & \footnotesize 20.52 \\
%  \hline
%  6 & \footnotesize 7.23 & \footnotesize 8.56 & \footnotesize 10.64 & \footnotesize 12.59 & \footnotesize 15.03 & \footnotesize 16.81 & \footnotesize 18.55 & \footnotesize 22.46 \\
%  7 & \footnotesize 8.38 & \footnotesize 9.80 & \footnotesize 12.02 & \footnotesize 14.07 & \footnotesize 16.62 & \footnotesize 18.48 & \footnotesize 20.28 & \footnotesize 24.32 \\
%  \hline
%\end{tabular}
%\caption{A section of the chi-square table. A complete table is in Appendix~\ref{chiSquareProbabilityTable}.}
%\label{chiSquareProbabilityTableShort}
%\end{figure}
%
%\begin{examplewrap}
%\begin{nexample}{Figure~\ref{chiSquareAreaAbove6Point25WithDF3} shows a chi-square distribution with 3 degrees of freedom and an upper shaded tail starting at 6.25. Use Figure~\ref{chiSquareProbabilityTableShort} to estimate the shaded area.}
%This distribution has three degrees of freedom, so only the row with 3 degrees of freedom (df) is relevant. This row has been italicized in the table. Next, we see that the value -- 6.25 -- falls in the column with upper tail area 0.1. That is, the shaded upper tail of Figure~\ref{chiSquareAreaAbove6Point25WithDF3} has area 0.1.
%\end{nexample}
%\end{examplewrap}

%\begin{figure}
%\centering
%\subfigure[]{
%\Figures[A chi-square distribution with 3 degrees of freedom is shown, with the area above 6.25 shaded. This region appears to be about 10\% of the area under the curve.]
%{0.475}{arrayOfFigureAreasForChiSquareDistribution/chiSquareAreaAbove6Point25WithDF3}{chiSquareAreaAbove6Point25WithDF3}
%\label{chiSquareAreaAbove6Point25WithDF3}
%}
%\subfigure[]{
%\Figures[A chi-square distribution with 2 degrees of freedom is shown, with the area above 4.3 shaded. This region appears to be about 10\% of the area under the curve.]
%{0.475}{arrayOfFigureAreasForChiSquareDistribution/chiSquareAreaAbove4Point3WithDF2}{chiSquareAreaAbove4Point3WithDF2}
%\label{chiSquareAreaAbove4Point3WithDF2}
%}
%\subfigure[]{
%\Figures[A chi-square distribution with 5 degrees of freedom is shown, with the area above 5.1 shaded. This region appears to be very roughly 50\% of the area under the curve.]
%{0.475}{arrayOfFigureAreasForChiSquareDistribution/chiSquareAreaAbove5Point1WithDF5}{chiSquareAreaAbove5Point1WithDF5}
%\label{chiSquareAreaAbove5Point1WithDF5}
%}
%\subfigure[]{
%\Figures[A chi-square distribution with 7 degrees of freedom is shown, with the area above 11.7 shaded. This region appears to be about 15\% of the area under the curve.]
%{0.475}{arrayOfFigureAreasForChiSquareDistribution/chiSquareAreaAbove11Point7WithDF7}{chiSquareAreaAbove11Point7WithDF7}
%\label{chiSquareAreaAbove11Point7WithDF7}
%}
%\subfigure[]{
%\Figures[A chi-square distribution with 4 degrees of freedom is shown, with the area above 10 shaded. This region appears to be about 5\% of the area under the curve.]
%{0.475}{arrayOfFigureAreasForChiSquareDistribution/chiSquareAreaAbove10WithDF4}{chiSquareAreaAbove10WithDF4}
%\label{chiSquareAreaAbove10WithDF4}
%}
%\subfigure[]{
%\Figures[A chi-square distribution with 3 degrees of freedom is shown, with the area above 9.21 shaded. This region appears to be about 3\% of the area under the curve.]
%{0.475}{arrayOfFigureAreasForChiSquareDistribution/chiSquareAreaAbove9Point21WithDF3}{chiSquareAreaAbove9Point21WithDF3}
%\label{chiSquareAreaAbove9Point21WithDF3}
%}
%\caption{
%\textbf{\subref{chiSquareAreaAbove6Point25WithDF3}}~Chi-square distribution with 3~degrees of freedom, area above 6.25 shaded.
%\textbf{\subref{chiSquareAreaAbove4Point3WithDF2}}~2~degrees of freedom, area above 4.3 shaded.
%\textbf{\subref{chiSquareAreaAbove5Point1WithDF5}}~5~degrees of freedom, area above 5.1 shaded.
%\textbf{\subref{chiSquareAreaAbove11Point7WithDF7}}~7~degrees of freedom, area above 11.7 shaded.
%\textbf{\subref{chiSquareAreaAbove10WithDF4}}~4~degrees of freedom, area above 10 shaded.
%\textbf{\subref{chiSquareAreaAbove9Point21WithDF3}}~3~degrees of freedom, area above 9.21 shaded.
%}
%\label{arrayOfFigureAreasForChiSquareDistribution}
%\end{figure}

%\begin{examplewrap}
%\begin{nexample}{We rarely observe the \emph{exact} value in the table. For instance, Figure~\ref{chiSquareAreaAbove4Point3WithDF2} shows the upper tail of a chi-square distribution with 2 degrees of freedom. The lower bound for this upper tail is at 4.3, which does not fall in Figure~\ref{chiSquareProbabilityTableShort}. Find the approximate tail area.}
%The cutoff 4.3 falls between the second and third columns in the 2 degrees of freedom row. Because these columns correspond to tail areas of 0.2 and 0.1, we can be certain that the area shaded in Figure~\ref{chiSquareAreaAbove4Point3WithDF2} is between 0.1 and 0.2.
%\end{nexample}
%\end{examplewrap}



\index{data!racial make-up of jury|(}
In the previous section, Section~\ref{chiSquareTestStatistic}, we identified a new test statistic ($\chi^2$) within the context of assessing whether there was evidence of racial/ethnic bias in how jurors were sampled. %The null hypothesis represented the claim that jurors were randomly sampled and there was no racial/ethnic bias. The alternative hypothesis was that there was racial/ethnic bias in how the jurors were sampled.
%
We determined that a large $\chi^2$ value would suggest strong evidence favoring the alternative hypothesis: that there was racial/ethnic bias. However, we could not quantify what the chance was of observing such a large test statistic ($\chi^2=5.89$) if the null hypothesis actually was true. This is where the chi-square distribution becomes useful. If the null hypothesis was true and there was no racial/ethnic bias, then $\chi^2$ would follow a chi-square distribution, with three degrees of freedom in this case. Under certain conditions, the statistic $\chi^2$ follows a chi-square distribution with $k-1$ degrees of freedom, where $k$ is the number of bins or categories of the variable.

%\begin{examplewrap}
%\begin{nexample}{How many categories were there in the juror example? How many degrees of freedom should be associated with the chi-square distribution used for $\chi^2$?}
%In the jurors example, there were $k=4$ categories: White, Black, Hispanic, and other. According to the rule above, the test statistic $\chi^2$ should then follow a chi-square distribution with $k-1 = 3$ degrees of freedom if $H_0$ is true.
%\end{nexample}
%\end{examplewrap}
\begin{figure}[h]
\centering
\Figure[A chi-square distribution with three degrees of freedom is shown, with the area to the right of 5.89 shaded.  This region appears to be about 10\% of the area under the curve.]
{0.61}{jurorHTPValueShown}
\caption{The p-value for the juror hypothesis test is shaded in the chi-square distribution with $df=3$.}
\label{jurorHTPValueShown}
\end{figure}

\begin{examplewrap}
\begin{nexample}{In our jury example, we have four categories of race/ethnicity.  If the null hypothesis is true, the test statistic $\chi^2=5.89$ would be closely associated with a chi-square distribution with three degrees of freedom. Using this distribution and test statistic, identify the p-value and state whether or not there is evidence of racial/ethnic bias in the juror selection.  See Section~\ref{techchisqdist} for ways to find areas under a chi-square distribution using technology.}
The chi-square distribution and p-value are shown in Figure~\ref{jurorHTPValueShown}. Because larger chi-square values correspond to stronger evidence against the null hypothesis, we shade the upper tail to represent the p-value. Using technology, we look at the chi-square distribution with 3 degrees of freedom and find the area to the right of $\chi^2=5.89$.  This area, which corresponds to the p-value, is equal to 0.117.  This p-value is larger than the default significance level of 0.05, so we do not reject the null hypothesis.  In other words, the data do not provide convincing evidence of racial/ethnic bias in the juror selection.
\index{data!racial make-up of jury|)}
\end{nexample}
\end{examplewrap}



The test that we just carried out regarding jury selection is known as the \termni{$\pmb{\chi^2}$ goodness of fit test}. It is called ``goodness of fit" because we test whether or not the proposed or expected distribution is a good fit for the observed data.

Just like we checked conditions to use the normal model in earlier sections, we must also check conditions to safely model $\chi^2$ with a chi-square distribution. Here we have a random sample, which is less than 10\% of all potential jurors.  For chi-square, we have a different sample~size condition.  Each expected count must be at least 5. In the juror example, the expected counts were 198, 19.25, 33, and 24.75, all easily above~5, so we can model the $\chi^2$ test statistic using a chi-square distribution.

%\begin{onebox}{Chi-square goodness of fit test for one-way table}
%Suppose we are to evaluate whether there is convincing evidence that a set of observed counts $O_1$, $O_2$, ..., $O_k$ in $k$ categories are unusually different from what might be expected under a null hypothesis. Calculate the \emph{expected counts} that are based on the null hypothesis $E_1$, $E_2$, ..., $E_k$. If each expected count is at least 5 and the null hypothesis is true, then the test statistic below follows a chi-square distribution with $k-1$ degrees of freedom:
%\begin{align*}
%\chi^2 = \frac{(O_1 - E_1)^2}{E_1} + \frac{(O_2 - E_2)^2}{E_2} + \cdots + \frac{(O_k - E_k)^2}{E_k}
%\end{align*}
%The p-value for this test statistic is found by looking at the upper tail of this chi-square distribution. We consider the upper tail because larger values of $\chi^2$ would provide greater evidence against the null hypothesis.\end{onebox}
%
\begin{onebox}{Conditions for the chi-square goodness of fit test}
The chi-square goodness of fit test requires the test statistic to be well modeled by a chi-square distribution.  This will be valid when the observations are independent and the expected counts are large.  If these conditions are not met, the chi-square goodness of fit test should not be used.\vspace{-1mm}
\begin{description}
\setlength{\itemsep}{0mm}
\item[Independence.] The observations can be considered independent if the data come from a random process.  If randomly sampling without replacement from a finite population, the observations can be considered independent when sampling less than 10\% of the population.  
\item[Large expected counts.] In order for the $\chi^2$-statistic to follow the chi-square distribution, each particular bin or category must have at least \mbox{5~expected} cases under the assumption that the null hypothesis is true.
\end{description}
\end{onebox}


%%
\subsection{Summary and worked example}

\begin{onebox}{Goodness of fit test for a one-way table}
 When there is one sample and we are comparing the distribution of a categorical variable to a specified or population distribution, 
\\
\\
\inferencestep{Identify} Use a \termni{\pmb{$\chi^2$} goodness of fit test} and the desired $\alpha$ significance level.  
\begin{itemize}
\setlength{\itemsep}{0mm}
\item[]  $H_0$:\, The distribution of [...] matches the specified or population distribution. 
\item[]  $H_A$: The distribution of [...] doesn't match the specified or population distribution.
\end{itemize}
\inferencestep{Check} Check that the test statistic follows a chi-square distribution, assuming $H_0$ is true.\vspace{-1mm}
{\setlength{\leftmargini}{13mm}
\begin{itemize}
\setlength{\itemsep}{0mm}
\item[1.] Independence:  Data come from a random sample or random process.  If sampling 
without replacement, check that sample size is less than 10\% of the population size.
\item[2.] Expected counts:  All expected counts are $\ge$ 5. (calculate and record expected counts).
\end{itemize}
}
\inferencestep{Calculate} Calculate the $\chi^2$-statistic, $df$, and p-value.\vspace{-1mm}  
\begin{itemize}
\setlength{\itemsep}{0mm}
\item[] test statistic:  $\chi^2 =\sum{ \frac{\text{(observed } - \text{ expected})^2}{\text{expected}}}$ 
\item[] $df =$ \# of categories $-$ 1
\item[] p-value = (area to the \emph{right} of $\chi^2$-statistic under the chi-square distribution with the appropriate $df$)
\end{itemize}
\inferencestep{Conclude} Compare the p-value to $\alpha$, and draw a conclusion in context.
\begin{itemize}\vspace{-1mm}
\setlength{\itemsep}{0mm}
\item[] If the p-value is $\le \alpha$, reject $H_0$; there is sufficient evidence that [$H_A$ in context]. 
\item[] If the p-value is $> \alpha$, do not reject $H_0$; there is not sufficient evidence that [$H_A$ in context].
\end{itemize}
\end{onebox}


%Have you ever wondered about the color distribution of
%M\&M's$^{\text{\textregistered}}$?
%If so, then you will be glad to know that Rick Wicklin, a statistician
%working at the statistical software company SAS, wondered about this too.
%But he did more than wonder; he decided to collect data to test whether the
%distribution of M\&M colors was consistent with the stated distribution
%published on the Mars website in 2008.
%Starting at end of 2016, over the course of several weeks,
%he collected a sample of 712 candies, or about 1.5 pounds.
%We will investigate his results in the next example.
%You can read about his adventure in the Quartz article linked
%in the Data Appendix, which starts on page~\pageref{data_appendix}.

\D{\newpage}

\begin{examplewrap}
\begin{nexample}
{Starting in 2016, a statistician named Rick Wicklin collected a sample of 712 M\&M's to see if there was evidence that the actual color distribution of M\&M's differed from the stated color distribution of M\&M's on the Mars website, which had not been updated since 2008.  Wickin's sample color distribution and the Mars website's stated color distribution are shown in the table below.
(You can read about Wicklin's adventure in the Quartz article linked in the Data Appendix, which starts on page~\pageref{data_appendix}.) \\
\begin{center}
\begin{small}
\begin{tabular}{ll ccc ccc}
\hline
	 & \hspace{1mm} & Blue & Orange & Green & Yellow & Red & Brown\\
\hline
website percentages (2008):&		& 24\% & 20\% & 16\% & 14\% & 13\% & 13\%  \\
observed percentages:&		& 18.7\% & 18.7\% & 19.5\% & 14.5\% & 15.1\% & 13.5\%  \\
\hline
\end{tabular}
\end{small}
\end{center}

Is there evidence at the 5\% significance level that the distribution of M\&M's in 2016 were different from the stated distribution on the website in 2008? Use the four-step framework to organize your work. }

\begin{description}
\item[\inferencestep{Identify}]  
Because we have one variable (color), broken up into multiple categories, we choose the \mbox{chi-square goodness of fit test.} We will test the following hypotheses at the $\alpha=0.05$ significance level.
\begin{itemize}\vspace{-1mm}
\setlength{\itemsep}{0mm}
\item[] $H_0$:  \,The distribution of M\&M colors is the same as the stated distribution in 2008. 
\item[] $H_A$: The distribution of M\&M colors is different than the stated distribution in 2008.
 \end{itemize}
\item[\inferencestep{Check}]  We must verify that the test statistic follows a chi-square distribution.  Note that there is only one sample here.  The website percentages are considered fixed -- they are not the result of a sample and do not have sampling variability associated with them.  To carry out the chi-square goodness of fit test, we will have to assume that Wicklin's sample can be considered a random sample of M\&M's.  We note that the total population size of M\&M's is much larger than 10 times the sample size of 712.  Next, we need to find the expected counts.  Here, $n=712$.  If $H_0$ is true, then we would expect 24\% of the M\&M's to be Blue, 20\% to be Orange, etc.  So the expected counts can be found as:

\begin{small}
\begin{tabular}{ll ccc ccc}
\hline
	 & \hspace{1mm} & Blue & Orange & Green & Yellow & Red & Brown\\
\hline
expected counts:&		& 0.24(712) &  0.20(712) & 0.16(712) & 0.14(712) & 0.13(712) & 0.13(712)  \\
&		& = 170.9 &  = 142.4 & = 113.9 & = 99.6 & = 92.6 & = 92.6\\ 
\hline
\end{tabular}
\end{small}

\item[ \inferencestep{Calculate} ]  We will calculate the chi-square statistic, degrees of freedom, and the p-value.\\
To calculate the chi-square statistic, we need the observed counts as well as the expected counts.  To find the observed counts, we use the observed percentages.  For example, 18.7\% of $712 = 0.187(712)=133$.

\begin{center}
\begin{small}
\begin{tabular}{ll ccc ccc}
\hline
	 & \hspace{1mm} & Blue & Orange & Green & Yellow & Red & Brown\\
\hline
observed counts:&		& 133 & 133 & 139 & 103 & 108 & 96  \\
expected counts:&		& 170.9 &  142.4 & 113.9 & 99.6 & 92.6 & 92.6\\
\hline
\end{tabular}
\end{small}
\end{center}
\begin{small}
\begin{align*}
\chi^2
  =& \sum{\frac{\text{(observed } - \text{ expected})^2}
      {\text{expected}}}\\
  =& \frac{(133 - 170.9)^2}{170.9}
      + \frac{(133 - 142.4)^2}{142.4}
      %+ \frac{(139 - 113.9)^2}{113.9}
      %+ \frac{(103 - 99.6)^2}{99.6}
      + \cdots
      + \frac{(108 - 92.6)^2}{92.6}
      + \frac{(96 - 92.6)^2}{92.6}\\
=&8.41+0.62+5.53+0.12+2.56+0.12\\
=&17.36
\end{align*}
\end{small}

Because there are six colors, the degrees of freedom is $6-1=5$. In a chi-square test, the p-value is always the area to the \emph{right} of the chi-square statistic.  Here, the area to the right of 17.36 under the chi-square distribution with 5 degrees of freedom is $0.004$.  
\item[\inferencestep{Conclude}]  The p-value of 0.004 is $< 0.05$, so we reject $H_0$; there is sufficient evidence that the distribution of M\&M's does not match the stated distribution on the website in 2008.  
\end{description}
\end{nexample}
\end{examplewrap}

%\begin{examplewrap}
%\begin{nexample}
%{For Wicklin's sample, which color showed the most prominent difference from the stated website distribution in 2008?}
%We can compare the website percentages with the observed percentages.  However, another approach is to look at the terms used when calculating the chi-square statistic.  We note that the largest term, 8.41, corresponds to Blue.  This means that the observed number for Blue was, relatively speaking, the farthest from the expected number among all of the colors.  This is consistent with the observation that the largest difference in website percentage and observed percentage is for Blue (24\% vs 18.7\%).  Wicklin observed far fewer Blue M\&M's than would have been expected if the website percentages were still true.
%\end{nexample}
%\end{examplewrap}


\D{\newpage}

%%
\subsection{Technology: the chi-square goodness of fit test}
\label{techGOF}

\noindent A spinner has four colors that are supposed to be equally likely:  red, green, blue, yellow.  Someone records the number of each color after many spins in a game.  After 200 spins, there are 59 red, 44 green, 54 blue and 41 yellow.  Use technology to find the test statistic, df, and p-value for a chi-square goodness of fit test, testing whether there is evidence that the colors do not have the same likelihood of coming up.  Also find the expected values and chi-square contributions for the test.  Assume conditions for the test are met. \\

\noindent \textbf{Desmos}:  Use the \texttt{chisqtest()} function as explained below.
\begin{enumerate}
\setlength{\itemsep}{0mm}
\item Click \calctext{+} in the upper left, then choose \calctext{inference}.  
\item Choose \calctext{$\chi^2$ goodness of fit test} in the pop-up window.  
\begin{center}
\fbox{\Figures[A Desmos calculator screen is shown. The + and inference option are highlighted. ]
{0.3}{technologyInferenceProps}{desmosInference}}\hspace{10mm}
\fbox{\Figures[A Desmos calculator screen is shown with the inference pop-up box. chi-square goodness of fit test is highlighted. ]
{0.3}{technologyInferenceProps}{desmosInferenceChiSqGOF}}
\end{center}
\item Enter the observed counts in the \calctext{Observed} column.  If the null hypothesis is that the categories are equally likely, you can leave the \calctext{Expected} column blank.  Otherwise, enter the expected values based on $H_0$.  Click \calctext{Create Test}.\\ \\
\indent\hspace{-4mm} * You can type \calctext{chisqgof([59, 44, 54, 41])} in place of steps 1-3 above.  
\vspace{1mm}
\item Click the triangle next to \calctext{Observed (Expected)}, then click the checkbox next to \calctext{Expected} to see the expected counts. Click the checkbox next to \calctext{Contributions} to see each value's contribution to the chi-square statistic.  Click the checkbox next to \calctext{Totals} to see the column totals.  

\item Click the triangle next to \calctext{Significance Test} to see the test statistic, df, and p-value. 
\begin{center}
\fbox{\Figures[A Desmos calculator screen is shown.  A chi-square test goodness of fit test box is shown, with 59, 44, 54, and 41 entered under Observed.  The Expected column is blank.  The Create Test button is highlighted. ]
{0.4}{technologyInferenceProps}{desmosChiSqGOF1}}\hspace{7mm}
\fbox{\Figures[A Desmos calculator screen is shown with chisqgof({[59, 44, 54, 41]}) entered.  The observed and expected counts and chi-square contributions are shown.  The chi-square statistic of 4.303, df = 3 and p-value = 0.231. The chi-square distribution is shown with the area to the right of 4.303 shaded.  ]
{0.4}{technologyInferenceProps}{desmosChiSqGOF2}}
\end{center}
\end{enumerate}


\newpage

\noindent \R{}:  Chi-square goodness of fit test\\
Use \texttt{chisq.test(x = c(\text{observed counts}), p = c(\text{expected proportions}))}.\\ \\
\texttt{> \calctext{X = chisq.test(c(59, 44, 54, 41), c(0.25, 0.25, 0.25, 0.25))}} or\\
\texttt{> \calctext{X = chisq.test(x = c(59, 44, 54, 41), p = c(0.25, 0.25, 0.25, 0.25))}}\\ \\
\texttt{> \calctext{X}}\\
\texttt{	Chi-squared test for given probabilities\\
data:  c(59, 44, 54, 41)\\
\fbox{X-squared = 4.303, df = 3, p-value = 0.2305}}\\ 

\noindent \texttt{> \calctext{X$\$$expected}}\\
\texttt{[1] 49.5 49.5 49.5 49.5}\\

\noindent \texttt{> \calctext{(X$\$$residuals)\textasciicircum 2}}\\
\texttt{[1] 1.8232323 0.6111111 0.4090909 1.4595960}\\  \\

\noindent \textbf{Calculator}:  NumWorks calculator instructions and example output are included.  For the TI-83/84 and Casio calculators, general instructions are provided, and worked example videos can be accessed via the \includegraphics[height=3mm]{extraTeX/icons/video_camera.png} icon or at \oiRedirect{ti84_playlist}{\textbf{openintro.org/ti}} and \oiRedirect{casio-9750-playlist}{\textbf{openintro.org/casio}}.\\ 

\begin{onebox}{NumWorks: Chi-square goodness of fit test}
\label{normalnumworks}
Use \calctext{OK} or \calctext{EXE} to make a selection.
\begin{enumerate}
\setlength{\itemsep}{0mm}
\item From the home screen, select \calcbutton{Inference}, then \calctext{Tests}, then \calctext{Chi-square}, then \calctext{Goodness of fit}.  If these options do not appear, click the \calcbutton{$\lhookleftarrow$} button in the upper right as many times as needed. 
\item Enter the Observed counts, then enter the Expected counts.  Use arrows as needed.  Press the down arrow and record the df.  Enter \calctext{$\alpha$}, then choose \calcbutton{Next}. 
\item On this screen, you will see the chi-square statistic and p-value.  Use the up and right arrow and choose \calctext{Contributions} to see the chi-square contributions.  
\begin{center}
\Figures[ ]
{0.35}{technologyInferenceProps}{numworksChiSqGOF1}\hspace{10mm}
\Figures[ ]
{0.35}{technologyInferenceProps}{numworksChiSqGOF2}
\end{center}
\item When you have recorded the information, press the down arrow and choose \calctext{Next} to see the chi-square distribution with the p-value shaded.  
\begin{center}
\Figures[ ]
{0.35}{technologyInferenceProps}{numworksChiSqGOF3}\hspace{10mm}
\end{center}
\vspace{-1.5mm}
\end{enumerate}
\end{onebox}
 
\begin{onebox}{\videohref{ti84_chisq_GOF_test} TI-84: Chi-square goodness of fit test\vspace{0.5mm}}
Use \calctext{STAT}, \calctext{TESTS}, $\calctextmath{\chi^2}$\calctext{GOF-Test}.
\begin{enumerate}
\setlength{\itemsep}{0mm}
\item Enter the observed counts into list \calctext{L1} and the expected counts into list \calctext{L2}.
\item Choose \calctext{STAT}.
\item Right arrow to \calctext{TESTS}.
\item Down arrow and choose \calctext{D:}$\calctextmath{\chi^2}$\calctext{GOF-Test}.
\item Leave \calctext{Observed:~L1} and \calctext{Expected:~L2}.
\item Enter the degrees of freedom after \calctext{df}:
\item Choose \calctext{Calculate} or \calctext{Draw} and hit \calcbutton{ENTER}.  \calctext{Draw} shows the chi-square statistic and p-value as well as a graph of the chi-square distribution with p-value shaded.  \calctext{Calculate} returns: \\[1mm]
\begin{tabular}{l ll}
$\calctextmath{\chi^2}$ & chi-square test statistic \\
\calctext{p} & p-value \\
\calctext{df} & degrees of freedom\\
\calctext{CNTRB} showing the chi-square contributions.  \\Hit the right arrow to see all of the contributions.
\end{tabular}
\end{enumerate}
TI-83: Unfortunately the TI-83 does not have this test built in. To carry out the test manually, make list \calctext{L3 = (L1 - L2)}$\calctextmath{^2}$\calctext{ / L2} and do \calctext{1-Var-Stats} on \calctext{L3}. The sum of \calctext{L3} will correspond to the value of $\chi^2$ for this test.\end{onebox}

\begin{onebox}{\videohref{casio_chisq_GOF_test} Casio fx-9750GII: Chi-square goodness of fit test}
\ \vspace{-5mm} \
\begin{enumerate}
\setlength{\itemsep}{0mm}
\item Navigate to \calctext{STAT} (\calcbutton{MENU} button, then hit the \calcbutton{2} button or select \calctext{STAT}).
\item Enter the observed counts into a list (e.g. \calctext{List 1}) and the expected counts into list (e.g. \calctext{List 2}).
\item Choose the \calctext{TEST} option (\calcbutton{F3} button).
\item Choose the \calctext{CHI} option (\calcbutton{F3} button).
\item Choose the \calctext{GOF} option (\calcbutton{F1} button).
\item Adjust the \calctext{Observed} and \calctext{Expected} lists to the corresponding list numbers from Step~2.
\item Enter the degrees of freedom, \calctext{df}.
\item Specify a list where the contributions to the test statistic will be reported using~\calctext{CNTRB}. This list number should be different from the others.
\item Hit the \calcbutton{EXE} button, which returns \\[1mm]
  \begin{tabular}{l ll}
  $\calctextmath{\chi^2}$ & chi-square test statistic \\
  \calctext{p} & p-value \\
  \calctext{df} & degrees of freedom \\
  \calctext{CNTRB} & list showing the test statistic contributions
  \end{tabular}
\end{enumerate}
\end{onebox}


\index{chi-square goodness of fit test@$\chi^2$ goodness of fit test|)}
\D{\newpage}

%%
\subsection*{Section summary} 
\begin{itemize}

\item While a normal distribution is defined by its mean and standard deviation, the chi-square distribution is defined by just one parameter called \termsub{degrees of freedom}{degrees of freedom (df)!chi-square}.  For a chi-square distribution, as the degrees of freedom increases:  the center increases, the spread increases, and the shape becomes more symmetric and more normal.

\item When we want to see if a hypothesized model is a good fit for observed data or if data is representative of a particular population, we can use a \termni{$\pmb{\chi^2}$ goodness of fit test}\index{chi-square goodness of fit test@$\chi^2$ goodness of fit test}.  This test requires one variable with multiple categories (bins) that can be arranged in a one-way table.

\item The hypotheses for a $\chi^2$ goodness of fit test can be written as:
\begin{itemize}
\item[] $H_0$: The distribution of [...] matches the specified or population distribution. 
\item[] $H_A$: The distribution of [...] doesn't match the specified or population distribution. 
\end{itemize}
\item For the $\chi^2$ goodness of fit test, we check the following conditions to verify that the test statistic follows a chi-square distribution.  
\begin{itemize}
\item[] 1.  Independence:  Data come from a random sample or random process.  When sampling 
\item[] \quad \ without replacement, check that sample size is less than 10\% of the population size.
\item[] 2.  Expected counts:  All expected counts are $\ge$ 5.
\end{itemize}

\item We calculate the test statistic as follows:
\begin{itemize}
\item[] test statistic:  $\chi^2 =\sum{ \frac{\text{(observed } - \text{ expected})^2}{\text{expected}}}$; \quad \quad $df =$ \# of categories $-$ 1
\end{itemize}
Always use whole numbers (counts) for the observed values, not proportions or percents.\\
For each category, the expected counts can be found by multiplying the sample~size by the expected proportion under the null hypothesis.  Expected counts do \emph{not} need to be integers.  

\item The p-value is the area to the \emph{right} of the $\chi^2$-statistic under the chi-square distribution with the appropriate $df$.

\item A larger $\chi^2$ represents greater deviation between the observed values and the expected values, relative to the expected values.  For a fixed degrees of freedom, a larger $\chi^2$ value leads to a smaller p-value, providing greater evidence against $H_0$. 

\item For a $\chi^2$ test, the p-value corresponds to the probability of getting a test statistic as large as we got or larger, assuming the null hypothesis is true, i.e. that the population distribution is as hypothesized.
\end{itemize}


%%%%%%%%Section Exercises
{\input{ch_inference_for_props/TeX/goodness_of_fit_using_chi-square_(special_topic).tex}}


%_________________________________________________
\section[Chi-square tests for two-way tables]{Chi-square tests for two-way tables }
\label{twoWayTablesAndChiSquare}

\sectionintro{
\noindent%
Does the distribution of successful versus unsuccessful web searches differ among different search algorithms?  Is there an association between people's generation and whether or not they take action to help address climate change?  In order to answer questions such as these, we revisit two-way tables, and we learn about two new and closely related chi-square tests. 


%%
\subsection*{Learning objectives}

\begin{enumerate}
\setlength{\itemsep}{0mm}
\item Describe chi-square distributions.

\item Identify and set up an appropriate testing method for comparing distributions in two-way tables of categorical data.

\item Identify the null and alternative hypotheses for a chi-square test for homogeneity or independence.

\item Justify the appropriateness
of a hypothesis test for independence or
homogeneity using a chi-square distribution
by verifying
conditions.

\item Calculate expected counts for two-way tables of categorical data, assuming a null hypothesis is true.

\item Calculate the appropriate test statistic, degrees of freedom and p-value for a chi-square test for homogeneity or independence.

\item  Interpret the p-value for a chi-square test for homogeneity or independence.

\item Justify a claim about the population based on the results of a chi-square test for homogeneity or independence.

\item Explain the differences and similarities between the chi-square test for homogeneity and chi-square test for independence.


\end{enumerate}
}


%%

\index{chi-square test for homogeneity@$\chi^2$ test for homogeneity|(}
\subsection{Introducing the chi-square test for homogeneity}
Google is constantly running experiments to test new search algorithms. For example, Google might test three algorithms using a sample of 10,000 google.com search queries. Figure~\ref{googleSearchAlgorithmByAlgorithmOnly} shows an example of 10,000 queries randomly split into three algorithm groups.\footnote{Google regularly runs experiments in this manner to help improve their search engine. It is entirely possible that if you perform a search and so does your friend, that you will have different search results. While the data presented in this section resemble what might be encountered in a real experiment, these data are simulated.} The group sizes were specified before the start of the experiment to be 5000 for the current algorithm and 2500 for each test algorithm.

\begin{figure}[h]
\centering
\quad \quad \quad \quad \var{Search algorithm} \\
\begin{tabular}{ll ccc ll}
\cline{3-7}
	 & \hspace{1mm} & current & test 1 & test 2 & \hspace{1mm} & Total \\
Counts &		& 5000 & 2500 & 2500 & & 10000 \\
\hline
\end{tabular}
\caption{Experiment breakdown of test subjects into three search groups.}
\label{googleSearchAlgorithmByAlgorithmOnly}
\end{figure}


In this experiment, the explanatory variable is the search algorithm. However, an outcome variable is also needed. This outcome variable should somehow reflect whether the search results satisfied the user.  We will define the values of the \var{outcome} variable as ``success": no new related search and ``failure": follow-up related search.  

Figure~\ref{googleSearchAlgorithmByAlgorithmAndPerformanceWithTotals} provides the results from the experiment. These data are very similar to the count data in Section~\ref{oneWayChiSquare}. However, now the different combinations of two variables are binned in a \emph{two-way} table. In examining these data, we want to evaluate whether there is strong evidence that at least one algorithm is more successful than the others. 

%To do so, we apply a chi-square test to this two-way table. The ideas of this test are similar to those ideas in the one-way table case. However, degrees of freedom and expected counts are computed a little differently than before.

\begin{figure}[h]
\centering
\quad \quad \quad \quad \var{Search algorithm} \\
\begin{tabular}{lll crr rr}
\cline{3-7}
&& \hspace{1mm} & current & test 1 & test 2 & \hspace{1mm} & Total \\
\cline{2-8}
&success				   & & 3511    & 1749 & 1818 & 				& 7078 \\
\raisebox{1.5ex}[0pt]{\var{outcome}}
&failure				   & & 1489    & 751	& 682    &				& 2922 \\
\cline{2-8}
&Total						   & & 5000    & 2500 & 2500 & 				& 10000 \\
\cline{2-8}
\end{tabular}
\caption{Results of the Google search algorithm experiment.}
\label{googleSearchAlgorithmByAlgorithmAndPerformanceWithTotals}
\end{figure}

%\begin{onebox}{What is so different about one-way tables and two-way tables?}
%A one-way table describes counts for each outcome in a single variable. A two-way table describes counts for \emph{combinations} of outcomes for two variables. When we consider a two-way table, we often would like to know, are these variables related in any way?\end{onebox}


\begin{examplewrap}
\label{searchalgorithmexample}
\begin{nexample}{What is the ultimate goal of the Google experiment? What are the null and alternative hypotheses, in regular words?}
The ultimate goal is to see whether there is a difference in the performance of the algorithms. The hypotheses can be described as the following:\D{\vspace{-2mm}}
\begin{itemize}
\setlength{\itemsep}{0mm}
\item[$H_0$:] There is no difference in the distribution of the \var{outcome} variable across the three search algorithms: current, test~1, and test~2.
\item[$H_A$:] There is a difference in the distribution of the \var{outcome} variable across the three search algorithms:  current, test~1, and  test~2.
\end{itemize}

Because the \var{outcome} variable has only two values: ``success" and ``failure", the hypotheses could also be worded as:
\begin{itemize}
\setlength{\itemsep}{0mm}
\item[$H_0$:] The proportion of successes would be the same regardless of which search algorithm is used.  
\item[$H_A$:] The proportion of successes would not be the same for the different search algorithms.  
\end{itemize}
\end{nexample}
\end{examplewrap}

The hypothesis test for this Google experiment is really about assessing whether there is statistically significant evidence that the likelihood of a successful search would be different based on the algorithm used.  In other words, the goal is to check whether the three search algorithms perform differently.  If there were only two algorithms, we could perform a two-sample Z-test for difference of population proportions, as we did in Section~\ref{differenceOfTwoProportionsTest}.   However, since we have three algorithms, we will need a new test that allows us to compare the distribution of a variable across multiple treatments or populations.  We call this test a \termni{chi-square test for homogeneity}.  

Homogeneity means ``same".  The null hypothesis of this test says that the distribution of a variable is the \emph{same} (or has no difference) across multiple treatments or populations.  In our Google experiment example, the null claim says that the distribution of the \var{outcome} variable (or the likelihood of success) is the same for each of the three algorithms: current, test 1, and test 2.



\D{\newpage}

%%
\subsection{Expected counts in two-way tables}

When there are more than two treatments or populations to compare, instead of calculating a Z test statistic, we calculate a new test statistic called a chi-square test statistic.  To do this, we must first calculate the expected count for each cell of the two-way table, under the assumption that the null hypothesis is true.

\begin{examplewrap}
\begin{nexample}{From the experiment, we estimate the overall proportion of successful searches as $\frac{7078}{10000} = 0.7078$. If there really is no difference among the algorithms and 70.78\% of searches, regardless of search algorithm, would result in ``success", how many of the 5000 searches in the ``current algorithm'' group would be expected to result in ``success"?} \label{googleExampleComputingTheExpectedNumberOfCurrentGroupWithNoNewSearch}
About 70.78\% of the 5000 would result in ``success":
$$ 0.7078\times 5000 = 3539\text{ searches} $$
That is, if there was no difference between the three algorithms, then we would expect 3539 of the current algorithm searches to result in ``success".
\end{nexample}
\end{examplewrap}

\begin{exercisewrap}
\begin{nexercise}\label{googleExampleComputingTheExpectedNumberOfNewAlgGroupWithNoNewSearch}
Using the same rationale described in Example~\ref{googleExampleComputingTheExpectedNumberOfCurrentGroupWithNoNewSearch}, about how many searches in each algorithm group would result in ``success" if the algorithms were equally helpful?\footnotemark
\end{nexercise}
\end{exercisewrap}
\footnotetext{We would expect $0.7078*2500 = 1769.5$. It is okay that this is not an integer.}

We can compute the expected number of ``success" for each group using the same strategy employed in Example~\ref{googleExampleComputingTheExpectedNumberOfCurrentGroupWithNoNewSearch} and Guided Practice~\ref{googleExampleComputingTheExpectedNumberOfNewAlgGroupWithNoNewSearch}. These expected counts are shown in Figure~\ref{googleSearchAlgorithmByAlgorithmAndPerformanceWithExpectedCounts}, alongside the observed counts from Figure~\ref{googleSearchAlgorithmByAlgorithmAndPerformanceWithTotals}.
\begin{figure}[h]
\centering
\quad \quad \quad \quad \var{Search algorithm} \\
\begin{tabular}{ll lll lll lll r}
\cline{3-11}
& \hspace{2mm} & \multicolumn{2}{l}{current} &&
					\multicolumn{2}{l}{test 1} &&
					\multicolumn{2}{l}{test 2} & \hspace{0mm}  &Total \\
\cline{2-12}
&success		   & 3511 &\highlightO{\footnotesize(3539.0)}    &&
					1749 &\highlightO{\footnotesize(1769.5)}	&&
					1818 &\highlightO{\footnotesize(1769.5)} &	& 7078 \\
\raisebox{1.5ex}[0pt]{\var{outcome}}
&failure		   & 1489 &\highlightO{\footnotesize(1461.0)}    &&
					751 &\highlightO{\footnotesize(730.5)}	&&
					682 &\highlightO{\footnotesize(730.5)}    &		& 2922 \\
\cline{2-12}
&Total				   & 5000 &&& 	2500 &&& 	2500 &&& 	10000 \\
\cline{2-12}
\end{tabular}
\caption{The observed counts and the \highlightO{(expected counts)}.}
\label{googleSearchAlgorithmByAlgorithmAndPerformanceWithExpectedCounts}
\end{figure}

The examples and exercises above provided some help in computing expected counts. In general, expected counts for a two-way table may be computed using the row totals, column totals, and the table total. For instance, if there was no difference between the groups, then about 70.78\% of each column should be in the first row:
\begin{align*}
0.7078\times (\text{column 1 total}) &= 3539 \\
0.7078\times (\text{column 2 total}) &= 1769.5 \\
0.7078\times (\text{column 3 total}) &= 1769.5
\end{align*}
Looking back, we see that 0.7078 was computed as $\frac{7078}{10000}$, the fraction of successful outcomes.  Therefore, these three expected counts could have been computed as:
\begin{align*}
\left(\frac{\text{row 1 total}}{\text{table total}}\right)\text{(column 1 total)} &= 3539 \\
\left(\frac{\text{row 1 total}}{\text{table total}}\right)\text{(column 2 total)} &= 1769.5 \\
\left(\frac{\text{row 1 total}}{\text{table total}}\right)\text{(column 3 total)} &= 1769.5
\end{align*}
\D{\newpage

\noindent}This leads us to a general formula for computing expected counts in a two-way table when we would like to test whether there is strong evidence of an association between the column variable and row variable.


\begin{onebox}{Computing expected counts in a two-way table}
To identify the expected count in a particular row and column, compute
$$\text{Expected Count} = \frac{(\text{row total}) \times  (\text{column total})}{\text{table total}}\vspace{2mm}$$\end{onebox}

We can use mosaic~plots, introduced in Section~\ref{mosaic_plots_subsection}, to visually compare the expected counts to the observed counts.  

\begin{figure}[h]
\Figures[Observed counts]{0.5}{gsearch}{gsearch_mosaic}
\Figures[Expected counts]{0.5}{gsearch}{gsearch_exp_mosaic}
\caption{Mosaic plots using values from Figure~\ref{googleSearchAlgorithmByAlgorithmAndPerformanceWithExpectedCounts}.  Left: observed counts; Right: expected counts assuming there is no difference in the distribution of the outcome variable across the three search algorithms: current, test 1, and test 2 in the population.}
\label{pewEVmosaicplots}
\end{figure}

The difference between the mosaic plot of observed counts and of expected counts appears relatively small.  However, even a small difference in this context could translate into a better experience for millions of users.  To determine whether the difference is significant we will need to carry out a hypothesis test and calculate the p-value.
%%
\subsection{Verifying conditions and calculating the test statistic}


When we have a two-way table of counts and the data is collected from multiple independent random samples or multiple randomly assigned treatments we would like to carry out what is called a \termni{chi-square test for homogeneity}.

\begin{onebox}{Conditions for the chi-square test for homogeneity}
There are two conditions that must be checked before performing a chi-square test for homogeneity. If these conditions are not met, this test should not be used.\vspace{-1mm}
\begin{description}
\setlength{\itemsep}{0mm}
\item[Independence.] The data must be arrived at by taking two or more independent random samples or two or more randomly assigned treatments. When sampling without replacement from a finite population, the sample sizes should be less than 10\% of the corresponding population sizes.  
\item[Large expected counts.] All of the cells in the two-way table must have at least 5~expected cases assuming the null hypothesis is true.
\end{description}
\end{onebox}

\D{\newpage}

In our Google example, we have an experiment and the three algorithms are randomly assigned to the queries.  Also, all the expected counts, assuming the null hypothesis is true, are well over 5.  Therefore, the conditions for applying the chi-square test for homogeneity are met.  

In previous hypothesis tests, we constructed a test statistic of the following form:
$$ Z = \frac{\text{point estimate} - \text{null value}}{SE \text{ of point estimate}} $$
This construction was based on (1) identifying the difference between a point estimate and an expected value if the null hypothesis was true, and (2) standardizing that difference using the standard error of the point estimate. These two ideas will help in the construction of an appropriate test statistic for count data.

In this example we have six combinations of Search Algorithm and Result: (current \& Success), (current \& Failure), (test 1 \& Success), (test 1 \& Failure), (test 2 \& Success), and (test 2 \& Failure). Because we have six values rather than just one or two, we need a new tool to analyze the data. Our strategy will be to find a test statistic that measures the overall deviation between the observed and the expected counts. For each cell in the table, we first find the difference between the observed and expected counts.  Then we square those differences.  Next, we must standardize each term.  To know whether the squared difference is large, we divide it by what was expected.  Finally we add up all these terms and this sum gives us a new test statistic called $\chi^2$ (read as chi-square).\\

The chi-square test statistic for a two-way table is found as follows:
\begin{align*}
&\text{General formula}& &\frac{(\text{observed count } - \text{ expected count})^2}{\text{expected count}} \\
&\text{Row 1, Col 1}& &\frac{(3511 - 3539)^2}{3539} = 0.222 \\
&\text{Row 1, Col 2}& &\frac{(1749 - 1769.5)^2}{1769.5} = 0.237 \\
& \hspace{9mm}\vdots & &\hspace{13mm}\vdots \\
&\text{Row 2, Col 3}& &\frac{(682 - 730.5)^2}{730.5} = 3.220
\end{align*}
Adding the computed value for each cell gives the chi-square test statistic:
$$\chi^2 = 0.222 + 0.237 + \dots + 3.220 = 6.120$$
The final number $\chi^2$ measures how strongly the observed counts deviate from the expected counts, relative to the expected counts.  Moreover, each term in the sum tells us the \term{chi-square contribution} for that cell.  The larger the chi-square contribution the farther the observed value is from the expected value, relative to expected.  Here, the largest chi-square contribution is 3.220, which tells us that the observed count for (test 2 \& Failure) has the largest relative difference from what would be expected under the null hypothesis of no difference. Also, the (observed count $-$ expected count) for (test2 \& Failure) is negative, telling us the observed is \emph{less} than what would be expected under the null hypothesis.



\subsection{Calculating and interpreting the p-value for a chi-square test}

If the null hypothesis is true, then the chi-square test statistic follows a distribution called a \emph{chi-square distribution}. This is the same distribution we saw in the ``Goodness of fit using chi-square (special topic)" section.  The \termni{chi-square distribution} is sometimes used to characterize data sets and statistics that are always positive and typically right skewed. Recall a normal distribution had two parameters -- mean and standard deviation -- that could be used to describe its exact characteristics. The chi-square distribution has just one parameter called \termsub{degrees of freedom (df)}{degrees of freedom (df)!chi-square}, which influences the shape, center, and spread of the distribution.  For two way tables, the degrees of freedom is equal to (number of rows $-$ 1)$\times$ (number of columns $-$ 1).



\begin{onebox}{Computing degrees of freedom for a two-way table}
When using the chi-square test to a two-way table, we use
$$ df = (\text{\# of rows }-1)\times (\text{\# of columns }-1) $$
\end{onebox}
%
%\begin{onebox}{Use two-proportion methods for 2-by-2 contingency tables}
%When analyzing 2-by-2 contingency tables, use the two-proportion methods introduced in Section~\ref{differenceOfTwoProportions}.\end{onebox}


Figure~\ref{chiSquareDistributionWithInceasingDF2} illustrates three general properties of chi-square distributions as the degrees of freedom increases:  the distribution becomes more symmetric, the center moves to the right, and the variability inflates.

\begin{figure}[h]
\centering
\Figure[Three chi-square distributions are shown with degrees of freedom 2, 4, and 9 on the same plot. The horizontal axis ranges from 0 to 25 -- recall that the chi-square distributions never take values smaller than 0. The chi-square distribution with 2 degrees of freedom starts at a peak at zero and then quickly declines more than halfway by the value of 2 and trails off after a value of about 5. The chi-square distribution with 4 degrees of freedom starts at 0 and quickly rises to a peak at about 2, before gradually declining and then more steeply declining starting at 3, before starting to flatten at about 5 or 6. The distribution has fallen very close to the horizontal axis by a value of 10. The chi-square distribution with 9 degrees of freedom starts at zero before gradually rising up to a peak at about 7 before declining again and trailing off between at around 15.]
{0.6}{chiSquareDistributionWithInceasingDF}
\caption{Three chi-square distributions with varying degrees of freedom.  The distributions are non-negative and right skewed.  As the degrees of freedom increase, chi-square distributions become less skewed and have a larger center and spread.}
\label{chiSquareDistributionWithInceasingDF2}
\end{figure}


To compute the p-value in our example, we need to know the chi-square statistic and the degrees of freedom.  We calculated the test statistic as $\chi^2  = 6.12$.  The degrees of freedom for our $3\times 2$ table is calculated as: $(3-1)\times(2-1)= 2$.  If the null hypothesis is true (i.e. the algorithms are equally successful), then the test statistic $\chi^2 = 6.12$ closely follows a chi-square distribution with 2 degrees of freedom.  To know how unlikely it is to get a test statistic at least as large as we got, assuming the null hypothesis is true, we find the area to the right of $\chi^2 = 6.12$ under the chi-square distribution with 2 degrees of freedom, as shown in Figure~\ref{googleHTForDiffAlgPerformancePValue}.  While it is possible to find areas under a chi-square distribution using a chi-square table, such as the one found in Appendix~\vref{chiSquareProbabilityTable}, it is more common to use technology.  See Section~\ref{techchisqdist} for multiple ways to find areas under a chi-square distribution using technology.

\begin{figure}[h]
\centering
\Figure[A chi-square distribution with 2 degrees of freedom is shown.  The graph is very right skewed.  The area to the right of the value 6.12 is shaded and corresponds to an area or p-value of 0.047.]
{0.6}{googleHTForDiffAlgPerformancePValue}
\caption{Computing the p-value for the Google hypothesis test.}
\label{googleHTForDiffAlgPerformancePValue}
\end{figure}



\begin{examplewrap}
\begin{nexample}{Compute the p-value and draw a conclusion about whether the search algorithms have different success rates.}
Using technology, we find that the p-value, which corresponds to the area under the chi-square distribution with 2 degrees of freedom to the \emph{right} of $\chi^2=6.12$, equals 0.047.  Using an $\alpha=0.05$ significance level, the p-value $< \alpha$, so we reject $H_0$.  The data provide convincing evidence that there is a difference in the distribution of the outcome variable (success rates), among the three algorithms.
\index{data!search algorithm|)}
\end{nexample}
\end{examplewrap}


\begin{examplewrap}
\begin{nexample}{Interpret the p-value for this test.}
The p-value of 0.047 tells us that there is a 4.7\% chance of getting a test statistic as large or larger than we got if $H_0$ is true, that is, if the algorithms do in fact perform equally well.  
\end{nexample}
\end{examplewrap}


Notice that the conclusion of the test is that there is some difference in performance among the algorithms.  This chi-square test does not tell us \emph{which} algorithm performed better than the others.  To compare the performance of the algorithms, we calculate the proportion of successes for each algorithm as follows:  
\begin{align*}
\text{current:}~ \frac{3511}{5000} = 0.7022 \quad \text{test 1:}~ \frac{1749}{2500} = 0.700 \quad \text{test 2:}~ \frac{1818}{2500} = 0.7272
\end{align*}

In Figure~\ref{gsearchSegBar} we compare the proportion of successes and failures for each algorithm using a mosaic~plot (left) and a simpler stacked bar chart (right).

\begin{figure}[h]
\centering
\Figures[Observed counts]{0.49}{gsearch}{gsearch_mosaic2}
\Figures[]
{0.49}{gsearch}{gsearchSegBar}
\caption{A mosaic plot (left) and a stacked bar chart (right) showing the proportion of successes and failures for each algorithm in the Google experiment.}
\label{gsearchSegBar}
\end{figure}

Our calculations and our graphs suggest that the test 2 algorithm performed better than the current algorithm and test 1 algorithm, because it led higher rates of success; however, to formally test this specific claim we would need to use a test that includes a multiple comparisons correction, which is beyond the scope of this book.

A careful reader may have noticed that when there are exactly 2 random samples or treatments and the counts can be arranged in a $2\times 2$ table, both a chi-square test for homogeneity \emph{and} a two-sample Z-test for $p_1 - p_2$ could apply.   In this case, the chi-square test for homogeneity and the two-sided two-sample Z-test for $p_1 - p_2$ are equivalent, meaning that they produce the same p-value.\footnote{Sometimes the large counts condition for the Z-test is weakened to require the expected number of successes and failures to be at least 5, making it consistent with the chi-square condition that expected counts must at least 5.}


%	Approve	Disapprove
%Obama	56	41
%Dem	49	43
%Rep	36	56
%http://www.people-press.org/2012/03/14/romney-leads-gop-contest-trails-in-matchup-with-obama/
%March 7-11, 2012
%1503 adults



\index{chi-square test for homogeneity@$\chi^2$ test for homogeneity|)}

\D{\newpage}

%%
\subsection{The chi-square test for independence in two-way tables}
\index{chi-square test for independence@$\chi^2$ test for independence|(}

In Chapter~\ref{ch_probability} we determined whether two events $A$ and $B$ are independent by checking if $P(B | A ) = P(B)$.  Using the \var{family\_college} data set, we saw that the probability a teenager attended college given that one of the teen's parents has a college degree is higher than the unconditional probability that a teenager attended college, making ``teenager attended college" and ``one of the teen's parents has a college degree" dependent.  While $P(\text{\var{teen} \resp{college}}\ |\ \text{\var{parent} \resp{degree}})$ is not exactly equal to $P(\text{\var{teen} \resp{college}})$, we may wonder -- is this difference within the realm of expected variation or is this difference evidence of a real association between these two variables in the \emph{population} from which the sample was taken?  To answer this, we use a chi-square test for independence.

The chi-square test for independence tests for an association between two categorical variables within a population using data from a single random sample from that population.  The null claim is always that the two variables are independent in the population, while the alternative claim is that the variables are dependent in the population.   While the chi-square test for independence and the chi-square test for homogeneity are distinct, we will see that the calculations performed for these two tests are identical.

We begin by looking at a new example where the categorical variables each have three levels. Figure~\ref{pewResearchPollOnEV} summarizes the results of a Pew Research poll conducted in April-May of 2025. A random sample of adults in the US was taken, and each was asked how seriously they will consider buying an electric vehicle (EV) the next time they purchase a vehicle.  Respondents were also classified as living in an Urban, Suburban, or Rural residential type.  We would like to determine if residential type and consideration of buying an EV are associated.

\index{data!pew research EV}

\begin{figure}[h]
\centering
\begin{tabular}{ll ccc lr}
 & \hspace{1mm} & & \var{Consideration of buying an EV}&  & \hspace{1mm} &  \\
\cline{3-5}
 & \hspace{1mm} & Not too or  & Very or  & Don't expect to & \hspace{1mm} &  \\
 & \hspace{1mm} & not at all likely & somewhat likely & buy a vehicle & \hspace{1mm} & Total \\
\hline
Urban				   & & 748    &   621   & 207 &				& 1576 \\
Suburban			   & & 1466    & 978 & 353   &				& 2797 \\
Rural			   & & 460    & 130 & 122   &				& 712 \\
\hline
Total					   & & 2674    & 1729 & 682 & 				& 5085 \\
\hline
\end{tabular}
\caption{Results of a Pew Research poll from May 2025.}
\label{pewResearchPollOnEV}
\end{figure}

%EV data: https://www.pewresearch.org/science/2025/06/05/views-on-trump-administration-energy-policies-and-priorities/
%Urban/Rural/Suburban breakdown: https://www.pewresearch.org/social-trends/2018/05/22/demographic-and-economic-trends-in-urban-suburban-and-rural-communities/
% Because the pew EV percents did not add to 100, I restandardized them within each Urban/Suburban/Rural group by dividing the EV percent by the total of 103 or 99.  Eg. 5085*0.31 = 1576.  (47/99)*1576 = 748

\begin{examplewrap}
\begin{nexample}
{What are appropriate hypotheses for such a test?}\label{hypothesisTestSetupForPewResearchPollOnApprovalRatingsForChiSquareSection}
The null claim always states that there is no association between the variables or that the variables are independent.  We seek to find evidence for the alternative claim, that there is an association between the variables.
\begin{itemize}
\item[$H_0$:] Residential type and consideration of buying an EV in the population of US adults not associated.
\item[$H_A$:] Residential type and consideration of buying an EV in the population of US adults are associated (dependent). 
\end{itemize}
\end{nexample}
\end{examplewrap}


The null claim implies that there is no difference in consideration of buying an EV among Urban, Suburban, and Rural residing adults in the US.  The alternative claim implies that there is some difference in consideration of buying an EV among Urban, Suburban, and Rural residing adults in the US, e.g. perhaps Urban residing adults in the US are more likely to consider buying an EV.


\begin{examplewrap}
\begin{nexample}{Using Figure~\ref{pewResearchPollOnEV}, find the proportion of people in the sample who said they are are ``Not too or not at all likely" to buy an EV within each residential type.}
This is equivalent to finding conditional probabilities as follows:
\begin{align*}
P(\text{Not too or Not at all likely to buy an EV } | \text{ Urban}) &= \frac{748}{1576} = 0.475\\
P(\text{Not too or Not at all likely to buy an EV } | \text{ Suburban}) &= \frac{1466}{2797} = 0.524\\
P(\text{Not too or Not at all likely to buy an EV } | \text{ Rural}) &= \frac{460}{712} = 0.646.
\end{align*}
% R <- c(2119, 2104); C <- c(1458, 1382, 1383); R*C[1]/sum(C); R*C[2]/sum(C); R*C[3]/sum(C)
\end{nexample}
\end{examplewrap}

Based on these calculations, we can see that within the data set, these variables are dependent, as those in Rural areas are more likely to say ``Not too or not at all likely" to buy an EV than those in Suburban or Urban areas.  However, a hypothesis test is always concerned with what is true in the \emph{population} from which the sample was taken.  We want to ask whether the association we see in the sample data could be explained by random variation or whether there is a real association in the greater population from which we sampled.  To do a chi-square test of independence to answer this question, we need to check that the following conditions are met.

\begin{onebox}{Conditions for the chi-square test for independence}
A chi-square test for independence requires two categorical variables and the following conditions must be met.\vspace{-1mm}
\begin{description}
\setlength{\itemsep}{0mm}
\item[Independence.] The data must come from one random sample. When sampling without replacement, the sample size should be less than 10\% of the population size.  
\item[Large expected counts.] All of the cells in the two-way table must have expected counts of at least 5 under the assumption that the null hypothesis is true.
\end{description}
\end{onebox}

%\D{\newpage}

\begin{examplewrap}
\begin{nexample}{If the null hypothesis is true and residential type and consideration of buying an EV are independent, what proportion of each residential type would we expect to say that they are ``Not too or not at all likely" to buy an EV?  Use the data from Figure~\ref{pewResearchPollOnEV}.}
If residential type and consideration of buying an EV are independent, we would expect the proportion who would say that they are ``Not too or not at all likely"  to buy an EV to be the \emph{same} for each residential type.  To find this expected proportion, we use the overall proportion, which corresponds to the unconditional probability of saying``Not too or not at all likely" to buy an EV.  To find this we take the column total that said ``Not too or not at all likely" to buy an EV and divide by the table total.  This gives: $\frac{2674}{5085} = 0.5259$.
% R <- c(2119, 2104); C <- c(1458, 1382, 1383); R*C[1]/sum(C); R*C[2]/sum(C); R*C[3]/sum(C)
\end{nexample}
\end{examplewrap}

\begin{examplewrap}
\begin{nexample}{Find the expected counts for the first column of Figure~\ref{pewResearchPollOnEV}.}
We multiply the row totals by the overall proportion who said ``Not too or not at all likely" to buy an EV.  
\begin{align*}
(\text{Urban row total})\times  0.5259&=1576\times  0.5259= 828.8 \\
(\text{Suburban row total)} \times 0.5259 &= 2797\times 0.5259= 1471.0 \\
(\text{Rural row total}) \times 0.5259 &=712\times 0.5259 = 374.4
\end{align*}
\end{nexample}
\end{examplewrap}

\D{\newpage}

We can use the same process for finding the expected counts for the second and third columns of the table.  In each case, we will be multiplying:  $\text{row total}\times \frac{\text{column total}}{\text{table total}}$.  In other words, just as with the chi-square test for homogeneity, we calculate the expected counts as follows:
$$\text{Expected Count} = \frac{(\text{row total}) \times  (\text{column total})}{\text{table total}}$$

Figure~\ref{pewResearchPollOnEVexpectedcounts} show the table of observed counts, with the corresponding expected counts assuming the null hypothesis is true and the variables are independent.  There are nine combinations of residential type and consideration of buying an EV.
\begin{figure}[h]
\centering
\quad \quad \quad \quad \var{Consideration of buying an EV} \\
\begin{tabular}{ll rll rll rll r}
\cline{2-10}
 \hspace{2mm} && \multicolumn{2}{c}{Not too or} &&
					\multicolumn{2}{c}{Very or} &&
					\multicolumn{2}{c}{Don't expect to} & \hspace{0mm}  & \\
 \hspace{2mm} && \multicolumn{2}{c}{not at all likely} &&
					\multicolumn{2}{c}{somewhat likely} &&
					\multicolumn{2}{c}{buy a vehicle} & \hspace{0mm}  &Total \\
\cline{1-12}
Urban		   && 748 &\highlightO{\footnotesize(828.8)}    &&
					621 &\highlightO{\footnotesize(535.9)}	&&
					207 &\highlightO{\footnotesize(211.4)} &	& 1576 \\

Suburban		   && 1466 &\highlightO{\footnotesize(1471.0)}    &&
					978 &\highlightO{\footnotesize(951.0)}	&&
					353 &\highlightO{\footnotesize(375.1)}    &		& 2797 \\
Rural		   && 460 &\highlightO{\footnotesize(374.4)}    &&
					130 &\highlightO{\footnotesize(242.1)}	&&
					122 &\highlightO{\footnotesize(95.5)}    &		& 712 \\
\cline{1-12}
Total				   && 2674 &&& 	1729 &&& 	682 &&& 	5085 \\
\cline{1-12}
\end{tabular}
\caption{The observed counts and the \highlightO{(expected counts)}.}
\label{pewResearchPollOnEVexpectedcounts}
\end{figure}

Figure~\ref{pewEVmosaicplots} offers a visual comparison of the observed and expected counts using mosaic plots.  We see that the Urban, Suburban, and Rural residing group sizes are different, which explains variations in expected counts within the table.  However, the expected \emph{proportion} for each poll response is the same within each residential type, and the expected proportion of each residential type within each poll response is the same, under the assumption that that the variables are independent for adults in the US.

%\begin{figure}[h]
%\centering
%  \begin{subfigure}{.5}
%    \Figures[Oberved counts]
%{pewEV}{pew_ev_mosaic}
%    \caption{Observed Counts}
%  \end{subfigure}
%\hfill
%  \begin{subfigure}{.5}
%    \Figures[Expected counts]
%{pewEV}{pew_ev_exp_mosaic}
%    \caption{Expected Counts}
%  \end{subfigure}
%\caption{Mosaic plots comparing the observed counts and the expected counts within each cell of the two-way table.}
%\label{pewEVmosaicplots}
%\end{figure}

\begin{figure}[h]
\Figures[Observed counts]{0.5}{pewEV}{pew_ev_mosaic}
\Figures[Expected counts]{0.5}{pewEV}{pew_ev_exp_mosaic}
\caption{Mosaic plots for Figure~\ref{pewResearchPollOnEVexpectedcounts}.  Left: observed counts; Right: expected counts assuming indpendence in the population.}
\label{pewEVmosaicplots}
\end{figure}

All of the expected counts are at least 5.  Also, in this Pew research poll, the data came from a random sample of adults in the US and the population size for adults in the US is much larger than 10 times the sample size of 5085.  Therefore, conditions for the chi-square test for independence are met.

\D{\newpage}

The chi-square test for independence and the chi-square test for homogeneity both involve counts in a two-way table.  The expected counts, chi-square statistic, degrees of freedom, and p-value are calculated in the same way.  

\begin{examplewrap}
\begin{nexample}{Calculate the chi-square statistic.}
We calculate $\frac{(\text{obs} - \text{exp})^2}{\text{exp}}$ for each of the nine cells in the table. Adding the results of each cell gives the chi-square test statistic.
\begin{align*}
\chi^2 =& \sum{\frac{(\text{obs} - \text{exp})^2}{\text{exp}}}\\
=& \frac{(748-828.8)^2}{828.8} +  \frac{(621-535.9)^2}{535.9} +  \cdots + \frac{(122-95.5)^2}{95.5} \\
=& 7.9 + 13.5 + \cdots + 7.4  \\
=& 102.4
\end{align*}
\end{nexample}
\end{examplewrap}

\begin{examplewrap}
\begin{nexample}{Find the p-value for the test and state the appropriate conclusion.}
We must first find the degrees of freedom for this chi-square test.  Because there are 3 rows and 3 columns, the degrees of freedom is $df=(3-1)\times (3-1) = 4$. We find the area to the right of $\chi^2=102.4$ under the chi-square distribution with $df=4$.  The p-value is extremely small, much less than 0.01, so we reject $H_0$.  We have evidence that the residential type and consideration of buying an EV in the population of US adults are associated / dependent.  
\end{nexample}
\end{examplewrap}




\newpage
\subsection{Comparing and applying the chi-square tests for two-way tables}

We have seen that the chi-square test for homogeneity and for independence are both used for two-way tables of counts.  The calculation of the expected counts, test statistic, and p-value is identical for the two tests.  The main differences between them lie in \emph{how the data is collected} and how we then present the hypotheses and check the random condition.  We summarize the two tests here.

\begin{onebox}{$\pmb{\MakeLowercase{\chi^2}}$ test for homogeneity and for independence}

When there are multiple samples or treatments and we are comparing the distribution
of a categorical variable across several groups, e.g. comparing the distribution of
rural/urban/suburban dwellers among 4 states, 
\\
\\
\inferencestep{Identify} Use a \termni{$\pmb{\chi^2}$ test for homogeneity}\index{chi-square test for homogeneity@$\chi^2$ test for homogeneity} at the desired $\alpha$ significance level.
\vspace{-1mm}
\begin{itemize}
\setlength{\itemsep}{0mm}
\item[]  $H_0$: \,There is no difference in the distribution of [...] across populations or treatments.  
\item[] $H_A$: There is a difference in the distribution of [...] across populations or treatments.  
\end{itemize}
\inferencestep{Check} Check that the test statistic follows a chi-square distribution, assuming $H_0$ is true.\vspace{-1mm}
{\setlength{\leftmargini}{13mm}
\begin{itemize}
\setlength{\itemsep}{0mm}
\item[1.] Independence:  Data come from multiple random samples or from a randomized 
experiment with multiple treatments.  If sampling without replacement, check that the
sample size is less than 10\% of the population size for each sample.
\item[2.] Expected counts:  All expected counts are $\ge 5$ (calculate and record expected counts).
\end{itemize}
}
\vspace{2mm}
When there is one sample and we are looking for association or dependence between two categorical variables, e.g. testing for an association between gender and political party,\\
\\
\inferencestep{Identify} Use a \termni{$\pmb{\chi^2}$ test for independence}\index{chi-square test for independence@$\chi^2$ test for independence} at the desired $\alpha$ significance level.
\vspace{-1mm}
\begin{itemize}
\setlength{\itemsep}{0mm}
 \item[]  $H_0$: \,[variable 1] and [variable 2]  in the population are independent.
\item[] $H_A$: [variable 1] and [variable 2] in the population are dependent.
\end{itemize}
\inferencestep{Check} Check that the test statistic follows a chi-square distribution, assuming $H_0$ is true.\vspace{-1mm}
{\setlength{\leftmargini}{13mm}
\begin{itemize}
\setlength{\itemsep}{0mm}
\item[1.]  Independence:  Data come from one random sample.  If sampling without replacement, 
check that the sample size is less than 10\% of the population size.
\item[2.] Expected counts:  All expected counts are $\ge 5$ (calculate and record expected counts).
\end{itemize}
}
\vspace{2mm}
The calculate and conclude steps for the chi-square test for homogeneity and test for independence are the same.\\
\\
\inferencestep{Calculate} Calculate the $\chi^2$-statistic, $df$, and p-value.\vspace{-1mm}  
\begin{itemize}
\setlength{\itemsep}{0mm}
\item[] test statistic:  $\chi^2 =\sum{ \frac{\text{(observed } - \text{ expected})^2}{\text{expected}}}$ 
\item[] $df = (\# \text{ of rows} - 1) \times (\# \text{ of columns} - 1)$
\item[] p-value = (area to the \emph{right} of $\chi^2$-statistic under the chi-square distribution with the appropriate $df$)
\end{itemize}
\inferencestep{Conclude} Compare the p-value to $\alpha$, and draw a conclusion in context.
\begin{itemize}\vspace{-1mm}
\setlength{\itemsep}{0mm}
\item[] If the p-value is $\le \alpha$, reject $H_0$; there is sufficient evidence that [$H_A$ in context]. 
\item[] If the p-value is $> \alpha$, do not reject $H_0$; there is not sufficient evidence that [$H_A$ in context].
\end{itemize}\end{onebox}

%
%
%\begin{onebox}{$\pmb{\MakeLowercase{\chi^2}}$ test for independence}
%When there is one sample and we are looking for association or dependence between two categorical variables, e.g. testing for an association between gender and political party,
%\\
%\\
%\inferencestep{Identify} Use a \termni{$\pmb{\chi^2}$ test for independence}\index{chi-square test for independence@$\chi^2$ test for independence}.  Test the following hypotheses at the desired $\alpha$ significance level.
%\vspace{-1mm}
%\begin{itemize}
%\setlength{\itemsep}{0mm}
% \item[] \quad $H_0$: \,[variable 1] and [variable 2] are independent.
%\item[] \quad $H_A$: [variable 1] and [variable 2] are dependent.
%\end{itemize}
%\inferencestep{Check} Check that the test statistic follows a chi-square distribution, assuming $H_0$ is true.\vspace{-1mm}
%\begin{itemize}
%\setlength{\itemsep}{0mm}
%\item[] 1. Independence:  Data come from one random sample.  If sampling without replacement, check that the sample size is less than 10\% of the population size.
%\item[] 2. Expected counts:  All expected counts are $\ge 5$ (calculate and record expected counts).
%\end{itemize}
%\inferencestep{Calculate} Calculate the $\chi^2$-statistic, $df$, and p-value.\vspace{-1mm}  
%\begin{itemize}
%\setlength{\itemsep}{0mm}
%\item[] test statistic:  $\chi^2 =\sum{ \frac{\text{(observed } - \text{ expected})^2}{\text{expected}}}$ 
%\item[] $df = (\# \text{ of rows} - 1) \times (\# \text{ of columns} - 1)$
%\item[] p-value = (area to the \emph{right} of $\chi^2$-statistic with the appropriate $df$)
%\end{itemize}
%\inferencestep{Conclude} Compare the p-value to $\alpha$, and draw a conclusion in context.
%\begin{itemize}\vspace{-1mm}
%\setlength{\itemsep}{0mm}
%\item[] If the p-value is $\le \alpha$, reject $H_0$; there is sufficient evidence that [$H_A$ in context]. 
%\item[] If the p-value is $> \alpha$, do not reject $H_0$; there is not sufficient evidence that [$H_A$ in context].
%\end{itemize}\end{onebox}



\begin{examplewrap}
\begin{nexample}{
 In an experiment, each individual was asked to be a seller of an iPod
  (a product commonly used to store music on before smart phones).
  The participant received \$10 + 5\% of the sale price for participating.
  The iPod they were selling had frozen twice in the past inexplicitly but
  otherwise worked fine. Unbeknownst to the participants who were the sellers
in the study,
the buyers were collaborating with the researchers
to evaluate the influence of different questions
on the likelihood of getting the sellers to disclose
the past issues with the iPod.
The scripted buyers ended with one of three questions:
 \begin{itemize}\vspace{-2mm}
\setlength{\itemsep}{0mm}
    \item{General: What can you tell me about it?}
    \item{Positive Assumption: It doesn't have any problems, does it?}
    \item{Negative Assumption: What problems does it have?}
  \end{itemize}
The outcome variable is whether the participant discloses or hides the problem with the iPod.
\begin{center}
\begin{tabular}{l l c c c l}
								&			& \multicolumn{2}{c}{\textit{Question Type}}	& &\hspace{10mm}\ 		\\
\cline{3-5}
								&			& General		& Positive Assump.		& Negative Assump.	\\
\cline{2-5}
\textit{Response}								& Disclose		& 2		& 23		& 36	\\
					& Hide		& 71			& 50 			& 37	\\
\cline{2-5}
								& Total		& 73		& 73		& 73
\end{tabular}
\end{center}
 Is there evidence that the phrasing of the question affects how likely individuals are to disclose the problems with the iPod?  Carry out an appropriate test at the 0.05 significance level.  }
\vspace{-1mm}
\begin{description}
\item[\inferencestep{Identify}] We have an experiment with 3 treatments (question types) and we want to know if the distribution of disclose/hide is the same for each of the three question types, so we want a chi-square test for homogeneity.  We test the following hypotheses at the $\alpha=0.05$ \mbox{significance level.}
\begin{itemize}
\setlength{\itemsep}{0mm}
\item[] $H_0$: \,There is no difference in likelihood to disclose across the three question types.  
\item[] $H_A$: There is a difference in likelihood to disclose across the three question types.  
\end{itemize}

\item[\inferencestep{Check}] This is an experiment in which there were three randomly assigned treatments (question types).  All values in the following table of expected counts are $\ge$ 5.
\vspace{-3mm}
\begin{center}
\begin{tabular}{l l c c c l}
								&			& \multicolumn{3}{c}{\textit{Question Type}}	&\hspace{17mm}\ 		\\
\cline{3-5}
								&			& General		& Positive Assump. & Negative Assump.	\\
\cline{2-5}
\textit{Response}									& Disclose		& 20.3		& 20.3 & 20.3 	\\
				& Hide			& 52.7		& 52.7 &  52.7	\\
\cline{2-5}
\end{tabular}
\end{center}

\item[\inferencestep{Calculate}]  Using technology, we get $\chi^2 = 40.1$, $df = (\# \text{ of rows} - 1) \times (\# \text{ of cols} - 1) = 2\times 1 = 2$.
\newline The p-value is the area under the chi-square distribution with 2 degrees of freedom to the right of $\chi^2=40.1$. The p-value is almost 0.  
\item[\inferencestep{Conclude}]  Because the p-value $\approx$ 0 $ < \alpha$, we reject $H_0$. We have strong evidence that there is a difference in likelihood to disclose across the three question types. 
\end{description}
\end{nexample}
\end{examplewrap}

%\begin{exercisewrap}
%\begin{nexercise}
%If an error was made in the test in the previous example, would it have been a Type~I error or a Type~II error?\footnotemark
%\end{nexercise}
%\end{exercisewrap}
%\footnotetext{In this test, the p-value was less than $\alpha$, so we rejected $H_0$.  If $H_0$ is in fact true, and we reject it, that would be committing a Type~I error.  We could not have made a Type~II error, because a Type~II error involves not rejecting~$H_0$.}


\begin{examplewrap}
\begin{nexample}{Which combination of Response and Question Type is the most underrepresent from what would be expected under the null hypothesis of no difference?  }
Using a technology option from Section~\ref{techchisq2way}, we find the chi-square contributions for each cell:\\ \\
16.53 \ \ 0.3497 \ \ 12.07\\
6.382 \ \ 0.135 \ \ \ 4.66\\ \\
General/Disclose has the largest chi-square contribution, so it deviated the most from what was expected under the null hypothesis of no difference.  However, was it more or less than expected?  Here we see that (observed $-$ expected) = (2 $-$ 20.3), which is negative, so we know that there were \emph{fewer} in the General group that chose Disclose than we would have expected.
\end{nexample}
\end{examplewrap}

\index{data!pew research climate action}
\begin{examplewrap}
\begin{nexample}{A 2021 Pew Research poll asked a random sample of US residents their generation and whether they have personally taken action to help address climate change within the last year.  The data are shown below.
\label{generationclimate}
\begin{center}
\begin{tabular}{l l c c ll}
								&			& \multicolumn{2}{c}{\textit{Response}}	& &\hspace{10mm}\ 		\\
\cline{3-4}
								&			& Took action		& Didn't take action		& Total	\\
\cline{2-5}
								& Gen Z		& \ \ 292		& \ \ \ 620		&  \ \ \ 912	\\
\textit{Generation}					& Millenial			& \ \ 885			& \ 2,275 			& \ 3,160	\\
								& Gen X			& \ \ 809			& \ 2,709 			& \ 3,518	\\
								& Boomer \& older	& 1,276			& \ 4,798 			& \ 6,074	\\
\cline{2-5}
								& Total		& 3,262		& 10,402		& 13,664
\end{tabular}
\end{center}
We can see that the percent in the sample from each generation that took action vary:  32\% for Gen Z, 28\% for Millenial, 23\% for Gen X, and 21\% for Boomer \& older.  However, could this be due to random variation based on who happened to end up in the sample?  Carry out an appropriate test at the 0.05 significance level to see if there is an association between generation and taking action to help address climate change.}
\begin{description}
\item[\inferencestep{Identify}] Two variables were recorded on the respondents: generation and whether or not they have taken action to help address climate change within the last year.  We have one random sample and we want to know if these variables are associated / dependent, so we will carry out a chi-square test for independence.  We will test the following hypotheses at the $\alpha=0.05$ significance level.  
\begin{itemize}
\setlength{\itemsep}{0mm}
\item[]$H_0$: \,Generation and taking action to help address climate change among US residents
\item[] \qquad \ are \mbox{independent.}
\item[]$H_A$: Generation and taking action to help address climate change among US residents 
\item[] \qquad \ are \mbox{dependent.}
\end{itemize}

\item[\inferencestep{Check}] According to the problem, there was one random sample taken.  We note that the population of US residents is much larger than 10 times the sample size of 13,664.  Also, all values in the table of expected counts are $\ge$ 5.
Table of expected counts:
\begin{center}
\begin{tabular}{l l c c l}
								&			& \multicolumn{2}{c}{\textit{Response}}	&\hspace{17mm}\ 		\\
\cline{3-4}
								&			& Took action		& Didn't take action	\\
\cline{2-4}
								& Gen Z			& \ \ 217.72		& \ \ 694.28	\\
\textit{Generation}					& Millenial		& \ \ 754.39		& 2405.60	\\
								& Gen X			& \ \ 839.85		& 2678.10	\\
								& Boomer \& older	& 1450.00		& 4624.00	\\
\cline{2-4}
\end{tabular}
\end{center}

\item[\inferencestep{Calculate}]  Using technology, we get $\chi^2 = 91.9$, $df = (\# \text{ of rows} - 1) \times (\# \text{ of columns} - 1) = 3\times 1 = 3$.  The p-value is the area under the chi-square distribution with 3 degrees of freedom to the right of $\chi^2=91.9$.  Thus, the p-value = 8.46x$10^{-20}$ $\approx$ 0.
\item[\inferencestep{Conclude}]  Because the p-value $\approx$ 0 $ < \alpha$, we reject $H_0$. We have sufficient evidence that generation and taking action to help address climate change among US residents are dependent.
\end{description}
\end{nexample}
\end{examplewrap}

\begin{exercisewrap}
\begin{nexercise}
In context, interpret the p-value of the test from the above example.\footnotemark
\end{nexercise}
\end{exercisewrap}
\footnotetext{Recall that the p-value in this test is calculated as the area to the right of $\chi^2 = 91.9$ under the chi-square distribution with 3 degrees of freedom.  We interpret the p-value as follows:  Assuming the null hypothesis is true, i.e. that generation and response really are independent, there is close to a 0\% probability of getting a $\chi^2$-statistic as large or larger than 91.9.  Equivalently, it is the probability of our observed counts being this different from the expected counts, relative to the expected counts, if the null is true, i.e. that generation and response really are independent. }

\index{chi-square test for independence@$\chi^2$ test for independence|)}

\D{\newpage}


\subsection[Technology: chi-square distribution probabilities]{Technology: chi-square distribution probabilities}
\label{techchisqdist}

\noindent Use technology to find the upper tail area for a chi-square distribution with 5 degrees of freedom and a cutoff of 5.1. \\


\noindent \textbf{Desmos}:  Use the \texttt{chsqdist(df)} function, replacing \texttt{df} with the degrees of freedom.
\begin{enumerate}
\setlength{\itemsep}{0mm}
\item Type \calctext{chisqdist(5)}.
\item Click the triangle next to \calctext{Cumulative Probability}.
\item Choose \calctext{Inner}, \calctext{Outer}, \calctext{Left} or \calctext{Right} as illustrated below.  Usually you will want Right.
\item Choose \calctext{Area} and enter the desired boundary value(s) as illustrated below.
\item Click the magnifying glass to Zoom Fit the graphing window.
\begin{center}
\fbox{\Figures[A desmos calculator screen is shown with chisqdist(5). Right and Area are chosen.  P(x $\ge$ 5.1) =  0.404.  A graph of the chi-square distribution with 5 df is show and the area to the right of 5.1 is shaded. ]
{0.65}{technologyInferenceProps}{desmosChiSqDist}}
\end{center}
\end{enumerate}


%%
\vspace{5mm}
\noindent \R{}:   \\
\texttt{pchisq(q, df)} will give the area to the left of \texttt{q}, so we add \texttt{lower.tail = FALSE} to get the area to the right.\\

\noindent \texttt{> \calctext{pchisq(5.1, df = 5, lower.tail = FALSE)}}\\
\texttt{[1] 0.4037985}\\ \\

\newpage
%%
\noindent \textbf{Calculator}:  NumWorks calculator instructions and example output are included.  For the TI-83/84 and Casio calculators, general instructions are provided, and worked example videos can be accessed via the \includegraphics[height=3mm]{extraTeX/icons/video_camera.png} icon or at \oiRedirect{ti84_playlist}{\textbf{openintro.org/ti}} and \oiRedirect{casio-9750-playlist}{\textbf{openintro.org/casio}}.\\ 

\begin{onebox}{NumWorks: Finding area under the chi-square distribution}
\label{normalnumworks}
Use \calctext{OK} or \calctext{EXE} to make a selection.
\begin{enumerate}
\setlength{\itemsep}{0mm}
\item From the home screen, select \calcbutton{Distributions}, arrow down and choose \calctext{Chi-square}.  If a list of distributions does not appear, click the \calcbutton{$\lhookleftarrow$} button in the upper right as many times as needed.
\item Enter the \calctext{Degrees of freedom}.  Hit the down arrow and choose \calcbutton{Next}. 
\item Hit the left arrow to highlight the graph.  Hit the down arrow to choose whether you want left, inner, or right, then hit \calcbutton{OK}.  Hit the right arrow and enter the boundary value(s), then hit \calcbutton{EXE}.
\begin{center}
\Figures[ ]
{0.35}{technologyInferenceProps}{numworksChiSqDist}
\end{center}
\vspace{-1.5mm}
\end{enumerate}
\end{onebox}
%
\begin{onebox}{\videohref{ti84_chisq_tail_area} TI-84: Finding an upper tail area under the chi-square distribution}
\label{chisqtail}
Use the $\calctextmath{\chi^2}$\calctext{cdf} command to find areas under the chi-square distribution.
\begin{enumerate}
\setlength{\itemsep}{0mm}
\item Hit \calcbutton{2ND} \calcbutton{VARS} (i.e. \calctext{DISTR}).
\item Choose \calctext{8:}$\calctextmath{\chi^2}$\calctext{cdf}.
\item Enter the lower bound, which is generally the chi-square value.
\item Enter the upper bound. Use a large number, such as 1000.
\item Enter the degrees of freedom.
\item Choose \calctext{Paste} and hit \calcbutton{ENTER}.
\end{enumerate}
TI-83: Do steps~1-2, then type the lower bound, upper bound, and degrees of freedom separated by commas. e.g. $\calctextmath{\chi^2}$\calctext{cdf(5, 1000, 3)}, and hit \calcbutton{ENTER}.\end{onebox}
%
\begin{onebox}{\videohref{casio_chisq_tail_area} Casio fx-9750GII: Finding an upper tail area under the chi-sq.~curve}
\ \vspace{-5mm} \  
\begin{enumerate}
\setlength{\itemsep}{0mm}
\item Navigate to \calctext{STAT} (\calcbutton{MENU} button, then hit the \calcbutton{2} button or select \calctext{STAT}).
\item Choose the \calctext{DIST} option (\calcbutton{F5} button).
\item Choose the \calctext{CHI} option (\calcbutton{F3} button).
\item Choose the \calctext{Ccd} option (\calcbutton{F2} button).
\item If necessary, select the \calctext{Var} option (\calcbutton{F2} button).
\item Enter the \calctext{Lower} bound (generally the chi-square value).
\item Enter the \calctext{Upper} bound (use a large number, such as 1000).
\item Enter the degrees of freedom, \calctext{df}.
\item Hit the \calcbutton{EXE} button.
\end{enumerate}
\end{onebox}


\newpage
%%
\subsection{Technology: the chi-square test for two-way tables}
\label{techchisq2way}

\noindent 
Consider the data from the search algorithm experiment introduced in Example~\ref{searchalgorithmexample}.  Use technology to find the test statistic, $df$, and p-value for a chi-square test for homogeneity, testing whether there is evidence that the algorithms do not perform equally well.  Also find the expected values and chi-square contributions for this test.  Conditions were verified to be met.

\begin{figure}[h]
\centering
\quad \quad \quad \quad \var{Search algorithm} \\
\begin{tabular}{lll crr rr}
\cline{3-7}
&& \hspace{1mm} & current & test 1 & test 2 & \hspace{1mm} & Total \\
\cline{2-8}
&success				   & & 3511    & 1749 & 1818 & 				& 7078 \\
\raisebox{1.5ex}[0pt]{\var{outcome}}
&failure				   & & 1489    & 751	& 682    &				& 2922 \\
\cline{2-8}
&Total						   & & 5000    & 2500 & 2500 & 				& 10000 \\
\cline{2-8}
\end{tabular}
\end{figure}


\vspace{2mm}

\noindent \textbf{Desmos}:  Use the \texttt{chisqtest()} function as explained below.
\begin{enumerate}
\setlength{\itemsep}{0mm}
\item Click \calctext{+} in the upper left, then choose \calctext{inference}.  
\item Choose \calctext{$\chi^2$ test for independence} in the pop-up window.  The calculations for the chi-square test for homogeneity and independence are the same and both use this test.
%\begin{center}
%\fbox{\Figures[A Desmos calculator screen is shown. The + and inference option are highlighted. ]
%{0.3}{technologyInferenceProps}{desmosInference}}\hspace{10mm}
%\fbox{\Figures[A Desmos calculator screen is shown with the inference pop-up box. z-test for proportions is highlighted. ]
%{0.3}{technologyInferenceProps}{desmosInferenceChiSq2Way}}
%\end{center}
\item Enter the observed counts in the table.  Use the down arrow and right arrow to enter additional row and column values.  Do not enter the row and column totals.  Click \calctext{Create Test}.
\begin{center}
\fbox{\Figures[A Desmos calculator screen is shown.  A chi-square test for independence box is shown, with 3511, 1749, and 1818 entered in the first row and 1489, 751, and 682 entered in the second row. ]
{0.4}{technologyInferenceProps}{desmosChiSq2WayData}}
\end{center}
\indent\hspace{-4mm} * You can type \calctext{chisqtest([3511,1489], [1749,751], [1818,682])} in place of steps 1-3.  
\vspace{1mm}
\item Click the triangle next to \calctext{Observed (Expected)}.  Click the checkbox next to \calctext{Expected} to see the expected counts in parentheses in each cell. Click the checkbox next to \calctext{Contributions} to see a graphical representation of the size of each value's contribution to the chi-square statistic.  Click the checkbox next to \calctext{Totals} to see the row and column totals.  Also, click any cell in the table to produce a pop-up box with the corresponding Observed value,  Expected value, and the Contribution to the chi-square statistic.
\item Click the triangle next to \calctext{Significance Test} to see the test statistic, df, and p-value. 
\begin{center}
\fbox{\Figures[A Desmos calculator screen is shown with chisqtest({[3511, 1489]}, {[1749, 751]}, {[1818, 682]}) entered.  The observed and expected counts and totals are shown as well as the chi-square statistic of 6.12, with df = 2 and p-value = 0.047. The bottom, right cell is clicked, showing an Observed: 682, Expected: 913.125, Contribution: 58.50104.  ]
{0.65}{technologyInferenceProps}{desmosChiSq2WayTest}}
\end{center}
\end{enumerate}

\newpage
%%
\noindent \R{}:  Chi-square test for two-way tables\\
Use \texttt{chisq.test()} with \texttt{cbind()} as illustrated below to bind the \textit{columns} into a table.  \\ \\
\texttt{> \calctext{X = chisq.test(cbind(c(3511,1489), c(1749,751), c(1818,682)))}}\\
\texttt{> \calctext{X}}\\ 
\texttt{	Pearson's Chi-squared test\\
data:  cbind(c(3511, 1489), c(1749, 751), c(1818, 682))\\
\fbox{X-squared = 6.1203, df = 2, p-value = 0.04688}}\\ 

\noindent \texttt{> \calctext{X$\$$expected}}\\ 
\texttt{[,1] [,2]  [,3]}\\
\texttt{[,1] 3539 1769.5 1769.5}\\
\texttt{[,2]  1461 730.5 730.5}\\ 
\texttt{> \calctext{(X$\$$residuals)\textasciicircum 2}}\\
\texttt{[,1]\ [,2]\ [,3]}\\
\texttt{[1,]\ 0.2215315\ 0.2374965\ 1.329330}\\
\texttt{[2,]\ 0.5366188\ 0.5752909\ 3.220055}\\
\\
\\
%%
\noindent \textbf{Calculator}:  NumWorks calculator instructions and example output are included.  For the TI-83/84 and Casio calculators, general instructions are provided, and worked example videos can be accessed via the \includegraphics[height=3mm]{extraTeX/icons/video_camera.png} icon or at \oiRedirect{ti84_playlist}{\textbf{openintro.org/ti}} and \oiRedirect{casio-9750-playlist}{\textbf{openintro.org/casio}}.

\begin{onebox}{NumWorks: Chi-square test for homogeneity and independence}
\label{normalnumworks}
Use \calctext{OK} or \calctext{EXE} to make a selection.
\begin{enumerate}
\setlength{\itemsep}{0mm}
\item From the home screen, select \calcbutton{Inference}, then \calctext{Tests}, then \calctext{Chi-square}, then \calctext{Homogeneity/Indpendence}.  If these options do not appear, click the \calcbutton{$\lhookleftarrow$} button in the upper right as many times as needed. 
\item Enter the observed counts, then \calctext{$\alpha$}, then choose \calcbutton{Next}.  Use arrows as needed.
\item On this screen, you will see the table of expected counts.  Use the arrows to see any rows or columns that do not fit on the screen. To see the chi-square contributions, click the up and right arrow to choose \calctext{Contributions}.  When you are finished, choose \calctext{Next}.
\begin{center}
\Figures[ ]
{0.35}{technologyInferenceProps}{numworksChiSq2Way1}\hspace{10mm}
\Figures[ ]
{0.35}{technologyInferenceProps}{numworksChiSq2Way2}
\end{center}
\item On this screen, you will see the test statistic, p-value and df.  Choose \calctext{Next} to see the chi-square distribution with the p-value shaded.  
\begin{center}
\Figures[ ]
{0.35}{technologyInferenceProps}{numworksChiSq2Way3}\hspace{10mm}
\Figures[ ]
{0.35}{technologyInferenceProps}{numworksChiSq2Way4}
\end{center}
\vspace{-1.5mm}
\end{enumerate}
\end{onebox}

\newpage


\begin{onebox}{\videohref{ti84_chisq_2_way_test} TI-83/84: Chi-square test for homogeneity and independence}
\label{chisq2waytest}
\label{2waytable}
First enter the counts in a two-way table.
\begin{enumerate}
\setlength{\itemsep}{0mm}
\item Hit \calcbutton{2ND} $\calctextmath{x^{-1}}$ (i.e. \calctext{MATRIX}).
\item Right arrow to \calctext{EDIT}.
\item Hit \calcbutton{1} or \calcbutton{ENTER} to select matrix \calctext{A}.
\item Enter the dimensions by typing \#rows, \calcbutton{ENTER}, \#columns, \calcbutton{ENTER}.
\item Enter the data from the two-way table.
\end{enumerate}

Then use \calctext{STAT}, \calctext{TESTS}, $\calctextmath{\chi^2}$\calctext{-Test}.   Make sure you have entered the counts as described above.
\begin{enumerate}
\setlength{\itemsep}{0mm}
\item Choose \calctext{STAT}.
\item Right arrow to \calctext{TESTS}.
\item Down arrow and choose \calctext{C:}$\calctextmath{\chi^2}$\calctext{-Test}.
\item Down arrow, choose \calctext{Calculate} or \calctext{Draw} and hit \calcbutton{ENTER}.  \calctext{Draw} shows the chi-square statistic and p-value as well as a graph of the chi-square distribution with p-value shaded.  \calctext{Calculate} returns: \\[1mm]
\begin{tabular}{l l}
$\calctextmath{\chi^2}$ & chi-square test statistic \\
\calctext{p} & p-value \\
\calctext{df} & degrees of freedom
\end{tabular}
\end{enumerate}
\noindent Edit \calctext{Matrix B} to see the expected counts. Make sure you have already done the steps above.
\begin{enumerate}
\setlength{\itemsep}{0mm}
\item Hit \calctext{2ND} $\calctextmath{x^{-1}}$ (i.e. \calctext{MATRIX}).
\item Right arrow to \calctext{EDIT}.
\item Hit \calcbutton{2} to see matrix \calctext{B}.  This matrix contains the expected counts.
\end{enumerate}
\end{onebox}

\begin{onebox}{\videohref{casio_chisq_2_way_test} Casio fx-9750GII: Chi-square test for homogeneity and independence}
\ \vspace{-5mm} \
\begin{enumerate}
\setlength{\itemsep}{0mm}
\item Navigate to \calctext{STAT} (\calcbutton{MENU} button, then hit the \calcbutton{2} button or select \calctext{STAT}).
\item Choose the \calctext{TEST} option (\calcbutton{F3} button).
\item Choose the \calctext{CHI} option (\calcbutton{F3} button).
\item Choose the \calctext{2WAY} option (\calcbutton{F2} button).
\item Enter the data into a matrix:
  \begin{itemize}
  \setlength{\itemsep}{0mm}
  \item Hit $\calctextmath{\triangleright}$\calctext{MAT} (\calcbutton{F2} button).
  \item Navigate to a matrix you would like to use (e.g. \calctext{Mat C}) and hit \calcbutton{EXE}.
  \item Specify the matrix dimensions: \calctext{m} is for rows, \calctext{n} is for columns.
  \item Enter the data.
  \item Return to the test page by hitting \calcbutton{EXIT} twice.
  \end{itemize}
\item Enter the \calctext{Observed} matrix that was used by hitting \calctext{MAT} (\calcbutton{F1} button) and the matrix letter (e.g.~\calcbutton{C}).
\item Enter the \calctext{Expected} matrix where the expected values will be stored (e.g.~\calcbutton{D}).
\item Hit the \calcbutton{EXE} button, which returns \\[1mm]
  \begin{tabular}{l ll}
  $\calctextmath{\chi^2}$ & chi-square test statistic \\
  \calctext{p} & p-value \\
  \calctext{df} & degrees of freedom \\
  \end{tabular}
\item To see the expected values, go to $\calctextmath{\triangleright}$\calctext{MAT} (\calcbutton{F6} button) and select the corresponding matrix.
\end{enumerate}
\end{onebox}






 
\D{\newpage}

%%
\subsection*{Section summary}
\begin{itemize}

\item The chi-square statistic measures the distance between observed and
expected counts relative to expected counts.

\item Chi-square distributions have positive values and are skewed right. Within this
family of density curves, the skew becomes less pronounced with increasing
degrees of freedom.

\item To determine whether the distributions of a categorical variable across two or
more populations are different, the appropriate test is the \termni{chi-square test for
homogeneity}.  An example is testing for a difference in the distribution of rural/urban/suburban dwellers across 4 states.

\item[]The hypotheses for a chi-square test for
homogeneity are:
\begin{itemize}
\setlength{\itemindent}{3mm}
\item[$H_0$:] \,There is no difference in the distribution of [...] across population or treatments.
\item[$H_A$:]There is a difference in the distribution of [...] across populations or treatments.
\end{itemize}
The conditions for a chi-square test for
homogeneity are:
\begin{itemize}
\item[1.] Independence:  The data come from two or more independent random samples, each with sample size $<$ 10\% of its corresponding population size if sampling without replacement OR the data come from an experiment with two or more randomly assigned treatments.
\item[2.]  Expected counts: all expected counts, assuming the null hypothesis is true, should be \mbox{$\ge 5$.}  
\end{itemize}

\item To determine whether row and column variables in a two-way table of
categorical data might be associated in the single population from which
the data were sampled, the appropriate test is the \termni{chi-square test for
independence}.  An example is testing for an association between gender and political party within a particular town.
\item[]The hypotheses for a chi-square test for
independence are:

\begin{itemize}
\setlength{\itemindent}{3mm}
\item[$H_0$:]\, there is no association between two categorical variables in a given population or 
\item[] the two categorical variables in a given population are
independent. 
\item[$H_A$:] there is an association between two
categorical variables in a given population or 
\item[]the two categorical variables in a
given population are not independent.
\end{itemize}

The conditions for a chi-square test for
independence are:\begin{itemize}
\item[1.] Independence:  The data come from \emph{one} random sample, with sample size $<$ 10\% of the population size if sampling without replacement.
\item[2.]  Expected counts: all expected counts, assuming the null hypothesis is true, should be \mbox{$\ge 5$.}  
\end{itemize}

\item The expected values (under the null hypothesis) in a particular cell of a two-way
table of categorical data can be calculated using the formula:  expected value = $\frac{(\text{row total})\times (\text{column total})}{\text{table total}}$.  

\item A chi-square test for homogeneity and for independence use a chi-square statistic:  \\
$\chi^2 =\sum{ \frac{\text{(observed count} - \text{ expected count})^2}{\text{expected count}}}$,
where the sum is taken over all cells of the two-way table.

\item The chi-square statistic has a chi-square distribution with \mbox{$df$ = (\# of rows $-$ 1)(\# of cols $-$ 1).}

\item The p-value for a chi-square test is the area to the \emph{right} of the $\chi^2$-statistic under the chi-square distribution with the appropriate $df$.  This can be found using technology.

\item The p-value for a chi-square test is the probability of obtaining a $\chi^2$ value as large or larger than the $\chi^2$-statistic that was observed, assuming the null hypothesis is true.

\item A formal decision explicitly compares the p-value to the significance level.  If the \mbox{p-value $\le \alpha$,} then reject the null hypothesis; if the p-value $> \alpha$, then fail to reject the null hypothesis.  The conclusion should be stated in terms of the alternative hypothesis and should include context, using non-causal language.

\item The results of a chi-square test for homogeneity or independence can serve
as the statistical reasoning to support the answer to an investigative question
about the population that was sampled (independence) or the populations that
were sampled (homogeneity).
\end{itemize}


%%%%%%%%Section Exercises
{\input{ch_inference_for_props/TeX/chi-square_tests_for_two-way_tables.tex}}


%______________________________________________
\reviewchapterheader{}

\noindent Calculating a confidence interval or a test statistic and p-value are generally done with statistical software.  It is important, then, to focus not just on the calculations, but on the following components:
\begin{enumerate}\vspace{-1mm}
\setlength{\itemsep}{0mm}
\item Choose the correct procedure.
\item Understand when the procedure does or does not apply by checking relevant conditions.
\item Interpret the results in context.
\end{enumerate}
Choosing the correct procedure requires understanding the \textit{method} of data collection and the \textit{type} of data collected. All of the inference procedures in Chapter~\thechapter~are for categorical variables.  Here we list the two confidence intervals and five hypothesis tests encountered in this chapter and when to use them.  
\begin{itemize}\vspace{-2mm}
\setlength{\itemsep}{0mm}
\item \textbf{one-sample Z-interval/test for \pmb{$p$}}
\begin{itemize}\vspace{-1mm}
\setlength{\itemsep}{0mm}
\item \emph{1 random sample}, a yes/no variable
\item Ask about the proportion of a yes/no variable in a single population; e.g. determine if there is evidence that the true approval rating for a governor is greater than 50\%.  
\end{itemize}

\item \textbf{two-sample Z-interval/test for \pmb{$p_1 - p_2$}}
\begin{itemize}\vspace{-2mm}
\setlength{\itemsep}{0mm}
\item \emph{2 independent random samples or randomly assigned treatments}, a yes/no variable
\item Compare two populations or treatments to each other with respect to one yes/no variable; e.g. comparing the proportion under age 18 in two different counties.
\end{itemize}

\item \textbf{$\pmb{\chi^2}$ goodness of fit test} (special topic)
\begin{itemize}\vspace{-2mm}
\setlength{\itemsep}{0mm}
\item \emph{1 random sample}, a categorical variable (generally at least three categories)
\item Compare the distribution of a categorical variable to a fixed or known population distribution; e.g. comparing the distribution of color among M\&M's to the published color distribution. 
\end{itemize}

\item \textbf{$\pmb{\chi^2}$ test for homogeneity}: 
\begin{itemize}\vspace{-2mm}
\setlength{\itemsep}{0mm}
\item \emph{2+ independent random samples or randomly assigned treatments}, a categorical variable
\item Compare the distribution of a categorical variable across several populations or treatments; e.g. comparing party affiliation over various years or patient improvement across 3 treatments.
\end{itemize}

\item \textbf{$\pmb{\chi^2}$ test for independence}
\begin{itemize}\vspace{-2mm}
\setlength{\itemsep}{0mm}
\item \emph{1 random sample}, 2 categorical variables
\item Determine if, in a single population, there is an association between two categorical variables; e.g. looking for association at a particular school between grade level and whether or not one plays a sport.
\end{itemize}

\end{itemize}
Even when the data type and data collection method correspond to a particular test, we must verify that conditions are met to see if the assumptions of the test are reasonable.  All of the inferential procedures of this chapter require some type of random sample or process.  In addition, the one-sample Z-test/interval for $p$ and the two-sample Z-test/interval for $p_1 - p_2$ require that the large counts condition is met and the three $\chi^2$ tests require that all expected counts are at least 5.
\\
\\
Finally, being able to accurately interpret a confidence interval or p-value and use them to justify claims about a population are essential. 