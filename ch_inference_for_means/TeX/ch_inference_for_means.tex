\begin{chapterpage}{Inference for numerical data:  means}
  \chaptertitle{Inference for numerical \titlebreak{}  data: means}
  \label{inferenceForNumericalData}
  \label{ch_inference_for_means}
   \chaptersection{distributionofxbar}
  \chaptersection{oneSampleMeansCI}
  \chaptersection{oneSampleMeansTest}
 \chaptersection{distributionofdifferenceofmeans}
  \chaptersection{differenceOfTwoMeansCI}
  \chaptersection{differenceOfTwoMeansTest}
\label{differenceOfTwoMeansTest}

\end{chapterpage}
%\chapter{Inference for means}
 % \label{ch_inference_for_means}

\renewcommand{\chapterfolder}{ch_inference_for_means}


%%%%%%%% update chapter intro

\chapterintro{Chapter~\ref{inferenceForCategoricalData} summarized inference procedures for categorical data (counts and proportions), using the normal distribution and the chi-square distribution. In this chapter, we focus on inference procedures for numerical data and we encounter a new distribution called the $t$-distribution. In each case, the inference ideas remain the same: determine which point estimate or test statistic is useful, identify an appropriate distribution for the point estimate or test statistic, and apply the ideas of inference.  
}



%____________________________________
\section[Sampling distribution of a sample mean]{Sampling distribution of a sample mean }
\label{distributionofxbar}

\sectionintro{
\noindent%
If the mean race time among all runners of a certain race is 94~minutes with a standard deviation of 16~minutes, what is the probability that the average race time of 30 randomly selected runners will be within 16~minutes of the mean?  The answer is not 68\%!
To answer this question we must visualize and understand what is called the \emph{sampling distribution} of a sample mean.


%%
\subsection*{Learning objectives}
\begin{enumerate}
\setlength{\itemsep}{0mm}

\item Interpret and apply the concept of a sampling distribution in the context of a sample mean.

\item Distinguish between the standard deviation of a population and the standard deviation of a sampling distribution.

\item Calculate the mean and standard deviation of the sampling distribution of a sample mean.

\item Justify whether the independence condition is satisfied when considering properties of the sampling distribution of a sample mean.  

\item Determine whether or not the shape of the sampling distribution of a sample mean is approximately normal.

\item Interpret the mean, standard
deviation, and probabilities for
the sampling distribution of a
sample mean

\end{enumerate}
}

%%
\subsection{Building a sampling distribution for a sample mean}


In this section we consider a data set called \data{run17}, which represents all
19,961 runners who finished the 2017 Cherry Blossom 10 mile run in Washington, DC.
Part of this data set is shown in Figure~\ref{run17DF}, and the variables are
described in Figure~\ref{run17Variables}.

\begin{figure}[h]
\centering
\begin{tabular}{rrrrr}
  \hline
ID & time & age & gender & state \\ 
  \hline
1 & 92.25 & 38.00 & M & MD \\ 
2 & 106.35 & 33.00 & M & DC \\ 
%3 & 89.33 & 55.00 & F & VA \\ 
%4 & 113.50 & 24.00 & F & VA \\ 
$\vdots$ & $\vdots$ & $\vdots$ & $\vdots$ & $\vdots$ \\
16923 & 122.87 & 37.00 & F & VA \\ 
16924 & 93.30 & 27.00 & F & DC \\ 
   \hline
\end{tabular}
\caption{Four observations from the \data{run17} data set.}
\label{run17DF}
\end{figure}
% library(openintro); library(xtable); data(run10); xtable(run10[c(1,2,3,4, nrow(run10)-1:0), c("time", "age", "gender", "state")])

\begin{figure}[h]
\centering\small
\begin{tabular}{l p{65mm}}
\hline
{\bf variable} & {\bf description} \\
\hline
\var{time} & Ten mile run time, in minutes \\
\var{age} & Age, in years \\
\var{gender} & Gender (\resp{M} for male, \resp{F} for female) \\
\var{state} & Home state (or country if not from the US) \\
\hline
\end{tabular}
\caption{Variables and their descriptions for the \data{run17} data set.}
\label{run17Variables}
\end{figure}

\index{data!run17samp|(}

\D{\newpage}

These data are special because they include the results for the entire population of runners who finished the 2017 Cherry Blossom Run. We took a simple random sample of this population, which is represented in Figure~\ref{run17sampDF}. A histogram summarizing the time variable in the \data{run17samp} data set is shown in Figure~\ref{run17sampHistograms}.

\begin{figure}[h]
\centering
\begin{tabular}{rrrrr}
  \hline
ID & time & age & gender & state \\ 
  \hline
1983 & 88.31 & 59 & M & MD \\ 
8192 & 100.67 & 32 & M & VA \\ 
%11020 & 109.52 & 33 & F & VA \\ 
  $\vdots$ &   $\vdots$ &   $\vdots$ &   $\vdots$ &   $\vdots$ \\ 
1287 & 89.49 & 26 & M & DC \\ 
   \hline
\end{tabular}
\caption{Three observations for the \data{run17samp} data set, which represents a simple random sample of 100 runners from the 2017 Cherry Blossom Run.}
\label{run17sampDF}
%library(openintro); library(xtable); data(run10); data(run10samp); xtable(run10samp[c(1,2,3,100),])
\end{figure}

\begin{figure}[h]
\centering
 \Figure[A histogram of "time" for the sample Cherry Blossom Race data is shown. The data are nearly symmetric with a center at about 95 minutes and a standard deviation of roughly 20 minutes. All times lie between 50 and 140 minutes.] {0.7}{run17sampHistograms} 
\caption{Histogram of \var{time} for a single sample of size 100. The average of the sample is in the mid-90s and the standard deviation of the sample $s\approx 17$ minutes.
}
\label{run17sampHistograms}
\end{figure}



From the random sample represented in \data{run17samp}, we use our sample mean to estimate that the average time it takes to run 10 miles is 95.61 minutes. Suppose we take another random sample of 100 individuals and take its mean: 95.30 minutes. Suppose we took another (93.43 minutes) and another (94.16 minutes), and so on. If we do this many many times -- which we can do only because we have the entire population data set -- we can build up a \term{sampling distribution} for the sample mean when the sample size is 100, shown in Figure~\ref{netTime1000SamplingDistribution}.

\newpage
\begin{figure}[h]
   \centering
\Figure [A histogram is displayed with the text ``The distribution of sample means, shown here, is much narrower than the distribution of raw observations."  This distribution is also centered around 95, but has a much smaller standard deviation of about 2.  All values lie between about 90 and 100.]{0.85}{netTime1000SamplingDistribution}
   \caption{A histogram of 1000 sample means for run time, where the samples are of size $n=100$. This histogram approximates the true sampling distribution of the sample mean, with mean $\mu_{\bar{x}}$ and standard deviation $\sigma_{\bar{x}}$.}
   \label{netTime1000SamplingDistribution}
\end{figure}

\begin{onebox}{Sampling distribution of a sample mean}
The sampling distribution of a sample mean $\bar{x}$ is the distribution of  $\bar{x}$ values for all random samples of a given size from a given population. 
\end{onebox}


\subsection[The mean and standard deviation of $\bar{x}$]{The mean and standard deviation of $\pmb{\bar{x}}$}

The sampling distribution shown in Figure~\ref{netTime1000SamplingDistribution} is unimodal and approximately symmetric. It is also centered exactly at the true population mean: $\mu=94.52$. Intuitively, this makes sense. The sample mean should be an unbiased estimator of the population mean.  We use $\mu_{\bar{x}}$ to denote the mean of the sampling distribution of $\bar{x}$.  


We can see that the sample mean has some variability around the population mean, which can be quantified using the standard deviation of this distribution of sample means. The standard deviation of the sample mean tells us how far the typical estimate is away from the actual population mean, 94.52 minutes. It also describes the typical \term{error} of an estimate, and is denoted by the symbol $\sigma_{\bar{x}}$. 

%\begin{onebox}{Standard deviation of $\bar{x}$}
%The standard deviation of $\bar{x}$ describes the typical variation in samples means from the population mean for all random samples of size $n$ from a certain population.
%\end{onebox}

\begin{examplewrap}
\begin{nexample}{Looking at Figures~\ref{run17sampHistograms} and \ref{netTime1000SamplingDistribution}, we see that the standard deviation of the sample mean with $n=100$ is much smaller than the standard deviation of a single sample. Interpret this statement and explain why it is true.}The variation from one-sample mean to another sample mean is much smaller than the variation from one individual to another individual. This makes sense because when we average over 100 values, the large and small values tend to balance each other out. For instance, while many individuals have a time under 90 minutes, we can see in Figure~\ref{netTime1000SamplingDistribution} that it is unlikely for the \emph{average} of 100 randomly sampled runners to be less than 90 minutes.
\end{nexample}
\end{examplewrap}

\D{\newpage}

%\begin{exercisewrap}
%\begin{nexercise}
%(a) Would you rather use a small sample or a large sample when estimating a parameter? Why? (b) Using your reasoning from (a), would you expect a point estimate based on a small sample to have smaller or larger standard deviation than a point estimate based on a larger sample?\footnotemark
%\end{nexercise}
%\end{exercisewrap}
%\footnotetext{(a) Consider two random samples: one of size 10 and one of size 1000. Individual observations in the small sample are highly influential on the estimate while in larger samples these individual observations would more often average each other out. The larger sample would tend to provide a better estimate. (b) If we think an estimate is better, we probably mean it typically has less error. Based on (a), our intuition suggests that a larger sample size corresponds to a smaller standard deviation.}

When considering how to calculate the standard deviation of a sample mean, there is one problem: there is no obvious way to estimate this from a single sample. However, statistical theory provides a helpful formula for this situation.  

In the sample of 100 runners, the standard deviation of the sample mean is equal to one-tenth of the population standard deviation: $15.93/10 = 1.59$. In other words, the standard deviation of the sample mean based on 100 observations is equal to
\begin{eqnarray*}
\sigma_{\bar{x}} = \frac{\sigma_{x}}{\sqrt{n}} = \frac{15.93}{\sqrt{100}} = 1.59
\end{eqnarray*}
where $\sigma_{x}$ is the standard deviation of the individuals in the population.  This formula is not coincidental, and the standard deviation of the sample mean is generally equal equal to $\frac{\sigma_{x}}{\sqrt{n}}$. 




\begin{onebox}{Mean and standard deviation of a sample mean}
The mean and standard deviation of the sampling distribution of a sample mean describe the center and spread of the distribution of sample means $\bar{x}$ for all random samples of size $n$ from a population of size $N$.  Let $\mu$ represent the population mean.  We find the mean and standard deviation of the sampling distribution of $\bar{x}$ as follows:  \vspace{-1mm}
\begin{align*}
\mu_{\bar{x}} &= \mu \\
 \sigma_{\bar{x}} &= \frac{\sigma}{\sqrt{n}} \quad \text{ when } n<0.10(N) \text{ if sampling without replacement}
\end{align*}
\end{onebox}

\begin{examplewrap}
\begin{nexample}{We calculated the mean and standard deviation of the samping distribution of mean run time with $n=100$ runners to be 94.52 minutes and 1.59 minutes, respectively.  Interpret these quantities.}The mean run time among all random samples of size $n=100$ runners is 94.52 minutes.  Among all random samples of $n=100$ runners, the sample mean would typically vary from the population mean of 94.52 minutes by about 1.59 minutes.  
\end{nexample}
\end{examplewrap}

\begin{exercisewrap}
\begin{nexercise}
The average of the runners' ages is 35.05 years with a standard deviation of $\sigma = 8.97$. A simple random sample of 100 runners is taken. (a)~What is the standard deviation of the sample mean? (b)~Would you be surprised to get a sample of size 100 with an average of 36~years?\footnotemark\end{nexercise}
\end{exercisewrap}
\footnotetext{(a) Assuming the sample size of 100 is less than 10\% of the population size, that is that the number of total runners is greater than 1000, we apply the formula for the standard deviation of the sample mean as follows: $\sigma_{\bar{y}} = 8.97/\sqrt{100} = 0.90$ years. (b) It would not be surprising. 36 years is about 1 standard deviation from the true mean of 35.05. Based on the 68, 95 rule, we would get a sample mean at least this far away from the true mean approximately $100\% - 68\% = 32\%$ of the time.}

%library(openintro); library(xtable); data(run10); data(run10samp); mean(run10samp$age); sd(run10samp$age); sd(run10$age, na.rm=TRUE)

\begin{exercisewrap}
\begin{nexercise}
(a) Would you be more trusting of a sample that has 100 observations or 400 observations? (b) We want to show mathematically that our estimate tends to be better when the sample size is larger. If the standard deviation of the individual observations is 10, what is our estimate of the standard deviation of the mean when the sample size is 100? What about when it is 400? (c) Explain how your answer to (b) mathematically justifies your intuition in part~(a).\footnotemark
\end{nexercise}
\end{exercisewrap}
\footnotetext{(a) Extra observations are usually helpful in understanding the population, so a point estimate with 400 observations seems more trustworthy. (b) The standard deviation of the mean when the sample size is 100 is given by $10/\sqrt{100} = 1$. For 400:  $10/\sqrt{400} = 0.5$. The larger sample has a smaller standard deviation of the mean. (c) The standard deviation of the mean of the sample with 400 observations is lower than that of the sample with 100 observations. The standard deviation of $\bar{x}$ describes the typical error, and because it is lower for the larger sample, this mathematically shows the estimate from the larger sample tends to be better -- though it does not guarantee that every large sample will provide a better estimate than a particular small sample.}


\D{\newpage}

%%
\subsection{The Central Limit Theorem revisited}
\label{cltSection}

\index{Central Limit Theorem|(}

In Figure~\ref{netTime1000SamplingDistribution}, the sampling distribution of the sample mean looks approximately normally distributed. Will the sampling distribution of a mean always be nearly normal? To address this question, we will investigate three cases to see roughly when the approximation is reasonable.

We consider three data sets: one from a \emph{uniform} distribution, one from an \emph{right skewed} distribution, and the other from a \emph{normal} distribution. These distributions are shown in the top panels of Figure~\ref{cltSimulations}. 


The left panel in the $n=2$ row represents the sampling distribution of $\bar{x}$ if it is the sample mean of two observations from the uniform distribution shown. The dashed line represents the closest approximation of the normal distribution. Similarly, the center and right panels of the $n=2$ row represent the respective distributions of $\bar{x}$ for data from right skewed and normal distributions.


\begin{examplewrap}
\begin{nexample}
{Examine the distributions in each row of Figure~\ref{cltSimulations}. What do you notice about the sampling distribution of the mean as the sample size, $n$, becomes larger?}
The normal model becomes better as larger samples are used. However, in the case when the population distribution is normally distributed, the distribution of the sample mean is normal for all sample sizes.
\end{nexample}
\end{examplewrap}

\begin{exercisewrap}
\begin{nexercise}For the distributions in Figure~\ref{cltSimulations}, would a normal model for a sample mean be appropriate when the sample size is at least 30?\footnotemark
\end{nexercise}
\end{exercisewrap}
\footnotetext{Yes, the sampling distributions when $n = 30$ all look very much like a normal distribution.}

\begin{onebox}{Determining if the sample mean is normally distributed}
If the population distribution is normal, the sampling distribution of $\bar{x}$ will be normal for any sample size. \\[2mm]
The less normal the population, the larger $n$ needs to be for the sampling distribution of $\bar{x}$ to be nearly normal. A good rule of thumb is that for most populations, the sampling distribution of $\bar{x}$ will be approximately normal if $n \ge 30$.\end{onebox}

This brings us back to the \term{Central Limit Theorem}, introduced in Section~\ref{clt}.  The Central Limit Theorem (CLT) is a fundamental theorem of Statistics because it allows us to understand the shape of certain sampling distributions, no matter the shape of the population from which the sample is drawn.  This in turn allows us to easily find probabilities and, as we saw in Chapter~\ref{ch_inference_for_props}, calculate p-values that we otherwise would not be able to.


\begin{onebox}{Central Limit Theorem (CLT)}
For any population with a fixed mean and standard deviation, the shape of the sampling distribution of the mean of a random sample becomes more normal as the sample size $n$ gets larger.
\end{onebox}

\begin{figure}
   \centering
\Figure [At the top are shown three population distribution graphs.  The first is uniform, the second right skewed, and the third is normal.  Below these three population distributions are sampling distributions for a mean, for samples of size n = 2, n = 5, n = 12, and n = 30.  All the sampling distributions have the same center, but as n, the sample size, increases, the sampling distributions become narrower.  The sampling distributions from the normal population are all normal.  The sampling distributions from the uniform distribution are not normal for n = 2, but appear approximately normal for n = 5 and greater.  The sampling distributions from the right skewed population do not appear approximately normal until n = 30.] {}{cltSimulations}
   \caption{Sampling distributions for the mean at different sample sizes and for three different distributions. The dashed red lines show normal distributions.  Note the change in scale of the horizontal axis for larger values of $n$.}
   \label{cltSimulations}
\end{figure}

\D{\newpage}


%%
\subsection[Using a normal model for the sampling distribution of $\bar{x}$]{Using a normal model for the sampling distribution of \pmb{$\bar{x}$}}

We have already encountered a normal model for data and for sample proportions.  When appropriate conditions are met, we can also use a normal approximation to estimate probabilities involving the distribution of a sample average. We must remember to verify that the conditions are met and use the mean $\mu_{\bar{x}}$ and standard deviation $\sigma_{\bar{x}}$ for the sampling distribution of the sample average.

\begin{onebox}{Three important facts about the distribution of a sample mean \pmb{\MakeLowercase{$\bar{x}$}}}
When the observations can be considered independent, such as from a random sample of size $n$ from a population of size $N$, the distribution of the sample mean can be described as follows.\begin{enumerate}
\setlength{\itemsep}{0mm}
\item The mean of a sample mean is denoted by $\mu_{\bar{x}}$, and it is equal to $\mu$.
\item The SD of a sample mean is denoted by $\sigma_{\bar{x}}$, and it is equal to $\frac{\sigma}{\sqrt{n}}$, when $n<0.10(N)$.
\item When the population distribution is nearly normal or when $n\ge 30$, the sample mean closely follows a normal distribution. 
\end{enumerate}\end{onebox}

Before we apply a normal model to a sample mean, we review the use of normal approximation in the context of a population distribution.

\begin{examplewrap}
\begin{nexample}{
In the 2017 Cherry Blossom 10 mile run, the average time for all of the runners is 94.52 minutes with a standard deviation of 8.97 minutes. The distribution of run times is approximately normal. Find the probability that a randomly selected runner completed the run in less than 90 minutes.}
$X$: time of randomly selected runner (in minutes)\\ \\
The problem tells us that X has an approximately normal distribution with mean 94.52 and standard deviation 8.97.  We will use a technology option from Section~\ref{technormal} to find the relevant area under a normal distribution.  \\

We can either use $X$ is Normal($\mu$ = 94.52, $\sigma$ = 8.97) to find that $P(X < 90) = 0.307$,
or we can use the standard normal distribution, Normal($\mu$ = 0, $\sigma$ = 1), and find:
\begin{align*}
&Z = \frac{x - \mu}{\sigma}=\frac{90-94.52}{8.97}=-0.504 \\
&P(Z < -0.504) = 0.307
\end{align*}
\begin{center}
  \Figures[A normal distribution with a mean of 94.52 and standard deviation of 2.01 has the area below the distribution shaded for horizontal values smaller than 90.]
{0.4}{cherryBlossom}{cherry1}\hspace{5mm}
  \Figures[A normal distribution with a mean of 0 and standard deviation of 1 has the area below the distribution shaded for horizontal values smaller than -0.504.]
{0.4}{cherryBlossom}{cherry1Z}
\end{center}

There is about a 30.7\% probability that a randomly selected runner will completed the run in less than 90~minutes.
\label{cherry1}
\end{nexample}
\end{examplewrap}

\begin{examplewrap}
\begin{nexample}{
Using the information from Example~\ref{cherry1}, find the probabiliy that the average of 20 runners' times is less than 90~minutes.}
Here we are interested in an \emph{average}, so we use the sampling distribution of the sample average.  \\ \\
$\bar{x}$: sample mean of 20 randomly selected runners (in minutes)\\ \\
$\mu_{\bar{x}}=\mu=94.52$\\ \\
The sample size 20 is less than 10\% of all runners so we can calculate the standard deviation as follows:
$\sigma_{\bar{x}}=\frac{\sigma}{\sqrt{n}}=\frac{8.97}{\sqrt{20}}=2.01$. \\ \\
The population distribution of run time is approximately normal, so we can use a normal model for $\bar{x}$.  Given $\bar{x}$ is approximately Normal($\mu$ = 94.52, $\sigma$ = 2.01), we find that $P(\bar{x} < 90) = 0.012$.\\ \\
Alternately, we could use the standard normal distribution, Normal($\mu=0$, $\sigma=1$), and find:
\begin{align*}
&Z = \frac{\bar{x} - \mu_{\bar{x}}}{\sigma_{\bar{x}}}=\frac{90 - 94.52}{\frac{8.97}{\sqrt{20}}}=-2.25\\
&P(Z < -2.25) = 0.0123
\end{align*}
\begin{center}
  \Figures[A normal distribution with a mean of 94.52 and standard deviation of 2.01 has the area below the distribution shaded for horizontal values smaller than 90.]
{0.4}{cherryBlossom}{cherry20}\hspace{5mm}
  \Figures[A normal distribution with a mean of 0 and standard deviation of 1 has the area below the distribution shaded for horizontal values smaller than -2.25.]
{0.4}{cherryBlossom}{cherry20Z}
\end{center}
There is a 1.2\% probability that the average run time of 20 randomly selected runners will be less than 90~minutes.
\label{cherry20}
\end{nexample}
\end{examplewrap}

In Section~\ref{oneSampleTTests}, Hypothesis testing for a population mean, we will see parallels between the calculation of the Z-score shown above and the calculation of the test statistic.

\begin{exercisewrap}
\begin{nexercise}
Intuitively, why does it make sense that the probability found in Example~\ref{cherry20} is smaller than the probability found in Example~\ref{cherry1}?\footnotemark
\end{nexercise}
\end{exercisewrap}
\footnotetext{When we average over 20 values, we expect less variability than when looking at individual values.  Thus, if we are trying to estimate a population mean, our estimate will be more likely to be close to the true mean using a sample size of 20 than using a sample size of 1.  Equivalently, our estimate will be \emph{less} likely to be far from the true value using a sample size of 20 than using a sample size of 1.} 


\begin{onebox}{Remember to divide by $\pmb{\sqrt{\MakeLowercase{n}}}$}
When finding the probability that an \emph{average} or mean is greater or less than a particular value, remember to divide the standard deviation of the population by $\sqrt{n}$ to calculate the correct~SD.\end{onebox}

\D{\newpage}

\begin{examplewrap}
\begin{nexample}{
The average of all the runners' ages is 35.05 years with a standard deviation of $\sigma = 8.97$. The distribution of age is somewhat skewed. What is the probability that a randomly selected runner is older than 37 years?}Because the distribution of age is skewed and is not normal, we cannot use normal approximation for this problem. In order to answer this question, we would need to look at all of the data.
\end{nexample}
\end{examplewrap}

\begin{exercisewrap}
\begin{nexercise}
What is the probability that the average of 50 randomly selected runners is greater than 37 years?\footnotemark
\end{nexercise}
\end{exercisewrap}
\footnotetext{Because $n=50\ge 30$, the sampling distribution of the sample mean is approximately normal, so we can use the normal approximation for $\bar{x}$ . The population mean $\mu$ is given as 35.05 years.
\begin{align*}
&\sigma_{\bar{x}}
	= \frac{\sigma}{\sqrt{n}}
	= \frac{8.97}{\sqrt{50}}=1.27
&&Z=\frac{\bar{x}-\mu_{\bar{x}}}{\sigma_{\bar{x}}} = \frac{37-35.05}{1.27}=1.535
&&P(Z > 1.535) = 0.062
\end{align*}
There is a 6.2\% chance that the average age of 50 runners will be greater than 37.} 

The previous examples highlight the power of the Central Limit Theorem for sample means.  Even if the population is not normally distributed, for large enough $n$, the sampling distribution of the \emph{sample mean} will be approximately normally distributed, allowing us to calculate relevant probabilities using a normal model.  When a normal model cannot be used, there may be no straight-forward way to calculate these desired probabilities.

\D{\newpage}

%%
\subsection*{Section summary}

\begin{itemize}
\item The symbol $\bar{x}$ denotes a sample average.  $\bar{x}$ for any particular sample is a number.  However, $\bar{x}$ can vary from sample to sample.   The \term{sampling distribution} of a sample mean $\bar{x}$ is the distribution of values of $\bar{x}$ for all random samples of size $n$ from a given population.  

\item When the observations can be considered independent, such as from a \emph{random} sample:
\begin{itemize}
\item The \textbf{mean} of the sampling distribution of a sample mean $\bar{x}$ is given by: \\
 $\mu_{\bar{x}} = \mu$, where $\mu$ is the population mean.

\item The \textbf{standard deviation} of the sampling distribution of a
sample mean $\bar{x}$ is given by: \\
$\sigma_{\bar{x}} = \frac{\sigma}{\sqrt{n}}$, where $\sigma$ is the population standard deviation.  When sampling without replacement, the sample size $n$ should be less than 10\% of the population size $N$, i.e. $n < 0.10(N)$, in order for this standard deviation formula to be used.

\item The \textbf{shape} of the sampling distribution of a sample mean $\bar{x}$ is approximately normal if the population distribution can be modeled by a normal distribution (regardless of the sample size) or the sample size $n \ge 30$.  
\end{itemize}


\item Consider taking a random sample from a population with a fixed mean and standard deviation.  The \term{Central Limit Theorem} ensures that regardless of the shape of the original population, as the sample size increases, the distribution of the sample average $\bar{x}$ becomes more normal.  

\item $\mu_{\bar{x}}$, the mean of $\bar{x}$, describes the average of the sample means among all random samples of size $n$ from a given population.  

\item $\sigma_{\bar{x}}$, the standard deviation of $\bar{x}$, measures how far the sample means typically vary from the population mean $\mu$ for all random samples of size $n$ from a given population.  

\item The standard deviation of $\bar{x}$ will be \textit{smaller} than the standard deviation of the population by a factor of $\sqrt{n}$.  The larger the sample size, the better the estimate $\bar{x}$ tends to be for $\mu$.

\item To use a normal model to find probabilities involving a sample mean, first verify that the conditions for independence are met and that the sample size is at least 30 or the population distribution is approximately normal. Identify the distribution and its parameters, write the relevant probability statement, and answer the question in context.

\item The mean, standard deviation, and probabilities for a sampling distribution of a
sample mean should be interpreted within the context of a specific population






\end{itemize}

%%%%%%%%%%Section exercises
{\input{ch_inference_for_means/TeX/sampling_distribution_of_a_sample_mean.tex}}


%_________________________________
\section[Confidence intervals for a population mean]{Confidence intervals for a population mean}
\label{oneSampleMeansCI}%


\sectionintro{
\noindent%
How can we use sample data to estimate an unknown population mean, such as the true average mercury content in a particular type of dolphin?  How can we calculate the margin of error for a given confidence level?  While the concepts and the framework are the same as for estimating unknown population proportions, to estimate means we must investigate and use a new family of distributions, called $t$-distributions.  

%%
\subsection*{Learning objectives}
\begin{enumerate}
\setlength{\itemsep}{0mm}
\item Describe $t$-distributions.  

\item Identify and set up an appropriate confidence interval procedure for a population mean $\mu$ or mean difference $\mu_d$.

\item Justify the appropriateness
of constructing a confidence
interval for a population
mean or population mean
difference by verifying
conditions. 

\item Calculate the degrees of freedom and an appropriate confidence interval for a population mean or mean differences.

\item Calculate the standard error and margin of error for a sample size for a one-sample $t$-interval.

\item Interpret a confidence interval for a population mean or mean differences in context.

\item Justify a claim about a population mean or mean difference based on an appropriate confidence interval.
\item Identify the relationships
among sample size,
confidence interval width,
confidence level, and margin
of error for a population mean
or population mean difference.

\end{enumerate}
}

%subsection[Nearly normal population with known SD]{Nearly normal population with known SD}
%%
%%
\subsection[Using a normal distribution for inference when $\sigma$ is known]{Using a normal distribution for inference when \pmb{$\sigma$} is known}
\label{nearlyNormalPopWithKnownSD}

In Section~\ref{distributionofxbar} we saw that the distribution of a sample mean is normal if the population distribution is normal or if the sample size is at least 30. In these problems, we used the population mean and population standard deviation to find a Z-score. However, in the case of inference, these values will be unknown. In rare circumstances we may know the standard deviation of a population, even though we do not know its mean. For example, in some industrial processes, the mean may be known to shift over time, while the standard deviation of the process remains the same. In these cases, we can use the normal model as the basis for our inference procedures. We use $\bar{x}$ as our point estimate for $\mu$ and the $SD$ formula for a sample mean calculated in Section~\ref{distributionofxbar}: $\sigma_{\bar{x}} =\frac{\sigma}{\sqrt{n}}$.  That leads to a confidence interval and a test statistic as follows:
\begin{align*}
\text{CI:  } \bar{x} &\ \pm \ z^{\star}\frac{\sigma}{\sqrt{n}}
&&Z = \frac{\bar{x} - \text{null value}}{\frac{\sigma}{\sqrt{n}}}
\end{align*}

How do we evaluate $\sigma_{\bar{x}}$ if we do not know the population standard deviation $\sigma$, as is usually the case?  The best we can do is use the sample standard deviation, denoted by $s$, to estimate $\sigma$.  This gives us an estimate of $\sigma_{\bar{x}}$ which we call the Standard Error (SE) of $\bar{x}$.
\begin{align*}
SE_{\bar{x}}= \frac{s}{\sqrt{n}}
\end{align*}
However, when we do this we run into a problem:  when carrying out our inference procedures, we will be trying to estimate \emph{two} quantities: both the mean and the standard deviation. Looking at the $SD$ and $SE$ formulas, we can make some important observations that will give us a hint as to what will happen when we use $s$ instead of $\sigma$.
\begin{itemize}
\setlength{\itemsep}{0mm}
\item For a given population, $\sigma$ is a fixed number and does not vary.
\item $s$, the standard deviation of a sample, will vary from one sample to the next and will not be exactly equal to $\sigma$.
\item The larger the sample size $n$, the better the estimate $s$ will tend to be for $\sigma$.
\end{itemize}

For this reason, the normal model may work reasonably well when the sample size is large. For smaller sample sizes, we run into a problem: our use of $s$, which is used when computing the standard error, tends to add more variability to our test statistic. It is this extra variability that leads us to a new distribution: the \mbox{$t$-distribution}.


%%
%%
\subsection[Introducing the $t$-distribution]{Introducing the \pmb{$t$}-distribution}
\label{introducingTheTDistribution}

\index{t-distribution@$t$-distribution|(}

When we use the sample standard deviation $s$ in place of the population standard deviation $\sigma$ to standardize the sample mean, we get a new distribution - one that is similar to the normal distribution, but has greater spread. This distribution is known as the $t$-distribution. A $t$-distribution, shown as a solid line in Figure~\ref{tDistCompareToNormalDist}, has a bell shape. However, its tails are thicker than the normal model's. We can see that a greater proportion of the area under the $t$-distribution is beyond 2 standard units from 0 than under the normal distribution.  These extra thick tails account for the extra variation introduced when we estimate $\sigma$ with the sample standard deviation $s$.  

\begin{figure}[h]
\centering
  \Figure[A standard normal distribution and a t-distribution are shown. The t-distribution also has a bell-shape, but it is more sharply peaked than the normal distribution and also has thicker tails than the normal distribution. For example, the is a sizable fraction of the distribution -- perhaps 5\% for this particular t-distribution -- that extends below -3 and above positive 3, while the normal distribution is very close to zero when looking below -3 or above positive 3.]
{0.55}{tDistCompareToNormalDist}
\caption{Comparison of a $t$-distribution (solid line) and a normal distribution (dotted line).}
\label{tDistCompareToNormalDist}
\end{figure}

The $t$-distribution, always centered at zero, has a single parameter: degrees of freedom. The \termsub{degrees of freedom (df)}{degrees of freedom (df)!$t$-distribution} describes the precise form of the bell-shaped $t$-distribution. Several $t$-distributions are shown in Figure~\ref{tDistConvergeToNormalDist}. When there are more degrees of freedom, the $t$-distribution looks more like the standard normal distribution.

\begin{figure}[h]
\centering
 \Figure[Four t-distributions with degrees of freedom of 1, 2, 4, and 8 are shown along with a normal distribution on the same plot. The larger the degrees of freedom, the more closely the t-distribution aligns with the normal distribution, meaning that the shape of the peak becomes less sharp and the less "thick" the distributions tails appear.]
{0.72}{tDistConvergeToNormalDist}
\caption{The larger the degrees of freedom, the more closely the $t$-distribution resembles the standard normal distribution.}
\label{tDistConvergeToNormalDist}
\end{figure}

\begin{onebox}{Degrees of freedom}
$t$-distributions are identified using a
parameter known as the degrees of freedom ($df$), which is based on
the sample size(s).  When the degrees of freedom are small, the $t$-distribution
has a much narrower peak and fatter tails than a normal distribution. The larger the degrees of freedom, the more closely the $t$-distribution resembles the standard normal~distribution.\end{onebox}


%\begin{onebox}{Degrees of freedom}
%The degrees of freedom describes the shape of the $t$-distribution. The larger the degrees of freedom, the more closely the distribution resembles the standard normal~distribution.\end{onebox}

When the degrees of freedom is large, about 30 or more, the $t$-distribution is nearly indistinguishable from the normal distribution. In Section~\ref{tDistSolutionToSEProblem}, we will see how degrees of freedom relates to sample size.

We will find it useful to become familiar with the $t$-distribution, because it plays a very similar role to the normal distribution during inference.  We use a \termsub{$\pmb{t}$-table}
    {t-table@$t$-table}, partially shown in Figure~\ref{tTableSample_ch_inf_means}, in place of the normal probability table when the population standard deviation is unknown, especially when the sample size is small. A~larger table is presented in Appendix~\ref{tDistributionTable}.

\begin{figure}[hht]
\centering
\begin{tabular}{r | rrr rr}
one tail & \hspace{1.5mm}  0.100 & \hspace{1.5mm} 0.050 & \hspace{1.5mm} 0.025 & \hspace{1.5mm} 0.010 & \hspace{1.5mm} 0.005  \\
\hline
{$df$} \hfill 1  &  {\normalsize  3.078} & {\normalsize  6.314} & {\normalsize 12.71} & {\normalsize 31.82} & {\normalsize 63.66}  \\
2  &  {\normalsize  1.886} & {\normalsize  2.920} & {\normalsize  4.303} & {\normalsize  6.965} & {\normalsize  9.925}  \\
3  &  {\normalsize  1.638} & {\normalsize  2.353} & {\normalsize  3.182} & {\normalsize  4.541} & {\normalsize  5.841}  \\
$\vdots$ & $\vdots$ &$\vdots$ &$\vdots$ &$\vdots$ & \\
17  &  {\normalsize  1.333} & {\normalsize  1.740} & {\normalsize  2.110} & {\normalsize  2.567} & {\normalsize  2.898}  \\
\highlightO{18}  &  \highlightO{\normalsize  1.330} & \highlightO{\normalsize  1.734} & \highlightO{\normalsize  2.101} & \highlightO{\normalsize  2.552} & \highlightO{\normalsize  2.878}  \\
19  &  {\normalsize  1.328} & {\normalsize  1.729} & {\normalsize  2.093} & {\normalsize  2.539} & {\normalsize  2.861}  \\
20  &  {\normalsize  1.325} & {\normalsize  1.725} & {\normalsize  2.086} & {\normalsize  2.528} & {\normalsize  2.845}  \\
$\vdots$ & $\vdots$ &$\vdots$ &$\vdots$ &$\vdots$ & \\
1000  &  {\normalsize  1.282} & {\normalsize  1.646} & {\normalsize  1.962} & {\normalsize  2.330} & {\normalsize  2.581}  \\
$\infty$   &  {\normalsize  1.282} & {\normalsize  1.645} & {\normalsize  1.960} & {\normalsize  2.326} & {\normalsize  2.576}   \\
\hline
Confidence level C  &  {\normalsize  80\%} & {\normalsize 90\%} & {\normalsize 95\%} & {\normalsize  98\%} & {\normalsize  99\%}  \\
\hline
\end{tabular}
\caption{An abbreviated look at the $t$-table. Each row represents a different $t$-distribution. The columns describe the cutoffs for specific tail areas. The row with $df=18$ has been \highlightO{highlighted}.}
\label{tTableSample_ch_inf_means}
\end{figure}

Each row in the $t$-table represents a $t$-distribution with different degrees of freedom. The columns correspond to tail probabilities. For instance, if we know we are working with the $t$-distribution with $df=18$, we can examine row 18, which is \highlightO{highlighted} in Figure~\ref{tTableSample_ch_inf_means}. If we want the value in this row that identifies the cutoff for an upper tail of 10\%, we can look in the column where \emph{one tail} is 0.100. This cutoff is 1.330. If we had wanted the cutoff for the lower 10\%, we would use -1.330. Just like the normal distribution, all $t$-distributions are symmetric.


%
%\begin{examplewrap}
%\begin{nexample}{For the $t$-distribution with 18 degrees of freedom, what percent of area of this distribution is below $-$2.552?  Use the partial $t$-table shown in Figure~\ref{tTableSample_ch_inf_means}.}
%Using row $df = 18$, we find 2.552 in the table. The area in each tail is 0.100, therefore, 10\% is to the left of $-$2.552.  
%\end{nexample}
%\end{examplewrap}

\begin{examplewrap}
\begin{nexample}{For the $t$-distribution with 18 degrees of freedom as shown in Figure~\ref{tDistDF18}, what percent of the distribution is contained between -1.734 and +1.734?  Use the partial $t$-table shown in Figure~\ref{tTableSample_ch_inf_means}.}
Using row $df = 18$, we find 1.734 in the table. The area in each tail is 0.050 for a total of 0.100, which leaves 0.900 in the middle between -1.734 and +1.734. This corresponds to 90\%, which can be found at the very bottom of that  column.  
\end{nexample}
\end{examplewrap}

\begin{figure}
\centering
  \Figures[A t-distribution with 18 degrees of freedom is shown, where the area between $-$1.734 and 1.734 has been shaded.]
{0.4}{tDistDF18}{tDistDF18Middle}
\caption{The $t$-distribution with 18 degrees of freedom. The area between $-$1.734 and 1.734 is shaded.}
\label{tDistDF18}
\end{figure}

\newpage
\begin{examplewrap}
\begin{nexample}{For the $t$-distribution with 3 degrees of freedom, as shown in the left panel of Figure~\ref{tDistDF3}, what proportion of the distribution falls above 2.353?}
To find this area, we identify the appropriate row: $df=3$. Then we identify the column containing the absolute value of 2.353; it is the third column. Because we are looking for just one tail, we examine the top line of the table, which shows that a one tail area for a value in the third row corresponds to 0.05. That is, 5\% of the distribution falls above 2.353.
\end{nexample}
\end{examplewrap}

\begin{examplewrap}
\begin{nexample}{For the $t$-distribution with 3 degrees of freedom, as shown in the right panel of Figure~\ref{tDistDF3}, what should the value of $t^{\star}$ be so that 95\% of the area of the distribution falls between -$t^{\star}$ and +$t^{\star}$?}
We can look at the column in the $t$-table that says 95\% along the bottom row and trace it up to row $df = 3$ to find that $t^{\star} = 3.182$.
\end{nexample}
\end{examplewrap}


\begin{figure}
\centering
 \Figure[Two t-distributions with 3 degrees of freedom are shown. In the first plot, the area to the right of 2.353 is shaded.  In the second, the middle 95\% of the area is shaded.]
{0.83}{tDistDF3}
\caption{The $t$-distribution with 3 degrees of freedom is shown twice.  Left: the area above 2.353 is shaded.  Right: the middle 95\% of the area is shaded. }
\label{tDistDF3}
\end{figure}

\begin{exercisewrap}
\begin{nexercise}Without doing any calculations, will the area to the right of $Z=3$ under the standard normal distribution be greater than, less than, or equal to the area to the right of $t=3$ under the $t$-distribution with 35 degrees of freedom?\footnotemark
\end{nexercise}
\end{exercisewrap} 
\footnotetext{Because the $t$-distribution has greater spread and thicker tails than the normal distribution, we would expect the upper tail area to the right of $Z=3$ under the standard normal distribution to be less than the upper tail area to the right of $t=3$ under the $t$ distribution with 35 degrees of freedom.  One can confirm that the area to the right of $Z = 3$ is 0.0013, which is less than 0.0025.  With a smaller degrees of freedom, this difference would be even more pronounced.  Try it!}


When the desired degrees of freedom is not listed on the table, choose a conservative value: round the degrees of freedom down, i.e. move \emph{up} to the previous row listed. Another option is to use technology to get a more precise answer.  See Section~\ref{techtdist} for finding areas and boundary values for $t$-distributions using technology.


\D{\newpage}

%%
\subsection[Technology: $t$-distribution probabilities and boundary values]{Technology: \pmb{$t$}-distribution probabilities and boundary values}
\label{techtdist}

\noindent Given a $t$-distribution with 3 degrees of freedom:
\begin{itemize}
\item[(i)] Find the area to the right of $t=1$.
\item[(ii)] Find the boundary value $t^{\star}$ such that 95\% of the area is between $-t^{\star}$ and $t^{\star}$.
\end{itemize}
 
\noindent \\
\textbf{Desmos}:  Use the \texttt{tdist(df)} function, replacing \texttt{df} with the degrees of freedom.
\begin{enumerate}
\setlength{\itemsep}{0mm}
\item Type \calctext{tdist(3)}.
\item Click the triangle next to \calctext{Cumulative Probability}.
\item Choose \calctext{Inner}, \calctext{Outer}, \calctext{Left} or \calctext{Right} as illustrated below.
\begin{itemize}
\item[(i)] To find a probability/area, choose \calctext{Area} and enter the boundary value(s).
\item[(ii)] To find a boundary value, choose \calctext{Bounds} and enter the desired proportion to the right of the $=$ sign.  
\end{itemize}
\item Click the magnifying glass to Zoom Fit the graphing window.
\end{enumerate}

\noindent (i) Finding probabilities/areas.
\begin{center}
\fbox{\Figures[add description ]
{0.95}{technologyInferenceMeans}{desmosTRight}}
\end{center}
\noindent \\
(ii) Finding boundary value(s).
\begin{center}
\fbox{\Figures[add description ]
{0.95}{technologyInferenceMeans}{desmosTCenter}}
\end{center}



%%
\noindent \\
\R{}:  Probabilities and boundary values for a $t$-distribution with a given $df$.\\

\noindent (i) \texttt{ pt(q, df)} gives the area to the left of \texttt{q}, so we add \texttt{lower.tail = FALSE} to get the area to the right.\\
\noindent \texttt{> \calctext{pt(1, df = 3, lower.tail = FALSE)}}\\
\texttt{[1] 0.1955011}\\ \\

\noindent (ii) \texttt{ qt(p, df)} gives the $t^{\star}$ value that has the probability \texttt{p} to the \emph{left} of it, unless specified otherwise. To have 95\% in the middle implies that there is  2.5\% in the upper (and lower) tail.\\
\noindent \texttt{> \calctext{qt(0.025, df = 3, lower.tail = FALSE)}}\\
\texttt{[1] 3.182446}\

\newpage

%%
\noindent \textbf{Calculator}:  NumWorks calculator instructions and example output are included.  For the TI-83/84 and Casio calculators, general instructions are provided, and worked example videos can be accessed via the \includegraphics[height=3mm]{extraTeX/icons/video_camera.png} icon or at \oiRedirect{ti84_playlist}{\textbf{openintro.org/ti}} and \oiRedirect{casio-9750-playlist}{\textbf{openintro.org/casio}}.
\\


\begin{onebox}{NumWorks: Area and boundary values for the T-distribution}
\label{normalnumworks}
Use \calctext{OK} or \calctext{EXE} to make a selection.
\begin{enumerate}
\setlength{\itemsep}{0mm}
\item From the home screen, select \calcbutton{Distributions}, arrow down and choose \calctext{Student's t}.  If a list of distributions does not appear, click the \calcbutton{$\lhookleftarrow$} button in the upper right as many times as needed.
\item Enter the \calctext{Degrees of freedom}.  Hit the down arrow and choose \calcbutton{Next}. 
\item Hit the left arrow to highlight the graph.  Hit the down arrow to choose whether you want left, inner, or right, then hit \calcbutton{OK}.  Hit the right arrow to enter desired values.  
\begin{itemize}
\item[(i)] For a probability, enter the boundary value(s), then hit \calcbutton{EXE}.  
\item[(ii)] For a boundary value, enter the desired area as a decimal to the right of the $=$ sign, then hit \calcbutton{EXE}.
\end{itemize}
\begin{center}
\Figures[ ]
{0.35}{technologyInferenceMeans}{numworksTRight}\hspace{10mm}
\Figures[]
{0.35}{technologyInferenceMeans}{numworksTCenter}
\end{center}
\vspace{-1.5mm}
\end{enumerate}
\end{onebox}

%%
\begin{onebox}{TI-84: Finding area under the T-distribution}
Use \calcbutton{2ND} \calcbutton{VARS}, \calctext{tcdf} to find an area/proportion/probability between two $t$-scores or to the left or right of a $t$-score.\vspace{-1mm}
\begin{enumerate}
\setlength{\itemsep}{0mm}
\item Choose \calcbutton{2ND} \calcbutton{VARS} (i.e. \calctext{DISTR}).
\item Choose \calctext{6:tcdf}.
\item Enter the \calctext{lower} (left) $t$-score and the \calctext{upper} (right) $t$-score.
\vspace{-1.5mm}
  \begin{itemize}
  \setlength{\itemsep}{0mm}
  \item If finding just a lower tail area, set \calctext{lower} to \calctext{-$\infty$} ($-$1E99).
  \item If finding just an upper tail area, set \calctext{upper} to \calctext{$\infty$} ($-$1E99).
\end{itemize}
\item Enter the degrees of freedom after \calctext{df:}.
\item Down arrow, choose \calctext{Paste}, and hit \calcbutton{ENTER}.\vspace{-1.5mm}
\end{enumerate}
TI-83: Do steps 1-2, then enter lower bound, upper bound, and df separated by commas as follows:  \calctext{tcdf(lower, upper, df)}.  Then hit \calcbutton{ENTER}.\end{onebox}
 

\index{t-distribution@$t$-distribution|)}


\D{\newpage}

%%
\subsection[Checking conditions for inference on a mean using the $t$-distribution]{Checking conditions for inference on a mean using the \pmb{$t$}-distribution}
\label{tDistSolutionToSEProblem}

Using the $t$-distribution for inference on a mean requires that the theoretical \textbf{sampling distribution of the sample mean $\bar{x}$ is nearly normal}.  In practice, we check whether this assumption is reasonable by verifying that certain conditions are met.  


\begin{description}
\setlength{\itemsep}{0mm}
\item[Independence.]
  Observations can be considered independent when the data are
  collected from a \emph{random process}, such as rolling a die,
  or from a \emph{random sample}.
  Without a random sample or process, the standard error formula
  would not apply, and it is unclear to what population the
  inference would apply.
  Recall that when sampling without replacement from a finite
  population, the observations can be considered independent when
  sampling less than 10\% of the population.  
\item[Large sample / normal population.]
  We saw in Section~\ref{distributionofxbar} that in order for
  the sampling distribution of a sample mean to be nearly normal,
  we also need the sample to be drawn from a nearly normal population
  or we need the sample size to be at least 30 ($n\ge 30$).     
\end{description}

What should we do when the sample size is small and we are not sure whether the population distribution is nearly normal?  In this case, a good practice is to check for excessive skew or clear outliers in the data, which would provide evidence that the population distribution from which we sampled is not nearly normal.  If the data do not show obvious skew or outliers and we do not have reason to expect non-normality based on context-relevant knowledge (e.g. salaries are not normally distributed), then the idea of a nearly normal population is generally considered \emph{reasonable}.  

Note that by looking at a small data set, we cannot \emph{prove} that the population distribution is nearly normal.  However, the data can suggest to us whether the population distribution being nearly normal is an unreasonable assumption.  

\begin{onebox}{The normality condition with small samples}
{If the sample is small and there is strong skew or extreme outliers in the data, the population from which the sample was drawn may not be nearly normal. }
\end{onebox}

Ideally, we use a graph of the data to check for strong skew or outliers.  When the full data set is not available, summary statistics can also be used. 

For larger samples, it is less necessary to check for skew in the data.  In general, when the sample size is 30 or more, it is no longer necessary that the population distribution be nearly normal.  When the sample size is large, the Central Limit Theorem tells us that the sampling distribution of the sample mean will be nearly normal regardless of the distribution of the population.


\begin{examplewrap}
\begin{nexample}{Sometimes we do not know what the population distribution looks like. We have to infer it based on the distribution of a single sample. Figure~\ref{pokerProfitsCanApplyNormalToSampMean} shows a histogram of 20 observations. These represent winnings and losses from 20 consecutive days of a professional poker player. Based on this sample data, can the normal approximation be applied to the distribution of the sample mean?}
We should consider each of the required conditions.
\begin{itemize}
\setlength{\itemsep}{0mm}
\item[(1)] These are referred to as \term{time series data}, because the data arrived in a particular sequence. If the player wins on one day, it may influence how she plays the next. To make the assumption of independence we should perform careful checks on such data.
\item[(2)] The sample size is 20, which is smaller than 30.
\item[(3)] There are two outliers in the data, both quite extreme, which suggests the population may not be normal and instead may be very strongly skewed or have distant outliers. Outliers can play an important role and affect the distribution of the sample mean and the estimate of the standard deviation of the sample mean.
\end{itemize}
Since we should be skeptical of the independence of observations and the extreme upper outliers pose a challenge, we should not use the normal model for the sample mean of these 20 observations. If we can obtain a much larger sample, then the concerns about skew and outliers would no longer apply.
\end{nexample}
\end{examplewrap}

\begin{figure}[ht]
   \centering
\Figure [A histogram is shown, labeled ``Poker Winnings and Losses (US$).  The range is from -200 to positive 500 and the distribution is very right skewed.  The vertical axis is labeled Frequency and ranges from 0 to 13. ] {0.55}{pokerProfitsCanApplyNormalToSampMean}
   \caption{Sample distribution of poker winnings. These data include two very clear outliers. These are problematic when considering the normality of the sample mean. For example, outliers are often an indicator of very strong skew.}
   \label{pokerProfitsCanApplyNormalToSampMean}
\end{figure}

\begin{onebox}{Examine data structure when considering independence}
{Some data sets are collected in such a way that they have a natural underlying structure between observations, e.g. when observations occur consecutively. Be especially cautious about independence assumptions regarding such data sets.}
\end{onebox}

\begin{onebox}{Watch out for strong skew and outliers}
{Strong skew in the population is often identified by the presence of clear outliers in the data. If a data set has prominent outliers, then a larger sample size will be needed for the sampling distribution of $\bar{x}$ to be normal. There are no simple guidelines for what sample size is big enough for each situation. However, we can use the rule of thumb that, in general, an $n$ of at least 30 is sufficient for most cases.}
\index{skew!strongly skewed guideline}
\end{onebox}
\index{Central Limit Theorem|)}


%%
\subsection[One-sample $t$-interval for a mean]{One-sample \pmb{$t$}-interval for a mean}
\label{oneSampleTConfidenceIntervals}

\index{t-interval@$t$-interval!for a mean|(}
\index{one-sample $t$-interval|see{$t$-interval for a mean}}

Dolphins are at the top of the oceanic food chain, which causes dangerous substances such as mercury to concentrate in their organs and muscles. This is an important problem for both dolphins and other animals who eat them.
\captionsetup{width=86mm}

\begin{figure}[h]
\centering
\Figures[A Risso's dolphin is shown surfacing in water. The area forward of its face is mostly white, and then its body is gray and white streaked together.]
{0.7}{rissosDolphin}{rissosDolphin.jpg}  \\
\addvspace{2mm}
\begin{minipage}{\textwidth}
   \caption[rissosDolphinPic]{A Risso's dolphin.\vspace{-1mm} \\
   -----------------------------\vspace{-2mm}\\
   {\footnotesize Photo by Mike Baird (\oiRedirect{textbook-bairdphotos_com}{www.bairdphotos.com}). \oiRedirect{textbook-CC_BY_2}{CC~BY~2.0~license}.\vspace{-10mm}}}
   \label{rissosDolphin}
\end{minipage}
\vspace{3mm}
\end{figure}
\captionsetup{width=\mycaptionwidth}

We would like to create a confidence interval to estimate the average mercury content in dolphin muscles.  We will use a sample of 19 Risso's dolphins from the Taiji area in Japan.  The data are summarized in Figure~\ref{summaryStatsOfHgInMuscleOfRissosDolphins}. 

\begin{figure}[h]
\centering
\begin{tabular}{ccc cc}
\hline
$n$ & $\bar{x}$ & $s$ & minimum & maximum \\
19   & 4.4	  & 2.3  & 1.7	       & 9.2 \\
\hline
\end{tabular}
\caption{Summary of mercury content in the muscle of 19 Risso's dolphins from the Taiji area. Measurements are in $\mu$g/wet g (micrograms of mercury per wet gram of muscle).}
\label{summaryStatsOfHgInMuscleOfRissosDolphins}
\end{figure}

Because we are estimating a mean, we would like to construct a $t$-interval, but first we must check whether the conditions for using a $t$-interval are met.  We will start by assuming that the sample of 19 Risso's dolphins constitutes a random sample.  Next, we note that the sample size is small (less than 30), and we do not know whether the distribution of mercury content for all dolphins is nearly normal.  Therefore, we must look at the data.  Since we do not have all of the data to graph, we look at the summary statistics provided in Figure~\ref{summaryStatsOfHgInMuscleOfRissosDolphins}. With such a small sample, these summary statistics do not suggest extreme skew or extreme outliers; all observations are within 2.5 standard deviations of the mean. Based on this evidence, we believe it is reasonable that the population distribution of mercury content in dolphins could be nearly normal.  

\D{\newpage}

With both conditions met, we will construct a 95\% confidence interval.  Recall that a confidence interval has the following form:
\begin{eqnarray*}
\text{point estimate} \ \pm\  \text{critical value}\times SE\text{ of estimate}
\end{eqnarray*}
The point estimate is the sample mean and the $SE$ of the sample mean is given by $s/\sqrt{n}$.  What do we use for the critical value?  Since we are using the $t$-distribution, we use a $t$-table or technology to find the critical value.  We denote the critical value $t^{\star}$.
\begin{itemize}
\setlength{\itemsep}{0mm}
\item For a 95\% confidence interval, we want to find the cutoff $t^{\star}$ such that 95\% of the $t$-distribution is between -$t^{\star}$ and $t^{\star}$.
\item Using the $t$-table on page~\pageref{tTableSample_ch_inf_means}, we look at the row that corresponds to the degrees of freedom and the column that corresponds to the confidence level.
\end{itemize}

\begin{onebox}{Degrees of freedom for a single sample}
If the sample has $n$ observations and we are examining a single mean, then we use the \mbox{$t$-distribution} with $df=n-1$.
\end{onebox}

\begin{examplewrap}
\begin{nexample}
{Calculate a 95\% confidence interval for the average mercury content in dolphin muscles based on this sample. Recall that $n=19$, $\bar{x}=4.4$ $\mu$g/wet g, and $s=2.3$ $\mu$g/wet g.  }
To find the critical value $t^{\star}$ we use the $t$-distribution with $n-1$ degrees of freedom.  The sample size is 19, so $df=19-1=18$ degrees of freedom.  Using the $t$-table with row $df=18$ and column corresponding to a 95\% confidence level, we get $t^{\star}=2.10$.  The point estimate is the sample mean $\bar{x}$ and the standard error of a sample mean is given by $\frac{s}{\sqrt{n}}$.  Now we have all the pieces we need to calculate a 95\% confidence interval for the average mercury content in dolphin muscles.  
\begin{align*}
\text{point estimate} \ &\pm\  \text{critical value} \times SE \ \text{of estimate} \\
\bar{x} \ &\pm\  t^{\star}\times \frac{s}{\sqrt{n}} \qquad df=n-1\\
4.4 \ &\pm\  2.10 \times  \frac{2.3}{\sqrt{19}} \quad df=18 \\
 \ (3.&29 \text{, } 5.51)
\end{align*}

\end{nexample}
\end{examplewrap}

\begin{examplewrap}
\begin{nexample}
{How do we interpret this 95\% confidence interval?  To what population is it applicable?}
A random sample of Risso's dolphins was taken from the Taiji area in Japan.  The mercury content in the muscles of other types of dolphins and from dolphins from other regions may vary.  Therefore, we can only make an inference to Risso's dolphins from this area.  We are 95\% confident that the interval (3.29, 5.51) contains the true average mercury content ($\mu$g/wet gram) in the muscles of Risso's dolphins in the Taiji area of Japan.  We can also say that we are 95\% confident the true average mercury content in the muscles of Risso's dolphins in the Taiji area of Japan is between 3.29 and 5.51 $\mu$g/wet gram. 

\end{nexample}
\end{examplewrap}
\index{data!dolphins and mercury|)}


\begin{examplewrap}
\begin{nexample}
{Someone makes a claim that the mean mercury content in the muscles of Risso's dolphins in the Taiji area of Japan is 6.0 $\mu$g/wet gram.  Based on the calculated confidence interval, do you have evidence against this claim?}
Because 6.0 is not in the interval, we do have evidence, at the 95\% confidence level, against this claim.  Because the entire interval is below 6.0, we have evidence that the true mean mercury content is less than 6.0 $\mu$g/wet gram.
\end{nexample}
\end{examplewrap}

\begin{examplewrap}
\begin{nexample}
{Intepret the confidence level of 95\%}
In repeated random sampling of this size from this population, approximately 95\% of the confidence intervals created will capture the true mean mercury content in the muscles of Risso's dolphins in the Taiji area of Japan.
\end{nexample}
\end{examplewrap}

%%
\subsection{Estimating a mean of differences}
\label{ciMeanOfDifferences}
\index{t-interval@$t$-interval!for a mean of differences|(}
\index{paired $t$-interval|(}
\index{paired $t$-interval|seealso{$t$-interval for a mean of differences}}
\label{oneSampleTConfidenceIntervals}

\label{pairedData}

\index{paired data|(}
\index{data!textbooks|(}



\newcommand{\uclabookN}{68}
\newcommand{\uclabookM}{3.58}
\newcommand{\uclabookSD}{13.42}
\newcommand{\uclabookSE}{1.63}

\index{paired data|(}
\index{data!textbooks|(}

\noindent%
Do course books tend to be cheaper on Amazon or at a college bookstore?  How big is this difference, on average?  We investigate a specific example involving books for UCLA courses and comparing their price on Amazon and at the UCLA Bookstore.  In an earlier edition of this textbook,
we found that Amazon prices were, on average,
lower than those of the UCLA Bookstore for UCLA courses
in 2010.
It's been awhile, and many stores have adapted
to the online market, so we wondered,
how is the UCLA Bookstore doing today?

We sampled 201 UCLA courses.
Of those, \uclabookN{}
required books that could be found on Amazon.
A~portion of the data set from these courses
is shown in Figure~\ref{textbooksDF},
where prices are in U.S. dollars.

\begin{figure}[h]
\centering
\begin{tabular}{r ll ccc}
  \hline
 & subject &
     course\us{}number &
     bookstore &
     amazon &
     price\us{}difference \\ 
  \hline
  1 & American Indian Studies & M10 & 47.97 & 47.45 & 0.52 \\ 
  2 & Anthropology & 2 & 14.26 & 13.55 & 0.71 \\ 
  3 & Arts and Architecture & 10 & 13.50 & 12.53 & 0.97 \\
  $\vdots$ & $\vdots$ & $\vdots$ & $\vdots$ & $\vdots$ & $\vdots$ \\
  67 & Korean & 1 & 24.96 & 23.79 & 1.17 \\ 
  68 & Jewish Studies & M10 & 35.96 & 32.40 & 3.56 \\
  \hline
\end{tabular}
\caption{Five cases of the \data{textbooks} data set.}
\label{textbooksDF}
\end{figure}
% library(openintro); library(xtable); library(dplyr); d <- select(ucla_textbooks_f18, subject, course_num, bookstore_new, amazon_new); d$price_diff <- d$bookstore_new - d$amazon_new; d <- subset(d, !is.na(bookstore_new) & !is.na(amazon_new)); rownames(d) <- NULL; xtable(d[c(1:3, nrow(d) - 1:0),])

Each textbook has two corresponding prices in the data set:
one for the UCLA Bookstore and one for Amazon.
Therefore, each textbook price from the UCLA bookstore
has a natural correspondence with a textbook price from
Amazon.
When two sets of observations have this special
correspondence, they are said to be \term{paired}.

\begin{onebox}{Paired data}
  Two sets of observations are \emph{paired} if each
  observation in one set has a special correspondence
  or connection with exactly one observation in the other
  data set.
\end{onebox}

To analyze paired data, it is often useful to look
at the difference in outcomes of each pair of observations.
In the \data{textbook} data set, we look at the differences
in prices, which is represented as the \data{d} variable.
Here, for each book, the differences are taken as
\begin{eqnarray*}
\text{UCLA Bookstore price} - \text{Amazon price}
\end{eqnarray*}

It is important that we always subtract using
a consistent order;
here Amazon prices are always subtracted from UCLA prices.
A histogram of these differences is shown in
Figure~\ref{diffInTextbookPricesF18}.
Using differences between paired observations
is a common and useful way to analyze paired data.

\begin{figure}
\centering
 \Figures[A histogram is shown for "UCLA bookstore Price minus Amazon Price, in US dollars", where values range from -\$20 to positive \$80. The distribution has a prominent peak at or slightly above \$0, with the wide majority of data lying between \$20 and positive \$20. There are also 4 bins above \$20 that have non-zero heights: bin \$20 to \$30 has a height of 2, bin \$30 to \$40 has a height of 2, bin \$50 to \$60 has a height of 1, and bin \$70 to \$80 has a height of 1.]
{0.73}{textbooksF18}{diffInTextbookPricesF18}
\caption{Histogram of the difference in price for
    each book sampled.
    These data are very strongly skewed.}
\label{diffInTextbookPricesF18}
\end{figure}

\begin{exercisewrap}
\begin{nexercise}
The first difference shown in Figure~\ref{textbooksDF}
is computed as: $47.97 - 47.45 = 0.52$.
What does this difference tell us about the price for this textbook on Amazon versus the UCLA bookstore?\footnotemark
\end{nexercise}
\end{exercisewrap}
\footnotetext{The difference is taken as UCLA Bookstore price $-$ Amazon price.  Because the difference is positive, it tells us that the UCLA Bookstore price was \emph{greater} for this textbook.  In fact, it was $\$0.52$, or 52 cents, more expensive at the UCLA bookstore than on Amazon.  }


\begin{figure}[hh]
\centering
\begin{tabular}{ccccc}
\hline
$n_{_{\text{\emph{d}}}}$	&\hspace{3mm}& $\bar{x}_{_{\text{\emph{d}}}}$	&\hspace{3mm}& $s_{_{\text{\emph{d}}}}$ \vspace{1mm}\\
\uclabookN{}  && \uclabookM{}  && \uclabookSD{} \\
\hline
\end{tabular}
\caption{Summary statistics for the price differences.
    There were 68 books, so there are \uclabookN{}
    differences.}
\label{textbooksSummaryStats}
\end{figure}


Paired data are often analyzed using the $t$-distribution, but before doing so it is important to verify that some conditions are met.

The observations are based on a random sample of books from a much larger population of books (more than 680 books),
so independence is reasonable.
While the distribution of the data is very strongly skewed,
we do have $n = \uclabookN{}$ observations.  This sample size is large enough that we do not have to worry about whether the population distribution for difference in price might be nearly normal or not.
Because the conditions are satisfied,
we can use the $t$-distribution in this setting.


We compute the standard error associated with
$\bar{x}_{\text{\emph{d}}}$ using the standard
deviation of the differences
($s_{_{\text{\emph{d}}}} = \uclabookSD{}$)
and the number of differences
($n_{_{\text{\emph{d}}}} = \uclabookN{}$):
\begin{align*}
SE_{\bar{x}_{\text{\emph{d}}}}
  = \frac{s_{\text{\emph{d}}}}{\sqrt{n_{\text{\emph{d}}}}}
  = \frac{\uclabookSD{}}{\sqrt{\uclabookN{}}} = \uclabookSE{}
\end{align*}

We will construct a 95\% confidence interval for the average price difference between books at the UCLA Bookstore and on Amazon. We must find the critical value, $t^{\star}$. Since $df = 67$ is not on the $t$-table, round the $df$ down to 60 to get a $t^{\star}$ of 2.00 for 95\% confidence, or use a technology option from Section~\ref{techtdist} to get a $t^{\star}$ of 1.996 using 67 degrees of freedom.  Plugging in the $t^{\star}$ value, point estimate, and standard error into the confidence interval formula, we~get:
\begin{align*}
\text{point estimate} \ &\pm\ t^{\star}\times SE\ \text{of estimate}\\
      \uclabookM{} \ &\pm\ 1.996 \times \frac{\uclabookSD{}}{\sqrt{\uclabookN{}}} \quad df=67 \\
      (0.33&,  6.83)
\end{align*}
We are 95\% confident that the interval (0.33, 6.83) contains the true average price difference in UCLA course books (UCLA Bookstore $-$ Amazon), that is, we are 95\% confident that the UCLA bookstore is, on average, between \$0.33 and \$6.83 \emph{more} expensive than Amazon for UCLA course books. Because our interval is entirely above 0, we have evidence that the true average difference is greater than zero, meaning we have evidence that, on average, books are more expensive at the UCLA Bookstore. 

%\begin{examplewrap}
%\begin{nexample}
%{Based on the interval, can we say that 95\% of the books cost between \$0.33 and \$6.83 more at the UCLA Bookstore than on Amazon? }No.  This interval is attempting to estimate the \emph{average} difference with 95\% confidence.  It is not attempting to capture 95\% of the values.  A quick look at Figure~\ref{diffInTextbookPricesF18} shows that the percent of differences that fall between \$0.32 and \$6.84 is much less than 95\%.
%\end{nexample}
%\end{examplewrap}

\newpage
\begin{exercisewrap}
\begin{nexercise}
Based on the interval, should we recommend that UCLA students always buy their books on Amazon?\footnotemark
\end{nexercise}
\end{exercisewrap}
\footnotetext{No, the fact that Amazon, is on average, less expensive does not imply that it is less expensive for \emph{every} book.  Examining the distribution in Figure~\ref{diffInTextbookPricesF18}, we see that there are many cases where the difference (UCLA Bookstore $-$ Amazon) is negative, meaning that these books are \emph{more} expensive on Amazon.}


\subsection[Technology: the one-sample $t$-interval for $\mu$]{Technology:  the one-sample \pmb{$t$}-interval for \pmb{$\mu$}}
\label{1SampTint}

\noindent Section~\ref{tech1T} demonstrates how to calculate the one-sample $t$-interval and the one-sample $t$-test (introduced in the next section) using Desmos, R, and the NumWorks, TI-83/84 and Casio calculator. 

\subsection[Summary and worked examples]{Summary and worked examples}

\begin{onebox}{Constructing a confidence interval for a mean}
To carry out a complete confidence interval procedure to estimate a single population mean,
\\
\\
\inferencestep{Identify} Identify the interval procedure, parameter, and confidence level.\vspace{-1mm}
\begin{itemize}
\item [] Use a \termsub{one-sample \pmb{$t$}-interval for \pmb{$\mu$}}{t-interval@$t$-interval!for a mean}.  Define the  population mean $\mu$ in words, referencing the population of interest.  Choose a confidence level (C\%).
\item[] When there is paired numerical data, use this same procedure to estimate $\mu_{\text{\emph{d}}}$, the mean of the population differences.  In this case, use the mean and standard deviation of the sample differences, $\bar{x}_{\text{\emph{d}}}$ and $s_{\text{\emph{d}}}$, and the number of sample differences, $n_{\text{\emph{d}}}$, when calculating the confidence interval.   
\end{itemize}
\inferencestep{Check} Check conditions for constructing a confidence interval using a $t$-distribution. \vspace{-1mm}
{\setlength{\leftmargini}{13mm}
\begin{itemize}
\setlength{\itemsep}{0mm} 
\item[1.] Independence:  Data come from a random sample or random process.  When sampling 
without replacement, check that sample size is less than 10\% of the population size.
\item[2.] Large sample or normal population:  $n\ge 30$ or the population distribution is nearly normal. If the sample size is less than 30 and the population distribution is unknown, check and confirm that there is no strong skew or outliers in the data in order to reasonably assume that the population distribution is nearly normal.
\end{itemize}
}
\inferencestep{Calculate} Calculate the confidence interval and record it in interval form. 
\begin{itemize}
\item[] $\text{point estimate}\ \pm\ t^{\star} \times SE\ \text{of estimate}$, \quad $df = n - 1$
\begin{itemize}
\item[] point estimate: $\bar{x}$, the sample mean 
\item[] $SE$ of estimate:  $\frac{s}{\sqrt{n}}$
\item[] $t^{\star}$: use technology or a $t$-table at row $df = n-1$ and confidence level C\%
\end{itemize}
\item[] (\underline{\ \ \ \ \ }, \underline{\ \ \ \ \ })
\end{itemize}
\inferencestep{Conclude} Interpret the interval and, if applicable, draw a conclusion in context. \vspace{-1mm}
\begin{itemize}
\item[] We are C\% confident that the interval (\underline{\ \ \ \ \ }, \underline{\ \ \ \ \ }) contains the true \emph{mean} of [...].  A conclusion depends upon whether the interval is entirely above, is entirely below, or contains the value of interest. 
\end{itemize}\end{onebox}



\newpage
\begin{examplewrap}
\begin{nexample}{The FDA's webpage provides some data on mercury content of fish.
    Based on a sample of 15 croaker white fish (Pacific), a sample mean and
    standard deviation were computed as 0.287 and 0.069 ppm (parts per million),
    respectively.
    The 15 observations ranged from 0.18 to 0.41 ppm.
    Construct an appropriate 95\% confidence interval for the true average
    mercury content of croaker white fish (Pacific).
    Is there evidence that the average mercury content is greater than 0.275 ppm?
    Use the four-step framework to organize your work.}
\label{croakerWhiteFishPacificExerConditions}
\begin{description}
\item[\inferencestep{Identify}] Because the parameter to be estimated is a single mean, we will use a one-sample $t$-interval for $\mu$.  Here, $\mu$ is the  true mean mercury content in croaker white fish (Pacific), and we will estimate this parameter at the 95\% confidence level.  
\item[\inferencestep{Check}] We must check that the sampling distribution of the mean can be modeled using a normal distribution.  We will assume that the sample constitutes a random sample of less than 10\% of all croaker white fish (Pacific) and that independence is reasonable. The sample size $n$ is small, but there are no obvious outliers; all observations are within 2 standard deviations of the mean. If there is skew, it is not too great. Therefore we think it is reasonable that the population distribution of mercury content in croaker white fish (Pacific) could be nearly normal.  
\item[\inferencestep{Calculate}]  We will calculate the interval:
\begin{align*}
\text{point estimate}\ \pm\ t^{\star} \times SE\ \text{of estimate}
\end{align*}
The point estimate is the sample mean: $\bar{x}= 0.287$.\\
\\
$SE$ of $\bar{x}$ = $ \frac{s}{\sqrt{n}} = \frac{0.069}{\sqrt{15}}$. \\

We find $t^{\star}$ for the one-sample $t$-interval using technology or using the $t$-table at row $df = n -1$ and confidence level C\%.  For a 95\% confidence level and $df = 15 - 1 = 14$, $t^{\star} = 2.145$. The 95\% confidence interval is given by:
\begin{align*}
0.287 \ \pm\  &2.145\times  \frac{0.069}{\sqrt{15}}  \qquad df = 14\\
0.287 \ \pm\  &2.145\times 0.0178 \\
(0.24&9,\ 0.325)
\end{align*}
\item[\inferencestep{Conclude}]  We are 95\% confident that the interval (0.249, 0.325) contains the true \emph{average} mercury content of croaker white fish (Pacific).  Because the interval contains 0.275 as well as values less than 0.275, we do not have evidence that the true average mercury content is  greater than 0.275 ppm.
\end{description}
\end{nexample}
\end{examplewrap}


\begin{examplewrap}
\begin{nexample}
{Based on the interval calculated in Example~\ref{croakerWhiteFishPacificExerConditions} above, can we say that 95\% of croaker white fish (Pacific) have mercury content between 0.249 and 0.325 ppm?}
No.  The interval estimates the \emph{average} amount of mercury with 95\% confidence.  It is not trying to capture 95\% of the values.  
\end{nexample}
\end{examplewrap}


\begin{examplewrap}
\begin{nexample}
{An SAT preparation company claims that its students' scores improve by over 100 points on average after their course. A consumer group would like to evaluate this claim, and they collect data on a random sample of 30 students who took the class. Each of these students took the SAT before and after taking the company's course, so we have a difference in scores for each student. We will examine these differences $x_1=57$, $x_2=133$, ..., $x_{30}=140$ as a sample to evaluate the company's claim. The distribution of the differences has a mean of 135.9 and a standard deviation of 82.2. Construct a confidence interval to estimate the true average change in SAT after taking the company's course.  Is there evidence at the 95\% confidence level that students score an average of more than 100 points higher after the class?  Use the four-step framework to organize your work.  
}
\begin{description}
\item[\inferencestep{Identify}] Because we have paired data and the parameter to be estimated is a mean of differences, we will use a one-sample $t$-interval for $\mu_{\text{\emph{d}}}$.  Here, $\mu_{\text{\emph{d}}}$ represents the true mean of (${\text{SAT score after course} - \text{SAT score before course}})$ for all students who would take the company's SAT prep course.  We will estimate this parameter at the 95\% confidence level.

\item[\inferencestep{Check}] We have a random sample of students with paired observations on them.  We will assume that these 30 students represent less than 10\% of the total number of such students.  Finally, the number of differences is $n_{\text{\emph{d}}}=30\ge 30$, so we can proceed with the one-sample $t$-interval.  
 
\item[\inferencestep{Calculate}]  We will calculate the confidence interval as follows.
\begin{align*}
\text{point estimate}\ \pm\ t^{\star} \times SE\ \text{of estimate}
\end{align*}
The point estimate is the sample mean of differences: $\bar{x}_{\text{\emph{d}}} = 135.9$.\\
\\
$SE$ of $\bar{x}_{\text{\emph{d}}}$ = $ \frac{s_{\text{\emph{d}}}}{\sqrt{n_{\text{\emph{d}}}}} = \frac{82.2}{\sqrt{30}}=15.0$.\\

We find $t^{\star}$ for the one-sample case using the $t$-table at row $df = n -1$ and confidence level C\%.  For a 95\% confidence level and $df = 30 - 1 = 29$, $t^{\star} = 2.045$.\\

The 95\% confidence interval is given by:
\begin{align*}
135.9 \ \pm\  &2.045\times  \frac{82.2}{\sqrt{30}}  \qquad df = 29\\
135.9 \ \pm\  &2.045\times 15.0 \\
(105.&2,\ 166.6)
\end{align*}
\item[\inferencestep{Conclude}]  We are 95\% confident that the interval (105.2, 166.6) contains the true \emph{average} change in SAT score following the company's course.  There is sufficient evidence that students score greater than 100 points higher, on average, after the company's course because the entire interval is above 100.  
\end{description}
\label{satci}
\end{nexample}
\end{examplewrap}


\begin{examplewrap}
\begin{nexample}
{Based on the interval calculated in Example~\ref{satci}, can a random student be 95\% confident that their SAT score will be 100 points higher if they take the company's course than if they do not take the company's course?}
No, the interval estimates the \emph{average} increase, not the increase of an individual student.   Moreover, this is not an experiment - we did not randomize some students to take the SAT course and some to not take it and then compare the scores between the two groups.  Instead, all students took the SAT course and each student's SAT score after the course was compared to their SAT score before the course.  It is possible that scores just tend to go up when taking the SAT a second time.  
\end{nexample}
\end{examplewrap}

\newpage
%%%%%%%%%%%%%%

%%
\subsection*{Section summary}
\begin{itemize} 

\item $t$-distributions form a family of symmetric,
bell-shaped, standardized distributions and are identified using a parameter known as the degrees of freedom (df), which is based on
the sample size(s). When the degrees of freedom are small, the $t$-distribution
has a much narrower peak and fatter tails than a normal distribution.  As the
degrees of freedom increase, the t-distributions more closely resemble the
standard normal distribution.
\item $t$-distributions are used for finding critical values and test statistics for
inferences about a population mean $\mu$ when the population standard
deviation $\sigma$ is unknown and the sample standard deviation $s$ must be used instead.

\item The appropriate confidence interval for a population mean $\mu$ with unknown population standard deviation $\sigma$ is a \termni{one-sample \pmb{$t$}-interval for \pmb{$\mu$}}.  The parameter $\mu$ should be identified in context.

\item Paired data can come from a random sample or a matched pairs experiment.  For a matched pairs design, the appropriate analysis calculates \emph{differences} between pairs of values to produce one sample
of differences. The confidence interval procedure for the matched pairs design is a one-sample t-interval for a population mean difference $\mu_d$.  Use $\bar{x}_{\text{\emph{d}}}$ for the sample mean difference, $s_{\text{\emph{d}}}$ for the standard deviation of sample differences, and $n_{\text{\emph{d}}}$ for the number of sample differences.  

\item The one-sample $t$-interval for $\mu$ or $\mu_d$ requires the following conditions are met.
\begin{itemize}
\item[1.] Independence:  The data come from a random sample or random process.  When sampling without replacement, check that the sample size is less than 10\% of the population size.
\item[2.] Large sample or normal population: $n\ge 30$ or population distribution is nearly normal. If the sample size is less than 30 and the population distribution is unknown, check and confirm that there is no strong skew or outliers in the data in order to reasonably assume that the population distribution is nearly normal.
\end{itemize}

\item The general form for a confidence interval is:  $\text{point estimate}\ \pm\ \text{critical value} \times SE\ \text{of estimate}$.

\item A C\% one-sample $t$-interval for $\mu$ can be written as: $\bar{x} \pm t^{\star}\frac{s}{\sqrt{n}}, \text{ with } df=n-1$.\\
$t^{\star}$ is the critical value for the central C\% of a $t$-distribution with $n-1$ degrees of freedom.  

\item The $SE$ of a sample mean is:  $\frac{s}{\sqrt{n}}$.

\item The margin of error of a sample mean is:  $t^{\star}\frac{s}{\sqrt{n}}$. 

\item Because the confidence interval is based on a sample, the point estimate has associated error and the confidence interval may or may not contain the true value of the population mean.  

\item The interpretation of the confidence level C\% is that in repeated random
sampling with the same sample size from the same population, approximately
C\% of confidence intervals created will capture the population mean or
population mean difference.

\item We say we are C\% confident that a particular interval (\underline{\ \ \ \ }, \underline{\ \ \ \ }) contains the true population mean or population mean difference.

\item A confidence interval provides a range of plausible values for a parameter and can be used as evidence to justify a claim about a population proportion.  At a particular confidence level, we say that values are considered reasonable if they are inside the confidence interval and that values are considered unreasonable if they are outside the confidence interval. 

\item For a given sample, increasing the confidence level will result in a larger critical value, a larger margin of error, and a wider confidence interval.

\item Increasing the sample size $n$ decreases the standard error of $\bar{x}$ and, when all other things remain the same, decreases the width of a confidence interval for $\mu$.  The width of the interval is approximately proportional to $\frac{1}{\sqrt{n}}$.

\end{itemize}


\D{\newpage}
%%%%%Section exercises
{\input{ch_inference_for_means/TeX/confidence_intervals_for_a_population_mean_with_the_t-distribution.tex}}


%%
\section[Hypothesis testing for a population mean]{Hypothesis testing for a population mean}
\label{oneSampleMeansTest}
\label{oneSampleTTests}
\index{t-test@$t$-test!for a mean|(}
\index{one-sample $t$-test|see{$t$-test for a mean}}




\sectionintro{
\noindent%
Is there evidence that the mean speed of U.S. runners has changed over time?  Is there evidence that, on average, the Amazon price for course books is lower than the price at a college bookstore for those same books?  In this section, we consider hypothesis testing for a mean and for a mean of differences.  As with confidence intervals for a mean, we will use the $t$-distribution.

%%
\subsection*{Learning objectives}
\begin{enumerate}
\setlength{\itemsep}{0mm}
\item Identify and set up an appropriate test for a population mean $\mu$ or mean difference $\mu_d$.

\item Identify the null and alternative hypotheses for a population mean or population mean difference with unknown $\sigma$.

\item Justify the appropriateness of a hypothesis test for a population mean or mean difference by verifying conditions.

\item Calculate the test statistic, degrees of freedom and p-value for a test for a population mean or mean difference.

\item Interpret the p-value of a hypothesis test for a population mean or mean difference.

\item Justify a claim about a population mean or mean difference based on the results of a test.  





\end{enumerate}
}

\subsection{Intro to hypothesis testing for a single mean}

\newcommand{\cherryblossomn}{100}
\newcommand{\cherryblossommean}{97.3}
\newcommand{\cherryblossomnull}{93.3}
\newcommand{\cherryblossomsd}{17.0}
\newcommand{\cherryblossomse}{1.7}
\newcommand{\cherryblossomt}{2.35}

Is the typical U.S. runner getting faster or slower over time? Technological advances in shoes, training, and diet might suggest runners would be faster. An opposing viewpoint might say that with the average body mass index on the rise, people tend to run slower. In fact, all of these components might be influencing run time.

We consider this question in the context of the Cherry Blossom Race, which is a 10-mile race in Washington, DC each~spring.  The average time for all runners who finished the Cherry Blossom Race in 2006 was \cherryblossomnull{} minutes (93 minutes and about 18 seconds). We want to determine using data from \cherryblossomn{} participants in the 2017 Cherry Blossom Race whether runners in this race are getting faster or slower, versus the other possibility that there has been no change.   Figure~\ref{run17SampTimeHistogram} shows run times for \cherryblossomn{} randomly selected participants.  

\begin{figure}[h]
\centering
 \Figures[A histogram of "time" for the sample Cherry Blossom Race data is shown. The data are nearly symmetric with a center at about 100 minutes and a standard deviation of roughly 15 to 20 minutes. All times lie between 50 and 140 minutes.]
{0.65}{run10SampTimeHistogram}{run17SampTimeHistogram} 
\caption{A histogram of \var{time} for the sample Cherry Blossom Race data.}
\label{run17SampTimeHistogram}
\end{figure}


\begin{examplewrap}
\begin{nexample}
{What are appropriate hypotheses for this context?}
We know that the average run time for all runners in 2006 was \cherryblossomnull{} minutes.  We have a sample of times from the 2017 race.  We are interested in whether the average run time has \emph{changed}, so we will use a two-sided $H_A$.\\
\\
Let $\mu$ represent the average 10-mile run time of all participants in 2017,\mbox{ which is unknown to us.}
\\
\\
$H_0$: $\mu = \cherryblossomnull{}$ minutes.
\\$H_A$: $\mu \neq \cherryblossomnull{}$ minutes. 
\end{nexample}
\end{examplewrap}

The data come from a random sample from a large population, so the observations are independent. Do we need to check for skew in the data? No -- with a sample size of \cherryblossomn{}, well over 30, the Central Limit Theorem tells us that the sampling distribution of $\bar{x}$ will be nearly normal.

With independence satisfied and slight skew not a concern for this large of a sample, we can proceed with performing a hypothesis test using the $t$-distribution.

The sample mean and sample standard deviation of the \cherryblossomn{} runners from the 2017 Cherry Blossom Race are \cherryblossommean{} and \cherryblossomsd{} minutes, respectively. We want to know whether the observed sample mean of \cherryblossommean{} is far enough away from \cherryblossomnull{} to provide convincing evidence of a real difference, or if it is within the realm of expected variation for a sample of size \cherryblossomn{}.  

To answer this question we will find the test statistic and p-value for the hypothesis test.  Since we will be using a sample standard deviation in our calculation of the test statistic, we will need to use a $t$-distribution, just as we did with confidence intervals for a mean.  We call the test statistic a $T$-statistic.  It has the same general form as a Z-statistic.
\begin{align*}
T = \frac{\text{point estimate } - \text{null value}}{SE\text{ of estimate}}
\end{align*}

As we saw before, when carrying out inference on a single mean, the degrees of freedom is given by $n-1$.  


\begin{onebox}{The T-statistic}
The \term{T-statistic} (or T-score) is analogous to a Z-statistic (or Z-score).  Both represent how many standard errors the observed value is from the null value.
\end{onebox}


\begin{examplewrap}
\begin{nexample}{Calculate the test statistic and degrees of freedom for this test.}
Here, our point estimate is the sample mean, $\bar{x}=\cherryblossommean{}$ minutes.  
\\
\\
The $SE$ of $\bar{x}$ = $\frac{s}{\sqrt{n}}$ = $\frac{\cherryblossomsd{}}{ \sqrt{\cherryblossomn{}}} = \cherryblossomse{}$ minutes.
\\
\\
The null value is the value hypothesized in the null hypothesis: $\mu_0 = 93.3$ minutes.
\begin{align*}
 T = \frac{\cherryblossommean{} - \cherryblossomnull{}}{\cherryblossomse{}} = \cherryblossomt{} \qquad df=\cherryblossomn{}-1=99
\end{align*}
\end{nexample}
\end{examplewrap}

\begin{examplewrap}
\begin{nexample}{Calculate the p-value and then interpret the p-value in context.  }
$H_A$ is $\mu \ne 93.3$, so this is a two-tailed test.  Using a technology option from Section~\ref{techtdist}, we find the p-value, which corresponds to the area below $-$\cherryblossomt{} plus the area above \cherryblossomt{} under the $t$-distribution with 99 degrees of freedom.  The p-value = 0.021.
\begin{center}
 \Figure[A t distribution with 99 degrees of freedom is shown.The area to the left of $-$\cherryblossomt{} and to the right of \cherryblossomt{} is shaded.]{0.53}{tDistDF99}
\end{center}
The p-value is the probability of getting data as extreme as we got assuming $H_0$ is true.  In context, we can say that there is a 2.1\% chance of getting a test statistic larger than 2.35 or less than $-2.35$ assuming the average 10-mile run time of all participants in 2017 really is 93.3 minutes.
\end{nexample}
\end{examplewrap}


\begin{examplewrap}
\begin{nexample}{Does the data provide sufficient evidence that the average Cherry Blossom Run time in 2017 is different than 93.3 min (the known value in 2006)?}
This depends upon the desired significance level.  Since the p-value = 0.02 $< 0.05$, there is sufficient evidence at the 5\% significance level.  However, as the p-value of 0.02 $> 0.01$, there is not sufficient evidence at the 1\% significance level.  This is why it is important to choose a significance level before seeing seeing the data and beginning the analysis.
\end{nexample}
\end{examplewrap}


\begin{examplewrap}
\begin{nexample}{Would you expect the hypothesized value of \cherryblossomnull{} to fall inside or outside of a 95\% confidence interval?  What about a 99\% confidence interval?} 
Because the hypothesized value of \cherryblossomnull{} was rejected by the two-sided $\alpha=0.05$ test, we would expect it to be outside the 95\% confidence interval.  However, because the hypothesized value of \cherryblossomnull{} was not rejected by the two-sided $\alpha=0.01$ test, we would expect it to fall inside the (wider) 99\% confidence interval.  
\end{nexample}
\end{examplewrap}


%%
\subsection{Hypothesis testing for a mean of differences}

Consider again the table summarizing data on: (UCLA Bookstore price $-$ Amazon price), for each of the 68 books sampled.

\begin{figure}[hh]
\centering
\begin{tabular}{ccccc}
\hline
$n_{_{\text{\emph{d}}}}$	&\hspace{3mm}& $\bar{x}_{_{\text{\emph{d}}}}$	&\hspace{3mm}& $s_{_{\text{\emph{d}}}}$ \vspace{1mm}\\
\uclabookN{}  && \uclabookM{}  && \uclabookSD{} \\
\hline
\end{tabular}
\caption{Summary statistics for the price differences.
    There were 68 books, so there are \uclabookN{}
    differences.}
\label{textbooksSummaryStats1}
\end{figure}
\index{t-test@$t$-test!for a mean of differences|(}
\index{paired $t$-test|(}
\index{paired $t$-test|seealso{$t$-test for a mean of differences}}

We will set up and implement a hypothesis test to determine whether, on average, there is a difference in textbook prices between Amazon and the UCLA bookstore.
\label{htForDiffInUCLAAndAmazonTextbookPrices}
We are considering two scenarios: there is no difference in prices or there is some difference in prices.
\begin{itemize}
\setlength{\itemsep}{0mm}
\item[$H_0$:] $\mu_{\text{\emph{d}}}=0$. On average, there is no difference in textbook prices.
\item[$H_A$:] $\mu_{\text{\emph{d}}} \neq 0$. On average, there is some difference in textbook prices.
\end{itemize}

\newpage
Conditions were checked in the previous section.  We noted that the observations are based on a random sample of books from a large population of books (more than 680 books) and that the sample size is well above 30, thus satisfying the conditions for a one-sample $t$-test.

Next we compute the test statistic.  The point estimate is the observed value of $\bar{x}_{\text{\emph{d}}}$.  The null value is the value hypothesized under the null hypothesis.  Here, the null hypothesis is that the true mean of the differences is 0.  
\begin{align*}
T
  = \frac{\text{point estimate} - \text{null value}}
      {SE \text{ of estimate}} =  \frac{\uclabookM{} - 0}{\frac{\uclabookSD{}}{\sqrt{\uclabookN{}}}}
  = \frac{\uclabookM{} - 0}{\uclabookSE{}} = 2.20
\end{align*}
The degrees of freedom are $df = \uclabookN{} - 1 = 67$.
To visualize the p-value, the sampling distribution
for $\bar{x}_{\text{\emph{d}}}$ is drawn as though
$H_0$ is true.  This is shown in
Figure~\ref{textbooksF18HTTails}.  Equivalently, we can draw T distribution with 67 degrees of freedom, shading the area to the left of $T=-2.20$ and to the right of $T=2.20$.  Because this is a two-sided test, the p-value corresponds to the area in both tails.  Using statistical software, we find the area in the tails to be 0.0312.

Because the p-value of 0.0312 is less than 0.05,
we reject the null hypothesis.  We have evidence that, on average, there is a difference in textbook prices.  In particular, we can say that, on average, Amazon prices are lower than the
UCLA Bookstore prices for UCLA course books.


\begin{examplewrap}
\begin{nexample}{The p-value for this two-sided test is 0.0312.  Interpret this quantity in context.  }
The p-value is the probability of getting data as extreme as we got assuming $H_0$ is true.  In context, we can say that there is a 3.12\% chance of getting a test statistic larger than 2.20 or less than $-2.20$ assuming there really is no difference, on average, between book prices at UCLA Bookstore and on Amazon.  Equivalently, we can say that there is a 3.12\% chance of getting a sample mean difference $\bar{x}_{d}$ greater than \$2.98 or less than $-$\$2.98 assuming there really is no difference, on average, between book prices at UCLA Bookstore and on Amazon.
\end{nexample}
\end{examplewrap}

\begin{figure}[h]
\centering
\Figures[A bell-shaped distribution is shown, with a center of mu-sub-0, which has a value of 0. The area under the distribution above x-bar-sub-d equals 3.58 is shaded, as is the corresponding tail below -3.58.]{0.65}{textbooksF18}{textbooksF18HTTails}
\caption{Sampling distribution of the mean difference in book prices, if the true average difference is zero.  $\bar{x}$ values at least as extreme as our $\bar{x}$ of 3.58 are shaded.}
\label{textbooksF18HTTails}
\end{figure}
\begin{figure}[h]
\centering
\Figures[The T distribution with 67 degrees of freedom.  T values at least as extreme as our T-statistic of 2.20 are shaded.]{0.65}{textbooksF18}{textbooksF18HTTailsT}
\caption{The T distribution with 67 degrees of freedom.  T values at least as extreme as our T-statistic of 2.20 are shaded.}
\label{textbooksF18HTTailsZ}
\end{figure}



\index{data!textbooks|)}

\newpage
%%
\subsection[Summary and worked examples]{Summary and worked examples}
%\subsection[Summary of the one-sample $t$-test for $\mu$]{Summary of the one-sample \pmb{$t$}-test for \pmb{$\mu$}}
\begin{onebox}{Hypothesis test for a mean}
To carry out a complete hypothesis test to evaluate a claim about a population mean,
\\
\\
\inferencestep{Identify} Identify the test procedure, parameter, significance level, and hypotheses.\vspace{-1mm}
\begin{itemize}
\item[] Use a \termsub{one-sample \pmb{$t$}-test for \pmb{$\mu$}}{t-test@$t$-test!for a mean}. Define the population mean $\mu$ in words, referencing the population of interest.  Choose a significance level ($\alpha$) and test the following hypotheses.
\end{itemize}
\vspace{-3mm}
\begin{itemize}
\setlength{\itemsep}{0mm} 
\item[] \quad \ $H_0$: \, $\mu = \mu_0$ 
\item[] \quad \ $H_A$: \ $\mu \ne \mu_0$;  \; $\mu > \mu_0$; \; or \; $\mu < \mu_0$ \qquad ($\mu_0$ is the null or hypothesized mean)\vspace{1mm}
\item[] When there is paired numerical data, use this same procedure to test whether $\mu_{\text{\emph{d}}}$, the mean of the population differences, is zero.  In this case, use the mean and standard deviation of the sample differences,  $\bar{x}_{\text{\emph{d}}}$ and  $s_{\text{\emph{d}}}$, and the number of sample differences, $n_{\text{\emph{d}}}$, when calculating the test statistic.
\end{itemize} 
\inferencestep{Check} Check conditions for the test statistic to have a $t$-distribution, assuming $H_0$ is true.  \vspace{-1mm}
{\setlength{\leftmargini}{13mm}
\begin{itemize}
\setlength{\itemsep}{0mm}
\item[1.] Independence:  Data come from a random sample or random process.  When sampling 
without replacement, check that sample size is less than 10\% of the population size.
\item[2.] Large sample or normal population:  $n\ge 30$ or the population distribution is nearly normal. If the sample size is less than 30 and the population distribution is unknown, check and confirm that there is no strong skew or outliers in the data in order to reasonably assume that the population distribution is nearly normal.
\end{itemize}
}
 \inferencestep{Calculate} Calculate the $t$-statistic, $df$, and p-value.
\begin{itemize}
\item[] $T = \frac{\text{point estimate } - \text{ null value}}{SE \text{ of estimate}}$,  \quad $df=n-1$
\begin{itemize}
\item[] point estimate: $\bar{x}$, the sample mean
\item[] $SE$ of estimate:  $\frac{s}{\sqrt{n}}$
\item[] null value: $\mu_0$
\end{itemize}
\item[] p-value = (based on the $t$-statistic, the $df$, and the direction of $H_A$)
\end{itemize}
 \inferencestep{Conclude} Compare the p-value to $\alpha$, and draw a conclusion in context.\vspace{-1mm}
\begin{itemize}
\item[] If the p-value is $\le \alpha$, reject $H_0$; there is sufficient evidence that [$H_A$ in context]. 
\item[] If the p-value is $> \alpha$, do not reject $H_0$; there is not sufficient evidence that [$H_A$ in context].
\end{itemize}\end{onebox}


\begin{examplewrap}
\begin{nexample}
{In Section~\ref{oneSampleTConfidenceIntervals}, we discussed an example involving the mercury content in croaker white fish (Pacific). Based on a sample of size 15, a sample mean and standard deviation were computed as 0.287 and 0.069 ppm (parts per million), respectively. Carry out an appropriate test to determine if 0.25 is a reasonable value for the average mercury content of croaker white fish (Pacific) using a 5\% significance level. Use the four-step method to organize your work.}

\begin{description}
\item[\inferencestep{Identify}]  Because we are hypothesizing about a single mean we choose the one-sample $t$-test for $\mu$.  Here, $\mu$ is the true mean mercury content in croaker white fish (Pacific), and we test the following hypotheses at the $\alpha=0.05$ significance level.\vspace{-1mm}
\begin{itemize}
\setlength{\itemsep}{0mm}
\item[]  $H_0$: \,$\mu=0.25$   
\item[] $H_A$: $\mu \ne 0.25$ 
\end{itemize}
 \item[\inferencestep{Check}]  The conditions were checked previously, namely -- the data come from a random sample of less than 10\% of the population of all croaker white fish (Pacific), and because $n$ is less than 30, we checked and confirmed that there is no strong skew or outliers in the data, so the assumption that the population distribution of mercury is nearly normally distributed is reasonable.  
\item[ \inferencestep{Calculate} ]  We will calculate the $t$-statistic, $df$, and p-value.
\begin{align*}
T = \frac{\text{point estimate } - \text{ null value}}{SE \text{ of estimate}}
\end{align*}

The point estimate is the sample mean: $\bar{x}$ =  0.287, and the null value is: $\mu_0=0.25$.\\

$SE$ of $\bar{x}$ =  $\frac{s}{\sqrt{n}} = \frac{0.069}{\sqrt{15}} = 0.0178$.  We calculate the test statistic as follows:
\begin{align*}
T = \frac{0.287 - 0.25}{\frac{0.069}{\sqrt{15}}}  = \frac{0.287 - 0.25}{0.0178} = 2.07 \qquad df= 15-1=14
\end{align*}

\begin{center}
\Figures[A t-distribution with 14 degrees of freedom is shown.  The area to the left of -2.07 and to the right of 2.07 is shaded.]
{0.5}{tDistDF14}{tDistDF14Both}
\end{center}
Because $H_A$ is a two-tailed test ( $\ne$ ), the p-value corresponds to the area to the right of 2.07 plus the area to the left of $-2.07$ under the $t$-distribution with 14 degrees of freedom.  The p-value = $2\times 0.029 = 0.058$.  

\item[\inferencestep{Conclude}]  The p-value of $0.058 > 0.05$, so we do not reject the null hypothesis. We do not have sufficient evidence that the average mercury content in croaker white fish (Pacific) is not 0.25.
\end{description}
\end{nexample}
\end{examplewrap}




\begin{exercisewrap}
\begin{nexercise}Recall that the 95\% confidence interval for the average mercury content in croaker white fish was (0.249, 0.325). Discuss whether the conclusion of the hypothesis test in the previous example is consistent or inconsistent with the conclusion of the confidence interval.\footnotemark
\end{nexercise}
\end{exercisewrap}
\footnotetext{It is consistent because 0.25 is located (just barely) inside the confidence interval, so it is considered a reasonable value. Our hypothesis test did not reject the hypothesis that $\mu=0.25$, also implying that it is a reasonable value. Note that the p-value was just over the cutoff of 0.05. This is consistent with the value of 0.25 being just inside the confidence interval.  Also note that the hypothesis test did not \emph{prove} that $\mu=0.25$.  The value 0.25 is just one of many reasonable values for the true mean.}


\D{\newpage}



\begin{examplewrap}
\begin{nexample}{An SAT preparation company claims that its students' scores
    improve by over 100 points on average after their course.
    A~consumer group would like to evaluate this claim, and they collect data
    on a random sample of 30 students who took the class.
    Each of these students took the SAT before and after taking the company's
    course, so we have a difference in scores for each student.
    We will examine these differences $x_1=57$, $x_2=133$, ..., $x_{30}=140$.
    The distribution of the differences has a mean of 135.9, a standard
    deviation of 82.2, and is shown below.
    Do the data provide convincing evidence to back up the company's claim?
    Use the four-step framework to organize your work.
    \begin{center}
\Figure[A histogram, labeled ``Differences", is shown that ranges from negative 100 to positive 300.  The mean is at approximately 140, with the vast majority of the area to the right of 0.]
{0.45}{satImprovementHTDataHistogram}
    \end{center}}\label{sat_prep_company_intro_example}
\begin{description}
\item[\inferencestep{Identify}] Because we have paired data and the parameter of interest is a mean of differences, we will use a one-sample $t$-test for $\mu_{\text{\emph{d}}}$.  Here $\mu_{\text{\emph{d}}}$ is the true mean of (${\text{SAT score after course} - \text{SAT score before course}})$ for all students who would take the company's SAT prep course.  We will test the following hypotheses at the $\alpha=0.05$ level.\vspace{-1mm}
\begin{itemize}
\setlength{\itemsep}{0mm}
\item[]  $H_0$: \,$\mu_{\text{\emph{d}}} = 100$.  On average, student scores improve by 100 points.   
\item[] $H_A$: $\mu_{\text{\emph{d}}} > 100$.  On average, student scores improve by more than 100 points.
\end{itemize}

\item[\inferencestep{Check}] We have a random sample of students and have paired data on them.  We will assume that this sample of size 30 represents less than 10\% of the total population of such students.  Finally, the number of differences is $n_{\text{\emph{d}}}=30\ge 30$, so we can proceed with the one-sample $t$-test.  
 
\item[\inferencestep{Calculate}]  We will calculate the test statistic, $df$, and p-value.
\begin{align*}
T = \frac{\text{point estimate } - \text{ null value}}{SE \text{ of estimate}}
\end{align*}
The point estimate is the sample mean of differences:  $\bar{x}_{\text{\emph{d}}}  = 135.9$\\[1mm]
$SE$ of $\bar{x}_{\text{\emph{d}}} $= $\frac{s_{\text{\emph{d}}} }{\sqrt{n_{\text{\emph{d}}} }} = \frac{82.2}{\sqrt{30}} = 15.0$ \\[1mm]
\begin{align*}
T = \frac{135.9-100}{\frac{82.2}{\sqrt{30}}} = \frac{135.9-100}{15.0}=2.4 \qquad df=30-1=29
\end{align*}
The p-value is the area to the right of 2.4 under the $t$-distribution with 29 degrees of freedom.  The p-value = 0.012.

\item[\inferencestep{Conclude}]  p-value $=0.012<\alpha$ so we reject the null hypothesis. The data provide convincing evidence to support the company's claim that students' scores improve by more than 100 points, on average, following the class.


\end{description}
\end{nexample}
\end{examplewrap}


\begin{exercisewrap}
\begin{nexercise}
Because we found evidence to support the company's claim, does this mean that a student will score more than 100 points higher on the SAT if they take the class than if they do not take the class?\footnotemark{}
\end{nexercise}
\end{exercisewrap}
\footnotetext{No.
    First, this is an observational study, so we cannot make a causal conclusion.
    Maybe SAT test takers tend to improve their score over time even if they don't
    take this SAT class.
    Second, the test considers the average.
    It does not imply that each student improved.
    With a sample standard deviation of 82.2 and a mean of 135.9,
    some students did worse after the SAT class, as shown in the histogram
    in Example~\ref{sat_prep_company_intro_example}.}

\index{data!SAT prep company|)}

\D{\newpage}




%%%%%%%%%%%%%%
\subsection[Technology: the one-sample $t$-interval and $t$-test for $\mu$]{Technology: the one-sample \pmb{$t$}-interval and \pmb{$t$}-test for \pmb{$\mu$}}
\label{tech1T}

\noindent The data set \data{loan50}, introduced in Chapter 1, contains information on randomly sampled loans.  Download the \data{loan50} CSV file from \oiRedirect{openintro-data}{openintro.org/data}.  Open it and calculate a 95\% confidence interval for the true mean of \data{loan$\_$amount}.  Also find the test statistic, df, and p-value for a test with the alternative hypothesis that the true mean is less than $\$$20,000.\\

\noindent \textbf{Desmos}:  Use the \texttt{ttest([data])} or \texttt{ttest(n, mean, stdev)} function as explained below.
\begin{enumerate}
\setlength{\itemsep}{0mm}
\item Click \calctext{+} in the upper left, then choose \calctext{inference}.  
\item Choose \calctext{$t$-test} in the pop-up window.
\begin{center}
\fbox{\Figures[A Desmos calculator screen is shown. The + and inference option are highlighted. ]
{0.3}{technologyInferenceMeans}{desmosInference}}\hspace{10mm}
\fbox{\Figures[A Desmos calculator screen is shown with the inference pop-up box. t-test is highlighted. ]
{0.3}{technologyInferenceMeans}{desmosInferenceTTest}}
\end{center}

\item If you have all the data, enter the data separated by commas or copy and paste it in the box.  Here we highlight the \texttt{loan$\_$amount} column and paste it in the box.  If you have the summary stats, click on \calctext{Stats} and then enter the \calctext{sample size}, \calctext{mean} and \calctext{stdev}.  Click \calctext{Create Test}. 
\begin{center}
\fbox{\Figures[A Desmos calculator screen shows a t-test box.  A list of data starting with \left 22000, 6000, 25000, 6000, 25000...\right is entered and partially shown.  Data is highlighted. There are empty boxes for sample size, mean, and stdeve below SAMPLE 1 and SAMPLE 2.  Stats is highlighted. ]
{0.35}{technologyInferenceMeans}{desmos1TData}}\hspace{5mm}
\fbox{\Figures[A Desmos calculator screen shows a t-test box. The boxes ]
{0.35}{technologyInferenceMeans}{desmos1TStats}}
\end{center}
%\begin{center}
%\fbox{\Figures[A Desmos calculator screen shows a t-test box with 15 entered for sample size, 0.287 entered for mean and 0.069 entered for stdev.  ]
%{0.65}{technologyInferenceMeans}{desmos1SampTInterval1}}
%\end{center}
\item Click the triangle next to \calctext{Confidence Interval} and input the desired \calctext{Confidence level}.  Here we use 0.95, which is entered by default.  Click the \calctext{\vdots} to the right of the confidence interval to more information.   
\item Click the triangle next to \calctext{Significance Test}.  Enter the hypothesized value for \calctext{mu} and select \calctext{Tails} to be \calctext{Left}, \calctext{Right} or \calctext{Both} depending on the direction of the alternative hypothesis.  Here the hypothesized value of $\mu$ is 20,000 and $H_A$ uses a $<$, so we select Tails to be Left.
\begin{center}
\fbox{\Figures[A Desmos calculator screen is shown.  ttest(\left 22000, 6000, 25000, 6000, 25000...\right ) is entered.  Confidence Interval is selected with Confidence level: 0.95.  The three vertical dots are also clicked showing Lower bound = 14111.6, Upper bound = 20054.4, Point estimate = 17083, and Standard error = 1478.62. ]
{0.35}{technologyInferenceMeans}{desmos1TCI}}\hspace{5mm}
\fbox{\Figures[A Desmos calculator screen is shown.  ttest(\left 22000, 6000, 25000, 6000, 25000...\right ) is entered.  Significance Test is selected.  The null difference is 0 and Tails is set to Both.  A t-curve is shown with the area to the left of -1.972 and to the right of 1.972 shaded. ]
{0.35}{technologyInferenceMeans}{desmos1TTest}}
\end{center}
\end{enumerate}

\newpage
%%
\noindent \R{}:  1-sample $t$-interval/test for $\mu$\\

\noindent First store the data into a variable as described on page~\pageref{rDescriptive}.  \\
\texttt{> \calctext{loan\_amount = scan()}} \hspace{3mm}  Hit return, paste the numerical data, then hit return and return again.\\

\noindent You can also manually type in data as follows:\\
\texttt{> \calctext{loan\_amount = c(22000, 6000, 25000, 6000...)}}\\


\noindent CONFIDENCE INTERVAL.
\\ \texttt{t.test(data, conf.level =  )} \\

\noindent \texttt{> \calctext{t.test(loan\_amount, conf.level = 0.95)}}\\  
\texttt{
	One Sample t-test\\
data:  loan\_amount\\
t = 11.553, df = 49, p-value = 0.000000000000001348\\
alternative hypothesis: true mean is not equal to 0\\
95 percent confidence interval:\\
\fbox{ 14111.59 20054.41}\\
sample estimates:\\
mean of x \\
    17083 }\\ 


\noindent HYPOTHESIS TEST.  
\\ \texttt{t.test(data, mu = ,  alternative = "two.sided","greater","less")}\\

\noindent If a hypothesized value for $\mu$ is not entered, a default of 0 is used.  If \texttt{alternative} is not specified, a default of \texttt{"two.sided"} is used.  Here our alternative hypothesis is $\mu < 20,000$. \\

\noindent \texttt{> \calctext{t.test(loan\_amount, mu = 20000, alternative = "less")}}\\
\texttt{
	One Sample t-test\\
data:  loan50$\$$loan\_amount\\
\fbox{t = -1.9728, df = 49, p-value = 0.02709}\\
alternative hypothesis: true mean is less than 20000\\
95 percent confidence interval:\\
     -Inf 19561.99\\
sample estimates:\\
mean of x \\
    17083 }\\ \\

\noindent If you have installed the \texttt{openintro} package as described on page~\pageref{rDescriptive}, you can skip the first step of storing the data into the variable \texttt{loan\_amount}.  Instead, simply reference \texttt{loan50$\$$loan\_amount}: \\
\texttt{> \calctext{t.test(loan50$\$$loan\_amount, conf.level = 0.95)}}

\newpage
%%%%%%%%%%%%
\noindent \textbf{Calculator}:  NumWorks calculator instructions and example output are included.  For the TI-83/84 and Casio calculators, general instructions are provided, and worked example videos can be accessed via the \includegraphics[height=3mm]{extraTeX/icons/video_camera.png} icon or at \oiRedirect{ti84_playlist}{\textbf{openintro.org/ti}} and \oiRedirect{casio-9750-playlist}{\textbf{openintro.org/casio}}.\\ 



\begin{onebox}{NumWorks: 1-sample T-interval.}
Use \calctext{OK} or \calctext{EXE} to make a selection.
\begin{enumerate}
\setlength{\itemsep}{0mm}
\item From the home screen, select \calcbutton{Inference}, then \calctext{Intervals}, then \calctext{One mean}, then \calctext{t-interval}.  If these options do not appear, click the \calcbutton{$\lhookleftarrow$} button in the upper right as many times as needed. 
\item Choose \calctext{Input statistics} or \calctext{Use a dataset} and enter the needed values.  Then use the down arrow and choose \calcbutton{Next}.
\item Note the quantities returned.  Press the down arrow and choose \calctext{Next}.
\item In addition to seeing the confidence interval displayed in two ways, you can press the up and down arrows to quickly change the confidence level and see the resulting interval and margin of error.
\begin{center}
\Figures[ ]
{0.35}{technologyInferenceMeans}{numworks1SampTInterval5}\hspace{10mm}
\Figures[ ]
{0.35}{technologyInferenceMeans}{numworks1SampTInterval6}
\end{center}
\vspace{-1.5mm}
\end{enumerate}
\end{onebox}
%
\begin{onebox}{NumWorks: 1-sample t-test}
\label{normalnumworks}
Use \calctext{OK} or \calctext{EXE} to make a selection.
\begin{enumerate}
\setlength{\itemsep}{0mm}
\item From the home screen, select \calcbutton{Inference}, then \calctext{Tests}, then \calctext{One mean}, then \calctext{t-test}.  If these options do not appear, click the \calcbutton{$\lhookleftarrow$} button in the upper right as many times as needed. 
\item Enter the value of the hypothesized mean for the Null hypothesis.  Press the down arrow.  Press \calcbutton{OK} and choose \calctext{$<$}, \calctext{$\ne$} , or \calctext{$>$}  for the Alternative hypothesis.  Press the down arrow and choose \calcbutton{Next}. 
\item Choose \calctext{Input statistics} or \calctext{Use a dataset} and enter the needed values.  Then use the down arrow and choose \calcbutton{Next}.
\item Note the quantities returned.  Click the down arrow and choose \calctext{Next}.
\item On this screen, the p-value and alpha are shaded on the t-distribution and can be visually compared.
\begin{center}
\Figures[ ]
{0.35}{technologyInferenceMeans}{numworks1SampTTest1}\hspace{10mm}
\Figures[ ]
{0.35}{technologyInferenceMeans}{numworks1SampTTest2}
\end{center}
\vspace{-1.5mm}
\end{enumerate}
\end{onebox}
%%
\begin{onebox}{\videohref{ti84_1_mean_CI} TI-83/84: 1-sample T-interval}
Use \calcbutton{STAT}, \calctext{TESTS}, \calctext{TInterval}.
\begin{enumerate}
\setlength{\itemsep}{0mm}
\item Choose \calcbutton{STAT}.
\item Right arrow to \calctext{TESTS}.
\item Down arrow and choose \calctext{8:TInterval}.
\item Choose \calctext{Data} if you have all the data or \calctext{Stats} if you have the mean and standard deviation.
\begin{itemize}
\item If you choose \calctext{Data}, let \calctext{List} be \calctext{L1} or the list in which you entered your data (don't forget to enter the data!) and let \calctext{Freq} be \calctext{1}.
\item If you choose \calctext{Stats}, enter the mean, $SD$, and sample size.
\end{itemize}
\item Let \calctext{C-Level} be the desired confidence level.
\item Choose \calctext{Calculate} and hit \calcbutton{ENTER}, which returns: \\[1mm]
\begin{tabular}{l l}
\calctext{(\underline{\ \ },\underline{\ \ })} & the confidence interval \\
$\calctextmath{\bar{x}}$ & the sample mean \\
\calctext{Sx} & the sample $SD$ \\
\calctext{n} & the sample size
\end{tabular}
\end{enumerate}
\end{onebox}
%

\begin{onebox}{\videohref{ti84_1_mean_HT} TI-83/84: 1-sample T-test}
Use \calctext{STAT}, \calctext{TESTS}, \calctext{T-Test}.
\begin{enumerate}
\setlength{\itemsep}{0mm}
\item Choose \calcbutton{STAT}.
\item Right arrow to \calctext{TESTS}.
\item Down arrow and choose \calctext{2:T-Test}.
\item Choose \calctext{Data} if you have all the data or \calctext{Stats} if you have the mean and standard deviation.  Note: When carrying out a test for a mean of differences, make sure to use the sample \emph{differences} or the summary statistics for the \emph{differences}. 
\item Let $\calctextmath{\mu_0}$ be the null or hypothesized value of $\mu$.
\begin{itemize}
\item If you choose \calctext{Data}, let \calctext{List} be \calctext{L1} or the list in which you entered your data (don't forget to enter the data!) and let \calctext{Freq} be \calctext{1}.
\item If you choose \calctext{Stats}, enter the mean, $SD$, and sample size.
\end{itemize}
\item Choose $\calctextmath{\ne}$, $\calctextmath{<}$, or $\calctextmath{>}$ to correspond to $H_A$.
\item Choose \calctext{Calculate} or \calctext{Draw} and hit \calcbutton{ENTER}.  \calctext{Draw} shows the t-statistic and p-value as well as a graph of the t-distribution with p-value shaded.  \calctext{Calculate} returns: \\[1mm]
\begin{tabular}{ll l ll}
\calctext{t} & T-statistic &\quad&
	\calctext{Sx} & the sample standard deviation \\
\calctext{p} & p-value &&
	\calctext{n} & the sample size \\
$\calctextmath{\bar{x}}$ & the sample mean
\end{tabular}
\end{enumerate}
\end{onebox}
%%
\begin{onebox}{\videohref{casio_1_mean_inference} Casio fx-9750GII: 1-sample T-interval}
\ \vspace{-5mm} \
\begin{enumerate}
\setlength{\itemsep}{0mm}
\item Navigate to \calctext{STAT} (\calcbutton{MENU} button, then hit the \calcbutton{2} button or select \calctext{STAT}).
\item If necessary, enter the data into a list.
\item Choose the \calctext{INTR} option (\calcbutton{F3} button), \calctext{t} (\calcbutton{F2} button), and \calctext{1-S} (\calcbutton{F1} button).
\item Choose either the \calctext{Var} option (\calcbutton{F2}) or enter the data in using the \calctext{List} option.
\item Specify the interval details:
  \begin{itemize}
  \setlength{\itemsep}{0mm}
  \item Confidence level of interest for \calctext{C-Level}.
  \item If using the \calctext{Var} option, enter the summary statistics. If using \calctext{List}, specify the list and leave \calctext{Freq} value at \calctext{1}.
  \end{itemize}
\item Hit the \calcbutton{EXE} button, which returns \\[1mm]
\begin{tabular}{ll}
  \calctext{Left}, \calctext{Right} & ends of the confidence interval \\
  $\calctextmath{\bar{x}}$ & sample mean \\
  \calctext{sx} & sample standard deviation \\
  \calctext{n} & sample size
\end{tabular}
\end{enumerate}
\end{onebox}
%
\begin{onebox}{\videohref{casio_1_mean_inference} Casio fx-9750GII: 1-sample T-test}
\ \vspace{-5mm} \
\begin{enumerate}
\setlength{\itemsep}{0mm}
\item Navigate to \calctext{STAT} (\calcbutton{MENU} button, then hit the \calcbutton{2} button or select \calctext{STAT}).
\item If necessary, enter the data into a list.  Note:  if doing a test for a mean of differences, enter the computed differences.
\item Choose the \calctext{TEST} option (\calcbutton{F3} button).
\item Choose the \calctext{t} option (\calcbutton{F2} button).
\item Choose the \calctext{1-S} option (\calcbutton{F1} button).
\item Choose either the \calctext{Var} option (\calcbutton{F2}) or enter the data in using the \calctext{List} option.
\item Specify the test details:
  \begin{itemize}
  \setlength{\itemsep}{0mm}
  \item Specify the sidedness of the test using the \calcbutton{F1}, \calcbutton{F2}, and \calcbutton{F3} keys.
  \item Enter the null value, $\calctextmath{\mu}$\calctext{0}.
  \item If using the \calctext{Var} option, enter the summary statistics. If using \calctext{List}, specify the list and leave \calctext{Freq} values at \calctext{1}.
  \end{itemize}
\item Hit the \calcbutton{EXE} button, which returns \\[1mm]
\begin{tabular}{ll l ll}
& alternative hypothesis &\hspace{5mm}&
	$\calctextmath{\bar{x}}$ & sample mean \\
\calctext{t} & T-statistic &&
	\calctext{sx} & sample standard deviation \\
\calctext{p} & p-value &&
	\calctext{n} & sample size
\end{tabular}
\end{enumerate}
\end{onebox}


\newpage
%%%%%%%%%%%%%%

%%
\subsection*{Section summary}
\begin{itemize} 

\item The appropriate hypothesis testing procedure for a population mean $\mu$ with unknown population standard deviation $\sigma$ is a \termni{one-sample \pmb{$t$}-test for \pmb{$\mu$}}.  The parameter $\mu$ should be identified in context.  

\item For a matched pairs design, the appropriate analysis calculates \emph{differences} between pairs of values to produce one sample of differences.  The hypothesis testing procedure for a matched pairs design is a one-sample $t$-test for a population mean difference, where we use $\mu_d$ for the population mean difference, $\bar{x}_{\text{\emph{d}}}$ for the mean of sample differences, $s_{\text{\emph{d}}}$ for the standard deviation of sample differences, and $n_{\text{\emph{d}}}$ for the number of sample differences.

\item The null hypotheses for a one-sample $t$-test for a population mean $\mu$ is:  
\begin{itemize}
\setlength{\itemindent}{3mm}
\item[$H_0$:] $\mu=\mu_0$, where $\mu_0$ is the null hypothesized value for the population mean.
\end{itemize}


\item The alternative hypothesis may be one-sided ($<$ or $>$) or two-sided ($\ne$).
\begin{itemize}
\setlength{\itemindent}{3mm}
\item[$H_A$:] $\mu<\mu_0$.  The p-value will correspond to a lower tail.
\item[$H_A$:] $\mu>\mu_0$.   The p-value will correspond to an upper tail.
\item[$H_A$:] $\mu\ne \mu_0$.  The p-value will correspond to both tails.
\end{itemize}

\item The one-sample $t$-test for a population mean or mean difference has the same conditions as the one-sample $t$-interval.  We check that the following conditions are met.
\begin{itemize}
\item[1.] Independence:  The data come from a random sample or random process.  When sampling without replacement, check that the sample size is less than 10\% of the population size.
\item[2.] Large sample or normal population: $n\ge 30$ or population distribution is nearly normal. If the sample size is less than 30 and the population distribution is unknown, check and confirm that there is no strong skew or outliers in the data in order to reasonably assume that the population distribution is nearly normal.
\end{itemize}

\item A test statistic has the form: \\
$$\text{test statistic} = \frac{\text{point estimate } - \text{ null value}}{SE \text{ of estimate}} .$$  

\item 
The test statistic for a one-sample $t$-test for $\mu$ is: \\
$$T = \frac{\bar{x} - \mu_0}{\frac{s}{\sqrt{n}}}\ ,\ df = n-1$$ \\
When the null hypothesis is true, the $t$-statistic follows a $t$-distribution with $df = n-1$.  

\item The p-value for a one-sample $t$-test for $\mu$ corresponds to a lower tail, upper tail, or both tails of the $t$-distribution with $n-1$ degrees of freedom, depending on whether the direction of the alternate hypothesis is $<$, $>$, or $\ne$.

\item The p-value for a one-sample $t$-test for $\mu$ is the probability of obtaining a $t$-statistic as small or smaller, as large or larger, or as extreme or more extreme than the $t$-statistic that was observed, depending on whether the direction of the alternate hypothesis is $<$, $>$, or $\ne$, assuming the null hypothesis is true (i.e. that the population mean really equals $\mu_0$).  

\item A formal decision explicitly compares the p-value to the significance level.  If the \mbox{p-value $\le \alpha$,} then reject the null hypothesis; if the \mbox{p-value $> \alpha$,} then fail to reject the null hypothesis.   The conclusion should be stated in terms of the alternative hypothesis and should include context, referencing the parameters and the populations, using non-causal language.

\end{itemize}



%%%%%Section exercises
{\input{ch_inference_for_means/TeX/hypothesis_testing_for_a_population_mean.tex}}




%______________________________________________
\section[Sampling distribution for a difference in sample means]{Sampling distribution for \pmb{$\bar{x}_1-\bar{x}_2$}}
\label{distributionofdifferenceofmeans}

\sectionintro{
\noindent%
If two populations means are the same, how much variability can we expect in sample means based on random samples of a certain size?  In this section, we describe the sampling distribution for a difference in sample means, and we find the probability that a sample difference would be greater than a certain value due to chance variation.

%%
\subsection*{Learning objectives}
\begin{enumerate}
\setlength{\itemsep}{0mm}


\item Calculate and interpret the mean and standard deviation of a sampling distribution for a difference in sample means.

\item Determine if the sampling distibution for a difference in sample means is approximately normal.

\item If appropriate, use the normal distribution to estimate probabiliies involving a difference in sample means and interpret these quantities. 

\end{enumerate}
}


\D{\newpage}

%%
\subsection{A sampling distribution for a difference in sample means} 

In hypothesis testing, we would like to ask:  assuming two population means are the same, what is the likelihood that two sample means will be as different as we observed in our samples?  To be able to calculate this p-value, we need to understand the properties of the sampling distribution for the difference of sample means.

In Section~\ref{distributionofxbar} we started with all of the data from the 2017 Cherry Blossom Run, and we considered what the sampling distribution for a mean would look like for random samples of size $n$.  The population mean for all the runners is 94.52 minutes and the population standard deviation is 15.93 minutes.  Now imagine taking two independent random samples of size 50 from this population.  What is the likelihood that the sample means from these two independent random samples (from populations with the same mean) would differ by at least 3 minutes?

In Section~\ref{distributionofdifference}, we conducted a simulation for the sampling distribution of $\hat{p}_1-\hat{p}_2$.  Here, we will conduct a simulation to approximate the sampling distribution of $\bar{x}_1 - \bar{x}_2$.  We take two separate and independent random samples of size 50 from the population of run time values, and the we find the difference in the sample means, rounded to the nearest 0.5.  We repeat this 300 times, giving us 300 values of  $\bar{x}_1 - \bar{x}_2$.  These 300 sample differences are graphed in Figure~\ref{diffmeanssimulation}.

We see that the distribution in Figure~\ref{diffmeanssimulation} is centered on 0, which makes sense because the samples come from the same population so the the sampling distributions for the mean have the same center.  Each dot in  Figure~\ref{diffmeanssimulation} represents one value of $\bar{x}_1 - \bar{x}_2$.  

Given that the samples are from the same population and that their expected means are the same, what is the likelihood that the sample means from these two independent random samples would differ by at least 3 minutes?  We can count that there are 61 values at or below $-3$ and 58 values at or above 3 so, based on the simulation, we estimate that there is a $\frac{119}{300}$, or about a 39.7\% chance that the sample means will differ by at least 3 minutes.  


\begin{figure}[h]
\centering
 \Figures[A simulation of 300 values for the difference in sample means.]
{0.9}{netTime100SamplingDistributionDotPlots}{netTime100SamplingDistribution}
\caption{300 simulated differences in sample means.}
\label{diffmeanssimulation}
\end{figure}

\newpage
\subsection{Mean and standard deviation for a difference in sample means}

We would like to be able to find the mean (expected value) and the standard deviation for a difference in sample means, $\bar{x}_1 - \bar{x}_2$. We again use the formulas discussed in Section~\ref{distributionofdifference_diff_samp_props} for a difference in two independent random variables, $X - Y$, but this time we apply it to a difference in sample means:
\begin{align*}
\mu_{\bar{x}_1 - \bar{x}_2}
  &= \mu_{\bar{x}_1} - \mu_{\bar{x}_2} = \mu_1 - \mu_2 \\
\sigma_{\bar{x}_1 - \bar{x}_2}
  &= \sqrt{(\sigma_{\bar{x}_1})^2 + (\sigma_{\bar{x}_2})^2}
  =  \sqrt{\frac{\sigma_1^2}{n_1} + \frac{\sigma_2^2}{n_2}} .
\end{align*}
That is, for two independent random samples, the distribution of values of $\bar{x}_1 - \bar{x}_2$ for all random samples of size $n_1$ and $n_2$ from given populations is centered on the true difference $\mu_1-\mu_2$ and the typical distance or error of $\bar{x}_1 - \bar{x}_2$ from $\mu_1-\mu_2$ is given by $\sqrt{\frac{\sigma_1^2}{n_1} + \frac{\sigma_2^2}{n_2}}$.
%Using $\mu$ for mean and $\sigma$ for SD, we summarize this as follows.  

\begin{onebox}{Mean and standard deviation of a difference in sample means}
The mean and standard deviation of the sampling distribution for a difference in sample means describe the center and spread of the distribution of $\bar{x}_1-\bar{x}_2$ values for all random samples of size $n_1$ and $n_2$ from the given populations.
Given population means $\mu_1$ and $\mu_2$, population sizes $N_1$ and $N_2$, individual population
standard deviations $\sigma_1$ and $\sigma_2$, and independent random samples
of size $n_1$ and $n_2$, we have the following:
\begin{align*}
\mu_{\bar{x}_1 - \bar{x}_2} &= \mu_1 - \mu_2\\
\sigma_{\bar{x}_1 - \bar{x}_2}&=  \sqrt{\frac{\sigma_1^2}{n_1} + \frac{\sigma_2^2}{n_2}}  \quad \text{ when } n_1<0.10(N_1) \text{ and } n_2<0.10(N_2) 
\vspace{1mm}
\end{align*}
\end{onebox}

When sampling without replacement, as is usually the case, the standard deviation formula will provide a good estimate when the sample sizes are less than 10\% of the corresponding population sizes.




\subsection[Using a normal model for the sampling distribution for $\bar{x}_1-\bar{x}_2$]{Using a normal model for the sampling distribution for \pmb{$\bar{x}_1-\bar{x}_2$}}
%%%
In Section~\ref{distributionofdifference_diff_samp_props},
we saw that the sum or difference of two random variables will be
nearly normal if each variable is itself nearly normal and the two
random variables are independent of each other.
We use this principle to identify that the difference
of sample means can be modeled using a normal distribution when each sample mean can be modeled using a normal distribution.

\begin{description}
\setlength{\itemsep}{0mm}
\item[Independence.]
  The observations should be independent within and between groups.  The independence condition is satisfied if the data is collected from 2 independent random samples, where each sample size is less than 10\% of the population size if done without replacement.  We also consider the independence condition satisfied if the data is collected from an experiment with two randomly assigned treatments (in this case the 10\% condition is not relevant and does not need to be checked).
\item[Large sample / normal population.]
  Each population distribution should be nearly normal
  or each sample size should be at least 30.
  As before, if the sample sizes are small and the population
  distributions are not known to be nearly normal,
  we look at the data for strong skew or outliers.
  If we do not find strong skew or outliers in either group,
  the assumption that the populations are nearly normal is typically considered reasonable.
\end{description}


\begin{examplewrap}
\begin{nexample}{
  Let's return to the Cherry Blossom Run application.
  We have that the population mean for all the runners in the 2017 Cherry Blossom Run is 94.52 minutes and the population standard deviation is 15.93 minutes.  If we take two independent random samples of 50 runners, what is the probability that the sample means from these two samples will differ by at least 3 minutes?}

Since either sample mean could be at least 3 minutes greater than the other sample mean, we want to find:
$P(\bar{x}_1 - \bar{x}_2 \le -3) + P(\bar{x}_1 - \bar{x}_2 \ge 3)$.
% = 2\times P(\bar{x}_1 - \bar{x}_2 > 3)$.  

First, we find the mean of  $\bar{x}_1-\bar{x}_2$: 
\begin{align*}
\mu_{\bar{x}_1-\bar{x}_2} &= \mu_1-\mu_2 = 94.52-94.52 = 0 
\end{align*}

Because the two random samples are independent and the sample sizes of $n_1=50$ and $n_2=50$ are both less than 10\% of the total number of runners, we calculate the standard deviation of $\bar{x}_1-\bar{x}_2$ as:  
\begin{align*}
\sigma_{\bar{x}_1-\bar{x}_2}
  &= \sqrt{\frac{\sigma_1^2}{n_1} + \frac{\sigma_2^2}{n_2}}
  = \sqrt{\frac{15.93^2}{50} + \frac{15.93^2}{50}}= 3.186
\end{align*}

Because the sample sizes $n_1$ and $n_2$ are both 50, and $50 \ge 30$, the distribution of $\bar{x}_1-\bar{x}_2$ is nearly normal whether or not the population distribution of run times is nearly normal.  Therefore, $\bar{x}_1-\bar{x}_2$ is approximately Normal($\mu$ = 0, $\sigma$ = 3.186). 

Using technology, we find that $P(\bar{x}_1 - \bar{x}_2 \le -3) + P(\bar{x}_1 - \bar{x}_2 \ge 3)$ = 0.173 + 0.173 = 0.346.     
\begin{center}
\Figure [A normal distribution is shown with mean 0 and standard deviation 3.186.  Two tails areas are shaded in:  the area to the left of -3 and the area to the right of positive 3.  The shaded area is about 34.6\% of the total area. ] {0.5}{cherry_blossom_2_mean_diff}
\end{center}
Even though the samples are from the same population of runners,
there is still about a 34.6\% probability that the sample means will differ by more than 3~minutes.
\end{nexample}
\end{examplewrap}

We can also find the probability above using the Z-score and the standard normal distribution, Normal($\mu=0$, $\sigma=1$), as follows:
\begin{align*}
Z =  \frac{3 - 0}{\sqrt{\frac{15.93^2}{50} + \frac{15.93^2}{50}}}=-0.942\\
P(Z \le -0.942) + P(Z \ge 0.942) = 0.346.
\end{align*}
\begin{center}
 \Figures[A normal distribution with a mean of 0 and standard deviation of 1 has the area below the distribution shaded for horizontal values smaller than -0.942 or greater than 0.942.]
{0.5}{cherry_blossom_2_mean_diff}{cherry_blossom_2_mean_diffZ}
\end{center}
We arrive at the same answer that there is about a 34.6\% chance that the sample means will differ by at least 3~minutes.  In Section~\ref{differenceOfTwoMeansTest}, Hypothesis testing for a difference in population means, we will see parallels between the calculation of the Z-score above and the calculation of the test statistic. 

\D{\newpage}

%%
\subsection*{Section summary}

\begin{itemize}


\item $\bar{x}_1-\bar{x}_2$ represents a difference in sample means and can take on different values for different samples.  For two independent populations, the sampling distribution of $\bar{x}_1-\bar{x}_2$ is the distribution of values of $\bar{x}_1-\bar{x}_2$ for all random samples of size $n_1$ and $n_2$ from given populations.

\item When the observations can be treated as independent, such as from two independent random samples or two randomly assigned treatments:
\begin{itemize}
\item The \textbf{mean} of the sampling distribution of $\bar{x}_1-\bar{x}_2$ is given by:  \\
 $\mu_{\bar{x}_1-\bar{x}_2}$ = $\mu_1-\mu_2$, where $\mu_1$ and $\mu_2$ are population means.

\item The \textbf{standard deviation} of the sampling distribution of $\bar{x}_1-\bar{x}_2$ is given by: \\
$\sigma_{\bar{x}_1-\bar{x}_2}$ =  $ \sqrt{\frac{\sigma_1^2}{n_1} + \frac{\sigma_2^2}{n_2}}$, where $\sigma_1$ and $\sigma_2$ are population standard deviations.  If randomly sampling without replacement, with each sample size should be less than the corresponding population size, i.e. $n_1<0.10(N_1$ and $n_2<0.10(N_2)$, for this standard deviation formula to be used.  If data is collected from an experiment with two randomly assigned treatments, the 10\% condition does not need to be checked.

  \item The \textbf{shape} of the sampling distribution of a difference in sample means is approximately normal when the distributions for both populations are nearly normal or when $n_1\ge 30$ and $n_2\ge 30$.  

\end{itemize}

\item $\mu_{\bar{x}_1-\bar{x}_2}$, the mean of $\bar{x}_1-\bar{x}_2$, describes the average of values of  $\bar{x}_1-\bar{x}_2$ for all random samples of size $n_1$ and $n_2$ from the given populations.  

\item $\sigma_{\bar{x}_1-\bar{x}_2}$, the standard deviation of $\bar{x}_1-\bar{x}_2$, describes the typical variation in values of $\bar{x}_1-\bar{x}_2$ from $\mu_1-\mu_2$ for all random samples of size $n_1$ and $n_2$ from the given populations.  

\item To use a normal model to find probabilities involving a difference in sample means, first verify that the conditions for independence are met and that the distributions for both populations are nearly normal or $n_1\ge 30$ and $n_2\ge 30$.   Identify the distribution and its parameters, write the relevant probability statement, and answer the question in context.

\item The mean, standard deviation, and probabilities for the sampling distribution
for a difference between two sample means should be interpreted
within the context of two specific populations.

\end{itemize}

%%%%%%%%%%Section exercises
{\input{ch_inference_for_means/TeX/sampling_distribution_for_a_difference_in_sample_means.tex}}



%________________________________
\section[Confidence intervals for a difference in population means]{Confidence intervals for \pmb{$\mu_1-\mu_2$}}
\label{differenceOfTwoMeansCI}%

\sectionintro{
\noindent%
Can a name affect how much an employer is willing to pay an applicant?  Are faculty willing to pay someone named ``John" more than someone named ``Jennifer"?  If so, how much more?  In this section we will learn a confidence interval procedure for estimating a difference between two means.


%%
\subsection*{Learning objectives}
\begin{enumerate}
\setlength{\itemsep}{0mm}

\item Determine when it is appropriate to use a one-sample $t$-procedure versus a two-sample $t$-procedure.

\item Identify and set up an appropriate confidence interval procedure for estimating the difference in population means $\mu_1-\mu_2$.
\item Verify whether conditions for a confidence interval for a difference in population means using a $t$-distribution are met.
\item Calculate an appropriate confidence interval for a difference in population means.

\item Calculate the standard error and margin of error for a confidence interval for a difference in population means.

\item Interpret a confidence interval for a difference in population means.

\item Justify a claim about the difference in population means based on an appropriate confidence interval

\end{enumerate}
}


%%
\subsection{Estimating a difference of means}

\index{t-interval@$t$-interval!for a difference of means|(}
\index{two-sample $t$-interval|see{$t$-interval for a difference of means}}



\newcommand{\johnn}{63}
\newcommand{\jennifern}{64}
\newcommand{\johnmean}{30,238}
\newcommand{\jennifermean}{26,508}
\newcommand{\johnsd}{5567}
\newcommand{\jennifersd}{7247}
\newcommand{\johnjenniferSE}{1151}

What's in a name?  Are employers more likely to offer interviews or higher pay to prospective employees when the name on a resume suggests the candidate is a man versus a woman?  This is a challenging question to tackle, because employers are influenced by many aspects of a resume.  Thinking back to Chapter 1, we could imagine a host of confounding factors associated with name and gender.  How could we possibly isolate just the factor of name?  We would need an experiment in which name was the only variable and everything else was held constant.

Researchers at Yale carried out precisely this experiment.
Their results were published in the Proceedings of the
National Academy of Sciences (PNAS).
The researchers sent out resumes to faculty at academic institutions
for a lab manager position.
The resumes were identical, except that on half of them the applicant's name
was John and on the other half, the applicant's name was Jennifer.
They wanted to see if faculty, specifically faculty trained in conducting
scientifically objective research, held implicit gender biases.

Unlike in a matched pairs scenario, each faculty member received only one resume.  We are interested in comparing the mean salary offered to John relative to the mean salary offered to Jennifer.  Instead of taking the average of a set of differences, we find the average of each group separately and take their difference.  Let
\begin{align*}
\bar{x}_1:& \text{ mean salary offered to John}\\
\bar{x}_2: &\text{ mean salary offered to Jennifer}
\end{align*}
We will use $\bar{x}_1 - \bar{x}_2$ as our point estimate for $\mu_1-\mu_2$.  The data is given in the table below.

\begin{center}
\begin{tabular}{l ccc}
\hline
Name\hspace{2mm}	& $n$	& $\bar{x}$	& $s$	\\
\hline 
John		& \johnn{}		& 		 \$\johnmean{} 	& \$\johnsd{}		 \\
Jennifer		& \jennifern{}		& \$\jennifermean{}		& \$\jennifersd{}		 \\
\hline
\end{tabular}
\end{center}
\label{summaryStatsForJohnJenniferStudy}
We can calculate the difference as 
\begin{align*}
 \bar{x}_1-\bar{x}_2 = \johnmean{} - \jennifermean{} = 3730.
\end{align*}

\begin{examplewrap}
\begin{nexample}
{Interpret the point estimate 3730.  Why might we want to construct a confidence interval?}
The average salary offered to John was \$3,730 higher than the average salary offered to Jennifer.  Because there is randomness in which faculty ended up in the John group and which faculty ended up in the Jennifer group, there is error in our estimate.  To measure the typical error we calculate the $SE$ for the difference in sample means.
\end{nexample}
\end{examplewrap}

We calculate the $SE$ for a difference in sample means as follows:  
\begin{align*}
SE_{\bar{x}_1-\bar{x}_2} = \sqrt{\frac{s_{1}^2}{n_{1}} + \frac{s_{2}^2}{n_{2}}}
\end{align*}

Note that the standard error for a difference in sample means follows the same structure as the standard deviation for a difference in sample means calculated in the previous section, except that we replace the unknown population standard deviations $\sigma_1$ and $\sigma_2$ with the sample standard deviations $s_1$ and $s_2$.

\begin{examplewrap}
\begin{nexample}
{Calculate and interpret the $SE$ for a difference in sample means.}
\begin{align*}
SE_{\bar{x}_1-\bar{x}_2} = \sqrt{\frac{s_{1}^2}{n_{1}} + \frac{s_{2}^2}{n_{2}}} = \sqrt{\frac{(\johnsd{})^2}{\johnn{}} + \frac{(\jennifersd{})^2}{\jennifern{}}} = \johnjenniferSE{}
\end{align*}
Using samples of size $n_1=63$ and $n_2=64$, the typical error when using $\bar{x}_1-\bar{x}_2$ to estimate $\mu_1-\mu_2$, the real difference in mean salary that the faculty would offer John versus Jennifer, is \$\johnjenniferSE{}.
\end{nexample}
\end{examplewrap}

We see that the difference in sample means of \$3,730 is more than 3 $SE$ above 0, which makes us think that the difference being 0 is unreasonable.  We would like to construct a 95\% confidence interval for the theoretical difference in mean salary that would be offered to John versus Jennifer.  For this, we need the degrees of freedom associated with a two-sample $t$-interval.  

\D{\newpage}

For the one-sample $t$-procedure, the degrees of freedom is given by the simple expression $n-1$, where $n$ is the sample size.  For the two-sample $t$-procedures, however, there is a complex formula for calculating the degrees of freedom, which is based on the two sample sizes and the two sample standard deviations.  In practice, we find the degrees of freedom using technology (see Section~\ref{2SampTint}).  If this is not possible, the alternative is to use the smaller of $n_1-1$ and $n_2-1$.  The degrees of freedom will fall between $n_1+n_2-2$ and the smaller of $n_1-1$ and $n_2-1$.

\begin{onebox}
{Degrees of freedom for two-sample T-procedures}
Use statistical software or a calculator to compute the degrees of freedom for two-sample \mbox{$t$-procedures}.  The degrees of freedom will fall between $n_1+n_2-2$ and the smaller of $n_1-1$ and $n_2-1$. 
\end{onebox}

\subsection{Conditions and calculations for a confidence interval for a difference of means}
%%%
When performing inference on a difference of means, $\mu_1-\mu_2$, we use the $t$-distribution just as we did for inference on a single mean.  In order to use the $t$-distribution, we need to check the following conditions.
\begin{description}
\setlength{\itemsep}{0mm}
\item[Independence.]
  The independence condition is satisfied if the data is collected from 2 independent random samples, where each sample size is less than 10\% of the population size if done without replacement.  We also consider the independence condition satisfied if the data is collected from an experiment with two randomly assigned treatments (in this case the 10\% condition is not relevant and does not need to be checked).
\item[Large sample / normal population.]
  Each population distribution should be nearly normal
  or each sample size should be at least 30.
  As before, if the sample sizes are small and the population
  distributions are not known to be nearly normal,
  we look at the data for strong skew or outliers.
  If we do not find strong skew or outliers in either group,
  the assumption that the populations are nearly normal is typically considered reasonable.
\end{description}



\begin{examplewrap}
\begin{nexample}{Verify that conditions are met for a two-sample $t$-test.  Then, construct the 95\% confidence interval for a difference of means.}
We noted previously that this is an experiment and that the two treatments (name Jennifer and name John) were randomly assigned.  Also, both sample sizes are well over 30, so conditions for using a $t$-interval are met.  Using technology, we find that $df= 118.1$.  Because 118.1 is not on the $t$-table, we round the degrees of freedom down to 100.  Using a $t$-table at row $df=100$ with 95\% confidence, we get a $t^{\star}$ = 1.984. We calculate the confidence interval as follows. 
\begin{align*}
\text{point estimate } &\pm \ t^{\star}\times SE \text{ of estimate}\\
3730\ &\pm \ 1.984\times \johnjenniferSE{}\\
 3730\ &\pm \ 2284\\
(1446&, 6014)
\end{align*}
\end{nexample}
\end{examplewrap}

\begin{exercisewrap}
\begin{nexercise}
Instead of using a $t$-table, use technology to calculate the 95\% confidence interval for the previous example.\footnotemark
\end{nexercise}
\end{exercisewrap}
\footnotetext{Using technology, we get the 95\% confidence interval:  (1461, 5999).}

\newpage
We are 95\% confident that the interval (\$1446, \$6014) contains the difference (John $-$ Jennifer) in mean salaries that faculty like the ones in this study would offer for a lab manager position.  That is, we are 95\% confident that the mean salary faculty like the ones in this study would offer John for a lab manager position is between \$1,446 and \$6,014 \emph{more} than the mean salary they would offer Jennifer for the position.\footnote{A similar study sent out identical resumes with different names to investigate the importance of perceived race.  Resumes with a name commonly perceived to be for a White person (e.g. Emily) were 50\% more likely to receive a callback than the same resume with a name commonly perceived to be for a Black person (e.g. Lakisha). More information is given in Appendix~\ref{data_appendix} -- see the \data{resume} data set.}   

\begin{examplewrap}
\begin{nexample}{Given that this was a well-designed experiment, can we say \emph{which} faculty discriminated in their salary offer?}
No - each faculty member received only one of the resumes.  A faculty member that offered ``Jennifer" a very low salary may have also offered ``John" a very low salary.  It is only possible to say that overall there is evidence that faculty are willing to offer John more money for the lab manager position than Jennifer.  Finding proof of bias for individual cases is a persistent challenge in enforcing anti-discrimination laws.\end{nexample}
\end{examplewrap}

\begin{exercisewrap}
\begin{nexercise}
We might imagine an experiment in which each faculty received both resumes, so that we could compare how much they would offer someone named John versus someone named Jennifer.  This would be a matched pairs experiment.  Is a matched pairs experiment feasible in this context?  Why or why not?\footnotemark 
\end{nexercise}
\end{exercisewrap}
\footnotetext{No, because what makes the experiment work is that the resumes are \emph{exactly the same} except for the name. An employer would notice something fishy if they received two identical resumes. }


%%
\subsection[Technology: the two-sample $t$-interval for $\mu_1 - \mu_2$]{Technology: the two-sample \pmb{$t$}-interval for \pmb{$\mu_1 - \mu_2$}}
\label{2SampTint}

\noindent Section~\ref{tech2T} demonstrates how to calculate the two-sample $t$-interval and the two-sample $t$-test (introduced in the next section) using Desmos, R, and the NumWorks, TI-83/84 and Casio calculator. 

\D{\newpage}
\subsection[Summary and worked example]{Summary and worked example}
%\subsection[Summary of the two-sample $t$-interval for $\mu_1 - \mu_2$]{Summary of the two-sample \pmb{$t$}-interval for \pmb{$\mu_1 - \mu_2$}}
\begin{onebox}{Constructing a confidence interval for a difference in means}
To carry out a complete confidence interval procedure to estimate the difference in population means,
\\
\\
\inferencestep{Identify} Identify the interval procedure, parameter, and confidence level.\vspace{-1mm}
\begin{itemize}
\item[] Use a \termsub{two-sample \pmb{$t$}-interval for \pmb{$\mu_1 - \mu_2$}}{t-interval@$t$-interval!for a difference of means}. Define the difference in population means $\mu_1 - \mu_2$ in words, referencing the populations of interest.  Choose a confidence level (C\%).  
\end{itemize}
 \inferencestep{Check} Check conditions for constructing a confidence interval based on a $t$-distribution.  
{\setlength{\leftmargini}{13mm}
\begin{itemize}
\setlength{\itemsep}{0mm}
\item[1.] Independence:  Data come from 2 independent random samples or from a randomized 
experiment with 2 treatments.  When sampling without replacement, check that the  
sample size is less than 10\% of the population size for each sample.
\item[2.] Large samples or normal populations:  $n_1\ge 30$ and $n_2\ge 30$ or both population 
distributions are nearly normal.  If the sample sizes are less than 30 and the population distributions are unknown, there should be no strong skew or outliers in either data set (this makes us believe that it is reasonable that both population distributions could be nearly normal).  
\end{itemize}
}
 \inferencestep{Calculate}  Calculate the confidence interval and record it in interval form.
\begin{itemize}
\item[] $\text{point estimate}\ \pm \ t^{\star} \times SE\ \text{of estimate}$, \quad $df$: use technology to calculate
\begin{itemize}
\item[] point estimate: $\bar{x}_1 - \bar{x}_2$, the difference in sample means 
\item[] $SE$ of estimate:  $\sqrt{\frac{s^2_1}{n_1}+\frac{s^2_2}{n_2}}$
\item[] $t^{\star}$: use technology or use a $t$-table at row $df$ and confidence level C\%
\end{itemize}
\item[] (\underline{\ \ \ \ \ }, \underline{\ \ \ \ \ })
\end{itemize}
 \inferencestep{Conclude} Interpret the interval and, if applicable, draw a conclusion in context.\vspace{-1mm}
\begin{itemize}
\item[] We are C\% confident that the interval (\underline{\ \ \ \ \ }, \underline{\ \ \ \ \ }) contains the difference (specify order) in the true mean [...].  If applicable, draw a conclusion based on whether the interval is entirely above, is entirely below, or contains the value 0. 
\end{itemize}\end{onebox}

\begin{examplewrap}
\label{twoexams}
\begin{nexample}
{
An instructor decided to run two slight variations of the same exam. Prior to passing out the exams, she shuffled the exams together to ensure each student received a random version. Summary statistics for how students performed on these two exams are shown in Figure~\ref{summaryStatsForTwoVersionsOfExams2nd}. Anticipating complaints from students who took Version~B, she would like to evaluate whether the difference observed in the groups is so large that it provides convincing evidence that Version~B was more difficult (on average) than Version~A.  Use a 95\% confidence interval to estimate the difference (version A $-$ version B) in average score.

\begin{center}
\begin{tabular}{l rrrrr}
\hline
Version\hspace{2mm}	& $n$	& $\bar{x}$	& $s$	& min	& max  \\
\hline
A		& 30		& 79.4		& 14 	& 45		& 100 \\
B		& 30		& 74.1		& 20		& 32		& 100 \\
\hline
\end{tabular}
\end{center}
\label{summaryStatsForTwoVersionsOfExams2nd}

}
\begin{description}
\item[\inferencestep{Identify}] Because we are estimating the difference between two means, we will use a two-sample $t$-interval for $\mu_1 - \mu_2$. We define $\mu_1 - \mu_2$ as the difference (Version A $-$ Version B) in average score, and we will estimate this parameter at the 95\% confidence level.

\item[\inferencestep{Check}] The data was collected from a randomized experiment with two treatments:  Version A and Version B of test.   The 10\% condition does not need to be checked here because we are not sampling from a population.  There were 30 students in each group, so the condition that both group sizes are at least 30 is met.   
\item[\inferencestep{Calculate}]  We will calculate the confidence interval as follows.
\begin{align*}
\text{point estimate}\ \pm\ t^{\star} \times SE\ \text{of estimate}
\end{align*}
The point estimate is the difference in sample means: $\bar{x}_1-\bar{x}_2 = 79.4 - 74.1 = 5.3$.\\
\\
$SE$ of $\bar{x}_1-\bar{x}_2$ = $\sqrt{\frac{s_1^2}{n_1} + \frac{s_2^2}{n_2}} = \sqrt{\frac{14^2}{30} + \frac{20^2}{30}} = 4.46$. \\

Using technology, we find $df=51.9$ and $t^{\star} = 2.007$.  The 95\% confidence interval is given by:
\begin{align*}
(79.4 - 74.1) \ \pm\  &2.007\times \sqrt{\frac{14^2}{30} + \frac{20^2}{30}}   \qquad df = 51.9\\
5.3 \ \pm\  &2.007\times 4.46 \\
(-3.6&6,\ 14.26)
\end{align*}
\item[\inferencestep{Conclude}]  We are 95\% confident that the interval ($-$3.66, 14.26) contains the difference (Version A $-$Version B) in average score that students like those in the study would receive if given Version A or Version B.  Because the interval contains both positive and negative values, the data do not convincingly show that one exam version is more difficult than the other, and the teacher should not be convinced that she should add points to the Version B exam scores.

\end{description}
\end{nexample}
\end{examplewrap}


\D{\newpage}


\index{t-interval@$t$-interval!for a difference of means|)}

%%%%%Section exercises
\subsection*{Section summary}
\begin{itemize} 
\item This section introduced inference for a difference of means, which is distinct from inference for a mean difference.  To calculate a difference of means, $\bar{x}_1-\bar{x}_2$, we first calculate the mean of each group, then we take the difference between those two statistics.  To calculate a mean difference, $\bar{x}_{\text{\emph{d}}}$, we first calculate all of the differences, then we find the mean of those differences.

\item The appropriate confidence interval to estimate a difference between two population means $\mu_1$ and $\mu_2$ is a \termni{two-sample \pmb{$t$}-interval for \pmb{$\mu_1-\mu_2$}}.  The parameters $\mu_1$ and $\mu_2$ should be identified in context.

\item The two-sample $t$-interval for a difference in population means requires the follow conditions be met:  
\begin{itemize}
\item[1.] Independence:  The data come from two independent random samples, each with sample size $<$10\% of its corresponding population size if sampling without replacement OR the data come from a randomized experiment with two randomly assigned treatments.
\item[2.] Large sample or normal population: both sample sizes are at least 30 or both population distributions are nearly normal. If either sample size is less than 30 and the population distributions are unknown, check and confirm that there is no strong skew or outliers in either data set in order to reasonably assume that the population distributions are nearly normal.
\end{itemize}

\item The general form for a C\% confidence interval is: 
\begin{align*}
\text{point estimate}\ &\pm\ \text{margin of error}, \ \text{or}\\
\text{point estimate}\ &\pm\ \text{critical value} \times SE\ \text{of estimate}.
\end{align*}
\item A two-sample $t$-interval for a difference in population means $\mu_1-\mu_2$ can be written as follows:
\begin{center}
$(\bar{x}_1-\bar{x}_2) \ \pm\  t^{\star} \sqrt{\frac{s^2_1}{n_1}+\frac{s^2_2}{n_2}}$ , \ $df$: use technology.
\end{center}
$df$ is calculated using technology and will fall between $n_1+n_2-2$ and the smaller of $n_1-1$ and $n_2-1$. $t^{\star}$ is the critical value for the middle C\% of a $t$-distribution with the appropriate degrees of freedom. 


\item The $SE$ of $\bar{x}_1-\bar{x}_2$ is:  $\sqrt{\frac{s^2_1}{n_1}+\frac{s^2_2}{n_2}}$.


\item The margin of error of $\bar{x}_1-\bar{x}_2$ is: $t^{\star}\sqrt{\frac{s^2_1}{n_1}+\frac{s^2_2}{n_2}}$.

\item The interpretation of the confidence level C\% is:  In repeated random
sampling with the same sample size from the same populations, approximately
C\% of confidence intervals created will capture the true difference between the two
population means.

\item When interpreting a C\% confidence interval for a difference between two
population means, we say we are C\% confident that the interval (\underline{\ \ \ \ }, \underline{\ \ \ \ }) contains
the value of the difference in the population means.

\end{itemize}


%%%%%%%%%%Section exercises
{\input{ch_inference_for_means/TeX/confidence_intervals_for_a_difference_in_population_means.tex}}

%%
\section[Hypothesis testing for a difference in population means]{Hypothesis testing for \pmb{$\mu_1-\mu_2$}}
\label{differenceOfTwoMeansTest}
%Do not include the test with pooled standard deviations are grouped but mention it as one method that is discussed in other books. The reason: this is a poor test. If the sd's are remotely similar then the result will be basically the same as the sd's are not assumed to be the same. It is a big assumption that can cause problems with almost no benefits.

\sectionintro{
\noindent%
How do we measure how much evidence we have of a difference in means between two treatments or populations?  For example, how much evidence is there that using embryonic stem cells helps improve heart function following a heart attack?  Is there a significance difference in the average weight of newborns between mothers who smoke versus mothers who do not smoke?   In this section, we apply the hypothesis testing framework to a difference of population means.  


%%
\subsection*{Learning objectives}
\begin{enumerate}
\setlength{\itemsep}{0mm}

\item Determine when it is appropriate to use a one-sample $t$-procedure versus a two-sample $t$-procedure.

\item Identify and set up an appropriate testing method for a difference in population means $\mu_1-\mu_2$.

\item Verify whether conditions for the hypothesis test for a difference in population means using a $t$-distribution are met.

\item Calculate the $t$-statistic, degrees of freedom and p-value for a hypothesis test for a difference in population means.

\item Interpret the p-value of a hypothesis test for a difference in population means.

\item Justify a claim about the difference in population means based on the results of the test.  

\end{enumerate}
}


\index{data!baby\_smoke|(}
\index{t-test@$t$-test!for a difference of means|(}
\index{two-sample $t$-test|see{$t$-test for a difference of means}}


\subsection{Introducing hypothesis testing for a difference of means}

Four cases from a data set called \data{ncbirths}, which represents mothers and their newborns in North Carolina, are shown in Figure~\ref{babySmokeDF}. We are particularly interested in two variables: \var{weight} and \var{smoke}. The \var{weight} variable represents the weights of the newborns and the \var{smoke} variable describes which mothers smoked during pregnancy. We would like to know, is there convincing evidence that newborns from mothers who smoke have a different average birth weight than newborns from mothers who don't smoke? The smoking group includes a random sample of 50 cases and the nonsmoking group contains a random sample of 100 cases, represented in Figure~\ref{babySmokePlotOfTwoGroupsToExamineSkew}.

\begin{figure}[h]
\centering
\begin{tabular}{rrrrrll}
  \hline
 & fAge & mAge & weeks & weight & sex & smoke \\ 
  \hline
1 & NA & 13 &  37 & 5.00 & female & nonsmoker \\ 
  2 & NA & 14 &  36 & 5.88 & female & nonsmoker \\ 
  3 & 19 & 15 &  41 & 8.13 & male & smoker \\ 
  $\vdots$ &   $\vdots$ &   $\vdots$ &   $\vdots$ &   $\vdots$ &   $\vdots$ \\
  150 & 45 & 50 &  36 & 9.25 & female & nonsmoker \\ 
   \hline
\end{tabular}
\caption{Four cases from the \data{ncbirths} data set. The value ``NA'', shown for the first two entries of the first variable, indicates pieces of data that are missing.}
\label{babySmokeDF}
\end{figure}

\begin{figure}[hhh]
\centering
  \Figure[Two histograms are shown for "Newborn Weights, in pounds", one for "Mothers Who Smoked" and one for "Mothers Who Did Not Smoke". The histogram for "Mothers Who Smoked" is centered at about 7 and is left-skewed, with values ranging from about 1 pound to 10 pounds. The histogram for "Mothers Who Did Not Smoke" is centered at about 7.5 and is left-skewed, with values ranging from about 1 pound to 11 pounds.]
{0.63}{babySmokePlotOfTwoGroupsToExamineSkew}
\caption{The top panel represents birth weights for infants whose mothers smoked. The bottom panel represents the birth weights for infants whose mothers who did not smoke. The distributions exhibit moderate-to-strong and strong~skew, respectively.}
\label{babySmokePlotOfTwoGroupsToExamineSkew}
\end{figure}

\D{\newpage}

\begin{examplewrap}
\begin{nexample}{Set up appropriate hypotheses to evaluate whether there is a relationship between a mother smoking and average birth weight.}\label{babySmokeHTForWeight}
We define our parameters as follows:\\
$\mu_{1}$:  mean birth weight of newborns from North Carolina mothers who did smoke during pregnancy\\
$\mu_2$: mean birth weight of newborns from North Carolina mothers who did not smoke during pregnancy\\
\begin{itemize}
\setlength{\itemsep}{0mm}
\item[$H_0$:] $\mu_{1} - \mu_{2} = 0$.  There is no difference in average birth weight for newborns from mothers who did and did not smoke. 
\item[$H_A$:] $\mu_{1} - \mu_{2} \neq 0$. There is some difference in average newborn weights from mothers who did and did not smoke.
\end{itemize}
\end{nexample}
\end{examplewrap}

\subsection{Checking conditions for a hypothesis test for a difference of means}
The conditions for a two-sample $t$-test for $\mu_1-\mu_2$ are exactly the same as the conditions for a two-sample $t$-interval for $\mu_1-\mu_2$.  
\begin{description}
\setlength{\itemsep}{0mm}
\item[Independence.]
  The independence condition is satisfied if the data is collected from 2 independent random samples, where each sample size is less than 10\% of the population size if done without replacement.  We also consider the independence condition satisfied if the data is collected from an experiment with two randomly assigned treatments (in this case the 10\% condition is not relevant and does not need to be checked).
\item[Large sample / normal population.]
  Each population distribution should be nearly normal
  or each sample size should be at least 30.
  As before, if the sample sizes are small and the population
  distributions are not known to be nearly normal,
  we look at the data for strong skew or outliers.
  If we do not find strong skew or outliers in either group,
  the assumption that the populations are nearly normal is typically considered reasonable.
\end{description}

Let's check the two conditions necessary to use the $t$-distribution to the difference in sample means for the North Carolina births data set. (1)~We will assume that we have two independent random samples and that the populations they were sampled from are much larger than 10 times the sample sizes of 50 and 100.  (2)~The sample sizes of 50 and 100 are well over 30, so we do not worry about the distributions of the original populations.  Since both conditions are satisfied, we can use the two-sample $t$-test for $\mu_1-\mu_2$.  

%Summary statistics are shown for each sample in Figure~\ref{summaryStatsOfBirthWeightForNewbornsFromSmokingAndNonsmokingMothers}.

\begin{figure}[hhh]
\centering
\begin{tabular}{lrr}
	& \resp{smoker} & \resp{nonsmoker} \\
\hline
mean & 6.78 & 7.18 \\
st. dev. & 1.43 & 1.60 \\
samp. size & 50 & 100 \\
\hline
\end{tabular}
\caption{Summary statistics for the \data{ncbirths} data set.}
\label{summaryStatsOfBirthWeightForNewbornsFromSmokingAndNonsmokingMothers}
\end{figure}

\begin{examplewrap}
\begin{nexample}
{We will use the summary statistics in Figure~\ref{summaryStatsOfBirthWeightForNewbornsFromSmokingAndNonsmokingMothers} for this exercise.
\\ (a)~What is the point estimate of the population difference, $\mu_{1} - \mu_{2}$? 
\\(b)~Compute the standard error of the point estimate from part (a).}
(a)~The point estimate is the difference in sample means: $\bar{x}_{1} - \bar{x}_{2} = 6.78-7.18=-0.40$ pounds. \\
(b)~The standard error formula for a difference in sample means looks like the standard deviation formula for a difference in sample means, but with the sample standard deviations used in place of the population standard deviations.
\begin{eqnarray*}
SE_{\bar{x}_1-\bar{x}_2} = \sqrt{\frac{s_1^2}{n_1} + \frac{s_2^2}{n_2}}
	= \sqrt{\frac{1.43^2}{50} + \frac{1.60^2}{100}}
	= 0.26 \text{ pounds}
\end{eqnarray*}
\end{nexample}
\end{examplewrap}


\begin{examplewrap}
\begin{nexample}{Compute the test statistic. } \label{babySmokeHTForWeightComputePValueAndEvalHT}
We have already found the point estimate and the $SE$ of estimate.  The null hypothesis is that the two means are equal, or that their difference equals 0.  The null value for the difference, therefore is~0.  We now have everything we need to compute the test statistic.
\begin{eqnarray*}
T = \frac{\text{point estimate} - \text{null value}}{SE \text{ of estimate}} =  \frac{\ (6.78 - 7.18) - 0\ }{\sqrt{\frac{1.43^2}{50} + \frac{1.60^2}{100}}} = \frac{\ -0.40 - 0\ }{0.26} = -1.54
\end{eqnarray*}
\end{nexample}
\end{examplewrap}

\begin{examplewrap}
\begin{nexample}{Calculate the p-value for this hypothesis test.}
\label{pictureOfPValueForEstimateOfDiffOfMeansOfBirthWeights}
We want to find tail areas of a $t$-distribution, but we need to know the degrees of freedom for the $t$-distribution.  We saw previously that we can use the smaller of $n_1-1$ and $n_2-1$ for the degrees of freedom and then use a $t$-table to get the p-value if technology is not available.  Alternately, we can use a technology option from Section~\ref{tech2T} to find that the appropriate degrees of freedom for this test is 108.5.  For the $t$-distribution with $df = 108.5$, shown in Figure~\ref{tdf108}, the area to the left of $T=-1.54$ is 0.062.  Because this is a two-sided test, we care about both tails so we double this and find that the p-value is 0.124.
\end{nexample}
\end{examplewrap}

\begin{figure}
\centering
 \Figures[A bell-shaped curve that resembles a normal distribution is shown centered 0. The upper tail is shaded above a value marked as 1.54 and the corresponding lower tail is also shaded. These tails together appear to represent about 10\% to 15\% of the area under the distribution.]{0.6}{distOfDiffOfSampleMeansForBWOfBabySmokeData}{distOfDiffOfSampleMeansForBWOfBabySmokeDataT}
\caption{A $t$-distribution with 108.5 degrees of freedom.  Values at least as extreme as our test statistic of $-$1.54 are shaded.}
\label{tdf108}
\end{figure}

\begin{examplewrap}
\begin{nexample}{Interpret the p-value of 0.124 in the context of the problem.}
In this context, a p-value of 0.124 means that there is a 12.4\% probability of getting a T-statistic less than or equal to $-$1.54 or greater than or equal to 1.54 assuming there really is no difference in mean birth weight of newborns from North Carolina mothers who did smoke during pregnancy and newborns from North Carolina mothers who did not smoke during pregnancy. Equivalently, we can say that there is a 12.4\% probability of getting a difference in sample means as small or smaller than $-$0.40 or as large or larger than 0.40 with random samples of these sizes assuming there really is no difference in mean birth weight of newborns from North Carolina mothers who did smoke during pregnancy and newborns from North Carolina mothers who did not smoke during pregnancy.  In both cases, we are assessing the probability of getting a difference as extreme as we observed, under the assumption that $H_0$ is true.
\label{pvaluediffofmeans}
\end{nexample}
\end{examplewrap}




\begin{examplewrap}
\begin{nexample}{What can we conclude from this p-value?  Use a significance level of $\alpha=0.05$.  }
\label{pictureOfPValueForEstimateOfDiffOfMeansOfBirthWeights}
This p-value of 0.124 is larger the significance level of 0.05, so we do not reject the null hypothesis. There is not sufficient evidence to say there is a difference in average birth weight of newborns from North Carolina mothers who did smoke during pregnancy and newborns from North Carolina mothers who did not smoke during pregnancy.
\end{nexample}
\end{examplewrap}




\begin{examplewrap}
\begin{nexample}
{Does the conclusion to Example~\ref{babySmokeHTForWeightComputePValueAndEvalHT} mean that smoking and average birth weight are unrelated?}
Not necessarily. It is possible that there is some difference but that we did not detect it.  The result must be considered in light of other evidence and research.  In fact, larger data sets do tend to show that women who smoke during pregnancy have smaller newborns.
\end{nexample}
\end{examplewrap}


\begin{exercisewrap}
\begin{nexercise}
If we made an error in our conclusion, which type of error could we have made: Type~I or Type~II?\footnotemark
\end{nexercise}
\end{exercisewrap}
\footnotetext{Since we did not reject $H_0$, it is possible that we made a Type~II Error.  It is possible that there is some difference but that we did not detect it. }


\begin{exercisewrap}
\begin{nexercise} \label{babySmokeHTIDingHowToDetectDifferences}
If we made a Type~II Error and there is a difference, what could we have done differently in data collection to be more likely to detect the difference?\footnotemark
\end{nexercise}
\end{exercisewrap}
\footnotetext{We could have collected more data. If the sample sizes are larger, we tend to have a better shot at finding a difference if one exists.  In other words, increasing the sample size increases the power of the test.}
% Resource on this topic:
% http://archive.tobacco.org/Documents/documentquotes.html

\index{data!baby\_smoke|)}

\D{\newpage}
\subsection[Summary and worked example]{Summary and worked example}
%\subsection[Summary of the two-sample $t$-test for $\mu_1 - \mu_2$]{Summary of the two-sample \pmb{$t$}-test for \pmb{$\mu_1 - \mu_2$}}
\begin{onebox}{Hypothesis test for a difference in means}
To carry out a complete hypothesis test to compare two population means,
\\
\\
\inferencestep{Identify} Identify the test procedure, parameter, significance level, and hypotheses.\vspace{-1mm}
\begin{itemize}
\item[] Use a \termsub{two-sample \pmb{$t$}-test for \pmb{$\mu_1 - \mu_2$}}{t-test@$t$-test!for a difference of means}.  Define the population means $\mu_1$ and  $\mu_2$ in words, referencing the populations of interest.  Choose a significance level ($\alpha$) and test the following hypotheses.
\end{itemize}
\begin{itemize}
\setlength{\itemsep}{0mm}
\item[] \quad \ $H_0$: \,$\mu_1 = \mu_2 $ \qquad  \qquad  \qquad  \qquad \qquad \quad \:  \: \: ($\mu_1 - \mu_2  =0$)
\item[] \quad \ $H_A$: $\mu_1\ne \mu_2 $; \; $\mu_1 > \mu_2 $; \; or \; $\mu_1 < \mu_2$ \qquad  ($\mu_1- \mu_2 \ne 0$; \; $\mu_1 - \mu_2 > 0$; \; or \; $\mu_1 - \mu_2 < 0$)
\end{itemize}
 \inferencestep{Check} Check conditions for the test statistic to have a $t$-distribution, assuming $H_0$ is true.  \vspace{-1mm}
{\setlength{\leftmargini}{13mm}
\begin{itemize}
\setlength{\itemsep}{0mm}
\item[1.] Independence:  Data come from 2 independent random samples or from a randomized 
experiment with 2 treatments.  When sampling without replacement, check that the  
sample size is less than 10\% of the population size for each sample.
\item[2.] Large samples or normal populations:  $n_1\ge 30$ and $n_2\ge 30$ or both population 
distributions are nearly normal.  If the sample sizes are less than 30 and the population distributions are unknown, there should be no strong skew or outliers in either data set (this makes us believe that it is reasonable that both population distributions could be nearly normal).    
\end{itemize}
}
 \inferencestep{Calculate}  Calculate the $t$-statistic, $df$, and p-value.
\begin{itemize}
\item[] $T = \frac{\text{point estimate } - \text{ null value}}{SE \text{ of estimate}}$ \quad $df$: use technology to calculate
\begin{itemize}
\item[] point estimate: $\bar{x}_1 - \bar{x}_2$, the difference in sample means 
\item[] $SE$ of estimate:  $\sqrt{\frac{s^2_1}{n_1}+\frac{s^2_2}{n_2}}$
\item[] null value: 0
\end{itemize}
\item[] p-value = (based on the $t$-statistic, the $df$, and the direction of $H_A$)
\end{itemize}
 \inferencestep{Conclude} Compare the p-value to $\alpha$, and draw a conclusion in context.\vspace{-1mm}
\begin{itemize}
\item[] If the p-value is $\le \alpha$, reject $H_0$; there is sufficient evidence that [$H_A$ in context]. 
\item[] If the p-value is $> \alpha$, do not reject $H_0$; there is not sufficient evidence that [$H_A$ in context].
\end{itemize}\end{onebox}




\D{\newpage}
\index{data!stem cells, heart function|(}

\begin{examplewrap}
\label{ESC}
\begin{nexample} 
{\label{exerciseToEvaluteWhetherESCsAreHelpfulInImprovingHeartFunctionInSheep}
Do embryonic stem cells (ESCs) help improve heart function following a heart attack? The following table and figure summarize results from an experiment to test ESCs in sheep that had a heart attack.
\begin{center}
  \Figure[Two histograms are shown, one for "Embryonic stem cell transplant" and one for "Control (no treatment)". The data for the first histogram for the treatment group are roughly centered at about 3\%, with values ranging from about -5\% to positive 15\%. The data for the second histogram, which represents the control group, is approximately centered at -3\%, with values ranging from -10\% to about positive 2\%.]
{0.95}{stemCellTherapyForHearts}

\begin{tabular}{l rrrrr}
\hline
\hspace{10mm}	& $n$	& $\bar{x}$	& $s$  	 \\
\hline
ESCs		& 9		& 3.50		& 5.17  	\\
control		& 9		& -4.33		& 2.76  	 \\
\hline
\end{tabular}
\end{center}
Each of these sheep was randomly assigned to the ESC or control group, and the change in their hearts' pumping capacity was measured. A positive value generally corresponds to increased pumping capacity, which suggests a stronger recovery. The sample data is also graphed.  Use the given information and an appropriate statistical test to answer the research question.
}
\begin{description}
\item[\inferencestep{Identify}]  Because we are hypothesizing about a difference of means we use a two-sample $t$-test for $\mu_1 - \mu_2$.  Here,  $\mu_1$ is the mean percent change for sheep that would receive ESC and $\mu_2$ is the mean percent change for sheep that would be in the control group.  We will test the following hypotheses at the $\alpha=0.05$ significance level.\vspace{-1mm}
\begin{itemize}
\setlength{\itemsep}{0mm}
\item[]  $H_0$:\, $\mu_{1} = \mu_{2} $  
\item[] $H_A$: $\mu_{1} > \mu_{2} $ 
\end{itemize}
\item[\inferencestep{Check}]  The data come from a randomized experiment with two treatment groups: ESC and control.  Because this is an experiment, we do not need to check the 10\% condition.  The group sizes are small, but the data show no strong skew or outliers, so the assumption that the population distributions are nearly normal is reasonable.
\item[ \inferencestep{Calculate} ]  We will calculate the $t$-statistic and the p-value.
\begin{align*}
T = \frac{\text{point estimate } - \text{ null value}}{SE \text{ of estimate}}
\end{align*}
The point estimate is the difference in sample means: $\bar{x}_{1} - \bar{x}_{2}=3.50 - (-4.33) = 7.83$.\\
\\
$SE$ of $\bar{x}_1-\bar{x}_2$ = $\sqrt{\frac{s_1^2}{n_1} + \frac{s_2^2}{n_2}}= \sqrt{\frac{(5.17)^2}{9} + \frac{(2.76)^2}{9}} = 1.95$.\\
\\
The null value is the hypothesized difference in population means, which is 0.
\begin{align*}
T = \frac{(3.50 - (-4.33)) - 0}{\sqrt{\frac{(5.17)^2}{9} + \frac{(2.76)^2}{9}} } = \frac{7.83 - 0}{1.95} = 4.01 
\end{align*}
Because $H_A$ is an upper tail test ( $>$ ), the p-value corresponds to the area to the right of $t=4.01$ with the appropriate degrees of freedom.  Using technology, we find $df=12.2$ and p-value $ = 8.4\times 10^{-4}=0.00084$.  
\item[\inferencestep{Conclude}]  The p-value is much less than 0.05, so we reject the null hypothesis. There is sufficient evidence that embryonic stem cells improve the heart's pumping function in sheep that have suffered a heart attack.

\end{description}

\end{nexample}
\end{examplewrap}


\D{\newpage}


\subsection[Technology: the two-sample $t$-interval and $t$-test for $\mu_1 - \mu_2$]{Technology: the two-sample \pmb{$t$}-interval and \pmb{$t$}-test for \pmb{$\mu_1 - \mu_2$}}
\label{tech2T}

\noindent Use technology to find a 95\% confidence interval for a difference in true average scores between Version A and Version B of the exam, as described in Example~\ref{twoexams}.  Also find the test statistic and p-value for a two-sided test to evaluate whether there is evidence that the true means differ.  Conditions were verified to be met.
\begin{center}
\begin{tabular}{l rrrrr}
\hline
Version\hspace{2mm}	& $n$	& $\bar{x}$	& $s$	& min	& max  \\
\hline
A		& 30		& 79.4		& 14 	& 45		& 100 \\
B		& 30		& 74.1		& 20		& 32		& 100 \\
\hline
\end{tabular}
\end{center}


\noindent \textbf{Desmos}:  Use the \texttt{ttest([data],[data])} or \texttt{ttest(n1, mean1, stdev1, n2, mean1, stdev2)} function as explained below.
\begin{enumerate}
\setlength{\itemsep}{0mm}
\item Click \calctext{+} in the upper left, then choose \calctext{inference}.  
\item Choose \calctext{$t$-test} in the pop-up window.
\begin{center}
\fbox{\Figures[A Desmos calculator screen is shown. The + and inference option are highlighted. ]
{0.3}{technologyInferenceMeans}{desmosInference}}\hspace{10mm}
\fbox{\Figures[A Desmos calculator screen is shown with the inference pop-up box. t-test is highlighted. ]
{0.3}{technologyInferenceMeans}{desmosInferenceTTest}}
\end{center}
\item If you have all the data: under \calctext{SAMPLE 1} enter the first data set separated by commas or copy and paste it in the box, then click on \calctext{SAMPLE 2} and enter the second data set separated by commas or copy and paste it in the box.  
\\If you have the summary statistics: click on \calctext{Stats} and under \calctext{SAMPLE 1}, enter the first group's \calctext{sample size}, \calctext{mean} and \calctext{stdev}, then click on \calctext{SAMPLE 2} and enter the second group's \calctext{sample size}, \calctext{mean} and \calctext{stdev}.  Then click \calctext{Create Test}.  Here we have summary statistics, so we click \calctext{Stats}, enter the relevant values from the table above, then click Create Test.
\begin{center}
\fbox{\Figures[A Desmos calculator screen shows a t-test box. There are empty boxes under SAMPLE 1 and under SAMPLE 2. Data is highlighted. ]
{0.3}{technologyInferenceMeans}{desmos2TData}}\hspace{10mm}
\fbox{\Figures[A Desmos calculator screen shows a t-test box with 30 entered for sample size, 79.4 entered for mean and 14 entered for stdev for SAMPLE 1 and 30 entered for sample size, 74.1 entered for mean and 20 entered for stdev for SAMPLE 2.  Stats is highlighted. ]
{0.3}{technologyInferenceMeans}{desmos2TStats}}
\end{center}\vspace{5mm}
\indent\hspace{-4mm} * You can type \calctext{ttest(30, 79.4, 14, 30, 74.1, 20)} in place of steps 1-3 above.  
\newpage

\item Click the triangle next to \calctext{Confidence Interval} and input the desired \calctext{Confidence level}.  Here we use 0.95, which is entered by default.  Click on \calctext{\vdots } to the right of the confidence interval to see additional information.  You can also hover over the dot in the middle of the confidence interval to see the point estimate.  Find $df$ by clicking Significance Test.
\item Click the triangle next to \calctext{Significance Test}.  Enter the hypothesized difference for the null hypothesis.  Select \calctext{Tails} to be \calctext{Left}, \calctext{Right} or \calctext{Both} depending on the direction of the alternative hypothesis.  Here the hypothesized difference 0 and $H_A$ uses a $\ne$, so we select Tails to be Both.  
\begin{center}
\fbox{\Figures[A Desmos calculator screen is shown.  ttest(30, 79.4, 14, 30, 74.1, 20) is entered with  Confidence level: 0.95.  The cursor is hovering over the dot at the center of the confidence interval showing that the Point estimate is 5.3.  The three vertical dots are also clicked showing Lower bound = -3.64437, Upper bound = 14.2444, Point estimate = 5.3, and Standard error = 4.4572. ]
{0.35}{technologyInferenceMeans}{desmos2TCI}}\hspace{5mm}
\fbox{\Figures[A Desmos calculator screen is shown with ttest(30, 79.4, 14, 30, 74.1, 20).  Significance Test is selected hypothesized difference 0 and Tails set to Both.  The t-statistic is 1.189, the p-value is 0.24, and the df is 51.92.  A t- curve is shown with the area to the left of -1.189 and to the right of 1.189 shaded.]
{0.35}{technologyInferenceMeans}{desmos2TTest}}\\
\end{center}
\end{enumerate}

%%%%%%
\noindent \R{}:   2-sample $t$-interval/test for $\mu_1-\mu_2$

\noindent With all the data, use: \texttt{t.test(data 1, data 2, conf.level =  , alternative = )} \\

\noindent Here we do not have all the data, so we install the BSDA (Basic Statistics and Data Analysis) package.  You only need to enter the first line once on a computer and the second line once per R session.\\
\noindent \texttt{> \calctext{install.packages("BSDA")}}\\
\texttt{> \calctext{library(BSDA)}} \\ 
This allow us to use:\\
 \texttt{tsum.test(mean.x, sd.x, n.x, mean.y, sd.y, n.y, conf.level = , alternative = )}\\

\noindent CONFIDENCE INTERVAL.\\
\noindent \texttt{> \calctext{tsum.test(79.4, 14, 30, 74.1, 20, 30, conf.level = 0.95)}}\\
\texttt{
	Welch Modified Two-Sample t-Test\\
data:  Summarized x and y\\
t = 1.1891, df = 51.918, p-value = 0.2398\\
alternative hypothesis: true difference in means is not equal to 0\\
95 percent confidence interval:\\
\fbox{ -3.644372 14.244372}\\
sample estimates:\\
mean of x mean of y \\
     79.4      74.1\\ }


\noindent HYPOTHESIS TEST.\\
\noindent \texttt{> \calctext{tsum.test(79.4, 14, 30, 74.1, 20, 30, alternative = "two.sided")}}\\
\texttt{	
Welch Modified Two-Sample t-Test\\
data:  Summarized x and y\\
\fbox{t = 1.1891, df = 51.918, p-value = 0.2398}\\
alternative hypothesis: true difference in means is greater than 0\\
95 percent confidence interval:\\
 -2.164646        NA\\
sample estimates:\\
mean of x mean of y \\
     79.4      74.1 \\
}

\noindent Note that \texttt{conf.level = 0.95} and \texttt{alternative = "two.sided"} are the default values if those arguments are omitted.  You can also use \texttt{alternative = "less"} or \texttt{alternative = "greater"} .

\newpage
%%%%
\noindent \textbf{Calculator}:   NumWorks calculator instructions and example output are included.  For the TI-83/84 and Casio calculators, general instructions are provided, and worked example videos can be accessed via the \includegraphics[height=3mm]{extraTeX/icons/video_camera.png} icon or at \oiRedirect{ti84_playlist}{\textbf{openintro.org/ti}} and \oiRedirect{casio-9750-playlist}{\textbf{openintro.org/casio}}.\\


\begin{onebox}{NumWorks: 2-sample T-interval.}
Use \calctext{OK} or \calctext{EXE} to make a selection.
\begin{enumerate}
\setlength{\itemsep}{0mm}
\item From the home screen, select \calcbutton{Inference}, then \calctext{Intervals}, then \calctext{Two means}, then \calctext{t-interval}.  If these options do not appear, click the \calcbutton{$\lhookleftarrow$} button in the upper right as many times as needed. 
\item Choose \calctext{Input statistics} or \calctext{Use a dataset} and enter the needed values.  Then use the down arrow and choose \calcbutton{Next}.
\item Note the quantities returned.  Press the down arrow and choose \calctext{Next}.
\item In addition to seeing the confidence interval displayed in two ways, you can press the up and down arrows to quickly change confidence level and see the resulting interval and margin of error.
\begin{center}
\Figures[ ]
{0.35}{technologyInferenceMeans}{numworks2SampTInterval1}\hspace{10mm}
\Figures[ ]
{0.35}{technologyInferenceMeans}{numworks2SampTInterval2}
\end{center}
\vspace{-1.5mm}
\end{enumerate}
\end{onebox}
%
\begin{onebox}{NumWorks: 2-sample T-test}
\label{normalnumworks}
Use \calctext{OK} or \calctext{EXE} to make a selection.
\begin{enumerate}
\setlength{\itemsep}{0mm}
\item From the home screen, select \calcbutton{Inference}, then \calctext{Tests}, then \calctext{Two means}, then \calctext{t-test}.  If these options do not appear, click the \calcbutton{$\lhookleftarrow$} button in the upper right as many times as needed. 
\item Enter the hypothesized difference for the Null hypothesis.  Usually this will be 0.  Press the down arrow.  Press \calcbutton{OK} and choose \calctext{$<$}, \calctext{$\ne$} , or \calctext{$>$}  for the Alternative hypothesis.  Press the down arrow and choose \calcbutton{Next}. 
\item Choose \calctext{Input statistics} or \calctext{Use a dataset} and enter the needed values.  Then use the down arrow and choose \calcbutton{Next}.
\item Note the quantities returned.  Click the down arrow and choose \calctext{Next}.
\item On this screen, the p-value and alpha are shaded on the t-distribution and can be visually compared.
\begin{center}
\Figures[ ]
{0.35}{technologyInferenceMeans}{numworks2TTest1}\hspace{10mm}
\Figures[ ]
{0.35}{technologyInferenceMeans}{numworks2TTest2}
\end{center}
\vspace{-1.5mm}
\end{enumerate}
\end{onebox}


%%
\begin{onebox}{\videohref{ti84_2_mean_CI} TI-83/84: 2-sample T-interval}
Use \calctext{STAT}, \calctext{TESTS}, \calctext{2-SampTInt}.
\begin{enumerate}
\setlength{\itemsep}{0mm}
\item Choose \calctext{STAT}.
\item Right arrow to \calctext{TESTS}.
\item Down arrow and choose \calctext{0:2-SampTTInt}.
\item Choose \calctext{Data} if you have all the data or \calctext{Stats} if you have the means and standard deviations.\vspace{-1.5mm}
\begin{itemize}
\setlength{\itemsep}{0mm}
\item If you choose Data, let \calctext{List1} be \calctext{L1} or the list that contains sample 1 and let \calctext{List2} be \calctext{L2} or the list that contains sample 2 (don't forget to enter the data!). Let \calctext{Freq1} and \calctext{Freq2} be \calctext{1}.
\item If you choose \calctext{Stats}, enter the mean, SD, and sample size for sample 1 and for sample 2.
\end{itemize}
\item Let \calctext{C-Level} be the desired confidence level and let \calctext{Pooled} be \calctext{No}.
\item Choose \calctext{Calculate} and hit \calcbutton{ENTER}, which returns: \\[1mm]
\begin{tabular}{ll l ll}
\calctext{(\underline{\ \ },\underline{\ \ })} & the confidence interval &\quad&
	\calctext{Sx1} & SD of sample 1 \\
\calctext{df} & degrees of freedom &&
	\calctext{Sx2} & SD of sample 2 \\
$\calctextmath{\bar{x}_1}$ & mean of sample 1 &&
	\calctext{n1} & size of sample 1 \\
$\calctextmath{\bar{x}_2}$ & mean of sample 2 &&
	\calctext{n2} & size of sample 2
\end{tabular}
\end{enumerate}
\end{onebox}
%
\begin{onebox}{\videohref{ti84_2_mean_HT} TI-83/84: 2-sample T-test}
Use \calctext{STAT}, \calctext{TESTS}, \calctext{2-SampTTest}.
\begin{enumerate}
\setlength{\itemsep}{0mm}
\item Choose \calctext{STAT}.
\item Right arrow to \calctext{TESTS}.
\item Choose \calctext{4:2-SampTTest}.
\item Choose \calctext{Data} if you have all the data or \calctext{Stats} if you have the means and standard deviations.\vspace{-1.5mm}
\begin{itemize}
\setlength{\itemsep}{0mm}
\item If you choose \calctext{Data}, let \calctext{List1} be \calctext{L1} or the list that contains sample 1 and let \calctext{List2} be \calctext{L2} or the list that contains sample 2 (don't forget to enter the data!). Let \calctext{Freq1} and \calctext{Freq2} be \calctext{1}.
\item If you choose \calctext{Stats}, enter the mean, SD, and sample size for sample 1 and for sample 2
\end{itemize}
\item Choose $\calctextmath{\ne}$, $\calctextmath{<}$, or $\calctextmath{>}$ to correspond to $H_A$.
\item Let \calctext{Pooled} be \calctext{NO}.
\item Choose \calctext{Calculate} or \calctext{Draw} and hit \calcbutton{ENTER}.  \calctext{Draw} shows the t-statistic and p-value as well as a graph of the t-distribution with p-value shaded.  \calctext{Calculate} returns:  \\[1mm]
\begin{tabular}{ll l ll}
\calctext{t} & T-statistic &\quad&
	\calctext{Sx1} & SD of sample 1 \\
\calctext{p} & p-value &&
	\calctext{Sx2} & SD of sample 2 \\
\calctext{df} & degrees of freedom &&
	\calctext{n1} & size of sample 1 \\
$\calctextmath{\bar{x}_1}$ & mean of sample 1 &&
	n2 & size of sample 2 \\
$\calctextmath{\bar{x}_2}$ & mean of sample 2
\end{tabular}
\end{enumerate}
\end{onebox}

%%
\begin{onebox}{\videohref{casio_2_mean_inference} Casio fx-9750GII: 2-sample T-interval}
\ \vspace{-5mm} \
\begin{enumerate}
\setlength{\itemsep}{0mm}
\item Navigate to \calctext{STAT} (\calcbutton{MENU} button, then hit the \calcbutton{2} button or select \calctext{STAT}).
\item If necessary, enter the data into a list.
\item Choose the \calctext{INTR} option (\calcbutton{F4} button).
\item Choose the \calctext{t} option (\calcbutton{F2} button).
\item Choose the \calctext{2-S} option (\calcbutton{F2} button).
\item Choose either the \calctext{Var} option (\calcbutton{F2}) or enter the data in using the \calctext{List} option.
\item Specify the test details:
  \begin{itemize}
  \setlength{\itemsep}{0mm}
  \item Confidence level of interest for \calctext{C-Level}.
  \item If using the \calctext{Var} option, enter the summary statistics for each group. If using \calctext{List}, specify the lists and leave \calctext{Freq} values at \calctext{1}.
  \item Choose whether to pool the data or not.
  \end{itemize}
\item Hit the \calcbutton{EXE} button, which returns \\[1mm]
\begin{tabular}{ll}
  \calctext{Left}, \calctext{Right} & ends of the confidence interval \\
  \calctext{df} & degrees of freedom \\
  $\calctextmath{\bar{x}1}$, $\calctextmath{\bar{x}2}$ & sample means \\
  \calctext{sx1}, \calctext{sx2} & sample standard deviations \\
  \calctext{n1}, \calctext{n2} & sample sizes
\end{tabular}
\end{enumerate}
\end{onebox}
%
\begin{onebox}{\videohref{casio_2_mean_inference} Casio fx-9750GII: 2-sample T-test}
\ \vspace{-5mm} \
\begin{enumerate}
\setlength{\itemsep}{0mm}
\item Navigate to \calctext{STAT} (\calcbutton{MENU} button, then hit the \calcbutton{2} button or select \calctext{STAT}).
\item If necessary, enter the data into a list.
\item Choose the \calctext{TEST} option (\calcbutton{F3} button).
\item Choose the \calctext{t} option (\calcbutton{F2} button).
\item Choose the \calctext{2-S} option (\calcbutton{F2} button).
\item Choose either the \calctext{Var} option (\calcbutton{F2}) or enter the data in using the \calctext{List} option.
\item Specify the test details:
  \begin{itemize}
  \setlength{\itemsep}{0mm}
  \item Specify the sidedness of the test using the \calcbutton{F1}, \calcbutton{F2}, and \calcbutton{F3} keys.
  \item If using the \calctext{Var} option, enter the summary statistics for each group. If using \calctext{List}, specify the lists and leave \calctext{Freq} values at \calctext{1}.
  \item Choose whether to pool the data or not.
  \end{itemize}
\item Hit the \calcbutton{EXE} button, which returns \\[1mm]
\begin{tabular}{ll l ll}
$\calctextmath{\mu1}\ \_\_\ \calctextmath{\mu2}$ & alt. hypothesis &&
	$\calctextmath{\bar{x}1}$, $\calctextmath{\bar{x}2}$ & sample means \\
\calctext{t} & T-statistic &&
	\calctext{sx1}, \calctext{sx2} & sample standard deviations \\
\calctext{p} & p-value &&
	\calctext{n1}, \calctext{n2} & sample sizes \\
\calctext{df} & degrees of freedom
\end{tabular}
\end{enumerate}
\end{onebox}

\D{\newpage}

%%
\subsection*{Section summary}
\begin{itemize} 

\item The appropriate hypothesis testing procedure for a difference between two population means $\mu_1$ and $\mu_2$ is a two-sample $t$-test for $\mu_1-\mu_2$.  The parameters $\mu_1$ and $\mu_2$ should be identified in context.


\item The null hypotheses for a two-sample $t$-test for a difference in population means indicates no difference and is written as:  
\begin{itemize}
\setlength{\itemindent}{3mm}
\item[$H_0$:] $\mu_1=\mu_2$ (or equivalently $H_0$: $\mu_1-\mu_2 = 0$).  
\end{itemize}
\item A one-sided alternative hypothesis is written as: 
\begin{itemize}
\setlength{\itemindent}{3mm}
\item[$H_A$:] $\mu_1<\mu_2$ (or equivalently $H_A$: $\mu_1-\mu_2<0$), or
\item[$H_A$:] $\mu_1>\mu_2$ (or equivalently $H_A$: $\mu_1-\mu_2>0$).
\end{itemize}

\item[] A two-sided alternative hypothesis is written as: 
\begin{itemize}
\setlength{\itemindent}{3mm}
\item[$H_A$:] $\mu_1\ne \mu_2$ (or equivalently $H_A$: $\mu_1-\mu_2\ne 0$).
\end{itemize}



\item The null hypotheses for a two-sample $t$-test for a difference in population means can be written as:  $H_0$: $\mu_1 = \mu_2$ or $H_0$: $\mu_1-\mu_2=0$.  The one-sided alternative hypothesis is: $H_A$: $\mu_1<\mu_2$ (or equivalently $H_A$: $\mu_1-\mu_2<0$) or $H_A$: $\mu_1>\mu_2$ (or equivalently $H_A$: $\mu_1-\mu_2>0$).  The two-sided alternative hypothesis is: $H_A$: $\mu\ne \mu_0$ (or equivalently  $H_A$: $\mu_1-\mu_2 \ne 0$).

\item The two-sample $t$-test for a difference in population means has the same conditions as the two-sample $t$-interval for a difference in population means.  
\begin{itemize}
\item[1.] Independence:  The data come from two independent random samples, each with sample size $<10\%$ of its corresponding population size if sampling without replacement OR the data come from a randomized experiment with two randomly assigned treatments.
\item[2.] Large sample or normal population: both sample sizes are at least 30 or population distributions are nearly normal.  If either sample size is less than 30 and the population distributions are unknown, check and confirm that there is no strong skew or outliers in either data set in order to reasonably assume that the population distributions are nearly normal.
\end{itemize}

\item A test statistic has the form: 
\begin{center}
\text{test statistic} = $\frac{\text{point estimate } - \text{ null value}}{SE \text{ of estimate}}$ .  
\end{center}
\item The test statistic for a two-sample $t$-test for $\mu_1-\mu_2$ is:
\begin{center}
$T = \frac{(\bar{x}_1 - \bar{x}_2) - 0}{\sqrt{\frac{s^2_1}{n_1}+\frac{s^2_2}{n_2}}}$, \ $df$: use technology
\end{center}
When the null hypothesis is true, the test statistics has a $t$-distribution with degrees of freedom that can be calculated using technology.  The degrees of freedom fall between $n_1 + n_2 - 2$ and the smaller of $n_1-1$ and $n_2-1$.

\item The p-value of a $t$-test corresponds to a lower tail, upper tail, or both tails of the $t$-distribution with the appropriate degrees of freedom, depending on whether the direction of the alternate hypothesis is $<$, $>$, or $\ne$.

\item The p-value for a two-sample $t$-test for $\mu_1-\mu_2$ is the probability of obtaining $t$-statistic as small or smaller, as large or larger, or as extreme or more extreme than the $t$-statistic that was observed, depending on whether the direction of the alternative hypothesis is $<$, $>$, or $\ne$, assuming the null hypothesis is true (i.e. that the population means are equal to each other).  

\item A formal decision explicitly compares the p-value to the significance level.  If the \mbox{p-value $\le \alpha$,} then reject the null hypothesis; if the p-value $> \alpha$, then fail to reject the null hypothesis.  The conclusion should be stated in terms of the alternative hypothesis and should include context, referencing the parameters and the populations.  Use non-causal language unless a well-designed experiment was conducted.


\end{itemize}


%%%%%Section exercises
{\input{ch_inference_for_means/TeX/hypothesis_testing_for_a_difference_in_population_means.tex}}

%______________________________________________
\reviewchapterheader{}

\noindent We've reviewed a wide set of inference procedures over the last 2 chapters. Let's revisit each and discuss the similarities and differences among them.  The following confidence intervals and tests are structurally the same -- they all involve inference for a population parameter, where that parameter is a proportion, a difference of proportions, a mean, a mean of differences, or a difference of means. \vspace{-1mm}
\begin{itemize}
\setlength{\itemsep}{0mm}
\item one-sample $z$-test/interval for $p$
\item two-sample $z$-test/interval for $p_1 - p_2$
\item one-sample $t$-test/interval for $\mu$ or $\mu_d$
\item two-sample $t$-test/interval for $\mu_1 - \mu_2$
\end{itemize}
The above inferential procedures all involve a \textbf{point estimate}, a \textbf{standard error} of the estimate, and an assumption about the \textbf{shape of the sampling distribution} for the point estimate.
\\ 
\\ 
In Chapter~\ref{inferenceForCategoricalData}, we were also introduced to two $\chi^2$ tests for two-way tables:\vspace{-1mm}
\begin{itemize}
\setlength{\itemsep}{0mm}
\item $\chi^2$ test for homogeneity:  compares a categorical variable across multiple groups.
\item $\chi^2$ test for independence:  looks for association between two categorical variables. 
\end{itemize}
$\chi^2$ is a measure of \emph{overall} deviation between observed values and expected values, relative to expected values.  These tests stand apart from the other tests because when using $\chi^2$ there is not a parameter of interest.  For this reason there are no confidence intervals using $\chi^2$.  Also, for $\chi^2$ tests, the hypotheses are usually written in words, because they are not about a single parameter.  
\\
\\
While formulas and conditions vary, all of these procedures follow the same basic logic and process.
\begin{itemize}\vspace{-1mm}
\setlength{\itemsep}{0mm}
\item Identify the appropriate procedure and the parameter of interest (if applicable).  For a confidence interval, also identify the confidence level; for a hypothesis test, identify the significance level and the hypotheses to be tested.
\item Check that all conditions for the procedure are met.
\item Calculate the confidence interval or the test statistic and p-value, as well as the $df$ if applicable.
\item Conclude by interpreting the results in context and drawing a conclusion based on the data.
\end{itemize}
For a summary of these hypothesis test and confidence interval procedures, see the Inference Guide in Appendix~\ref{inferenceGuide}.
